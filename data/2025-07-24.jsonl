{"id": "2507.16922", "pdf": "https://arxiv.org/pdf/2507.16922.pdf", "abs": "https://arxiv.org/abs/2507.16922", "title": "A Unifying Scheme for Extractive Content Selection Tasks", "authors": ["Shmuel Amar", "Ori Shapira", "Aviv Slobodkin", "Ido Dagan"], "categories": ["cs.CL"], "comment": null, "summary": "A broad range of NLP tasks involve selecting relevant text spans from given\nsource texts. Despite this shared objective, such \\textit{content selection}\ntasks have traditionally been studied in isolation, each with its own modeling\napproaches, datasets, and evaluation metrics. In this work, we propose\n\\textit{instruction-guided content selection (IGCS)} as a beneficial unified\nframework for such settings, where the task definition and any\ninstance-specific request are encapsulated as instructions to a language model.\nTo promote this framework, we introduce \\igcsbench{}, the first unified\nbenchmark covering diverse content selection tasks. Further, we create a large\ngeneric synthetic dataset that can be leveraged for diverse content selection\ntasks, and show that transfer learning with these datasets often boosts\nperformance, whether dedicated training for the targeted task is available or\nnot. Finally, we address generic inference time issues that arise in LLM-based\nmodeling of content selection, assess a generic evaluation metric, and overall\npropose the utility of our resources and methods for future content selection\nmodels. Models and datasets available at https://github.com/shmuelamar/igcs."}
{"id": "2507.16947", "pdf": "https://arxiv.org/pdf/2507.16947.pdf", "abs": "https://arxiv.org/abs/2507.16947", "title": "AI-based Clinical Decision Support for Primary Care: A Real-World Study", "authors": ["Robert Korom", "Sarah Kiptinness", "Najib Adan", "Kassim Said", "Catherine Ithuli", "Oliver Rotich", "Boniface Kimani", "Irene King'ori", "Stellah Kamau", "Elizabeth Atemba", "Muna Aden", "Preston Bowman", "Michael Sharman", "Rebecca Soskin Hicks", "Rebecca Distler", "Johannes Heidecke", "Rahul K. Arora", "Karan Singhal"], "categories": ["cs.CL"], "comment": "Blog: https://openai.com/index/ai-clinical-copilot-penda-health/", "summary": "We evaluate the impact of large language model-based clinical decision\nsupport in live care. In partnership with Penda Health, a network of primary\ncare clinics in Nairobi, Kenya, we studied AI Consult, a tool that serves as a\nsafety net for clinicians by identifying potential documentation and clinical\ndecision-making errors. AI Consult integrates into clinician workflows,\nactivating only when needed and preserving clinician autonomy. We conducted a\nquality improvement study, comparing outcomes for 39,849 patient visits\nperformed by clinicians with or without access to AI Consult across 15 clinics.\nVisits were rated by independent physicians to identify clinical errors.\nClinicians with access to AI Consult made relatively fewer errors: 16% fewer\ndiagnostic errors and 13% fewer treatment errors. In absolute terms, the\nintroduction of AI Consult would avert diagnostic errors in 22,000 visits and\ntreatment errors in 29,000 visits annually at Penda alone. In a survey of\nclinicians with AI Consult, all clinicians said that AI Consult improved the\nquality of care they delivered, with 75% saying the effect was \"substantial\".\nThese results required a clinical workflow-aligned AI Consult implementation\nand active deployment to encourage clinician uptake. We hope this study\ndemonstrates the potential for LLM-based clinical decision support tools to\nreduce errors in real-world settings and provides a practical framework for\nadvancing responsible adoption."}
{"id": "2507.16951", "pdf": "https://arxiv.org/pdf/2507.16951.pdf", "abs": "https://arxiv.org/abs/2507.16951", "title": "Harnessing RLHF for Robust Unanswerability Recognition and Trustworthy Response Generation in LLMs", "authors": ["Shuyuan Lin", "Lei Duan", "Philip Hughes", "Yuxuan Sheng"], "categories": ["cs.CL"], "comment": null, "summary": "Conversational Information Retrieval (CIR) systems, while offering intuitive\naccess to information, face a significant challenge: reliably handling\nunanswerable questions to prevent the generation of misleading or hallucinated\ncontent. Traditional approaches often rely on external classifiers, which can\nintroduce inconsistencies with the core generative Large Language Models\n(LLMs). This paper introduces Self-Aware LLM for Unanswerability (SALU), a\nnovel approach that deeply integrates unanswerability detection directly within\nthe LLM's generative process. SALU is trained using a multi-task learning\nframework for both standard Question Answering (QA) and explicit abstention\ngeneration for unanswerable queries. Crucially, it incorporates a\nconfidence-score-guided reinforcement learning with human feedback (RLHF)\nphase, which explicitly penalizes hallucinated responses and rewards\nappropriate abstentions, fostering intrinsic self-awareness of knowledge\nboundaries. Through extensive experiments on our custom-built\nC-IR_Answerability dataset, SALU consistently outperforms strong baselines,\nincluding hybrid LLM-classifier systems, in overall accuracy for correctly\nanswering or abstaining from questions. Human evaluation further confirms\nSALU's superior reliability, achieving high scores in factuality, appropriate\nabstention, and, most importantly, a dramatic reduction in hallucination,\ndemonstrating its ability to robustly \"know when to say 'I don't know'.\""}
{"id": "2507.16971", "pdf": "https://arxiv.org/pdf/2507.16971.pdf", "abs": "https://arxiv.org/abs/2507.16971", "title": "Text-to-SPARQL Goes Beyond English: Multilingual Question Answering Over Knowledge Graphs through Human-Inspired Reasoning", "authors": ["Aleksandr Perevalov", "Andreas Both"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "During the final evaluation on the DBpedia- and Corporate-based KGQA\n  benchmarks within the Text2SPARQL challenge 2025, our approach took first\n  place among the other participants", "summary": "Accessing knowledge via multilingual natural-language interfaces is one of\nthe emerging challenges in the field of information retrieval and related ones.\nStructured knowledge stored in knowledge graphs can be queried via a specific\nquery language (e.g., SPARQL). Therefore, one needs to transform\nnatural-language input into a query to fulfill an information need. Prior\napproaches mostly focused on combining components (e.g., rule-based or\nneural-based) that solve downstream tasks and come up with an answer at the\nend. We introduce mKGQAgent, a human-inspired framework that breaks down the\ntask of converting natural language questions into SPARQL queries into modular,\ninterpretable subtasks. By leveraging a coordinated LLM agent workflow for\nplanning, entity linking, and query refinement - guided by an experience pool\nfor in-context learning - mKGQAgent efficiently handles multilingual KGQA.\nEvaluated on the DBpedia- and Corporate-based KGQA benchmarks within the\nText2SPARQL challenge 2025, our approach took first place among the other\nparticipants. This work opens new avenues for developing human-like reasoning\nsystems in multilingual semantic parsing."}
{"id": "2507.16819", "pdf": "https://arxiv.org/pdf/2507.16819.pdf", "abs": "https://arxiv.org/abs/2507.16819", "title": "Assessing Medical Training Skills via Eye and Head Movements", "authors": ["Kayhan Latifzadeh", "Luis A. Leiva", "Klen Čopič Pucihar", "Matjaž Kljun", "Iztok Devetak", "Lili Steblovnik"], "categories": ["cs.HC", "cs.CV"], "comment": null, "summary": "We examined eye and head movements to gain insights into skill development in\nclinical settings. A total of 24 practitioners participated in simulated baby\ndelivery training sessions. We calculated key metrics, including pupillary\nresponse rate, fixation duration, or angular velocity. Our findings indicate\nthat eye and head tracking can effectively differentiate between trained and\nuntrained practitioners, particularly during labor tasks. For example,\nhead-related features achieved an F1 score of 0.85 and AUC of 0.86, whereas\npupil-related features achieved F1 score of 0.77 and AUC of 0.85. The results\nlay the groundwork for computational models that support implicit skill\nassessment and training in clinical settings by using commodity eye-tracking\nglasses as a complementary device to more traditional evaluation methods such\nas subjective scores."}
{"id": "2507.16974", "pdf": "https://arxiv.org/pdf/2507.16974.pdf", "abs": "https://arxiv.org/abs/2507.16974", "title": "Leveraging Synthetic Data for Question Answering with Multilingual LLMs in the Agricultural Domain", "authors": ["Rishemjit Kaur", "Arshdeep Singh Bhankhar", "Surangika Ranathunga", "Jashanpreet Singh Salh", "Sudhir Rajput", "Vidhi", "Kashish Mahendra", "Bhavika Berwal", "Ritesh Kumar"], "categories": ["cs.CL", "cs.AI", "I.2.7; J.m"], "comment": "15 pages, 9 tables, Appendix A-K", "summary": "Enabling farmers to access accurate agriculture-related information in their\nnative languages in a timely manner is crucial for the success of the\nagriculture field. Although large language models (LLMs) can be used to\nimplement Question Answering (QA) systems, simply using publicly available\ngeneral-purpose LLMs in agriculture typically offer generic advisories, lacking\nprecision in local and multilingual contexts due to insufficient\ndomain-specific training and scarcity of high-quality, region-specific\ndatasets. Our study addresses these limitations by generating multilingual\nsynthetic agricultural datasets (English, Hindi, Punjabi) from\nagriculture-specific documents and fine-tuning language-specific LLMs. Our\nevaluation on curated multilingual datasets demonstrates significant\nimprovements in factual accuracy, relevance, and agricultural consensus for the\nfine-tuned models compared to their baseline counterparts. These results\nhighlight the efficacy of synthetic data-driven, language-specific fine-tuning\nas an effective strategy to improve the performance of LLMs in agriculture,\nespecially in multilingual and low-resource settings. By enabling more accurate\nand localized agricultural advisory services, this study provides a meaningful\nstep toward bridging the knowledge gap in AI-driven agricultural solutions for\ndiverse linguistic communities."}
{"id": "2507.17024", "pdf": "https://arxiv.org/pdf/2507.17024.pdf", "abs": "https://arxiv.org/abs/2507.17024", "title": "Write, Rank, or Rate: Comparing Methods for Studying Visualization Affordances", "authors": ["Chase Stokes", "Kylie Lin", "Cindy Xiong Bearfield"], "categories": ["cs.HC", "H.5.0"], "comment": "11 pages, 8 figures, accepted to IEEE VIS", "summary": "A growing body of work on visualization affordances highlights how specific\ndesign choices shape reader takeaways from information visualizations. However,\nmapping the relationship between design choices and reader conclusions often\nrequires labor-intensive crowdsourced studies, generating large corpora of\nfree-response text for analysis. To address this challenge, we explored\nalternative scalable research methodologies to assess chart affordances. We\ntest four elicitation methods from human-subject studies: free response,\nvisualization ranking, conclusion ranking, and salience rating, and compare\ntheir effectiveness in eliciting reader interpretations of line charts, dot\nplots, and heatmaps. Overall, we find that while no method fully replicates\naffordances observed in free-response conclusions, combinations of ranking and\nrating methods can serve as an effective proxy at a broad scale. The two\nranking methodologies were influenced by participant bias towards certain chart\ntypes and the comparison of suggested conclusions. Rating conclusion salience\ncould not capture the specific variations between chart types observed in the\nother methods. To supplement this work, we present a case study with GPT-4o,\nexploring the use of large language models (LLMs) to elicit human-like chart\ninterpretations. This aligns with recent academic interest in leveraging LLMs\nas proxies for human participants to improve data collection and analysis\nefficiency. GPT-4o performed best as a human proxy for the salience rating\nmethodology but suffered from severe constraints in other areas. Overall, the\ndiscrepancies in affordances we found between various elicitation\nmethodologies, including GPT-4o, highlight the importance of intentionally\nselecting and combining methods and evaluating trade-offs."}
{"id": "2507.16989", "pdf": "https://arxiv.org/pdf/2507.16989.pdf", "abs": "https://arxiv.org/abs/2507.16989", "title": "Obscured but Not Erased: Evaluating Nationality Bias in LLMs via Name-Based Bias Benchmarks", "authors": ["Giulio Pelosio", "Devesh Batra", "Noémie Bovey", "Robert Hankache", "Cristovao Iglesias", "Greig Cowan", "Raad Khraishi"], "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) can exhibit latent biases towards specific\nnationalities even when explicit demographic markers are not present. In this\nwork, we introduce a novel name-based benchmarking approach derived from the\nBias Benchmark for QA (BBQ) dataset to investigate the impact of substituting\nexplicit nationality labels with culturally indicative names, a scenario more\nreflective of real-world LLM applications. Our novel approach examines how this\nsubstitution affects both bias magnitude and accuracy across a spectrum of LLMs\nfrom industry leaders such as OpenAI, Google, and Anthropic. Our experiments\nshow that small models are less accurate and exhibit more bias compared to\ntheir larger counterparts. For instance, on our name-based dataset and in the\nambiguous context (where the correct choice is not revealed), Claude Haiku\nexhibited the worst stereotypical bias scores of 9%, compared to only 3.5% for\nits larger counterpart, Claude Sonnet, where the latter also outperformed it by\n117.7% in accuracy. Additionally, we find that small models retain a larger\nportion of existing errors in these ambiguous contexts. For example, after\nsubstituting names for explicit nationality references, GPT-4o retains 68% of\nthe error rate versus 76% for GPT-4o-mini, with similar findings for other\nmodel providers, in the ambiguous context. Our research highlights the stubborn\nresilience of biases in LLMs, underscoring their profound implications for the\ndevelopment and deployment of AI systems in diverse, global contexts."}
{"id": "2507.17139", "pdf": "https://arxiv.org/pdf/2507.17139.pdf", "abs": "https://arxiv.org/abs/2507.17139", "title": "Evaluation of the effects of frame time variation on VR task performance", "authors": ["Benjamin Watson", "Victoria Spaulding", "Neff Walker", "William Ribarsky"], "categories": ["cs.HC", "cs.ET"], "comment": null, "summary": "We present a first study of the effects of frame time variations, in both\ndeviation around mean frame times and period of fluctuation, on task\nperformance in a virtual environment (VE). Chosen are open and closed loop\ntasks that are typical for current applications or likely to be prominent in\nfuture ones. The results show that at frame times in the range deemed\nacceptable for many applications, fairly large deviations in amplitude over a\nfairly wide range of periods do not significantly affect task performance.\nHowever, at a frame time often considered a minimum for immersive VR, frame\ntime variations do produce significant effects on closed loop task performance.\nThe results will be of use to designers of VEs and immersive applications, who\noften must control frame time variations due to large fluctuations of\ncomplexity (graphical and otherwise) in the VE."}
{"id": "2507.17009", "pdf": "https://arxiv.org/pdf/2507.17009.pdf", "abs": "https://arxiv.org/abs/2507.17009", "title": "Multi-Label Classification with Generative AI Models in Healthcare: A Case Study of Suicidality and Risk Factors", "authors": ["Ming Huang", "Zehan Li", "Yan Hu", "Wanjing Wang", "Andrew Wen", "Scott Lane", "Salih Selek", "Lokesh Shahani", "Rodrigo Machado-Vieira", "Jair Soares", "Hua Xu", "Hongfang Liu"], "categories": ["cs.CL", "cs.IR", "q-bio.QM"], "comment": null, "summary": "Suicide remains a pressing global health crisis, with over 720,000 deaths\nannually and millions more affected by suicide ideation (SI) and suicide\nattempts (SA). Early identification of suicidality-related factors (SrFs),\nincluding SI, SA, exposure to suicide (ES), and non-suicidal self-injury\n(NSSI), is critical for timely intervention. While prior studies have applied\nAI to detect SrFs in clinical notes, most treat suicidality as a binary\nclassification task, overlooking the complexity of cooccurring risk factors.\nThis study explores the use of generative large language models (LLMs),\nspecifically GPT-3.5 and GPT-4.5, for multi-label classification (MLC) of SrFs\nfrom psychiatric electronic health records (EHRs). We present a novel end to\nend generative MLC pipeline and introduce advanced evaluation methods,\nincluding label set level metrics and a multilabel confusion matrix for error\nanalysis. Finetuned GPT-3.5 achieved top performance with 0.94 partial match\naccuracy and 0.91 F1 score, while GPT-4.5 with guided prompting showed superior\nperformance across label sets, including rare or minority label sets,\nindicating a more balanced and robust performance. Our findings reveal\nsystematic error patterns, such as the conflation of SI and SA, and highlight\nthe models tendency toward cautious over labeling. This work not only\ndemonstrates the feasibility of using generative AI for complex clinical\nclassification tasks but also provides a blueprint for structuring unstructured\nEHR data to support large scale clinical research and evidence based medicine."}
{"id": "2507.17209", "pdf": "https://arxiv.org/pdf/2507.17209.pdf", "abs": "https://arxiv.org/abs/2507.17209", "title": "HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery", "authors": ["Haoran Jiang", "Shaohan Shi", "Yunjie Yao", "Chang Jiang", "Quan Li"], "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Modern scientific discovery faces growing challenges in integrating vast and\nheterogeneous knowledge critical to breakthroughs in biomedicine and drug\ndevelopment. Traditional hypothesis-driven research, though effective, is\nconstrained by human cognitive limits, the complexity of biological systems,\nand the high cost of trial-and-error experimentation. Deep learning models,\nespecially graph neural networks (GNNs), have accelerated prediction\ngeneration, but the sheer volume of outputs makes manual selection for\nvalidation unscalable. Large language models (LLMs) offer promise in filtering\nand hypothesis generation, yet suffer from hallucinations and lack grounding in\nstructured knowledge, limiting their reliability. To address these issues, we\npropose HypoChainer, a collaborative visualization framework that integrates\nhuman expertise, LLM-driven reasoning, and knowledge graphs (KGs) to enhance\nhypothesis generation and validation. HypoChainer operates in three stages:\nFirst, exploration and contextualization -- experts use retrieval-augmented\nLLMs (RAGs) and dimensionality reduction to navigate large-scale GNN\npredictions, assisted by interactive explanations. Second, hypothesis chain\nformation -- experts iteratively examine KG relationships around predictions\nand semantically linked entities, refining hypotheses with LLM and KG\nsuggestions. Third, validation prioritization -- refined hypotheses are\nfiltered based on KG-supported evidence to identify high-priority candidates\nfor experimentation, with visual analytics further strengthening weak links in\nreasoning. We demonstrate HypoChainer's effectiveness through case studies in\ntwo domains and expert interviews, highlighting its potential to support\ninterpretable, scalable, and knowledge-grounded scientific discovery."}
{"id": "2507.17015", "pdf": "https://arxiv.org/pdf/2507.17015.pdf", "abs": "https://arxiv.org/abs/2507.17015", "title": "Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?", "authors": ["Arduin Findeis", "Floris Weers", "Guoli Yin", "Ke Ye", "Ruoming Pang", "Tom Gunter"], "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at ACL 2025", "summary": "Pairwise preferences over model responses are widely collected to evaluate\nand provide feedback to large language models (LLMs). Given two alternative\nmodel responses to the same input, a human or AI annotator selects the \"better\"\nresponse. This approach can provide feedback for domains where other hard-coded\nmetrics are difficult to obtain (e.g., chat response quality), thereby helping\nmodel evaluation or training. However, for some domains high-quality pairwise\ncomparisons can be tricky to obtain - from AI and humans. For example, for\nresponses with many factual statements, annotators may disproportionately weigh\nwriting quality rather than underlying facts. In this work, we explore\naugmenting standard AI annotator systems with additional tools to improve\nperformance on three challenging response domains: long-form factual, math and\ncode tasks. We propose a tool-using agentic system to provide higher quality\nfeedback on these domains. Our system uses web-search and code execution to\nground itself based on external validation, independent of the LLM's internal\nknowledge and biases. We provide extensive experimental results evaluating our\nmethod across the three targeted response domains as well as general annotation\ntasks, using RewardBench (incl. AlpacaEval and LLMBar), RewardMath, as well as\nthree new datasets for domains with saturated pre-existing datasets. Our\nresults indicate that external tools can indeed improve performance in many,\nbut not all, cases. More generally, our experiments highlight the sensitivity\nof performance to simple parameters (e.g., prompt) and the need for improved\n(non-saturated) annotator benchmarks. We share our code at\nhttps://github.com/apple/ml-agent-evaluator."}
{"id": "2507.17218", "pdf": "https://arxiv.org/pdf/2507.17218.pdf", "abs": "https://arxiv.org/abs/2507.17218", "title": "OceanVive: An Immersive Visualization System for Communicating Complex Oceanic Phenomena", "authors": ["Yang Ouyang", "Yuchen Wu", "Xiyuan Wang", "Laixin Xie", "Weicong Cheng", "Jianping Gan", "Quan Li", "Xiaojuan Ma"], "categories": ["cs.HC"], "comment": "To appear at the IEEE VIS Conference 2025", "summary": "Communicating the complexity of oceanic phenomena-such as hypoxia and\nacidification-poses a persistent challenge for marine science. Despite advances\nin sensing technologies and computational models, conventional formats like\nstatic visualizations and text-based reports often fall short in conveying the\ndynamics of ocean changes. To address this gap, we present OceanVive, an\nimmersive and interactive visualization system that transforms complex ocean\ndatasets into navigable spatial narratives. OceanVive incorporates an\nexploratory panel on a table-sized tablet for managing immersive content on a\nlarge screen and integrates adaptive visual encodings, contextual storytelling,\nand intuitive navigation pathways to support effective communication. We\nvalidate the system through expert interviews, demonstrating its potential to\nenhance science communication and promote deeper public understanding."}
{"id": "2507.17025", "pdf": "https://arxiv.org/pdf/2507.17025.pdf", "abs": "https://arxiv.org/abs/2507.17025", "title": "Evolutionary Feature-wise Thresholding for Binary Representation of NLP Embeddings", "authors": ["Soumen Sinha", "Shahryar Rahnamayan", "Azam Asilian Bidgoli"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Efficient text embedding is crucial for large-scale natural language\nprocessing (NLP) applications, where storage and computational efficiency are\nkey concerns. In this paper, we explore how using binary representations\n(barcodes) instead of real-valued features can be used for NLP embeddings\nderived from machine learning models such as BERT. Thresholding is a common\nmethod for converting continuous embeddings into binary representations, often\nusing a fixed threshold across all features. We propose a Coordinate\nSearch-based optimization framework that instead identifies the optimal\nthreshold for each feature, demonstrating that feature-specific thresholds lead\nto improved performance in binary encoding. This ensures that the binary\nrepresentations are both accurate and efficient, enhancing performance across\nvarious features. Our optimal barcode representations have shown promising\nresults in various NLP applications, demonstrating their potential to transform\ntext representation. We conducted extensive experiments and statistical tests\non different NLP tasks and datasets to evaluate our approach and compare it to\nother thresholding methods. Binary embeddings generated using using optimal\nthresholds found by our method outperform traditional binarization methods in\naccuracy. This technique for generating binary representations is versatile and\ncan be applied to any features, not just limited to NLP embeddings, making it\nuseful for a wide range of domains in machine learning applications."}
{"id": "2507.17226", "pdf": "https://arxiv.org/pdf/2507.17226.pdf", "abs": "https://arxiv.org/abs/2507.17226", "title": "A \"watch your replay videos\" reflection assignment on comparing programming without versus with generative AI: learning about programming, critical AI use and limitations, and reflection", "authors": ["Sarah \"Magz\" Fernandez", "Greg L Nelson"], "categories": ["cs.HC", "K.3"], "comment": null, "summary": "Generative AI is disrupting computing education. Most interventions focus on\nteaching GenAI use rather than helping students understand how AI changes their\nprogramming process. We designed and deployed a novel comparative video\nreflection assignment adapting the Describe, Examine, then Articulate Learning\n(DEAL) framework. In an introductory software engineering course, students\nrecorded themselves programming during their team project two times: first\nwithout, then with using generative AI. Students then analyzed their own videos\nusing a scaffolded set of reflection questions, including on their programming\nprocess and human, internet, and AI help-seeking. We conducted a qualitative\nthematic analysis of the reflections, finding students developed insights about\nplanning, debugging, and help-seeking behaviors that transcended AI use.\nStudents reported learning to slow down and understand before writing or\ngenerating code, recognized patterns in their problem-solving approaches, and\narticulated specific process improvements. Students also learned and reflected\non AI limits and downsides, and strategies to use AI more critically, including\nbetter prompting but also to benefit their learning instead of just completing\ntasks. Unexpectedly, the comparative reflection also scaffolded reflection on\nprogramming not involving AI use, and even led to students spontaneously\nsetting future goals to adopt video and other regular reflection. This work\ndemonstrates structured reflection on programming session videos can develop\nmetacognitive skills essential for programming with and without generative AI\nand also lifelong learning in our evolving field."}
{"id": "2507.17147", "pdf": "https://arxiv.org/pdf/2507.17147.pdf", "abs": "https://arxiv.org/abs/2507.17147", "title": "CogDual: Enhancing Dual Cognition of LLMs via Reinforcement Learning with Implicit Rule-Based Rewards", "authors": ["Cheng Liu", "Yifei Lu", "Fanghua Ye", "Jian Li", "Xingyu Chen", "Feiliang Ren", "Zhaopeng Tu", "Xiaolong Li"], "categories": ["cs.CL"], "comment": null, "summary": "Role-Playing Language Agents (RPLAs) have emerged as a significant\napplication direction for Large Language Models (LLMs). Existing approaches\ntypically rely on prompt engineering or supervised fine-tuning to enable models\nto imitate character behaviors in specific scenarios, but often neglect the\nunderlying \\emph{cognitive} mechanisms driving these behaviors. Inspired by\ncognitive psychology, we introduce \\textbf{CogDual}, a novel RPLA adopting a\n\\textit{cognize-then-respond } reasoning paradigm. By jointly modeling external\nsituational awareness and internal self-awareness, CogDual generates responses\nwith improved character consistency and contextual alignment. To further\noptimize the performance, we employ reinforcement learning with two\ngeneral-purpose reward schemes designed for open-domain text generation.\nExtensive experiments on the CoSER benchmark, as well as Cross-MR and\nLifeChoice, demonstrate that CogDual consistently outperforms existing\nbaselines and generalizes effectively across diverse role-playing tasks."}
{"id": "2507.17230", "pdf": "https://arxiv.org/pdf/2507.17230.pdf", "abs": "https://arxiv.org/abs/2507.17230", "title": "Designing for Learning with Generative AI is a Wicked Problem: An Illustrative Longitudinal Qualitative Case Series", "authors": ["Clara Scalzer", "Saurav Pokhrel", "Sara Hunt", "Greg L Nelson"], "categories": ["cs.HC", "K.3"], "comment": null, "summary": "Students continue their education when they feel their learning is meaningful\nand relevant for their future careers. Computing educators now face the\nchallenge of preparing students for careers increasingly shaped by generative\nAI (GenAI) with the goals of supporting their learning, motivation, ethics, and\ncareer development. Our longitudinal qualitative study of students in a\nGenAI-integrated creative media course shows how this is a \"wicked\" problem:\nprogress on one goal can then impede progress on other goals. Students\ndeveloped concerning patterns despite extensive instruction in critical and\nethical GenAI use including prompt engineering, ethics and bias, and industry\npanels on GenAI's career impact. We present an analysis of two students'\nexperiences to showcase this complexity. Increasing GenAI use skills can lower\nethics; for example, Pat started from purposefully avoiding GenAI use, to\ndependency. He described himself as a \"notorious cheater\" who now uses GenAi to\n\"get all the right answers\" while acknowledging he's learning less. Increasing\nethical awareness can lower the learning of GenAI use skills; for example,\nJay's newfound environmental concerns led to self-imposed usage limits that\nimpeded skill development, and new serious fears that GenAI would eliminate\ncreative careers they had been passionate about. Increased GenAI proficiency, a\npotential career skill, did not improve their career confidence. These findings\nsuggest that supporting student development in the GenAI era is a \"wicked\"\nproblem requiring multi-dimensional evaluation and design, rather than\noptimizing learning, GenAI skills, ethics, or career motivation individually."}
{"id": "2507.17178", "pdf": "https://arxiv.org/pdf/2507.17178.pdf", "abs": "https://arxiv.org/abs/2507.17178", "title": "SKA-Bench: A Fine-Grained Benchmark for Evaluating Structured Knowledge Understanding of LLMs", "authors": ["Zhiqiang Liu", "Enpei Niu", "Yin Hua", "Mengshu Sun", "Lei Liang", "Huajun Chen", "Wen Zhang"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Although large language models (LLMs) have made significant progress in\nunderstanding Structured Knowledge (SK) like KG and Table, existing evaluations\nfor SK understanding are non-rigorous (i.e., lacking evaluations of specific\ncapabilities) and focus on a single type of SK. Therefore, we aim to propose a\nmore comprehensive and rigorous structured knowledge understanding benchmark to\ndiagnose the shortcomings of LLMs. In this paper, we introduce SKA-Bench, a\nStructured Knowledge Augmented QA Benchmark that encompasses four widely used\nstructured knowledge forms: KG, Table, KG+Text, and Table+Text. We utilize a\nthree-stage pipeline to construct SKA-Bench instances, which includes a\nquestion, an answer, positive knowledge units, and noisy knowledge units. To\nevaluate the SK understanding capabilities of LLMs in a fine-grained manner, we\nexpand the instances into four fundamental ability testbeds: Noise Robustness,\nOrder Insensitivity, Information Integration, and Negative Rejection. Empirical\nevaluations on 8 representative LLMs, including the advanced DeepSeek-R1,\nindicate that existing LLMs still face significant challenges in understanding\nstructured knowledge, and their performance is influenced by factors such as\nthe amount of noise, the order of knowledge units, and hallucination\nphenomenon. Our dataset and code are available at\nhttps://github.com/Lza12a/SKA-Bench."}
{"id": "2507.17242", "pdf": "https://arxiv.org/pdf/2507.17242.pdf", "abs": "https://arxiv.org/abs/2507.17242", "title": "High-Density EEG Enables the Fastest Visual Brain-Computer Interfaces", "authors": ["Gege Ming", "Weihua Pei", "Sen Tian", "Xiaogang Chen", "Xiaorong Gao", "Yijun Wang"], "categories": ["cs.HC", "eess.SP", "q-bio.NC"], "comment": null, "summary": "Brain-computer interface (BCI) technology establishes a direct communication\npathway between the brain and external devices. Current visual BCI systems\nsuffer from insufficient information transfer rates (ITRs) for practical use.\nSpatial information, a critical component of visual perception, remains\nunderexploited in existing systems because the limited spatial resolution of\nrecording methods hinders the capture of the rich spatiotemporal dynamics of\nbrain signals. This study proposed a frequency-phase-space fusion encoding\nmethod, integrated with 256-channel high-density electroencephalogram (EEG)\nrecordings, to develop high-speed BCI systems. In the classical frequency-phase\nencoding 40-target BCI paradigm, the 256-66, 128-32, and 64-21 electrode\nconfigurations brought theoretical ITR increases of 83.66%, 79.99%, and 55.50%\nover the traditional 64-9 setup. In the proposed frequency-phase-space encoding\n200-target BCI paradigm, these increases climbed to 195.56%, 153.08%, and\n103.07%. The online BCI system achieved an average actual ITR of 472.7 bpm.\nThis study demonstrates the essential role and immense potential of\nhigh-density EEG in decoding the spatiotemporal information of visual stimuli."}
{"id": "2507.17186", "pdf": "https://arxiv.org/pdf/2507.17186.pdf", "abs": "https://arxiv.org/abs/2507.17186", "title": "FinGAIA: An End-to-End Benchmark for Evaluating AI Agents in Finance", "authors": ["Lingfeng Zeng", "Fangqi Lou", "Zixuan Wang", "Jiajie Xu", "Jinyi Niu", "Mengping Li", "Yifan Dong", "Qi Qi", "Wei Zhang", "Ziwei Yang", "Jun Han", "Ruilun Feng", "Ruiqi Hu", "Lejie Zhang", "Zhengbo Feng", "Yicheng Ren", "Xin Guo", "Zhaowei Liu", "Dongpo Cheng", "Weige Cai", "Liwen Zhang"], "categories": ["cs.CL"], "comment": null, "summary": "The booming development of AI agents presents unprecedented opportunities for\nautomating complex tasks across various domains. However, their multi-step,\nmulti-tool collaboration capabilities in the financial sector remain\nunderexplored. This paper introduces FinGAIA, an end-to-end benchmark designed\nto evaluate the practical abilities of AI agents in the financial domain.\nFinGAIA comprises 407 meticulously crafted tasks, spanning seven major\nfinancial sub-domains: securities, funds, banking, insurance, futures, trusts,\nand asset management. These tasks are organized into three hierarchical levels\nof scenario depth: basic business analysis, asset decision support, and\nstrategic risk management. We evaluated 10 mainstream AI agents in a zero-shot\nsetting. The best-performing agent, ChatGPT, achieved an overall accuracy of\n48.9\\%, which, while superior to non-professionals, still lags financial\nexperts by over 35 percentage points. Error analysis has revealed five\nrecurring failure patterns: Cross-modal Alignment Deficiency, Financial\nTerminological Bias, Operational Process Awareness Barrier, among others. These\npatterns point to crucial directions for future research. Our work provides the\nfirst agent benchmark closely related to the financial domain, aiming to\nobjectively assess and promote the development of agents in this crucial field.\nPartial data is available at https://github.com/SUFE-AIFLM-Lab/FinGAIA."}
{"id": "2507.17248", "pdf": "https://arxiv.org/pdf/2507.17248.pdf", "abs": "https://arxiv.org/abs/2507.17248", "title": "Reality Proxy: Fluid Interactions with Real-World Objects in MR via Abstract Representations", "authors": ["Xiaoan Liu", "Difan Jia", "Xianhao Carton Liu", "Mar Gonzalez-Franco", "Chen Zhu-Tian"], "categories": ["cs.HC", "cs.AI", "cs.GR", "H.5.2; I.3.6"], "comment": "16 pages, 9 figures. Accepted for publication in UIST'25 (The 38th\n  Annual ACM Symposium on User Interface Software and Technology), Busan,\n  Republic of Korea, 28 Sep - 1 Oct 2025", "summary": "Interacting with real-world objects in Mixed Reality (MR) often proves\ndifficult when they are crowded, distant, or partially occluded, hindering\nstraightforward selection and manipulation. We observe that these difficulties\nstem from performing interaction directly on physical objects, where input is\ntightly coupled to their physical constraints. Our key insight is to decouple\ninteraction from these constraints by introducing proxies-abstract\nrepresentations of real-world objects. We embody this concept in Reality Proxy,\na system that seamlessly shifts interaction targets from physical objects to\ntheir proxies during selection. Beyond facilitating basic selection, Reality\nProxy uses AI to enrich proxies with semantic attributes and hierarchical\nspatial relationships of their corresponding physical objects, enabling novel\nand previously cumbersome interactions in MR - such as skimming,\nattribute-based filtering, navigating nested groups, and complex multi object\nselections - all without requiring new gestures or menu systems. We demonstrate\nReality Proxy's versatility across diverse scenarios, including office\ninformation retrieval, large-scale spatial navigation, and multi-drone control.\nAn expert evaluation suggests the system's utility and usability, suggesting\nthat proxy-based abstractions offer a powerful and generalizable interaction\nparadigm for future MR systems."}
{"id": "2507.17216", "pdf": "https://arxiv.org/pdf/2507.17216.pdf", "abs": "https://arxiv.org/abs/2507.17216", "title": "The Pluralistic Moral Gap: Understanding Judgment and Value Differences between Humans and Large Language Models", "authors": ["Giuseppe Russo", "Debora Nozza", "Paul Röttger", "Dirk Hovy"], "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 4 figures", "summary": "People increasingly rely on Large Language Models (LLMs) for moral advice,\nwhich may influence humans' decisions. Yet, little is known about how closely\nLLMs align with human moral judgments. To address this, we introduce the Moral\nDilemma Dataset, a benchmark of 1,618 real-world moral dilemmas paired with a\ndistribution of human moral judgments consisting of a binary evaluation and a\nfree-text rationale. We treat this problem as a pluralistic distributional\nalignment task, comparing the distributions of LLM and human judgments across\ndilemmas. We find that models reproduce human judgments only under high\nconsensus; alignment deteriorates sharply when human disagreement increases. In\nparallel, using a 60-value taxonomy built from 3,783 value expressions\nextracted from rationales, we show that LLMs rely on a narrower set of moral\nvalues than humans. These findings reveal a pluralistic moral gap: a mismatch\nin both the distribution and diversity of values expressed. To close this gap,\nwe introduce Dynamic Moral Profiling (DMP), a Dirichlet-based sampling method\nthat conditions model outputs on human-derived value profiles. DMP improves\nalignment by 64.3% and enhances value diversity, offering a step toward more\npluralistic and human-aligned moral guidance from LLMs."}
{"id": "2507.17320", "pdf": "https://arxiv.org/pdf/2507.17320.pdf", "abs": "https://arxiv.org/abs/2507.17320", "title": "EventLines: Time Compression for Discrete Event Timelines", "authors": ["Yuet Ling Wong", "Niklas Elmqvist"], "categories": ["cs.HC"], "comment": "10 pages, 6 figures", "summary": "Discrete event sequences serve as models for numerous real-world datasets,\nincluding publications over time, project milestones, and medication dosing\nduring patient treatments. These event sequences typically exhibit bursty\nbehavior, where events cluster together in rapid succession, interspersed with\nperiods of inactivity. Standard timeline charts with linear time axes fail to\nadequately represent such data, resulting in cluttered regions during event\nbursts while leaving other areas unutilized. We introduce EventLines, a novel\ntechnique that dynamically adjusts the time scale to match the underlying event\ndistribution, enabling more efficient use of screen space. To address the\nchallenges of non-linear time scaling, EventLines employs the time axis's\nvisual representation itself to communicate the varying scale. We present\nfindings from a crowdsourced graphical perception study that examines how\ndifferent time scale representations influence temporal perception."}
{"id": "2507.17234", "pdf": "https://arxiv.org/pdf/2507.17234.pdf", "abs": "https://arxiv.org/abs/2507.17234", "title": "CLARIFID: Improving Radiology Report Generation by Reinforcing Clinically Accurate Impressions and Enforcing Detailed Findings", "authors": ["Kyeongkyu Lee", "Seonghwan Yoon", "Hongki Lim"], "categories": ["cs.CL"], "comment": null, "summary": "Automatic generation of radiology reports has the potential to alleviate\nradiologists' significant workload, yet current methods struggle to deliver\nclinically reliable conclusions. In particular, most prior approaches focus on\nproducing fluent text without effectively ensuring the factual correctness of\nthe reports and often rely on single-view images, limiting diagnostic\ncomprehensiveness. We propose CLARIFID, a novel framework that directly\noptimizes diagnostic correctness by mirroring the two-step workflow of experts.\nSpecifically, CLARIFID (1) learns the logical flow from Findings to Impression\nthrough section-aware pretraining, (2) is fine-tuned with Proximal Policy\nOptimization in which the CheXbert F1 score of the Impression section serves as\nthe reward, (3) enforces reasoning-aware decoding that completes \"Findings\"\nbefore synthesizing the \"Impression\", and (4) fuses multiple chest X-ray views\nvia a vision-transformer-based multi-view encoder. During inference, we apply a\nreasoning-aware next-token forcing strategy followed by report-level\nre-ranking, ensuring that the model first produces a comprehensive Findings\nsection before synthesizing the Impression and thereby preserving coherent\nclinical reasoning. Experimental results on the MIMIC-CXR dataset demonstrate\nthat our method achieves superior clinical efficacy and outperforms existing\nbaselines on both standard NLG metrics and clinically aware scores."}
{"id": "2507.17430", "pdf": "https://arxiv.org/pdf/2507.17430.pdf", "abs": "https://arxiv.org/abs/2507.17430", "title": "Layered Interactions: Exploring Non-Intrusive Digital Craftsmanship Design Through Lacquer Art Interfaces", "authors": ["Yan Dong", "Hanjie Yu", "Yanran Chen", "Zipeng Zhang", "Qiong Wu"], "categories": ["cs.HC"], "comment": "21 pages, 16 figures, published in ACM CHI 2025", "summary": "Integrating technology with the distinctive characteristics of craftsmanship\nhas become a key issue in the field of digital craftsmanship. This paper\nintroduces Layered Interactions, a design approach that seamlessly merges\nHuman-Computer Interaction (HCI) technologies with traditional lacquerware\ncraftsmanship. By leveraging the multi-layer structure and material properties\nof lacquerware, we embed interactive circuits and integrate programmable\nhardware within the layers, creating tangible interfaces that support diverse\ninteractions. This method enhances the adaptability and practicality of\ntraditional crafts in modern digital contexts. Through the development of a\nlacquerware toolkit, along with user experiments and semi-structured\ninterviews, we demonstrate that this approach not only makes technology more\naccessible to traditional artisans but also enhances the materiality and\nemotional qualities of interactive interfaces. Additionally, it fosters mutual\nlearning and collaboration between artisans and technologists. Our research\nintroduces a cross-disciplinary perspective to the HCI community, broadening\nthe material and design possibilities for interactive interfaces."}
{"id": "2507.17288", "pdf": "https://arxiv.org/pdf/2507.17288.pdf", "abs": "https://arxiv.org/abs/2507.17288", "title": "Triple X: A LLM-Based Multilingual Speech Recognition System for the INTERSPEECH2025 MLC-SLM Challenge", "authors": ["Miaomiao Gao", "Xiaoxiao Xiang", "Yiwen Guo"], "categories": ["cs.CL", "eess.AS"], "comment": null, "summary": "This paper describes our Triple X speech recognition system submitted to Task\n1 of the Multi-Lingual Conversational Speech Language Modeling (MLC-SLM)\nChallenge. Our work focuses on optimizing speech recognition accuracy in\nmultilingual conversational scenarios through an innovative encoder-adapter-LLM\narchitecture. This framework harnesses the powerful reasoning capabilities of\ntext-based large language models while incorporating domain-specific\nadaptations. To further enhance multilingual recognition performance, we\nadopted a meticulously designed multi-stage training strategy leveraging\nextensive multilingual audio datasets. Experimental results demonstrate that\nour approach achieves competitive Word Error Rate (WER) performance on both dev\nand test sets, obtaining second place in the challenge ranking."}
{"id": "2507.17524", "pdf": "https://arxiv.org/pdf/2507.17524.pdf", "abs": "https://arxiv.org/abs/2507.17524", "title": "SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition", "authors": ["Jiahao Tang", "Youjun Li", "Xiangting Fan", "Yangxuan Zheng", "Siyuan Lu", "Xueping Li", "Peng Fang", "Chenxi Li", "Zi-Gang Huang"], "categories": ["cs.HC"], "comment": null, "summary": "Electroencephalography(EEG) based emotion recognition holds great promise for\naffective brain-computer interfaces (aBCIs), yet practical deployment remains\nchallenging due to substantial inter-subject variability and the lack of\nlabeled data in target domains. To overcome these limitations, we present a\nnovel unsupervised Semantic-Dynamic Consistency domain adaptation network for\nfully label-free cross-subject EEG emotion recognition. First, we introduce a\nSame-Subject Same-Trial Mixup strategy that generates augmented samples via\nintra-trial interpolation, enhancing data diversity while explicitly preserving\nindividual identity to mitigate label ambiguity. Second, we construct a dynamic\ndistribution alignment module in reproducing kernel Hilbert space (RKHS),\njointly aligning marginal and conditional distributions through multi-objective\nkernel mean embedding, and leveraging a confidence-aware pseudo-labeling\nstrategy to ensure stable adaptation. Third, we propose a dual-domain\nsimilarity consistency learning mechanism that enforces cross-domain structural\nconstraints based on latent pairwise similarities, enabling semantic boundary\nlearning without relying on temporal synchronization or label priors. To\nvalidate the effectiveness and robustness of the proposed SDC-Net, extensive\nexperiments are conducted on three widely used EEG benchmark datasets: SEED,\nSEED-IV, and Faced. Comparative results against existing unsupervised domain\nadaptation methods demonstrate that SDC-Net achieves state-of-the-art\nperformance in emotion recognition under both cross-subject and cross-session\nconditions. This advancement significantly improves the accuracy and\ngeneralization capability of emotion decoding, and lays a solid foundation for\nreal-world applications of personalized affective brain-computer interfaces\n(aBCIs). The source code will be released at\nhttps://github.com/XuanSuTrum/SDC-Net."}
{"id": "2507.17399", "pdf": "https://arxiv.org/pdf/2507.17399.pdf", "abs": "https://arxiv.org/abs/2507.17399", "title": "Millions of $\\text{GeAR}$-s: Extending GraphRAG to Millions of Documents", "authors": ["Zhili Shen", "Chenxin Diao", "Pascual Merita", "Pavlos Vougiouklis", "Jeff Z. Pan"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Accepted by SIGIR 2025 LiveRAG Challenge Program", "summary": "Recent studies have explored graph-based approaches to retrieval-augmented\ngeneration, leveraging structured or semi-structured information -- such as\nentities and their relations extracted from documents -- to enhance retrieval.\nHowever, these methods are typically designed to address specific tasks, such\nas multi-hop question answering and query-focused summarisation, and therefore,\nthere is limited evidence of their general applicability across broader\ndatasets. In this paper, we aim to adapt a state-of-the-art graph-based RAG\nsolution: $\\text{GeAR}$ and explore its performance and limitations on the\nSIGIR 2025 LiveRAG Challenge."}
{"id": "2507.17543", "pdf": "https://arxiv.org/pdf/2507.17543.pdf", "abs": "https://arxiv.org/abs/2507.17543", "title": "Anticipate, Simulate, Reason (ASR): A Comprehensive Generative AI Framework for Combating Messaging Scams", "authors": ["Xue Wen Tan", "Kenneth See", "Stanley Kok"], "categories": ["cs.HC"], "comment": null, "summary": "The rapid growth of messaging scams creates an escalating challenge for user\nsecurity and financial safety. In this paper, we present the Anticipate,\nSimulate, Reason (ASR) framework, a generative AI method that enables users to\nproactively identify and comprehend scams within instant messaging platforms.\nUsing large language models, ASR predicts scammer responses, creates realistic\nscam conversations, and delivers real-time, interpretable support to end-users.\nWe develop ScamGPT-J, a domain-specific language model fine-tuned on a new,\nhigh-quality dataset of scam conversations covering multiple scam types.\nThorough experimental evaluation shows that the ASR framework substantially\nenhances scam detection, particularly in challenging contexts such as job\nscams, and uncovers important demographic patterns in user vulnerability and\nperceptions of AI-generated assistance. Our findings reveal a contradiction\nwhere those most at risk are often least receptive to AI support, emphasizing\nthe importance of user-centered design in AI-driven fraud prevention. This work\nadvances both the practical and theoretical foundations for interpretable,\nhuman-centered AI systems in combating evolving digital threats."}
{"id": "2507.17409", "pdf": "https://arxiv.org/pdf/2507.17409.pdf", "abs": "https://arxiv.org/abs/2507.17409", "title": "Investigating Subjective Factors of Argument Strength: Storytelling, Emotions, and Hedging", "authors": ["Carlotta Quensel", "Neele Falk", "Gabriella Lapesa"], "categories": ["cs.CL"], "comment": "Accepted to the 12th Workshop on Argument Mining (ArgMining) 2025", "summary": "In assessing argument strength, the notions of what makes a good argument are\nmanifold. With the broader trend towards treating subjectivity as an asset and\nnot a problem in NLP, new dimensions of argument quality are studied. Although\nstudies on individual subjective features like personal stories exist, there is\na lack of large-scale analyses of the relation between these features and\nargument strength. To address this gap, we conduct regression analysis to\nquantify the impact of subjective factors $-$ emotions, storytelling, and\nhedging $-$ on two standard datasets annotated for objective argument quality\nand subjective persuasion. As such, our contribution is twofold: at the level\nof contributed resources, as there are no datasets annotated with all studied\ndimensions, this work compares and evaluates automated annotation methods for\neach subjective feature. At the level of novel insights, our regression\nanalysis uncovers different patterns of impact of subjective features on the\ntwo facets of argument strength encoded in the datasets. Our results show that\nstorytelling and hedging have contrasting effects on objective and subjective\nargument quality, while the influence of emotions depends on their rhetoric\nutilization rather than the domain."}
{"id": "2507.17597", "pdf": "https://arxiv.org/pdf/2507.17597.pdf", "abs": "https://arxiv.org/abs/2507.17597", "title": "Explainable AI for Collaborative Assessment of 2D/3D Registration Quality", "authors": ["Sue Min Cho", "Alexander Do", "Russell H. Taylor", "Mathias Unberath"], "categories": ["cs.HC", "cs.CV"], "comment": null, "summary": "As surgery embraces digital transformation--integrating sophisticated\nimaging, advanced algorithms, and robotics to support and automate complex\nsub-tasks--human judgment of system correctness remains a vital safeguard for\npatient safety. This shift introduces new \"operator-type\" roles tasked with\nverifying complex algorithmic outputs, particularly at critical junctures of\nthe procedure, such as the intermediary check before drilling or implant\nplacement. A prime example is 2D/3D registration, a key enabler of image-based\nsurgical navigation that aligns intraoperative 2D images with preoperative 3D\ndata. Although registration algorithms have advanced significantly, they\noccasionally yield inaccurate results. Because even small misalignments can\nlead to revision surgery or irreversible surgical errors, there is a critical\nneed for robust quality assurance. Current visualization-based strategies alone\nhave been found insufficient to enable humans to reliably detect 2D/3D\nregistration misalignments. In response, we propose the first artificial\nintelligence (AI) framework trained specifically for 2D/3D registration quality\nverification, augmented by explainability features that clarify the model's\ndecision-making. Our explainable AI (XAI) approach aims to enhance informed\ndecision-making for human operators by providing a second opinion together with\na rationale behind it. Through algorithm-centric and human-centered\nevaluations, we systematically compare four conditions: AI-only, human-only,\nhuman-AI, and human-XAI. Our findings reveal that while explainability features\nmodestly improve user trust and willingness to override AI errors, they do not\nexceed the standalone AI in aggregate performance. Nevertheless, future work\nextending both the algorithmic design and the human-XAI collaboration elements\nholds promise for more robust quality assurance of 2D/3D registration."}
{"id": "2507.17442", "pdf": "https://arxiv.org/pdf/2507.17442.pdf", "abs": "https://arxiv.org/abs/2507.17442", "title": "Each to Their Own: Exploring the Optimal Embedding in RAG", "authors": ["Shiting Chen", "Zijian Zhao", "Jinsong Chen"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recently, as Large Language Models (LLMs) have fundamentally impacted various\nfields, the methods for incorporating up-to-date information into LLMs or\nadding external knowledge to construct domain-specific models have garnered\nwide attention. Retrieval-Augmented Generation (RAG), serving as an\ninference-time scaling method, is notable for its low cost and minimal effort\nfor parameter tuning. However, due to heterogeneous training data and model\narchitecture, the variant embedding models used in RAG exhibit different\nbenefits across various areas, often leading to different similarity\ncalculation results and, consequently, varying response quality from LLMs. To\naddress this problem, we propose and examine two approaches to enhance RAG by\ncombining the benefits of multiple embedding models, named Mixture-Embedding\nRAG and Confident RAG. Mixture-Embedding RAG simply sorts and selects\nretrievals from multiple embedding models based on standardized similarity;\nhowever, it does not outperform vanilla RAG. In contrast, Confident RAG\ngenerates responses multiple times using different embedding models and then\nselects the responses with the highest confidence level, demonstrating average\nimprovements of approximately 10% and 5% over vanilla LLMs and RAG,\nrespectively. The consistent results across different LLMs and embedding models\nindicate that Confident RAG is an efficient plug-and-play approach for various\ndomains. We will release our code upon publication."}
{"id": "2507.17688", "pdf": "https://arxiv.org/pdf/2507.17688.pdf", "abs": "https://arxiv.org/abs/2507.17688", "title": "Mindfulness Meditation and Respiration: Accelerometer-Based Respiration Rate and Mindfulness Progress Estimation to Enhance App Engagement and Mindfulness Skills", "authors": ["Mohammad Nur Hossain Khan", "David creswell", "Jordan Albert", "Patrick O'Connell", "Shawn Fallon", "Mathew Polowitz", "Xuhai \"orson\" Xu", "Bashima islam"], "categories": ["cs.HC", "cs.LG"], "comment": "Accepted in Proc. ACM Interact. Mob. Wearable Ubiquitous Technology\n  (IMWUT)", "summary": "Mindfulness training is widely recognized for its benefits in reducing\ndepression, anxiety, and loneliness. With the rise of smartphone-based\nmindfulness apps, digital meditation has become more accessible, but sustaining\nlong-term user engagement remains a challenge. This paper explores whether\nrespiration biosignal feedback and mindfulness skill estimation enhance system\nusability and skill development. We develop a smartphone's accelerometer-based\nrespiration tracking algorithm, eliminating the need for additional wearables.\nUnlike existing methods, our approach accurately captures slow breathing\npatterns typical of mindfulness meditation. Additionally, we introduce the\nfirst quantitative framework to estimate mindfulness skills-concentration,\nsensory clarity, and equanimity-based on accelerometer-derived respiration\ndata. We develop and test our algorithms on 261 mindfulness sessions in both\ncontrolled and real-world settings. A user study comparing an experimental\ngroup receiving biosignal feedback with a control group using a standard app\nshows that respiration feedback enhances system usability. Our respiration\ntracking model achieves a mean absolute error (MAE) of 1.6 breaths per minute,\nclosely aligning with ground truth data, while our mindfulness skill estimation\nattains F1 scores of 80-84% in tracking skill progression. By integrating\nrespiration tracking and mindfulness estimation into a commercial app, we\ndemonstrate the potential of smartphone sensors to enhance digital mindfulness\ntraining."}
{"id": "2507.17476", "pdf": "https://arxiv.org/pdf/2507.17476.pdf", "abs": "https://arxiv.org/abs/2507.17476", "title": "MultiNRC: A Challenging and Native Multilingual Reasoning Evaluation Benchmark for LLMs", "authors": ["Alexander R. Fabbri", "Diego Mares", "Jorge Flores", "Meher Mankikar", "Ernesto Hernandez", "Dean Lee", "Bing Liu", "Chen Xing"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Although recent Large Language Models (LLMs) have shown rapid improvement on\nreasoning benchmarks in English, the evaluation of such LLMs' multilingual\nreasoning capability across diverse languages and cultural contexts remains\nlimited. Existing multilingual reasoning benchmarks are typically constructed\nby translating existing English reasoning benchmarks, biasing these benchmarks\ntowards reasoning problems with context in English language/cultures. In this\nwork, we introduce the Multilingual Native Reasoning Challenge (MultiNRC), a\nbenchmark designed to assess LLMs on more than 1,000 native, linguistic and\nculturally grounded reasoning questions written by native speakers in French,\nSpanish, and Chinese. MultiNRC covers four core reasoning categories:\nlanguage-specific linguistic reasoning, wordplay & riddles, cultural/tradition\nreasoning, and math reasoning with cultural relevance. For cultural/tradition\nreasoning and math reasoning with cultural relevance, we also provide English\nequivalent translations of the multilingual questions by manual translation\nfrom native speakers fluent in English. This set of English equivalents can\nprovide a direct comparison of LLM reasoning capacity in other languages vs.\nEnglish on the same reasoning questions. We systematically evaluate current 14\nleading LLMs covering most LLM families on MultiNRC and its English equivalent\nset. The results show that (1) current LLMs are still not good at native\nmultilingual reasoning, with none scoring above 50% on MultiNRC; (2) LLMs\nexhibit distinct strengths and weaknesses in handling linguistic, cultural, and\nlogical reasoning tasks; (3) Most models perform substantially better in math\nreasoning in English compared to in original languages (+10%), indicating\npersistent challenges with culturally grounded knowledge."}
{"id": "2507.17734", "pdf": "https://arxiv.org/pdf/2507.17734.pdf", "abs": "https://arxiv.org/abs/2507.17734", "title": "DataWink: Reusing and Adapting SVG-based Visualization Examples with Large Multimodal Models", "authors": ["Liwenhan Xie", "Yanna Lin", "Can Liu", "Huamin Qu", "Xinhuan Shu"], "categories": ["cs.HC"], "comment": "Accepted to the IEEE Visualization Conference (VIS'25). 11 pages, 6\n  figures", "summary": "Creating aesthetically pleasing data visualizations remains challenging for\nusers without design expertise or familiarity with visualization tools. To\naddress this gap, we present DataWink, a system that enables users to create\ncustom visualizations by adapting high-quality examples. Our approach combines\nlarge multimodal models (LMMs) to extract data encoding from existing SVG-based\nvisualization examples, featuring an intermediate representation of\nvisualizations that bridges primitive SVG and visualization programs. Users may\nexpress adaptation goals to a conversational agent and control the visual\nappearance through widgets generated on demand. With an interactive interface,\nusers can modify both data mappings and visual design elements while\nmaintaining the original visualization's aesthetic quality. To evaluate\nDataWink, we conduct a user study (N=12) with replication and free-form\nexploration tasks. As a result, DataWink is recognized for its learnability and\neffectiveness in personalized authoring tasks. Our results demonstrate the\npotential of example-driven approaches for democratizing visualization\ncreation."}
{"id": "2507.17527", "pdf": "https://arxiv.org/pdf/2507.17527.pdf", "abs": "https://arxiv.org/abs/2507.17527", "title": "Seed LiveInterpret 2.0: End-to-end Simultaneous Speech-to-speech Translation with Your Voice", "authors": ["Shanbo Cheng", "Yu Bao", "Zhichao Huang", "Yu Lu", "Ningxin Peng", "Lu Xu", "Runsheng Yu", "Rong Cao", "Ting Han", "Zeyang Li", "Sitong Liu", "Shengtao Ma", "Shiguang Pan", "Jiongchen Xiao", "Nuo Xu", "Meng Yang", "Rong Ye", "Yiming Yu", "Ruofei Zhang", "Wanyi Zhang", "Wenhao Zhu", "Liehao Zou", "Lu Lu", "Yuxuan Wang", "Yonghui Wu"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Seed-LiveInterpret 2.0 Technical Report", "summary": "Simultaneous Interpretation (SI) represents one of the most daunting\nfrontiers in the translation industry, with product-level automatic systems\nlong plagued by intractable challenges: subpar transcription and translation\nquality, lack of real-time speech generation, multi-speaker confusion, and\ntranslated speech inflation, especially in long-form discourses. In this study,\nwe introduce Seed-LiveInterpret 2.0, an end-to-end SI model that delivers\nhigh-fidelity, ultra-low-latency speech-to-speech generation with voice cloning\ncapabilities. As a fully operational product-level solution, Seed-LiveInterpret\n2.0 tackles these challenges head-on through our novel duplex speech-to-speech\nunderstanding-generating framework. Experimental results demonstrate that\nthrough large-scale pretraining and reinforcement learning, the model achieves\na significantly better balance between translation accuracy and latency,\nvalidated by human interpreters to exceed 70% correctness in complex scenarios.\nNotably, Seed-LiveInterpret 2.0 outperforms commercial SI solutions by\nsignificant margins in translation quality, while slashing the average latency\nof cloned speech from nearly 10 seconds to a near-real-time 3 seconds, which is\naround a near 70% reduction that drastically enhances practical usability."}
{"id": "2507.17174", "pdf": "https://arxiv.org/pdf/2507.17174.pdf", "abs": "https://arxiv.org/abs/2507.17174", "title": "GhostUMAP2: Measuring and Analyzing (r,d)-Stability of UMAP", "authors": ["Myeongwon Jung", "Takanori Fujiwara", "Jaemin Jo"], "categories": ["cs.GR", "cs.HC", "cs.LG"], "comment": null, "summary": "Despite the widespread use of Uniform Manifold Approximation and Projection\n(UMAP), the impact of its stochastic optimization process on the results\nremains underexplored. We observed that it often produces unstable results\nwhere the projections of data points are determined mostly by chance rather\nthan reflecting neighboring structures. To address this limitation, we\nintroduce (r,d)-stability to UMAP: a framework that analyzes the stochastic\npositioning of data points in the projection space. To assess how stochastic\nelements, specifically initial projection positions and negative sampling,\nimpact UMAP results, we introduce \"ghosts\", or duplicates of data points\nrepresenting potential positional variations due to stochasticity. We define a\ndata point's projection as (r,d)-stable if its ghosts perturbed within a circle\nof radius r in the initial projection remain confined within a circle of radius\nd for their final positions. To efficiently compute the ghost projections, we\ndevelop an adaptive dropping scheme that reduces a runtime up to 60% compared\nto an unoptimized baseline while maintaining approximately 90% of unstable\npoints. We also present a visualization tool that supports the interactive\nexploration of the (r,d)-stability of data points. Finally, we demonstrate the\neffectiveness of our framework by examining the stability of projections of\nreal-world datasets and present usage guidelines for the effective use of our\nframework."}
{"id": "2507.17578", "pdf": "https://arxiv.org/pdf/2507.17578.pdf", "abs": "https://arxiv.org/abs/2507.17578", "title": "Synthetic Voice Data for Automatic Speech Recognition in African Languages", "authors": ["Brian DeRenzi", "Anna Dixon", "Mohamed Aymane Farhi", "Christian Resch"], "categories": ["cs.CL", "I.2.7"], "comment": "29 pages incl. appendix, 8 tables, 5 figures. Authors are listed in\n  alphabetical order", "summary": "Speech technology remains out of reach for most of the over 2300 languages in\nAfrica. We present the first systematic assessment of large-scale synthetic\nvoice corpora for African ASR. We apply a three-step process: LLM-driven text\ncreation, TTS voice synthesis, and ASR fine-tuning. Eight out of ten languages\nfor which we create synthetic text achieved readability scores above 5 out of\n7. We evaluated ASR improvement for three (Hausa, Dholuo, Chichewa) and created\nmore than 2,500 hours of synthetic voice data at below 1% of the cost of real\ndata. Fine-tuned Wav2Vec-BERT-2.0 models trained on 250h real and 250h\nsynthetic Hausa matched a 500h real-data-only baseline, while 579h real and\n450h to 993h synthetic data created the best performance. We also present\ngender-disaggregated ASR performance evaluation. For very low-resource\nlanguages, gains varied: Chichewa WER improved about 6.5% relative with a 1:2\nreal-to-synthetic ratio; a 1:1 ratio for Dholuo showed similar improvements on\nsome evaluation data, but not on others. Investigating intercoder reliability,\nASR errors and evaluation datasets revealed the need for more robust reviewer\nprotocols and more accurate evaluation data. All data and models are publicly\nreleased to invite further work to improve synthetic data for African\nlanguages."}
{"id": "2507.17264", "pdf": "https://arxiv.org/pdf/2507.17264.pdf", "abs": "https://arxiv.org/abs/2507.17264", "title": "Understanding Prompt Programming Tasks and Questions", "authors": ["Jenny T. Liang", "Chenyang Yang", "Agnia Sergeyuk", "Travis D. Breaux", "Brad A. Myers"], "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": null, "summary": "Prompting foundation models (FMs) like large language models (LLMs) have\nenabled new AI-powered software features (e.g., text summarization) that\npreviously were only possible by fine-tuning FMs. Now, developers are embedding\nprompts in software, known as prompt programs. The process of prompt\nprogramming requires the developer to make many changes to their prompt. Yet,\nthe questions developers ask to update their prompt is unknown, despite the\nanswers to these questions affecting how developers plan their changes. With\nthe growing number of research and commercial prompt programming tools, it is\nunclear whether prompt programmers' needs are being adequately addressed. We\naddress these challenges by developing a taxonomy of 25 tasks prompt\nprogrammers do and 51 questions they ask, measuring the importance of each task\nand question. We interview 16 prompt programmers, observe 8 developers make\nprompt changes, and survey 50 developers. We then compare the taxonomy with 48\nresearch and commercial tools. We find that prompt programming is not\nwell-supported: all tasks are done manually, and 16 of the 51 questions --\nincluding a majority of the most important ones -- remain unanswered. Based on\nthis, we outline important opportunities for prompt programming tools."}
{"id": "2507.17618", "pdf": "https://arxiv.org/pdf/2507.17618.pdf", "abs": "https://arxiv.org/abs/2507.17618", "title": "A Hybrid Early-Exit Algorithm for Large Language Models Based on Space Alignment Decoding (SPADE)", "authors": ["Bowen Zheng", "Ming Ma", "Zhongqiao Lin", "Tianming Yang"], "categories": ["cs.CL", "cs.PF"], "comment": null, "summary": "Large language models are computationally expensive due to their deep\nstructures. Prior research has shown that intermediate layers contain\nsufficient information to generate accurate answers, leading to the development\nof early-exit algorithms that reduce inference costs by terminating computation\nat earlier layers. However, these methods often suffer from poor performance\ndue to misalignment between intermediate and output layer representations that\nlead to decoding inaccuracy. To address these challenges, we propose SPADE\n(SPace Alignment DEcoding), a novel decoding method that aligns intermediate\nlayer representations with the output layer by propagating a minimally reduced\nsequence consisting of only the start token and the answer token. We further\noptimize the early-exit decision-making process by training a linear\napproximation of SPADE that computes entropy-based confidence metrics. Putting\nthem together, we create a hybrid early-exit algorithm that monitors confidence\nlevels and stops inference at intermediate layers while using SPADE to generate\nhigh-quality outputs. This approach significantly reduces inference costs\nwithout compromising accuracy, offering a scalable and efficient solution for\ndeploying large language models in real-world applications."}
{"id": "2507.17265", "pdf": "https://arxiv.org/pdf/2507.17265.pdf", "abs": "https://arxiv.org/abs/2507.17265", "title": "Visualization-Driven Illumination for Density Plots", "authors": ["Xin Chen", "Yunhai Wang", "Huaiwei Bao", "Kecheng Lu", "Jaemin Jo", "Chi-Wing Fu", "Jean-Daniel Fekete"], "categories": ["cs.GR", "cs.HC"], "comment": null, "summary": "We present a novel visualization-driven illumination model for density plots,\na new technique to enhance density plots by effectively revealing the detailed\nstructures in high- and medium-density regions and outliers in low-density\nregions, while avoiding artifacts in the density field's colors. When\nvisualizing large and dense discrete point samples, scatterplots and dot\ndensity maps often suffer from overplotting, and density plots are commonly\nemployed to provide aggregated views while revealing underlying structures.\nYet, in such density plots, existing illumination models may produce color\ndistortion and hide details in low-density regions, making it challenging to\nlook up density values, compare them, and find outliers. The key novelty in\nthis work includes (i) a visualization-driven illumination model that\ninherently supports density-plot-specific analysis tasks and (ii) a new image\ncomposition technique to reduce the interference between the image shading and\nthe color-encoded density values. To demonstrate the effectiveness of our\ntechnique, we conducted a quantitative study, an empirical evaluation of our\ntechnique in a controlled study, and two case studies, exploring twelve\ndatasets with up to two million data point samples."}
{"id": "2507.17634", "pdf": "https://arxiv.org/pdf/2507.17634.pdf", "abs": "https://arxiv.org/abs/2507.17634", "title": "WSM: Decay-Free Learning Rate Schedule via Checkpoint Merging for LLM Pre-training", "authors": ["Changxin Tian", "Jiapeng Wang", "Qian Zhao", "Kunlong Chen", "Jia Liu", "Ziqi Liu", "Jiaxin Mao", "Wayne Xin Zhao", "Zhiqiang Zhang", "Jun Zhou"], "categories": ["cs.CL", "cs.LG", "I.2.7"], "comment": null, "summary": "Recent advances in learning rate (LR) scheduling have demonstrated the\neffectiveness of decay-free approaches that eliminate the traditional decay\nphase while maintaining competitive performance. Model merging techniques have\nemerged as particularly promising solutions in this domain. We present\nWarmup-Stable and Merge (WSM), a general framework that establishes a formal\nconnection between learning rate decay and model merging. WSM provides a\nunified theoretical foundation for emulating various decay strategies-including\ncosine decay, linear decay and inverse square root decay-as principled model\naveraging schemes, while remaining fully compatible with diverse optimization\nmethods. Through extensive experiments, we identify merge duration-the training\nwindow for checkpoint aggregation-as the most critical factor influencing model\nperformance, surpassing the importance of both checkpoint interval and merge\nquantity. Our framework consistently outperforms the widely-adopted\nWarmup-Stable-Decay (WSD) approach across multiple benchmarks, achieving\nsignificant improvements of +3.5% on MATH, +2.9% on HumanEval, and +5.5% on\nMMLU-Pro. The performance advantages extend to supervised fine-tuning\nscenarios, highlighting WSM's potential for long-term model refinement."}
{"id": "2507.17401", "pdf": "https://arxiv.org/pdf/2507.17401.pdf", "abs": "https://arxiv.org/abs/2507.17401", "title": "The Wilhelm Tell Dataset of Affordance Demonstrations", "authors": ["Rachel Ringe", "Mihai Pomarlan", "Nikolaos Tsiogkas", "Stefano De Giorgis", "Maria Hedblom", "Rainer Malaka"], "categories": ["cs.RO", "cs.HC"], "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Affordances - i.e. possibilities for action that an environment or objects in\nit provide - are important for robots operating in human environments to\nperceive. Existing approaches train such capabilities on annotated static\nimages or shapes. This work presents a novel dataset for affordance learning of\ncommon household tasks. Unlike previous approaches, our dataset consists of\nvideo sequences demonstrating the tasks from first- and third-person\nperspectives, along with metadata about the affordances that are manifested in\nthe task, and is aimed towards training perception systems to recognize\naffordance manifestations. The demonstrations were collected from several\nparticipants and in total record about seven hours of human activity. The\nvariety of task performances also allows studying preparatory maneuvers that\npeople may perform for a task, such as how they arrange their task space, which\nis also relevant for collaborative service robots."}
{"id": "2507.17636", "pdf": "https://arxiv.org/pdf/2507.17636.pdf", "abs": "https://arxiv.org/abs/2507.17636", "title": "Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries", "authors": ["Victor Hartman", "Petter Törnberg"], "categories": ["cs.CL"], "comment": null, "summary": "Negative campaigning is a central feature of political competition, yet\nempirical research has been limited by the high cost and limited scalability of\nexisting classification methods. This study makes two key contributions. First,\nit introduces zero-shot Large Language Models (LLMs) as a novel approach for\ncross-lingual classification of negative campaigning. Using benchmark datasets\nin ten languages, we demonstrate that LLMs achieve performance on par with\nnative-speaking human coders and outperform conventional supervised machine\nlearning approaches. Second, we leverage this novel method to conduct the\nlargest cross-national study of negative campaigning to date, analyzing 18\nmillion tweets posted by parliamentarians in 19 European countries between 2017\nand 2022. The results reveal consistent cross-national patterns: governing\nparties are less likely to use negative messaging, while ideologically extreme\nand populist parties -- particularly those on the radical right -- engage in\nsignificantly higher levels of negativity. These findings advance our\nunderstanding of how party-level characteristics shape strategic communication\nin multiparty systems. More broadly, the study demonstrates the potential of\nLLMs to enable scalable, transparent, and replicable research in political\ncommunication across linguistic and cultural contexts."}
{"id": "2507.17481", "pdf": "https://arxiv.org/pdf/2507.17481.pdf", "abs": "https://arxiv.org/abs/2507.17481", "title": "AI in Design Education at College Level-Educators' Perspectives and Challenges", "authors": ["Lizhu Zhang", "Cecilia X. Wang"], "categories": ["cs.CY", "cs.HC"], "comment": null, "summary": "Artificial intelligence has deeply permeated numerous fields, especially the\ndesign area which relies on technology as a tool for innovation. This change\nnaturally extends to the field of design education, which is closest to design\npractice. This has led to further exploration of the impact of AI on\ncollege-level education in the design discipline. This study aims to examine\nhow current design educators perceive the role of AI in college-level design\neducation, their perspectives on integrating AI into teaching and research, and\ntheir concerns regarding its potential challenges in design education and\nresearch. Through qualitative, semi-structured, in-depth interviews with seven\nfaculties in U.S. design colleges, the findings reveal that AI, as a tool and\nsource of information, has become an integral part of design education. AI-\nderived functionalities are increasingly utilized in design software, and\neducators are actively incorporating AI as a theoretical framework in their\nteaching. Educators can guide students in using AI tools, but only if they\nfirst acquire a strong foundation in basic design principles and skills. This\nstudy also indicates the importance of promoting a cooperative relationship\nbetween design educators and AI. At the same time, educators express\nanticipation for advancements in ethical standards, authenticity, and the\nresolution of copyright issues related to AI."}
{"id": "2507.17702", "pdf": "https://arxiv.org/pdf/2507.17702.pdf", "abs": "https://arxiv.org/abs/2507.17702", "title": "Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models", "authors": ["Changxin Tian", "Kunlong Chen", "Jia Liu", "Ziqi Liu", "Zhiqiang Zhang", "Jun Zhou"], "categories": ["cs.CL", "I.2.7"], "comment": null, "summary": "Mixture-of-Experts (MoE) has become a dominant architecture for scaling Large\nLanguage Models (LLMs) efficiently by decoupling total parameters from\ncomputational cost. However, this decoupling creates a critical challenge:\npredicting the model capacity of a given MoE configurations (e.g., expert\nactivation ratio and granularity) remains an unresolved problem. To address\nthis gap, we introduce Efficiency Leverage (EL), a metric quantifying the\ncomputational advantage of an MoE model over a dense equivalent. We conduct a\nlarge-scale empirical study, training over 300 models up to 28B parameters, to\nsystematically investigate the relationship between MoE architectural\nconfigurations and EL. Our findings reveal that EL is primarily driven by the\nexpert activation ratio and the total compute budget, both following\npredictable power laws, while expert granularity acts as a non-linear modulator\nwith a clear optimal range. We integrate these discoveries into a unified\nscaling law that accurately predicts the EL of an MoE architecture based on its\nconfiguration. To validate our derived scaling laws, we designed and trained\nLing-mini-beta, a pilot model for Ling-2.0 series with only 0.85B active\nparameters, alongside a 6.1B dense model for comparison. When trained on an\nidentical 1T high-quality token dataset, Ling-mini-beta matched the performance\nof the 6.1B dense model while consuming over 7x fewer computational resources,\nthereby confirming the accuracy of our scaling laws. This work provides a\nprincipled and empirically-grounded foundation for the scaling of efficient MoE\nmodels."}
{"id": "2507.17518", "pdf": "https://arxiv.org/pdf/2507.17518.pdf", "abs": "https://arxiv.org/abs/2507.17518", "title": "Enabling Cyber Security Education through Digital Twins and Generative AI", "authors": ["Vita Santa Barletta", "Vito Bavaro", "Miriana Calvano", "Antonio Curci", "Antonio Piccinno", "Davide Pio Posa"], "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.HC", "cs.SE"], "comment": null, "summary": "Digital Twins (DTs) are gaining prominence in cybersecurity for their ability\nto replicate complex IT (Information Technology), OT (Operational Technology),\nand IoT (Internet of Things) infrastructures, allowing for real time\nmonitoring, threat analysis, and system simulation. This study investigates how\nintegrating DTs with penetration testing tools and Large Language Models (LLMs)\ncan enhance cybersecurity education and operational readiness. By simulating\nrealistic cyber environments, this approach offers a practical, interactive\nframework for exploring vulnerabilities and defensive strategies. At the core\nof this research is the Red Team Knife (RTK), a custom penetration testing\ntoolkit aligned with the Cyber Kill Chain model. RTK is designed to guide\nlearners through key phases of cyberattacks, including reconnaissance,\nexploitation, and response within a DT powered ecosystem. The incorporation of\nLarge Language Models (LLMs) further enriches the experience by providing\nintelligent, real-time feedback, natural language threat explanations, and\nadaptive learning support during training exercises. This combined DT LLM\nframework is currently being piloted in academic settings to develop hands on\nskills in vulnerability assessment, threat detection, and security operations.\nInitial findings suggest that the integration significantly improves the\neffectiveness and relevance of cybersecurity training, bridging the gap between\ntheoretical knowledge and real-world application. Ultimately, the research\ndemonstrates how DTs and LLMs together can transform cybersecurity education to\nmeet evolving industry demands."}
{"id": "2507.17709", "pdf": "https://arxiv.org/pdf/2507.17709.pdf", "abs": "https://arxiv.org/abs/2507.17709", "title": "TyDi QA-WANA: A Benchmark for Information-Seeking Question Answering in Languages of West Asia and North Africa", "authors": ["Parker Riley", "Siamak Shakeri", "Waleed Ammar", "Jonathan H. Clark"], "categories": ["cs.CL"], "comment": null, "summary": "We present TyDi QA-WANA, a question-answering dataset consisting of 28K\nexamples divided among 10 language varieties of western Asia and northern\nAfrica. The data collection process was designed to elicit information-seeking\nquestions, where the asker is genuinely curious to know the answer. Each\nquestion in paired with an entire article that may or may not contain the\nanswer; the relatively large size of the articles results in a task suitable\nfor evaluating models' abilities to utilize large text contexts in answering\nquestions. Furthermore, the data was collected directly in each language\nvariety, without the use of translation, in order to avoid issues of cultural\nrelevance. We present performance of two baseline models, and release our code\nand data to facilitate further improvement by the research community."}
{"id": "2507.17718", "pdf": "https://arxiv.org/pdf/2507.17718.pdf", "abs": "https://arxiv.org/abs/2507.17718", "title": "AI Telephone Surveying: Automating Quantitative Data Collection with an AI Interviewer", "authors": ["Danny D. Leybzon", "Shreyas Tirumala", "Nishant Jain", "Summer Gillen", "Michael Jackson", "Cameron McPhee", "Jennifer Schmidt"], "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "With the rise of voice-enabled artificial intelligence (AI) systems,\nquantitative survey researchers have access to a new data-collection mode: AI\ntelephone surveying. By using AI to conduct phone interviews, researchers can\nscale quantitative studies while balancing the dual goals of human-like\ninteractivity and methodological rigor. Unlike earlier efforts that used\ninteractive voice response (IVR) technology to automate these surveys, voice AI\nenables a more natural and adaptive respondent experience as it is more robust\nto interruptions, corrections, and other idiosyncrasies of human speech.\n  We built and tested an AI system to conduct quantitative surveys based on\nlarge language models (LLM), automatic speech recognition (ASR), and speech\nsynthesis technologies. The system was specifically designed for quantitative\nresearch, and strictly adhered to research best practices like question order\nrandomization, answer order randomization, and exact wording.\n  To validate the system's effectiveness, we deployed it to conduct two pilot\nsurveys with the SSRS Opinion Panel and followed-up with a separate\nhuman-administered survey to assess respondent experiences. We measured three\nkey metrics: the survey completion rates, break-off rates, and respondent\nsatisfaction scores. Our results suggest that shorter instruments and more\nresponsive AI interviewers may contribute to improvements across all three\nmetrics studied."}
{"id": "2507.17717", "pdf": "https://arxiv.org/pdf/2507.17717.pdf", "abs": "https://arxiv.org/abs/2507.17717", "title": "From Feedback to Checklists: Grounded Evaluation of AI-Generated Clinical Notes", "authors": ["Karen Zhou", "John Giorgi", "Pranav Mani", "Peng Xu", "Davis Liang", "Chenhao Tan"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "AI-generated clinical notes are increasingly used in healthcare, but\nevaluating their quality remains a challenge due to high subjectivity and\nlimited scalability of expert review. Existing automated metrics often fail to\nalign with real-world physician preferences. To address this, we propose a\npipeline that systematically distills real user feedback into structured\nchecklists for note evaluation. These checklists are designed to be\ninterpretable, grounded in human feedback, and enforceable by LLM-based\nevaluators. Using deidentified data from over 21,000 clinical encounters,\nprepared in accordance with the HIPAA safe harbor standard, from a deployed AI\nmedical scribe system, we show that our feedback-derived checklist outperforms\nbaseline approaches in our offline evaluations in coverage, diversity, and\npredictive power for human ratings. Extensive experiments confirm the\nchecklist's robustness to quality-degrading perturbations, significant\nalignment with clinician preferences, and practical value as an evaluation\nmethodology. In offline research settings, the checklist can help identify\nnotes likely to fall below our chosen quality thresholds."}
{"id": "2507.17744", "pdf": "https://arxiv.org/pdf/2507.17744.pdf", "abs": "https://arxiv.org/abs/2507.17744", "title": "Yume: An Interactive World Generation Model", "authors": ["Xiaofeng Mao", "Shaoheng Lin", "Zhen Li", "Chuanhao Li", "Wenshuo Peng", "Tong He", "Jiangmiao Pang", "Mingmin Chi", "Yu Qiao", "Kaipeng Zhang"], "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": null, "summary": "Yume aims to use images, text, or videos to create an interactive, realistic,\nand dynamic world, which allows exploration and control using peripheral\ndevices or neural signals. In this report, we present a preview version of\n\\method, which creates a dynamic world from an input image and allows\nexploration of the world using keyboard actions. To achieve this high-fidelity\nand interactive video world generation, we introduce a well-designed framework,\nwhich consists of four main components, including camera motion quantization,\nvideo generation architecture, advanced sampler, and model acceleration. First,\nwe quantize camera motions for stable training and user-friendly interaction\nusing keyboard inputs. Then, we introduce the Masked Video Diffusion\nTransformer~(MVDT) with a memory module for infinite video generation in an\nautoregressive manner. After that, training-free Anti-Artifact Mechanism (AAM)\nand Time Travel Sampling based on Stochastic Differential Equations (TTS-SDE)\nare introduced to the sampler for better visual quality and more precise\ncontrol. Moreover, we investigate model acceleration by synergistic\noptimization of adversarial distillation and caching mechanisms. We use the\nhigh-quality world exploration dataset \\sekai to train \\method, and it achieves\nremarkable results in diverse scenes and applications. All data, codebase, and\nmodel weights are available on https://github.com/stdstu12/YUME. Yume will\nupdate monthly to achieve its original goal. Project page:\nhttps://stdstu12.github.io/YUME-Project/."}
{"id": "2507.17718", "pdf": "https://arxiv.org/pdf/2507.17718.pdf", "abs": "https://arxiv.org/abs/2507.17718", "title": "AI Telephone Surveying: Automating Quantitative Data Collection with an AI Interviewer", "authors": ["Danny D. Leybzon", "Shreyas Tirumala", "Nishant Jain", "Summer Gillen", "Michael Jackson", "Cameron McPhee", "Jennifer Schmidt"], "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "With the rise of voice-enabled artificial intelligence (AI) systems,\nquantitative survey researchers have access to a new data-collection mode: AI\ntelephone surveying. By using AI to conduct phone interviews, researchers can\nscale quantitative studies while balancing the dual goals of human-like\ninteractivity and methodological rigor. Unlike earlier efforts that used\ninteractive voice response (IVR) technology to automate these surveys, voice AI\nenables a more natural and adaptive respondent experience as it is more robust\nto interruptions, corrections, and other idiosyncrasies of human speech.\n  We built and tested an AI system to conduct quantitative surveys based on\nlarge language models (LLM), automatic speech recognition (ASR), and speech\nsynthesis technologies. The system was specifically designed for quantitative\nresearch, and strictly adhered to research best practices like question order\nrandomization, answer order randomization, and exact wording.\n  To validate the system's effectiveness, we deployed it to conduct two pilot\nsurveys with the SSRS Opinion Panel and followed-up with a separate\nhuman-administered survey to assess respondent experiences. We measured three\nkey metrics: the survey completion rates, break-off rates, and respondent\nsatisfaction scores. Our results suggest that shorter instruments and more\nresponsive AI interviewers may contribute to improvements across all three\nmetrics studied."}
{"id": "2408.08068", "pdf": "https://arxiv.org/pdf/2408.08068.pdf", "abs": "https://arxiv.org/abs/2408.08068", "title": "The Paradox of Spreadsheet Self-Efficacy: Social Incentives for Informal Knowledge Sharing in End-User Programming", "authors": ["Qing", "Xia", "Advait Sarkar", "Duncan P. Brumby", "Anna Cox"], "categories": ["cs.HC"], "comment": "8 pages", "summary": "Informal Knowledge Sharing (KS) is vital for end-user programmers to gain\nexpertise. To better understand how personal (self-efficacy), social\n(reputational gains, trust between colleagues), and software-related\n(codification effort) variables influence spreadsheet KS intention, we\nconducted a multiple regressions analysis based on survey data from spreadsheet\nusers (n=100) in administrative and finance roles. We found that high levels of\nspreadsheet self-efficacy and a perception that sharing would result in\nreputational gains predicted higher KS intention, but individuals who found\nknowledge codification effortful showed lower KS intention. We also observed\nthat regardless of occupation, users tended to report a lower sense of\nself-efficacy in their general spreadsheet proficiency, despite also reporting\nhigh self-efficacy in spreadsheet use for job-related contexts. Our findings\nsuggest that acknowledging and designing for these social and personal\nvariables can help avoid situations where experienced individuals refrain\nunnecessarily from sharing, with implications for spreadsheet design."}
{"id": "2507.17728", "pdf": "https://arxiv.org/pdf/2507.17728.pdf", "abs": "https://arxiv.org/abs/2507.17728", "title": "Megrez2 Technical Report", "authors": ["Boxun Li", "Yadong Li", "Zhiyuan Li", "Congyi Liu", "Weilin Liu", "Guowei Niu", "Zheyue Tan", "Haiyang Xu", "Zhuyu Yao", "Tao Yuan", "Dong Zhou", "Yueqing Zhuang", "Bo Zhao", "Guohao Dai", "Yu Wang"], "categories": ["cs.CL"], "comment": null, "summary": "We present Megrez2, a novel lightweight and high-performance language model\narchitecture optimized for device native deployment. Megrez2 introduces a novel\ncross-layer expert sharing mechanism, which significantly reduces total\nparameter count by reusing expert modules across adjacent transformer layers\nwhile maintaining most of the model's capacity. It also incorporates pre-gated\nrouting, enabling memory-efficient expert loading and faster inference. As the\nfirst instantiation of the Megrez2 architecture, we introduce the\nMegrez2-Preview model, which is pre-trained on a 5-trillion-token corpus and\nfurther enhanced through supervised fine-tuning and reinforcement learning with\nverifiable rewards. With only 3B activated and 7.5B stored parameters,\nMegrez2-Preview demonstrates competitive or superior performance compared to\nlarger models on a wide range of tasks, including language understanding,\ninstruction following, mathematical reasoning, and code generation. These\nresults highlight the effectiveness of the Megrez2 architecture to achieve a\nbalance between accuracy, efficiency, and deployability, making it a strong\ncandidate for real-world, resource-constrained applications."}
{"id": "2409.14659", "pdf": "https://arxiv.org/pdf/2409.14659.pdf", "abs": "https://arxiv.org/abs/2409.14659", "title": "Image memorability predicts social media virality and externally-associated commenting", "authors": ["Shikang Peng", "Wilma A. Bainbridge"], "categories": ["cs.HC", "cs.CE", "cs.SI", "J.4"], "comment": "47 pages, 5 figures", "summary": "Visual content on social media plays a key role in entertainment and\ninformation sharing, yet some images gain more engagement than others. We\npropose that image memorability - the ability to be remembered - may predict\nviral potential. Using 1,247 Reddit image posts across three timepoints, we\nassessed memorability with neural network ResMem and correlated the predicted\nmemorability scores with virality metrics. Memorable images are consistently\nassociated with more comments, even after controlling for image categories with\nResNet-152. Semantic analysis revealed that memorable images relate to more\nneutral-affect comments, suggesting a distinct pathway to virality from\nemotional contents. Additionally, visual consistency analysis showed that\nmemorable posts inspired diverse, externally-associated comments. By analyzing\nResMem's layers, we found that semantic distinctiveness was key to both\nmemorability and virality even after accounting for image category effects.\nThis study highlights memorability as a unique correlate of social media\nvirality, offering insights into how visual features and human cognitive\nbehavioral interactions are associated with online engagement."}
{"id": "2507.17747", "pdf": "https://arxiv.org/pdf/2507.17747.pdf", "abs": "https://arxiv.org/abs/2507.17747", "title": "Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks", "authors": ["Linbo Cao", "Jinman Zhao"], "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 7 figures. Accepted to COLM 2025. Code available at:\n  github.com/l6cao/Debate-Driven-Evaluation", "summary": "As frontier language models increasingly saturate standard QA benchmarks,\nconcerns about data contamination, memorization, and escalating dataset\ncreation costs persist. We propose a debate-driven evaluation paradigm that\ntransforms any existing QA dataset into structured adversarial debates--where\none model is given the official answer to defend, and another constructs and\ndefends an alternative answer--adjudicated by a judge model blind to the\ncorrect solution. By forcing multi-round argumentation, this approach\nsubstantially increases difficulty while penalizing shallow memorization, yet\nreuses QA items to reduce curation overhead. We make two main contributions:\n(1) an evaluation pipeline to systematically convert QA tasks into debate-based\nassessments, and (2) a public benchmark that demonstrates our paradigm's\neffectiveness on a subset of MMLU-Pro questions, complete with standardized\nprotocols and reference models. Empirical results validate the robustness of\nthe method and its effectiveness against data contamination--a Llama 3.1 model\nfine-tuned on test questions showed dramatic accuracy improvements (50% -> 82%)\nbut performed worse in debates. Results also show that even weaker judges can\nreliably differentiate stronger debaters, highlighting how debate-based\nevaluation can scale to future, more capable systems while maintaining a\nfraction of the cost of creating new benchmarks. Overall, our framework\nunderscores that \"pretraining on the test set is no longer all you need,\"\noffering a sustainable path for measuring the genuine reasoning ability of\nadvanced language models."}
{"id": "2501.06348", "pdf": "https://arxiv.org/pdf/2501.06348.pdf", "abs": "https://arxiv.org/abs/2501.06348", "title": "Why Automate This? Exploring Correlations between Desire for Robotic Automation, Invested Time and Well-Being", "authors": ["Ruchira Ray", "Leona Pang", "Sanjana Srivastava", "Li Fei-Fei", "Samantha Shorey", "Roberto Martín-Martín"], "categories": ["cs.HC", "cs.RO"], "comment": "20 pages, 14 figures", "summary": "Understanding the motivations underlying the human inclination to automate\ntasks is vital to developing truly helpful robots integrated into daily life.\nAccordingly, we ask: are individuals more inclined to automate chores based on\nthe time they consume or the feelings experienced while performing them? This\nstudy explores these preferences and whether they vary across different social\ngroups (i.e., gender category and income level). Leveraging data from the\nBEHAVIOR-1K dataset, the American Time-Use Survey, and the American Time-Use\nSurvey Well-Being Module, we investigate the relationship between the desire\nfor automation, time spent on daily activities, and their associated feelings -\nHappiness, Meaningfulness, Sadness, Painfulness, Stressfulness, or Tiredness.\nOur key findings show that, despite common assumptions, time spent does not\nstrongly relate to the desire for automation for the general population. For\nthe feelings analyzed, only happiness and pain are key indicators. Significant\ndifferences by gender and economic level also emerged: Women prefer to automate\nstressful activities, whereas men prefer to automate those that make them\nunhappy; mid-income individuals prioritize automating less enjoyable and\nmeaningful activities, while low and high-income show no significant\ncorrelations. We hope our research helps motivate technologies to develop\nrobots that match the priorities of potential users, moving domestic robotics\ntoward more socially relevant solutions. We open-source all the data, including\nan online tool that enables the community to replicate our analysis and explore\nadditional trends at https://robin-lab.cs.utexas.edu/why-automate-this/."}
{"id": "2507.16820", "pdf": "https://arxiv.org/pdf/2507.16820.pdf", "abs": "https://arxiv.org/abs/2507.16820", "title": "Disaster Informatics after the COVID-19 Pandemic: Bibliometric and Topic Analysis based on Large-scale Academic Literature", "authors": ["Ngan Tran", "Haihua Chen", "Ana Cleveland", "Yuhan Zhou"], "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.DL"], "comment": "36 pages, 14 figures, 5 tables", "summary": "This study presents a comprehensive bibliometric and topic analysis of the\ndisaster informatics literature published between January 2020 to September\n2022. Leveraging a large-scale corpus and advanced techniques such as\npre-trained language models and generative AI, we identify the most active\ncountries, institutions, authors, collaboration networks, emergent topics,\npatterns among the most significant topics, and shifts in research priorities\nspurred by the COVID-19 pandemic. Our findings highlight (1) countries that\nwere most impacted by the COVID-19 pandemic were also among the most active,\nwith each country having specific research interests, (2) countries and\ninstitutions within the same region or share a common language tend to\ncollaborate, (3) top active authors tend to form close partnerships with one or\ntwo key partners, (4) authors typically specialized in one or two specific\ntopics, while institutions had more diverse interests across several topics,\nand (5) the COVID-19 pandemic has influenced research priorities in disaster\ninformatics, placing greater emphasis on public health. We further demonstrate\nthat the field is converging on multidimensional resilience strategies and\ncross-sectoral data-sharing collaborations or projects, reflecting a heightened\nawareness of global vulnerability and interdependency. Collecting and quality\nassurance strategies, data analytic practices, LLM-based topic extraction and\nsummarization approaches, and result visualization tools can be applied to\ncomparable datasets or solve similar analytic problems. By mapping out the\ntrends in disaster informatics, our analysis offers strategic insights for\npolicymakers, practitioners, and scholars aiming to enhance disaster\ninformatics capacities in an increasingly uncertain and complex risk landscape."}
{"id": "2501.08518", "pdf": "https://arxiv.org/pdf/2501.08518.pdf", "abs": "https://arxiv.org/abs/2501.08518", "title": "Alleviating Seasickness through Brain-Computer Interface-based Attention Shift", "authors": ["Xiaoyu Bao", "Kailin Xu", "Jiawei Zhu", "Haiyun Huang", "Kangning Li", "Qiyun Huang", "Yuanqing Li"], "categories": ["cs.HC", "cs.AI", "eess.SP", "q-bio.QM"], "comment": null, "summary": "Seasickness poses a widespread problem that adversely impacts both passenger\ncomfort and the operational efficiency of maritime crews. Although attention\nshift has been proposed as a potential method to alleviate symptoms of motion\nsickness, its efficacy remains to be rigorously validated, especially in\nmaritime environments. In this study, we develop an AI-driven brain-computer\ninterface (BCI) to realize sustained and practical attention shift by\nincorporating tasks such as breath counting. Forty-three participants completed\na real-world nautical experiment consisting of a real-feedback session, a\nresting session, and a pseudo-feedback session. Notably, 81.39\\% of the\nparticipants reported that the BCI intervention was effective. EEG analysis\nrevealed that the proposed system can effectively regulate motion sickness EEG\nsignatures, such as an decrease in total band power, along with an increase in\ntheta relative power and a decrease in beta relative power. Furthermore, an\nindicator of attentional focus, the theta/beta ratio, exhibited a significant\nreduction during the real-feedback session, providing further evidence to\nsupport the effectiveness of the BCI in shifting attention. Collectively, this\nstudy presents a novel nonpharmacological, portable, and effective approach for\nseasickness intervention, which has the potential to open up a brand-new\napplication domain for BCIs."}
{"id": "2507.16826", "pdf": "https://arxiv.org/pdf/2507.16826.pdf", "abs": "https://arxiv.org/abs/2507.16826", "title": "A Query-Aware Multi-Path Knowledge Graph Fusion Approach for Enhancing Retrieval-Augmented Generation in Large Language Models", "authors": ["Qikai Wei", "Huansheng Ning", "Chunlong Han", "Jianguo Ding"], "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Retrieval Augmented Generation (RAG) has gradually emerged as a promising\nparadigm for enhancing the accuracy and factual consistency of content\ngenerated by large language models (LLMs). However, existing RAG studies\nprimarily focus on retrieving isolated segments using similarity-based matching\nmethods, while overlooking the intrinsic connections between them. This\nlimitation hampers performance in RAG tasks. To address this, we propose QMKGF,\na Query-Aware Multi-Path Knowledge Graph Fusion Approach for Enhancing\nRetrieval Augmented Generation. First, we design prompt templates and employ\ngeneral-purpose LLMs to extract entities and relations, thereby generating a\nknowledge graph (KG) efficiently. Based on the constructed KG, we introduce a\nmulti-path subgraph construction strategy that incorporates one-hop relations,\nmulti-hop relations, and importance-based relations, aiming to improve the\nsemantic relevance between the retrieved documents and the user query.\nSubsequently, we designed a query-aware attention reward model that scores\nsubgraph triples based on their semantic relevance to the query. Then, we\nselect the highest score subgraph and enrich subgraph with additional triples\nfrom other subgraphs that are highly semantically relevant to the query.\nFinally, the entities, relations, and triples within the updated subgraph are\nutilised to expand the original query, thereby enhancing its semantic\nrepresentation and improving the quality of LLMs' generation. We evaluate QMKGF\non the SQuAD, IIRC, Culture, HotpotQA, and MuSiQue datasets. On the HotpotQA\ndataset, our method achieves a ROUGE-1 score of 64.98\\%, surpassing the\nBGE-Rerank approach by 9.72 percentage points (from 55.26\\% to 64.98\\%).\nExperimental results demonstrate the effectiveness and superiority of the QMKGF\napproach."}
{"id": "2507.14792", "pdf": "https://arxiv.org/pdf/2507.14792.pdf", "abs": "https://arxiv.org/abs/2507.14792", "title": "SenseSeek Dataset: Multimodal Sensing to Study Information Seeking Behaviors", "authors": ["Kaixin Ji", "Danula Hettiachchi", "Falk Scholer", "Flora D. Salim", "Damiano Spina"], "categories": ["cs.HC"], "comment": "Accepted in Proceedings of the ACM on Interactive, Mobile, Wearable\n  and Ubiquitous Technologies (IMWUT), September 2025", "summary": "Information processing tasks involve complex cognitive mechanisms that are\nshaped by various factors, including individual goals, prior experience, and\nsystem environments. Understanding such behaviors requires a sophisticated and\npersonalized data capture of how one interacts with modern information systems\n(e.g., web search engines). Passive sensors, such as wearables, capturing\nphysiological and behavioral data, have the potential to provide solutions in\nthis context. This paper presents a novel dataset, SenseSeek, designed to\nevaluate the effectiveness of consumer-grade sensors in a complex information\nprocessing scenario: searching via systems (e.g., search engines), one of the\ncommon strategies users employ for information seeking. The SenseSeek dataset\ncomprises data collected from 20 participants, 235 trials of the stimulated\nsearch process, 940 phases of stages in the search process, including the\nrealization of Information Need (IN), Query Formulation (QF), Query Submission\nby Typing (QS-T) or Speaking (QS-S), and Relevance Judgment by Reading (RJ-R)\nor Listening (RJ-L). The data includes Electrodermal Activities (EDA),\nElectroencephalogram (EEG), PUPIL, GAZE, and MOTION data, which were captured\nusing consumer-grade sensors. It also contains 258 features extracted from the\nsensor data, the gaze-annotated screen recordings, and task responses. We\nvalidate the usefulness of the dataset by providing baseline analysis on the\nimpacts of different cognitive intents and interaction modalities on the sensor\ndata, and effectiveness of the data in discriminating the search stages. To our\nknowledge, SenseSeek is the first dataset that characterizes the multiple\nstages involved in information seeking with physiological signals collected\nfrom multiple sensors. We hope this dataset can serve as a reference for future\nresearch on information-seeking behaviors."}
{"id": "2507.16834", "pdf": "https://arxiv.org/pdf/2507.16834.pdf", "abs": "https://arxiv.org/abs/2507.16834", "title": "Towards Robust Speech Recognition for Jamaican Patois Music Transcription", "authors": ["Jordan Madden", "Matthew Stone", "Dimitri Johnson", "Daniel Geddez"], "categories": ["eess.AS", "cs.AI", "cs.CL"], "comment": null, "summary": "Although Jamaican Patois is a widely spoken language, current speech\nrecognition systems perform poorly on Patois music, producing inaccurate\ncaptions that limit accessibility and hinder downstream applications. In this\nwork, we take a data-centric approach to this problem by curating more than 40\nhours of manually transcribed Patois music. We use this dataset to fine-tune\nstate-of-the-art automatic speech recognition (ASR) models, and use the results\nto develop scaling laws for the performance of Whisper models on Jamaican\nPatois audio. We hope that this work will have a positive impact on the\naccessibility of Jamaican Patois music and the future of Jamaican Patois\nlanguage modeling."}
{"id": "2507.16258", "pdf": "https://arxiv.org/pdf/2507.16258.pdf", "abs": "https://arxiv.org/abs/2507.16258", "title": "Animal Interaction with Autonomous Mobility Systems: Designing for Multi-Species Coexistence", "authors": ["Tram Thi Minh Tran", "Xinyan Yu", "Marius Hoggenmueller", "Callum Parker", "Paul Schmitt", "Julie Stephany Berrio Perez", "Stewart Worrall", "Martin Tomitsch"], "categories": ["cs.HC"], "comment": null, "summary": "Autonomous mobility systems increasingly operate in environments shared with\nanimals, from urban pets to wildlife. However, their design has largely focused\non human interaction, with limited understanding of how non-human species\nperceive, respond to, or are affected by these systems. Motivated by research\nin Animal-Computer Interaction (ACI) and more-than-human design, this study\ninvestigates animal interactions with autonomous mobility through a\nmulti-method approach combining a scoping review (45 articles), online\nethnography (39 YouTube videos and 11 Reddit discussions), and expert\ninterviews (8 participants). Our analysis surfaces five key areas of concern:\nPhysical Impact (e.g., collisions, failures to detect), Behavioural Effects\n(e.g., avoidance, stress), Accessibility Concerns (particularly for service\nanimals), Ethics and Regulations, and Urban Disturbance. We conclude with\ndesign and policy directions aimed at supporting multispecies coexistence in\nthe age of autonomous systems. This work underscores the importance of\nincorporating non-human perspectives to ensure safer, more inclusive futures\nfor all species."}
{"id": "2507.16835", "pdf": "https://arxiv.org/pdf/2507.16835.pdf", "abs": "https://arxiv.org/abs/2507.16835", "title": "Evaluating Speech-to-Text x LLM x Text-to-Speech Combinations for AI Interview Systems", "authors": ["Nima Yazdani", "Ali Ansari", "Aruj Mahajan", "Amirhossein Afsharrad", "Seyed Shahabeddin Mousavi"], "categories": ["eess.AS", "cs.CL"], "comment": null, "summary": "Voice-based conversational AI systems increasingly rely on cascaded\narchitectures combining speech-to-text (STT), large language models (LLMs), and\ntext-to-speech (TTS) components. However, systematic evaluation of different\ncomponent combinations in production settings remains understudied. We present\na large-scale empirical comparison of STT x LLM x TTS stacks using data from\nover 300,000 AI-conducted job interviews. We develop an automated evaluation\nframework using LLM-as-a-Judge to assess conversational quality, technical\naccuracy, and skill assessment capabilities. Our analysis of four production\nconfigurations reveals that Google STT paired with GPT-4.1 significantly\noutperforms alternatives in both conversational and technical quality metrics.\nSurprisingly, we find that objective quality metrics correlate weakly with user\nsatisfaction scores, suggesting that user experience in voice-based AI systems\ndepends on factors beyond technical performance. Our findings provide practical\nguidance for selecting components in multimodal conversational AI systems and\ncontribute a validated evaluation methodology for voice-based interactions."}
{"id": "2501.06488", "pdf": "https://arxiv.org/pdf/2501.06488.pdf", "abs": "https://arxiv.org/abs/2501.06488", "title": "NVS-SQA: Exploring Self-Supervised Quality Representation Learning for Neurally Synthesized Scenes without References", "authors": ["Qiang Qu", "Yiran Shen", "Xiaoming Chen", "Yuk Ying Chung", "Weidong Cai", "Tongliang Liu"], "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.MM", "eess.IV"], "comment": null, "summary": "Neural View Synthesis (NVS), such as NeRF and 3D Gaussian Splatting,\neffectively creates photorealistic scenes from sparse viewpoints, typically\nevaluated by quality assessment methods like PSNR, SSIM, and LPIPS. However,\nthese full-reference methods, which compare synthesized views to reference\nviews, may not fully capture the perceptual quality of neurally synthesized\nscenes (NSS), particularly due to the limited availability of dense reference\nviews. Furthermore, the challenges in acquiring human perceptual labels hinder\nthe creation of extensive labeled datasets, risking model overfitting and\nreduced generalizability. To address these issues, we propose NVS-SQA, a NSS\nquality assessment method to learn no-reference quality representations through\nself-supervision without reliance on human labels. Traditional self-supervised\nlearning predominantly relies on the \"same instance, similar representation\"\nassumption and extensive datasets. However, given that these conditions do not\napply in NSS quality assessment, we employ heuristic cues and quality scores as\nlearning objectives, along with a specialized contrastive pair preparation\nprocess to improve the effectiveness and efficiency of learning. The results\nshow that NVS-SQA outperforms 17 no-reference methods by a large margin (i.e.,\non average 109.5% in SRCC, 98.6% in PLCC, and 91.5% in KRCC over the second\nbest) and even exceeds 16 full-reference methods across all evaluation metrics\n(i.e., 22.9% in SRCC, 19.1% in PLCC, and 18.6% in KRCC over the second best)."}
{"id": "2507.16838", "pdf": "https://arxiv.org/pdf/2507.16838.pdf", "abs": "https://arxiv.org/abs/2507.16838", "title": "Segmentation-free Goodness of Pronunciation", "authors": ["Xinwei Cao", "Zijian Fan", "Torbjørn Svendsen", "Giampiero Salvi"], "categories": ["eess.AS", "cs.AI", "cs.CL"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Mispronunciation detection and diagnosis (MDD) is a significant part in\nmodern computer aided language learning (CALL) systems. Within MDD,\nphoneme-level pronunciation assessment is key to helping L2 learners improve\ntheir pronunciation. However, most systems are based on a form of goodness of\npronunciation (GOP) which requires pre-segmentation of speech into phonetic\nunits. This limits the accuracy of these methods and the possibility to use\nmodern CTC-based acoustic models for their evaluation. In this study, we first\npropose self-alignment GOP (GOP-SA) that enables the use of CTC-trained ASR\nmodels for MDD. Next, we define a more general alignment-free method that takes\nall possible alignments of the target phoneme into account (GOP-AF). We give a\ntheoretical account of our definition of GOP-AF, an implementation that solves\npotential numerical issues as well as a proper normalization which makes the\nmethod applicable with acoustic models with different peakiness over time. We\nprovide extensive experimental results on the CMU Kids and Speechocean762\ndatasets comparing the different definitions of our methods, estimating the\ndependency of GOP-AF on the peakiness of the acoustic models and on the amount\nof context around the target phoneme. Finally, we compare our methods with\nrecent studies over the Speechocean762 data showing that the feature vectors\nderived from the proposed method achieve state-of-the-art results on\nphoneme-level pronunciation assessment."}
{"id": "2502.13294", "pdf": "https://arxiv.org/pdf/2502.13294.pdf", "abs": "https://arxiv.org/abs/2502.13294", "title": "The \"Who\", \"What\", and \"How\" of Responsible AI Governance: A Systematic Review and Meta-Analysis of (Actor, Stage)-Specific Tools", "authors": ["Blaine Kuehnert", "Rachel M. Kim", "Jodi Forlizzi", "Hoda Heidari"], "categories": ["cs.CY", "cs.HC", "I.2; A.1"], "comment": "Accepted to ACM Conference on Fairness, Accountability, and\n  Transparency 2025. 15 pages, 3 figures", "summary": "The implementation of responsible AI in an organization is inherently complex\ndue to the involvement of multiple stakeholders, each with their unique set of\ngoals and responsibilities across the entire AI lifecycle. These\nresponsibilities are often ambiguously defined and assigned, leading to\nconfusion, miscommunication, and inefficiencies. Even when responsibilities are\nclearly defined and assigned to specific roles, the corresponding AI actors\nlack effective tools to support their execution.\n  Toward closing these gaps, we present a systematic review and comprehensive\nmeta-analysis of the current state of responsible AI tools, focusing on their\nalignment with specific stakeholder roles and their responsibilities in various\nAI lifecycle stages. We categorize over 220 tools according to AI actors and\nstages they address. Our findings reveal significant imbalances across the\nstakeholder roles and lifecycle stages addressed. The vast majority of\navailable tools have been created to support AI designers and developers\nspecifically during data-centric and statistical modeling stages while\nneglecting other roles such as institutional leadership, deployers, end-users,\nand impacted communities, and stages such as value proposition and deployment.\nThe uneven distribution we describe here highlights critical gaps that\ncurrently exist in responsible AI governance research and practice. Our\nanalysis reveals that despite the myriad of frameworks and tools for\nresponsible AI, it remains unclear \\emph{who} within an organization and\n\\emph{when} in the AI lifecycle a tool applies. Furthermore, existing tools are\nrarely validated, leaving critical gaps in their usability and effectiveness.\nThese gaps provide a starting point for researchers and practitioners to create\nmore effective and holistic approaches to responsible AI development and\ngovernance."}
{"id": "2507.16863", "pdf": "https://arxiv.org/pdf/2507.16863.pdf", "abs": "https://arxiv.org/abs/2507.16863", "title": "Pixels, Patterns, but No Poetry: To See The World like Humans", "authors": ["Hongcheng Gao", "Zihao Huang", "Lin Xu", "Jingyi Tang", "Xinhao Li", "Yue Liu", "Haoyang Li", "Taihang Hu", "Minhua Lin", "Xinlong Yang", "Ge Wu", "Balong Bi", "Hongyu Chen", "Wentao Zhang"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Achieving human-like perception and reasoning in Multimodal Large Language\nModels (MLLMs) remains a central challenge in artificial intelligence. While\nrecent research has primarily focused on enhancing reasoning capabilities in\nMLLMs, a fundamental question persists: Can Multimodal Large Language Models\ntruly perceive the world as humans do? This paper shifts focus from reasoning\nto perception. Rather than constructing benchmarks specifically for reasoning,\nwe introduce the Turing Eye Test (TET), a challenging perception-oriented\nbenchmark comprising four diagnostic tasks that evaluate MLLMs' performance on\nsynthetic images that humans process intuitively. Our findings reveal that\nstate-of-the-art MLLMs exhibit catastrophic failures on our perceptual tasks\ntrivial for humans. Both in-context learning and training on language\nbackbone-effective for previous benchmarks-fail to improve performance on our\ntasks, while fine-tuning the vision tower enables rapid adaptation, suggesting\nthat our benchmark poses challenges for vision tower generalization rather than\nfor the knowledge and reasoning capabilities of the language backbone-a key gap\nbetween current MLLMs and human perception. We release a representative subset\nof TET tasks in this version, and will introduce more diverse tasks and methods\nto enhance visual generalization in future work."}
{"id": "2506.04260", "pdf": "https://arxiv.org/pdf/2506.04260.pdf", "abs": "https://arxiv.org/abs/2506.04260", "title": "Turning to Online Forums for Legal Information: A Case Study of GDPR's Legitimate Interests", "authors": ["Lin Kyi", "Cristiana Santos", "Sushil Ammanaghatta Shivakumar", "Franziska Roesner", "Asia Biega"], "categories": ["cs.CY", "cs.HC"], "comment": "Accepted at Annual Privacy Forum 2025", "summary": "Practitioners building online services and tools often turn to online forums\nsuch as Reddit, Law Stack Exchange, and Stack Overflow for legal guidance to\nensure compliance with the GDPR. The legal information presented in these\nforums directly impacts present-day industry practitioner's decisions. Online\nforums can serve as gateways that, depending on the accuracy and quality of the\nanswers provided, may either support or undermine the protection of privacy and\ndata protection fundamental rights. However, there is a need for deeper\ninvestigation into practitioners' decision-making processes and their\nunderstanding of legal compliance when seeking for legal information online.\n  Using GDPR's ``legitimate interests'' legal ground for processing personal\ndata as a case study, we investigate how practitioners use online forums to\nidentify common areas of confusion in applying legitimate interests in\npractice, and evaluate how legally sound online forum responses are.\n  Our analysis found that applying the legal basis of legitimate interest is\ncomplex for practitioners, with important implications for how the GDPR is\nimplemented in practice. The legal analysis showed that crowdsourced legal\ninformation tends to be legally sound, though sometimes incomplete. We outline\nrecommendations to improve the quality of online forums by ensuring that\nresponses are more legally sound and comprehensive, enabling practitioners to\napply legitimate interests effectively in practice and uphold the GDPR."}
{"id": "2507.16877", "pdf": "https://arxiv.org/pdf/2507.16877.pdf", "abs": "https://arxiv.org/abs/2507.16877", "title": "ReMeREC: Relation-aware and Multi-entity Referring Expression Comprehension", "authors": ["Yizhi Hu", "Zezhao Tian", "Xingqun Qi", "Chen Su", "Bingkun Yang", "Junhui Yin", "Muyi Sun", "Man Zhang", "Zhenan Sun"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "15 pages, 7 figures", "summary": "Referring Expression Comprehension (REC) aims to localize specified entities\nor regions in an image based on natural language descriptions. While existing\nmethods handle single-entity localization, they often ignore complex\ninter-entity relationships in multi-entity scenes, limiting their accuracy and\nreliability. Additionally, the lack of high-quality datasets with fine-grained,\npaired image-text-relation annotations hinders further progress. To address\nthis challenge, we first construct a relation-aware, multi-entity REC dataset\ncalled ReMeX, which includes detailed relationship and textual annotations. We\nthen propose ReMeREC, a novel framework that jointly leverages visual and\ntextual cues to localize multiple entities while modeling their\ninter-relations. To address the semantic ambiguity caused by implicit entity\nboundaries in language, we introduce the Text-adaptive Multi-entity Perceptron\n(TMP), which dynamically infers both the quantity and span of entities from\nfine-grained textual cues, producing distinctive representations. Additionally,\nour Entity Inter-relationship Reasoner (EIR) enhances relational reasoning and\nglobal scene understanding. To further improve language comprehension for\nfine-grained prompts, we also construct a small-scale auxiliary dataset,\nEntityText, generated using large language models. Experiments on four\nbenchmark datasets show that ReMeREC achieves state-of-the-art performance in\nmulti-entity grounding and relation prediction, outperforming existing\napproaches by a large margin."}
{"id": "2506.16622", "pdf": "https://arxiv.org/pdf/2506.16622.pdf", "abs": "https://arxiv.org/abs/2506.16622", "title": "Modeling Public Perceptions of Science in Media", "authors": ["Jiaxin Pei", "Dustin Wright", "Isabelle Augenstein", "David Jurgens"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "Effectively engaging the public with science is vital for fostering trust and\nunderstanding in our scientific community. Yet, with an ever-growing volume of\ninformation, science communicators struggle to anticipate how audiences will\nperceive and interact with scientific news. In this paper, we introduce a\ncomputational framework that models public perception across twelve dimensions,\nsuch as newsworthiness, importance, and surprisingness. Using this framework,\nwe create a large-scale science news perception dataset with 10,489 annotations\nfrom 2,101 participants from diverse US and UK populations, providing valuable\ninsights into public responses to scientific information across domains. We\nfurther develop NLP models that predict public perception scores with a strong\nperformance. Leveraging the dataset and model, we examine public perception of\nscience from two perspectives: (1) Perception as an outcome: What factors\naffect the public perception of scientific information? (2) Perception as a\npredictor: Can we use the estimated perceptions to predict public engagement\nwith science? We find that individuals' frequency of science news consumption\nis the driver of perception, whereas demographic factors exert minimal\ninfluence. More importantly, through a large-scale analysis and carefully\ndesigned natural experiment on Reddit, we demonstrate that the estimated public\nperception of scientific information has direct connections with the final\nengagement pattern. Posts with more positive perception scores receive\nsignificantly more comments and upvotes, which is consistent across different\nscientific information and for the same science, but are framed differently.\nOverall, this research underscores the importance of nuanced perception\nmodeling in science communication, offering new pathways to predict public\ninterest and engagement with scientific content."}
{"id": "2507.16933", "pdf": "https://arxiv.org/pdf/2507.16933.pdf", "abs": "https://arxiv.org/abs/2507.16933", "title": "SiLQ: Simple Large Language Model Quantization-Aware Training", "authors": ["Steven K. Esser", "Jeffrey L. McKinstry", "Deepika Bablani", "Rathinakumar Appuswamy", "Dharmendra S. Modha"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "12 pages, 3 figures", "summary": "Large language models can be quantized to reduce inference time latency,\nmodel size, and energy consumption, thereby delivering a better user experience\nat lower cost. A challenge exists to deliver quantized models with minimal loss\nof accuracy in reasonable time, and in particular to do so without requiring\nmechanisms incompatible with specialized inference accelerators. Here, we\ndemonstrate a simple, end-to-end quantization-aware training approach that,\nwith an increase in total model training budget of less than 0.1%, outperforms\nthe leading published quantization methods by large margins on several modern\nbenchmarks, with both base and instruct model variants. The approach easily\ngeneralizes across different model architectures, can be applied to\nactivations, cache, and weights, and requires the introduction of no additional\noperations to the model other than the quantization itself."}
{"id": "2507.17232", "pdf": "https://arxiv.org/pdf/2507.17232.pdf", "abs": "https://arxiv.org/abs/2507.17232", "title": "A Highly Clean Recipe Dataset with Ingredient States Annotation for State Probing Task", "authors": ["Mashiro Toyooka", "Kiyoharu Aizawa", "Yoko Yamakata"], "categories": ["cs.MM", "cs.AI", "cs.CL"], "comment": "Accepted to ACM Multimedia 2025", "summary": "Large Language Models (LLMs) are trained on a vast amount of procedural\ntexts, but they do not directly observe real-world phenomena. In the context of\ncooking recipes, this poses a challenge, as intermediate states of ingredients\nare often omitted, making it difficult for models to track ingredient states\nand understand recipes accurately. In this paper, we apply state probing, a\nmethod for evaluating a language model's understanding of the world, to the\ndomain of cooking. We propose a new task and dataset for evaluating how well\nLLMs can recognize intermediate ingredient states during cooking procedures. We\nfirst construct a new Japanese recipe dataset with clear and accurate\nannotations of ingredient state changes, collected from well-structured and\ncontrolled recipe texts. Using this dataset, we design three novel tasks to\nevaluate whether LLMs can track ingredient state transitions and identify\ningredients present at intermediate steps. Our experiments with widely used\nLLMs, such as Llama3.1-70B and Qwen2.5-72B, show that learning ingredient state\nknowledge improves their understanding of cooking processes, achieving\nperformance comparable to commercial LLMs."}
{"id": "2507.17259", "pdf": "https://arxiv.org/pdf/2507.17259.pdf", "abs": "https://arxiv.org/abs/2507.17259", "title": "Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs", "authors": ["Eyal German", "Sagiv Antebi", "Daniel Samira", "Asaf Shabtai", "Yuval Elovici"], "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly trained on tabular data, which,\nunlike unstructured text, often contains personally identifiable information\n(PII) in a highly structured and explicit format. As a result, privacy risks\narise, since sensitive records can be inadvertently retained by the model and\nexposed through data extraction or membership inference attacks (MIAs). While\nexisting MIA methods primarily target textual content, their efficacy and\nthreat implications may differ when applied to structured data, due to its\nlimited content, diverse data types, unique value distributions, and\ncolumn-level semantics. In this paper, we present Tab-MIA, a benchmark dataset\nfor evaluating MIAs on tabular data in LLMs and demonstrate how it can be used.\nTab-MIA comprises five data collections, each represented in six different\nencoding formats. Using our Tab-MIA benchmark, we conduct the first evaluation\nof state-of-the-art MIA methods on LLMs finetuned with tabular data across\nmultiple encoding formats. In the evaluation, we analyze the memorization\nbehavior of pretrained LLMs on structured data derived from Wikipedia tables.\nOur findings show that LLMs memorize tabular data in ways that vary across\nencoding formats, making them susceptible to extraction via MIAs. Even when\nfine-tuned for as few as three epochs, models exhibit high vulnerability, with\nAUROC scores approaching 90% in most cases. Tab-MIA enables systematic\nevaluation of these risks and provides a foundation for developing\nprivacy-preserving methods for tabular data in LLMs."}
{"id": "2507.17335", "pdf": "https://arxiv.org/pdf/2507.17335.pdf", "abs": "https://arxiv.org/abs/2507.17335", "title": "TransLPRNet: Lite Vision-Language Network for Single/Dual-line Chinese License Plate Recognition", "authors": ["Guangzhu Xu", "Zhi Ke", "Pengcheng Zuo", "Bangjun Lei"], "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "License plate recognition in open environments is widely applicable across\nvarious domains; however, the diversity of license plate types and imaging\nconditions presents significant challenges. To address the limitations\nencountered by CNN and CRNN-based approaches in license plate recognition, this\npaper proposes a unified solution that integrates a lightweight visual encoder\nwith a text decoder, within a pre-training framework tailored for single and\ndouble-line Chinese license plates. To mitigate the scarcity of double-line\nlicense plate datasets, we constructed a single/double-line license plate\ndataset by synthesizing images, applying texture mapping onto real scenes, and\nblending them with authentic license plate images. Furthermore, to enhance the\nsystem's recognition accuracy, we introduce a perspective correction network\n(PTN) that employs license plate corner coordinate regression as an implicit\nvariable, supervised by license plate view classification information. This\nnetwork offers improved stability, interpretability, and low annotation costs.\nThe proposed algorithm achieves an average recognition accuracy of 99.34% on\nthe corrected CCPD test set under coarse localization disturbance. When\nevaluated under fine localization disturbance, the accuracy further improves to\n99.58%. On the double-line license plate test set, it achieves an average\nrecognition accuracy of 98.70%, with processing speeds reaching up to 167\nframes per second, indicating strong practical applicability."}
{"id": "2507.17501", "pdf": "https://arxiv.org/pdf/2507.17501.pdf", "abs": "https://arxiv.org/abs/2507.17501", "title": "DNT: a Deeply Normalized Transformer that can be trained by Momentum SGD", "authors": ["Xianbiao Qi", "Marco Chen", "Wenjie Xiao", "Jiaquan Ye", "Yelin He", "Chun-Guang Li", "Zhouchen Lin"], "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "We have introduced a novel architecture, Deeply Normalized\n  Transformer (DNT), which enables efficient training with vanilla momentum\n  SGDW (mSGDW), achieving performance on par with AdamW-optimized Transformers", "summary": "Transformers have become the de facto backbone of modern deep learning, yet\ntheir training typically demands an advanced optimizer with adaptive learning\nrate like AdamW, rather than a momentum SGDW (mSGDW). Previous works show that\nit is mainly due to a heavy-tailed distribution of the gradients. In this\npaper, we introduce a Deeply Normalized Transformer (DNT), which is\nmeticulously engineered to overcome this limitation enabling seamless training\nwith vanilla mSGDW while yielding comparable performance to the Transformers\ntrained via AdamW. To be specific, in DNT, we strategically integrate\nnormalization techniques at proper positions in the Transformers to effectively\nmodulate the Jacobian matrices of each layer, balance the influence of weights,\nactivations, and their interactions, and thus enable the distributions of\ngradients concentrated. We provide both theoretical justifications of the\nnormalization technique used in our DNT and extensive empirical evaluation on\ntwo popular Transformer architectures to validate that: a) DNT outperforms its\ncounterparts (\\ie, ViT and GPT), and b) DNT can be effectively trained with\nvanilla mSGDW."}
{"id": "2507.17515", "pdf": "https://arxiv.org/pdf/2507.17515.pdf", "abs": "https://arxiv.org/abs/2507.17515", "title": "URPO: A Unified Reward & Policy Optimization Framework for Large Language Models", "authors": ["Songshuo Lu", "Hua Wang", "Zhi Chen", "Yaohua Tang"], "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Large-scale alignment pipelines typically pair a policy model with a\nseparately trained reward model whose parameters remain frozen during\nreinforcement learning (RL). This separation creates a complex,\nresource-intensive pipeline and suffers from a performance ceiling due to a\nstatic reward signal. We propose a novel framework, Unified Reward & Policy\nOptimization (URPO), that unifies instruction-following (\"player\") and reward\nmodeling (\"referee\") within a single model and a single training phase. Our\nmethod recasts all alignment data-including preference pairs, verifiable\nreasoning, and open-ended instructions-into a unified generative format\noptimized by a single Group-Relative Policy Optimization (GRPO) loop. This\nenables the model to learn from ground-truth preferences and verifiable logic\nwhile simultaneously generating its own rewards for open-ended tasks.\nExperiments on the Qwen2.5-7B model demonstrate URPO's superiority. Our unified\nmodel significantly outperforms a strong baseline using a separate generative\nreward model, boosting the instruction-following score on AlpacaEval from 42.24\nto 44.84 and the composite reasoning average from 32.66 to 35.66. Furthermore,\nURPO cultivates a superior internal evaluator as a byproduct of training,\nachieving a RewardBench score of 85.15 and surpassing the dedicated reward\nmodel it replaces (83.55). By eliminating the need for a separate reward model\nand fostering a co-evolutionary dynamic between generation and evaluation, URPO\npresents a simpler, more efficient, and more effective path towards robustly\naligned language models."}
{"id": "2507.17563", "pdf": "https://arxiv.org/pdf/2507.17563.pdf", "abs": "https://arxiv.org/abs/2507.17563", "title": "BoSS: Beyond-Semantic Speech", "authors": ["Qing Wang", "Zehan Li", "Hang Lv", "Hongjie Chen", "Yaodong Song", "Jian Kang", "Jie Lian", "Jie Li", "Yongxiang Li", "Zhongjiang He", "Xuelong Li"], "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Human communication involves more than explicit semantics, with implicit\nsignals and contextual cues playing a critical role in shaping meaning.\nHowever, modern speech technologies, such as Automatic Speech Recognition (ASR)\nand Text-to-Speech (TTS) often fail to capture these beyond-semantic\ndimensions. To better characterize and benchmark the progression of speech\nintelligence, we introduce Spoken Interaction System Capability Levels (L1-L5),\na hierarchical framework illustrated the evolution of spoken dialogue systems\nfrom basic command recognition to human-like social interaction. To support\nthese advanced capabilities, we propose Beyond-Semantic Speech (BoSS), which\nrefers to the set of information in speech communication that encompasses but\ntranscends explicit semantics. It conveys emotions, contexts, and modifies or\nextends meanings through multidimensional features such as affective cues,\ncontextual dynamics, and implicit semantics, thereby enhancing the\nunderstanding of communicative intentions and scenarios. We present a\nformalized framework for BoSS, leveraging cognitive relevance theories and\nmachine learning models to analyze temporal and contextual speech dynamics. We\nevaluate BoSS-related attributes across five different dimensions, reveals that\ncurrent spoken language models (SLMs) are hard to fully interpret\nbeyond-semantic signals. These findings highlight the need for advancing BoSS\nresearch to enable richer, more context-aware human-machine communication."}
{"id": "2507.17588", "pdf": "https://arxiv.org/pdf/2507.17588.pdf", "abs": "https://arxiv.org/abs/2507.17588", "title": "Dual-branch Prompting for Multimodal Machine Translation", "authors": ["Jie Wang", "Zhendong Yang", "Liansong Zong", "Xiaobo Zhang", "Dexian Wang", "Ji Zhang"], "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Multimodal Machine Translation (MMT) typically enhances text-only translation\nby incorporating aligned visual features. Despite the remarkable progress,\nstate-of-the-art MMT approaches often rely on paired image-text inputs at\ninference and are sensitive to irrelevant visual noise, which limits their\nrobustness and practical applicability. To address these issues, we propose\nD2P-MMT, a diffusion-based dual-branch prompting framework for robust\nvision-guided translation. Specifically, D2P-MMT requires only the source text\nand a reconstructed image generated by a pre-trained diffusion model, which\nnaturally filters out distracting visual details while preserving semantic\ncues. During training, the model jointly learns from both authentic and\nreconstructed images using a dual-branch prompting strategy, encouraging rich\ncross-modal interactions. To bridge the modality gap and mitigate\ntraining-inference discrepancies, we introduce a distributional alignment loss\nthat enforces consistency between the output distributions of the two branches.\nExtensive experiments on the Multi30K dataset demonstrate that D2P-MMT achieves\nsuperior translation performance compared to existing state-of-the-art\napproaches."}
{"id": "2507.17746", "pdf": "https://arxiv.org/pdf/2507.17746.pdf", "abs": "https://arxiv.org/abs/2507.17746", "title": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains", "authors": ["Anisha Gunjal", "Anthony Wang", "Elaine Lau", "Vaskar Nath", "Bing Liu", "Sean Hendryx"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Extending Reinforcement Learning with Verifiable Rewards (RLVR) to real-world\ntasks often requires balancing objective and subjective evaluation criteria.\nHowever, many such tasks lack a single, unambiguous ground truth-making it\ndifficult to define reliable reward signals for post-training language models.\nWhile traditional preference-based methods offer a workaround, they rely on\nopaque reward functions that are difficult to interpret and prone to spurious\ncorrelations. We introduce $\\textbf{Rubrics as Rewards}$ (RaR), a framework\nthat uses structured, checklist-style rubrics as interpretable reward signals\nfor on-policy training with GRPO. Our best RaR method yields up to a $28\\%$\nrelative improvement on HealthBench-1k compared to simple Likert-based\napproaches, while matching or surpassing the performance of reward signals\nderived from expert-written references. By treating rubrics as structured\nreward signals, we show that RaR enables smaller-scale judge models to better\nalign with human preferences and sustain robust performance across model\nscales."}
{"id": "2403.14459", "pdf": "https://arxiv.org/pdf/2403.14459.pdf", "abs": "https://arxiv.org/abs/2403.14459", "title": "Multi-Level Explanations for Generative Language Models", "authors": ["Lucas Monteiro Paes", "Dennis Wei", "Hyo Jin Do", "Hendrik Strobelt", "Ronny Luss", "Amit Dhurandhar", "Manish Nagireddy", "Karthikeyan Natesan Ramamurthy", "Prasanna Sattigeri", "Werner Geyer", "Soumya Ghosh"], "categories": ["cs.CL", "cs.AI"], "comment": "Accepted as an oral presentation at ACL 2025. Code available at\n  https://github.com/IBM/ICX360", "summary": "Despite the increasing use of large language models (LLMs) for\ncontext-grounded tasks like summarization and question-answering, understanding\nwhat makes an LLM produce a certain response is challenging. We propose\nMulti-Level Explanations for Generative Language Models (MExGen), a technique\nto provide explanations for context-grounded text generation. MExGen assigns\nscores to parts of the context to quantify their influence on the model's\noutput. It extends attribution methods like LIME and SHAP to LLMs used in\ncontext-grounded tasks where (1) inference cost is high, (2) input text is\nlong, and (3) the output is text. We conduct a systematic evaluation, both\nautomated and human, of perturbation-based attribution methods for\nsummarization and question answering. The results show that our framework can\nprovide more faithful explanations of generated output than available\nalternatives, including LLM self-explanations. We open-source code for MExGen\nas part of the ICX360 toolkit: https://github$.$com/IBM/ICX360."}
{"id": "2405.08427", "pdf": "https://arxiv.org/pdf/2405.08427.pdf", "abs": "https://arxiv.org/abs/2405.08427", "title": "Impact of Stickers on Multimodal Sentiment and Intent in Social Media: A New Task, Dataset and Baseline", "authors": ["Yuanchen Shi", "Biao Ma", "Longyin Zhang", "Fang Kong"], "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 7 figures", "summary": "Stickers are increasingly used in social media to express sentiment and\nintent. Despite their significant impact on sentiment analysis and intent\nrecognition, little research has been conducted in this area. To address this\ngap, we propose a new task: \\textbf{M}ultimodal chat \\textbf{S}entiment\n\\textbf{A}nalysis and \\textbf{I}ntent \\textbf{R}ecognition involving\n\\textbf{S}tickers (MSAIRS). Additionally, we introduce a novel multimodal\ndataset containing Chinese chat records and stickers excerpted from several\nmainstream social media platforms. Our dataset includes paired data with the\nsame text but different stickers, the same sticker but different contexts, and\nvarious stickers consisting of the same images with different texts, allowing\nus to better understand the impact of stickers on chat sentiment and intent. We\nalso propose an effective multimodal joint model, MMSAIR, featuring\ndifferential vector construction and cascaded attention mechanisms for enhanced\nmultimodal fusion. Our experiments demonstrate the necessity and effectiveness\nof jointly modeling sentiment and intent, as they mutually reinforce each\nother's recognition accuracy. MMSAIR significantly outperforms traditional\nmodels and advanced MLLMs, demonstrating the challenge and uniqueness of\nsticker interpretation in social media. Our dataset and code are available on\nhttps://github.com/FakerBoom/MSAIRS-Dataset."}
{"id": "2408.16446", "pdf": "https://arxiv.org/pdf/2408.16446.pdf", "abs": "https://arxiv.org/abs/2408.16446", "title": "Is text normalization relevant for classifying medieval charters?", "authors": ["Florian Atzenhofer-Baumgartner", "Tamás Kovács"], "categories": ["cs.CL", "cs.IR"], "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in LNCS volume 15178 and is available online at\n  https://doi.org/10.1007/978-3-031-72440-4_12", "summary": "This study examines the impact of historical text normalization on the\nclassification of medieval charters, specifically focusing on document dating\nand locating. Using a data set of Middle High German charters from a digital\narchive, we evaluate various classifiers, including traditional and\ntransformer-based models, with and without normalization. Our results indicate\nthat the given normalization minimally improves locating tasks but reduces\naccuracy for dating, implying that original texts contain crucial features that\nnormalization may obscure. We find that support vector machines and gradient\nboosting outperform other models, questioning the efficiency of transformers\nfor this use case. Results suggest a selective approach to historical text\nnormalization, emphasizing the significance of preserving some textual\ncharacteristics that are critical for classification tasks in document\nanalysis."}
{"id": "2410.20682", "pdf": "https://arxiv.org/pdf/2410.20682.pdf", "abs": "https://arxiv.org/abs/2410.20682", "title": "SHARE: Shared Memory-Aware Open-Domain Long-Term Dialogue Dataset Constructed from Movie Script", "authors": ["Eunwon Kim", "Chanho Park", "Buru Chang"], "categories": ["cs.CL"], "comment": null, "summary": "Shared memories between two individuals strengthen their bond and are crucial\nfor facilitating their ongoing conversations. This study aims to make long-term\ndialogue more engaging by leveraging these shared memories. To this end, we\nintroduce a new long-term dialogue dataset named SHARE, constructed from movie\nscripts, which are a rich source of shared memories among various\nrelationships. Our dialogue dataset contains the summaries of persona\ninformation and events of two individuals, as explicitly revealed in their\nconversation, along with implicitly extractable shared memories. We also\nintroduce EPISODE, a long-term dialogue framework based on SHARE that utilizes\nshared experiences between individuals. Through experiments using SHARE, we\ndemonstrate that shared memories between two individuals make long-term\ndialogues more engaging and sustainable, and that EPISODE effectively manages\nshared memories during dialogue. Our dataset and code are available at\nhttps://github.com/e1kim/SHARE."}
{"id": "2411.10371", "pdf": "https://arxiv.org/pdf/2411.10371.pdf", "abs": "https://arxiv.org/abs/2411.10371", "title": "A Survey of Event Causality Identification: Taxonomy, Challenges, Assessment, and Prospects", "authors": ["Qing Cheng", "Zefan Zeng", "Xingchen Hu", "Yuehang Si", "Zhong Liu"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Event Causality Identification (ECI) has emerged as a pivotal task in natural\nlanguage processing (NLP), aimed at automatically detecting causal\nrelationships between events in text. In this comprehensive survey, we\nsystematically elucidate the foundational principles and technical frameworks\nof ECI, proposing a novel classification framework to categorize and clarify\nexisting methods. {We discuss associated challenges, provide quantitative\nevaluations, and outline future directions for this dynamic and rapidly\nevolving field. We first delineate key definitions, problem formalization, and\nevaluation protocols of ECI. Our classification framework organizes ECI methods\nbased on two primary tasks: Sentence-level Event Causality Identification\n(SECI) and Document-level Event Causality Identification (DECI). For SECI, we\nreview methods including feature pattern-based matching, machine learning-based\nclassification, deep semantic encoding, prompt-based fine-tuning, and causal\nknowledge pre-training, alongside common data augmentation strategies. For\nDECI, we focus on techniques such as deep semantic encoding, event graph\nreasoning, and prompt-based fine-tuning. We dedicate specific discussions to\nadvancements in multi-lingual and cross-lingual ECI as well as zero-shot ECI\nleveraging Large Language Models (LLMs). Furthermore, we analyze the strengths,\nlimitations, and unresolved challenges of each method. Extensive quantitative\nevaluations are conducted on four benchmark datasets to assess various ECI\nmethods. Finally, we explore future research directions."}
{"id": "2502.12988", "pdf": "https://arxiv.org/pdf/2502.12988.pdf", "abs": "https://arxiv.org/abs/2502.12988", "title": "Beyond Profile: From Surface-Level Facts to Deep Persona Simulation in LLMs", "authors": ["Zixiao Wang", "Duzhen Zhang", "Ishita Agrawal", "Shen Gao", "Le Song", "Xiuying Chen"], "categories": ["cs.CL"], "comment": "19 pages, 3 figures, ACL 2025 Findings", "summary": "Previous approaches to persona simulation large language models (LLMs) have\ntypically relied on learning basic biographical information, or using limited\nrole-play dialogue datasets to capture a character's responses. However, a\nholistic representation of an individual goes beyond surface-level facts or\nconversations to deeper thoughts and thinking. In this work, we introduce\nCharacterBot, a model designed to replicate both the linguistic patterns and\ndistinctive thought processes of a character. Using Lu Xun, a renowned Chinese\nwriter, as a case study, we propose four training tasks derived from his 17\nessay collections. These include a pre-training task focused on mastering\nexternal linguistic structures and knowledge, as well as three fine-tuning\ntasks: multiple-choice question answering, generative question answering, and\nstyle transfer, each aligning the LLM with Lu Xun's internal ideation and\nwriting style. To optimize learning across these tasks, we introduce a CharLoRA\nparameter updating mechanism, where a general linguistic style expert\ncollaborates with other task-specific experts to better study both the language\nstyle and the understanding of deeper thoughts. We evaluate CharacterBot on\nthree tasks for linguistic accuracy and opinion comprehension, demonstrating\nthat it significantly outperforms the baselines on our adapted metrics. We hope\nthat this work inspires future research on deep character persona simulation\nLLM."}
{"id": "2502.15910", "pdf": "https://arxiv.org/pdf/2502.15910.pdf", "abs": "https://arxiv.org/abs/2502.15910", "title": "Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models", "authors": ["Zheyuan Liu", "Guangyao Dou", "Xiangchi Yuan", "Chunhui Zhang", "Zhaoxuan Tan", "Meng Jiang"], "categories": ["cs.CL"], "comment": "ACL 2025 Main Conference", "summary": "Generative models such as Large Language Models (LLMs) and Multimodal Large\nLanguage Models (MLLMs) trained on massive datasets can lead them to memorize\nand inadvertently reveal sensitive information, raising ethical and privacy\nconcerns. While some prior works have explored this issue in the context of\nLLMs, it presents a unique challenge for MLLMs due to the entangled nature of\nknowledge across modalities, making comprehensive unlearning more difficult. To\naddress this challenge, we propose Modality Aware Neuron Unlearning (MANU), a\nnovel unlearning framework for MLLMs designed to selectively clip neurons based\non their relative importance to the targeted forget data, curated for different\nmodalities. Specifically, MANU consists of two stages: important neuron\nselection and selective pruning. The first stage identifies and collects the\nmost influential neurons across modalities relative to the targeted forget\nknowledge, while the second stage is dedicated to pruning those selected\nneurons. MANU effectively isolates and removes the neurons that contribute most\nto the forget data within each modality, while preserving the integrity of\nretained knowledge. Our experiments conducted across various MLLM architectures\nillustrate that MANU can achieve a more balanced and comprehensive unlearning\nin each modality without largely affecting the overall model utility."}
{"id": "2503.02382", "pdf": "https://arxiv.org/pdf/2503.02382.pdf", "abs": "https://arxiv.org/abs/2503.02382", "title": "An Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning", "authors": ["Wei Sun", "Qianlong Du", "Fuwei Cui", "Jiajun Zhang"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Enhancing the mathematical reasoning capabilities of Large Language Models\n(LLMs) is of great scientific and practical significance. Researchers typically\nemploy process-supervised reward models (PRMs) to guide the reasoning process,\neffectively improving the models' reasoning abilities. However, existing\nmethods for constructing process supervision training data, such as manual\nannotation and per-step Monte Carlo estimation, are often costly or suffer from\npoor quality. To address these challenges, this paper introduces a framework\ncalled EpicPRM, which annotates each intermediate reasoning step based on its\nquantified contribution and uses an adaptive binary search algorithm to enhance\nboth annotation precision and efficiency. Using this approach, we efficiently\nconstruct a high-quality process supervision training dataset named Epic50k,\nconsisting of 50k annotated intermediate steps. Compared to other publicly\navailable datasets, the PRM trained on Epic50k demonstrates significantly\nsuperior performance. Getting Epic50k at https://github.com/xiaolizh1/EpicPRM."}
{"id": "2503.02832", "pdf": "https://arxiv.org/pdf/2503.02832.pdf", "abs": "https://arxiv.org/abs/2503.02832", "title": "AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation", "authors": ["Songming Zhang", "Xue Zhang", "Tong Zhang", "Bojie Hu", "Yufeng Chen", "Jinan Xu"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL 2025 Main Conference, code available at:\n  https://github.com/songmzhang/AlignDistil", "summary": "In modern large language models (LLMs), LLM alignment is of crucial\nimportance and is typically achieved through methods such as reinforcement\nlearning from human feedback (RLHF) and direct preference optimization (DPO).\nHowever, in most existing methods for LLM alignment, all tokens in the response\nare optimized using a sparse, response-level reward or preference annotation.\nThe ignorance of token-level rewards may erroneously punish high-quality tokens\nor encourage low-quality tokens, resulting in suboptimal performance and slow\nconvergence speed. To address this issue, we propose AlignDistil, an\nRLHF-equivalent distillation method for token-level reward optimization.\nSpecifically, we introduce the reward learned by DPO into the RLHF objective\nand theoretically prove the equivalence between this objective and a\ntoken-level distillation process, where the teacher distribution linearly\ncombines the logits from the DPO model and a reference model. On this basis, we\nfurther bridge the accuracy gap between the reward from the DPO model and the\npure reward model, by building a contrastive DPO reward with a normal and a\nreverse DPO model. Moreover, to avoid under- and over-optimization on different\ntokens, we design a token adaptive logit extrapolation mechanism to construct\nan appropriate teacher distribution for each token. Experimental results\ndemonstrate the superiority of our AlignDistil over existing methods and\nshowcase fast convergence due to its token-level distributional reward\noptimization."}
{"id": "2503.03460", "pdf": "https://arxiv.org/pdf/2503.03460.pdf", "abs": "https://arxiv.org/abs/2503.03460", "title": "Visualising Policy-Reward Interplay to Inform Zeroth-Order Preference Optimisation of Large Language Models", "authors": ["Alessio Galatolo", "Zhenbang Dai", "Katie Winkle", "Meriem Beloucif"], "categories": ["cs.CL"], "comment": "ACL25 Findings", "summary": "Fine-tuning Large Language Models (LLMs) with first-order methods like\nback-propagation is computationally intensive. Zeroth-Order (ZO) optimisation\nuses function evaluations instead of gradients, reducing memory usage, but\nsuffers from slow convergence in high-dimensional models. As a result, ZO\nresearch in LLMs has mostly focused on classification, overlooking more complex\ngenerative tasks. In this paper, we introduce ZOPrO, a novel ZO algorithm\ndesigned for Preference Optimisation in LLMs. We begin by analysing the\ninterplay between policy and reward models during traditional (first-order)\nPreference Optimisation, uncovering patterns in their relative updates. Guided\nby these insights, we adapt Simultaneous Perturbation Stochastic Approximation\n(SPSA) with a targeted sampling strategy to accelerate convergence. Through\nexperiments on summarisation, machine translation, and conversational\nassistants, we demonstrate that our method consistently enhances reward signals\nwhile achieving convergence times comparable to first-order methods. While it\nfalls short of some state-of-the-art methods, our work is the first to apply\nZeroth-Order methods to Preference Optimisation in LLMs, going beyond\nclassification tasks and paving the way for a largely unexplored research\ndirection. Code and visualisations are available at\nhttps://github.com/alessioGalatolo/VisZOPrO"}
{"id": "2503.05200", "pdf": "https://arxiv.org/pdf/2503.05200.pdf", "abs": "https://arxiv.org/abs/2503.05200", "title": "ORANSight-2.0: Foundational LLMs for O-RAN", "authors": ["Pranshav Gajjar", "Vijay K. Shah"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NI"], "comment": null, "summary": "Despite the transformative impact of Large Language Models (LLMs) across\ncritical domains such as healthcare, customer service, and business marketing,\ntheir integration into Open Radio Access Networks (O-RAN) remains limited. This\ngap is primarily due to the absence of domain-specific foundational models,\nwith existing solutions often relying on general-purpose LLMs that fail to\naddress the unique challenges and technical intricacies of O-RAN. To bridge\nthis gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative\nto develop specialized foundational LLMs tailored for O-RAN. Built on 18 models\nspanning five open-source LLM frameworks -- Mistral, Qwen, Llama, Phi, and\nGemma -- ORANSight-2.0 fine-tunes models ranging from 1B to 70B parameters,\nsignificantly reducing reliance on proprietary, closed-source models while\nenhancing performance in O-RAN-specific tasks. At the core of ORANSight-2.0 is\nRANSTRUCT, a novel Retrieval-Augmented Generation (RAG)-based\ninstruction-tuning framework that employs two LLM agents -- a Mistral-based\nQuestion Generator and a Qwen-based Answer Generator -- to create high-quality\ninstruction-tuning datasets. The generated dataset is then used to fine-tune\nthe 18 pre-trained open-source LLMs via QLoRA. To evaluate ORANSight-2.0, we\nintroduce srsRANBench, a novel benchmark designed for code generation and\ncodebase understanding in the context of srsRAN, a widely used 5G O-RAN stack."}
{"id": "2503.13844", "pdf": "https://arxiv.org/pdf/2503.13844.pdf", "abs": "https://arxiv.org/abs/2503.13844", "title": "Towards Detecting Persuasion on Social Media: From Model Development to Insights on Persuasion Strategies", "authors": ["Elyas Meguellati", "Stefano Civelli", "Pietro Bernardelle", "Shazia Sadiq", "Irwin King", "Gianluca Demartini"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Political advertising plays a pivotal role in shaping public opinion and\ninfluencing electoral outcomes, often through subtle persuasive techniques\nembedded in broader propaganda strategies. Detecting these persuasive elements\nis crucial for enhancing voter awareness and ensuring transparency in\ndemocratic processes. This paper presents an integrated approach that bridges\nmodel development and real-world application through two interconnected\nstudies. First, we introduce a lightweight model for persuasive text detection\nthat achieves state-of-the-art performance in Subtask 3 of SemEval 2023 Task 3\nwhile requiring significantly fewer computational resources and training data\nthan existing methods. Second, we demonstrate the model's practical utility by\ncollecting the Australian Federal Election 2022 Facebook Ads (APA22) dataset,\npartially annotating a subset for persuasion, and fine-tuning the model to\nadapt from mainstream news to social media content. We then apply the\nfine-tuned model to label the remainder of the APA22 dataset, revealing\ndistinct patterns in how political campaigns leverage persuasion through\ndifferent funding strategies, word choices, demographic targeting, and temporal\nshifts in persuasion intensity as election day approaches. Our findings not\nonly underscore the necessity of domain-specific modeling for analyzing\npersuasion on social media but also show how uncovering these strategies can\nenhance transparency, inform voters, and promote accountability in digital\ncampaigns."}
{"id": "2503.22913", "pdf": "https://arxiv.org/pdf/2503.22913.pdf", "abs": "https://arxiv.org/abs/2503.22913", "title": "Resona: Improving Context Copying in Linear Recurrence Models with Retrieval", "authors": ["Xinyu Wang", "Linrui Ma", "Jerry Huang", "Peng Lu", "Prasanna Parthasarathi", "Xiao-Wen Chang", "Boxing Chen", "Yufei Cui"], "categories": ["cs.CL"], "comment": "Accepted at the Second Conference on Language Modeling", "summary": "Recent shifts in the space of large language model (LLM) research have shown\nan increasing focus on novel architectures to compete with prototypical\nTransformer-based models that have long dominated this space. Linear recurrent\nmodels have proven to be a viable competitor due to their computational\nefficiency. However, such models still demonstrate a sizable gap compared to\nTransformers in terms of in-context learning among other tasks that require\nrecalling information from a context. In this work, we introduce Resona, a\nsimple and scalable framework for augmenting linear recurrent models with\nretrieval. Resona augments models with the ability to integrate retrieved\ninformation from the provided input context, enabling tailored behavior to\ndiverse task requirements. Experiments on a variety of linear recurrent models\ndemonstrate that Resona-augmented models observe significant performance gains\non a variety of synthetic as well as real-world natural language tasks,\nhighlighting its ability to act as a general purpose method to improve the\nin-context learning and language modeling abilities of linear recurrent LLMs."}
{"id": "2505.22334", "pdf": "https://arxiv.org/pdf/2505.22334.pdf", "abs": "https://arxiv.org/abs/2505.22334", "title": "Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start", "authors": ["Lai Wei", "Yuting Li", "Kaipeng Zheng", "Chen Wang", "Yue Wang", "Linghe Kong", "Lichao Sun", "Weiran Huang"], "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have demonstrated\nimpressive chain-of-thought reasoning capabilities, with reinforcement learning\n(RL) playing a crucial role in this progress. While \"aha moment\"\npatterns--where models exhibit self-correction through reflection--are often\nattributed to emergent properties from RL, we first demonstrate that these\npatterns exist in multimodal LLMs (MLLMs) prior to RL training but may not\nnecessarily correlate with improved reasoning performance. Building on these\ninsights, we present a comprehensive study on enhancing multimodal reasoning\nthrough a two-stage approach: (1) supervised fine-tuning (SFT) as a cold start\nwith structured chain-of-thought reasoning patterns, followed by (2)\nreinforcement learning via GRPO to further refine these capabilities. Our\nextensive experiments show that this combined approach consistently outperforms\nboth SFT-only and RL-only methods across challenging multimodal reasoning\nbenchmarks. The resulting models achieve state-of-the-art performance among\nopen-source MLLMs at both 3B and 7B scales, with our 7B model showing\nsubstantial improvements over base models (e.g., 66.3 %$\\rightarrow$73.4 % on\nMathVista, 62.9 %$\\rightarrow$70.4 % on We-Math) and our 3B model achieving\nperformance competitive with several 7B models. Overall, this work provides\npractical guidance for building advanced multimodal reasoning models. Our code\nis available at https://github.com/waltonfuture/RL-with-Cold-Start."}
{"id": "2505.23404", "pdf": "https://arxiv.org/pdf/2505.23404.pdf", "abs": "https://arxiv.org/abs/2505.23404", "title": "MEF: A Capability-Aware Multi-Encryption Framework for Evaluating Vulnerabilities in Black-Box Large Language Models", "authors": ["Mingyu Yu", "Wei Wang", "Yanjie Wei", "Sujuan Qin", "Fei Gao", "Wenmin Li"], "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in adversarial jailbreak attacks have exposed critical\nvulnerabilities in Large Language Models (LLMs), enabling the circumvention of\nalignment safeguards through increasingly sophisticated prompt manipulations.\nBased on our experiments, we found that the effectiveness of jailbreak\nstrategies is influenced by the comprehension ability of the attacked LLM.\nBuilding on this insight, we propose a capability-aware Multi-Encryption\nFramework (MEF) for evaluating vulnerabilities in black-box LLMs. Specifically,\nMEF first categorizes the comprehension ability level of the LLM, then applies\ndifferent strategies accordingly: For models with limited comprehension\nability, MEF adopts the Fu+En1 strategy, which integrates layered semantic\nmutations with an encryption technique, more effectively contributing to\nevasion of the LLM's defenses at the input and inference stages. For models\nwith strong comprehension ability, MEF uses a more complex Fu+En1+En2 strategy,\nin which additional dual-ended encryption techniques are applied to the LLM's\nresponses, further contributing to evasion of the LLM's defenses at the output\nstage. Experimental results demonstrate the effectiveness of our approach,\nachieving attack success rates of 98.9% on GPT-4o (29 May 2025 release) and\n99.8% on GPT-4.1 (8 July 2025 release). Our work contributes to a deeper\nunderstanding of the vulnerabilities in current LLM alignment mechanisms."}
{"id": "2505.23822", "pdf": "https://arxiv.org/pdf/2505.23822.pdf", "abs": "https://arxiv.org/abs/2505.23822", "title": "Speech as a Multimodal Digital Phenotype for Multi-Task LLM-based Mental Health Prediction", "authors": ["Mai Ali", "Christopher Lucasius", "Tanmay P. Patel", "Madison Aitken", "Jacob Vorstman", "Peter Szatmari", "Marco Battaglia", "Deepa Kundur"], "categories": ["cs.CL", "cs.MM"], "comment": "6 pages, 1 figure, 3 tables. The corresponding author is Mai Ali\n  (maia dot ali at mail dot utoronto dot ca). Christopher Lucasius and Tanmay\n  P. Patel contributed equally", "summary": "Speech is a noninvasive digital phenotype that can offer valuable insights\ninto mental health conditions, but it is often treated as a single modality. In\ncontrast, we propose the treatment of patient speech data as a trimodal\nmultimedia data source for depression detection. This study explores the\npotential of large language model-based architectures for speech-based\ndepression prediction in a multimodal regime that integrates speech-derived\ntext, acoustic landmarks, and vocal biomarkers. Adolescent depression presents\na significant challenge and is often comorbid with multiple disorders, such as\nsuicidal ideation and sleep disturbances. This presents an additional\nopportunity to integrate multi-task learning (MTL) into our study by\nsimultaneously predicting depression, suicidal ideation, and sleep disturbances\nusing the multimodal formulation. We also propose a longitudinal analysis\nstrategy that models temporal changes across multiple clinical interactions,\nallowing for a comprehensive understanding of the conditions' progression. Our\nproposed approach, featuring trimodal, longitudinal MTL is evaluated on the\nDepression Early Warning dataset. It achieves a balanced accuracy of 70.8%,\nwhich is higher than each of the unimodal, single-task, and non-longitudinal\nmethods."}
{"id": "2506.02951", "pdf": "https://arxiv.org/pdf/2506.02951.pdf", "abs": "https://arxiv.org/abs/2506.02951", "title": "Adaptive Graph Pruning for Multi-Agent Communication", "authors": ["Boyi Li", "Zhonghan Zhao", "Der-Horng Lee", "Gaoang Wang"], "categories": ["cs.CL", "cs.MA"], "comment": "ECAI 2025", "summary": "Large Language Model (LLM) based multi-agent systems have shown remarkable\nperformance in various tasks, especially when enhanced through collaborative\ncommunication. However, current methods often rely on a fixed number of agents\nand static communication structures, limiting their ability to adapt to varying\ntask complexities. In this paper, we propose Adaptive Graph Pruning (AGP), a\nnovel task-adaptive multi-agent collaboration framework that jointly optimizes\nagent quantity (hard-pruning) and communication topology (soft-pruning).\nSpecifically, our method employs a two-stage training strategy: firstly,\nindependently training soft-pruning networks for different agent quantities to\ndetermine optimal agent-quantity-specific complete graphs and positional masks\nacross specific tasks; and then jointly optimizing hard-pruning and\nsoft-pruning within a maximum complete graph to dynamically configure the\nnumber of agents and their communication topologies per task. Extensive\nexperiments demonstrate that our approach is: (1) High-performing, achieving\nstate-of-the-art results across six benchmarks and consistently generalizes\nacross multiple mainstream LLM architectures, with a increase in performance of\n$2.58\\%\\sim 9.84\\%$; (2) Task-adaptive, dynamically constructing optimized\ncommunication topologies tailored to specific tasks, with an extremely high\nperformance in all three task categories (general reasoning, mathematical\nreasoning, and code generation); (3) Token-economical, having fewer training\nsteps and token consumption at the same time, with a decrease in token\nconsumption of $90\\%+$; and (4) Training-efficient, achieving high performance\nwith very few training steps compared with other methods. The performance will\nsurpass the existing baselines after about ten steps of training under six\nbenchmarks."}
{"id": "2506.15239", "pdf": "https://arxiv.org/pdf/2506.15239.pdf", "abs": "https://arxiv.org/abs/2506.15239", "title": "Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants", "authors": ["Jaione Bengoetxea", "Itziar Gonzalez-Dios", "Rodrigo Agerri"], "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we evaluate the capacity of current language technologies to\nunderstand Basque and Spanish language varieties. We use Natural Language\nInference (NLI) as a pivot task and introduce a novel, manually-curated\nparallel dataset in Basque and Spanish, along with their respective variants.\nOur empirical analysis of crosslingual and in-context learning experiments\nusing encoder-only and decoder-based Large Language Models (LLMs) shows a\nperformance drop when handling linguistic variation, especially in Basque.\nError analysis suggests that this decline is not due to lexical overlap, but\nrather to the linguistic variation itself. Further ablation experiments\nindicate that encoder-only models particularly struggle with Western Basque,\nwhich aligns with linguistic theory that identifies peripheral dialects (e.g.,\nWestern) as more distant from the standard. All data and code are publicly\navailable."}
{"id": "2506.16383", "pdf": "https://arxiv.org/pdf/2506.16383.pdf", "abs": "https://arxiv.org/abs/2506.16383", "title": "Large Language Models in Argument Mining: A Survey", "authors": ["Hao Li", "Viktor Schlegel", "Yizheng Sun", "Riza Batista-Navarro", "Goran Nenadic"], "categories": ["cs.CL"], "comment": "Work draft", "summary": "Argument Mining (AM), a critical subfield of Natural Language Processing\n(NLP), focuses on extracting argumentative structures from text. The advent of\nLarge Language Models (LLMs) has profoundly transformed AM, enabling advanced\nin-context learning, prompt-based generation, and robust cross-domain\nadaptability. This survey systematically synthesizes recent advancements in\nLLM-driven AM. We provide a concise review of foundational theories and\nannotation frameworks, alongside a meticulously curated catalog of datasets. A\nkey contribution is our comprehensive taxonomy of AM subtasks, elucidating how\ncontemporary LLM techniques -- such as prompting, chain-of-thought reasoning,\nand retrieval augmentation -- have reconfigured their execution. We further\ndetail current LLM architectures and methodologies, critically assess\nevaluation practices, and delineate pivotal challenges including long-context\nreasoning, interpretability, and annotation bottlenecks. Conclusively, we\nhighlight emerging trends and propose a forward-looking research agenda for\nLLM-based computational argumentation, aiming to strategically guide\nresearchers in this rapidly evolving domain."}
{"id": "2506.16622", "pdf": "https://arxiv.org/pdf/2506.16622.pdf", "abs": "https://arxiv.org/abs/2506.16622", "title": "Modeling Public Perceptions of Science in Media", "authors": ["Jiaxin Pei", "Dustin Wright", "Isabelle Augenstein", "David Jurgens"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "Effectively engaging the public with science is vital for fostering trust and\nunderstanding in our scientific community. Yet, with an ever-growing volume of\ninformation, science communicators struggle to anticipate how audiences will\nperceive and interact with scientific news. In this paper, we introduce a\ncomputational framework that models public perception across twelve dimensions,\nsuch as newsworthiness, importance, and surprisingness. Using this framework,\nwe create a large-scale science news perception dataset with 10,489 annotations\nfrom 2,101 participants from diverse US and UK populations, providing valuable\ninsights into public responses to scientific information across domains. We\nfurther develop NLP models that predict public perception scores with a strong\nperformance. Leveraging the dataset and model, we examine public perception of\nscience from two perspectives: (1) Perception as an outcome: What factors\naffect the public perception of scientific information? (2) Perception as a\npredictor: Can we use the estimated perceptions to predict public engagement\nwith science? We find that individuals' frequency of science news consumption\nis the driver of perception, whereas demographic factors exert minimal\ninfluence. More importantly, through a large-scale analysis and carefully\ndesigned natural experiment on Reddit, we demonstrate that the estimated public\nperception of scientific information has direct connections with the final\nengagement pattern. Posts with more positive perception scores receive\nsignificantly more comments and upvotes, which is consistent across different\nscientific information and for the same science, but are framed differently.\nOverall, this research underscores the importance of nuanced perception\nmodeling in science communication, offering new pathways to predict public\ninterest and engagement with scientific content."}
{"id": "2506.17286", "pdf": "https://arxiv.org/pdf/2506.17286.pdf", "abs": "https://arxiv.org/abs/2506.17286", "title": "GTA: Grouped-head latenT Attention", "authors": ["Luoyang Sun", "Cheng Deng", "Jiwen Jiang", "Xinjian Wu", "Haifeng Zhang", "Lei Chen", "Lionel Ni", "Jun Wang"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Attention mechanisms underpin the success of large language models (LLMs),\nyet their substantial computational and memory overhead poses challenges for\noptimizing efficiency and performance. A critical bottleneck arises as KV cache\nand attention computations scale rapidly with text length, challenging\ndeployment on hardware with limited computational and memory resources. We\nobserve that attention mechanisms exhibit substantial redundancy, since the KV\ncache can be significantly compressed and attention maps across heads display\nhigh similarity, revealing that much of the computation and storage is\nunnecessary. Leveraging these insights, we propose \\textbf{G}rouped-Head\nLaten\\textbf{T} \\textbf{A}ttention (GTA), a novel attention mechanism that\nreduces memory usage and computational complexity while maintaining\nperformance. GTA comprises two components: (1) a shared attention map mechanism\nthat reuses attention scores across multiple heads, decreasing the key cache\nsize; and (2) a nonlinear value decoder with learned projections that\ncompresses the value cache into a latent space, further cutting memory needs.\nGTA cuts attention computation FLOPs by up to \\emph{62.5\\%} versus\nGrouped-Query Attention and shrink the KV cache by up to \\emph{70\\%}, all while\navoiding the extra overhead of Multi-Head Latent Attention to improve LLM\ndeployment efficiency. Consequently, GTA models achieve a \\emph{2x} increase in\nend-to-end inference speed, with prefill benefiting from reduced computational\ncost and decoding benefiting from the smaller cache footprint."}
{"id": "2507.00782", "pdf": "https://arxiv.org/pdf/2507.00782.pdf", "abs": "https://arxiv.org/abs/2507.00782", "title": "A Diagrammatic Calculus for a Functional Model of Natural Language Semantics", "authors": ["Matthieu Pierre Boyer"], "categories": ["cs.CL", "cs.PL", "J.5; D.3.1; D.3.3"], "comment": "15 pages plus one page appendix, submission to CSL 2026", "summary": "In this paper, we study a functional programming approach to natural language\nsemantics, allowing us to increase the expressiveness of a more traditional\ndenotation style. We will formalize a category based type and effect system to\nrepresent the semantic difference between syntactically equivalent expressions.\nWe then construct a diagrammatic calculus to model parsing and handling of\neffects, providing a method to efficiently compute the denotations for\nsentences."}
{"id": "2507.03038", "pdf": "https://arxiv.org/pdf/2507.03038.pdf", "abs": "https://arxiv.org/abs/2507.03038", "title": "Cautious Next Token Prediction", "authors": ["Yizhou Wang", "Lingzhi Zhang", "Yue Bai", "Mang Tik Chiu", "Zhengmian Hu", "Mingyuan Zhang", "Qihua Dong", "Yu Yin", "Sohrab Amirghodsi", "Yun Fu"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL 2025", "summary": "Next token prediction paradigm has been prevailing for autoregressive models\nin the era of LLMs. The current default sampling choice for popular LLMs is\ntemperature scaling together with nucleus sampling to balance diversity and\ncoherence. Nevertheless, such approach leads to inferior performance in various\nNLP tasks when the model is not certain about testing questions. To this end,\nwe propose a brand new training-free decoding strategy, dubbed as Cautious Next\nToken Prediction (CNTP). In the decoding process, if the model has\ncomparatively high prediction entropy at a certain step, we sample multiple\ntrials starting from the step independently and stop when encountering any\npunctuation. Then we select the trial with the lowest perplexity score viewed\nas the most probable and reliable trial path given the model's capacity. The\ntrial number is negatively correlated with the prediction confidence, i.e., the\nless confident the model is, the more trials it should sample. This is\nconsistent with human beings' behaviour: when feeling uncertain or unconfident,\none tends to think more creatively, exploring multiple thinking paths, to\ncautiously select the path one feels most confident about. Extensive\nexperiments on both LLMs and MLLMs show that our proposed CNTP approach\noutperforms existing standard decoding strategies consistently by a clear\nmargin. Moreover, the integration of CNTP with self consistency can further\nimprove over vanilla self consistency. We believe our proposed CNTP has the\npotential to become one of the default choices for LLM decoding. Code is\navailable at https://github.com/wyzjack/CNTP."}
{"id": "2507.04224", "pdf": "https://arxiv.org/pdf/2507.04224.pdf", "abs": "https://arxiv.org/abs/2507.04224", "title": "Fairness Evaluation of Large Language Models in Academic Library Reference Services", "authors": ["Haining Wang", "Jason Clark", "Yueru Yan", "Star Bradley", "Ruiyang Chen", "Yiqiong Zhang", "Hengyi Fu", "Zuoyu Tian"], "categories": ["cs.CL", "cs.AI", "cs.DL"], "comment": null, "summary": "As libraries explore large language models (LLMs) for use in virtual\nreference services, a key question arises: Can LLMs serve all users equitably,\nregardless of demographics or social status? While they offer great potential\nfor scalable support, LLMs may also reproduce societal biases embedded in their\ntraining data, risking the integrity of libraries' commitment to equitable\nservice. To address this concern, we evaluate whether LLMs differentiate\nresponses across user identities by prompting six state-of-the-art LLMs to\nassist patrons differing in sex, race/ethnicity, and institutional role. We\nfound no evidence of differentiation by race or ethnicity, and only minor\nevidence of stereotypical bias against women in one model. LLMs demonstrated\nnuanced accommodation of institutional roles through the use of linguistic\nchoices related to formality, politeness, and domain-specific vocabularies,\nreflecting professional norms rather than discriminatory treatment. These\nfindings suggest that current LLMs show a promising degree of readiness to\nsupport equitable and contextually appropriate communication in academic\nlibrary reference services."}
{"id": "2507.06565", "pdf": "https://arxiv.org/pdf/2507.06565.pdf", "abs": "https://arxiv.org/abs/2507.06565", "title": "A Mathematical Theory of Discursive Networks", "authors": ["Juan B. Gutiérrez"], "categories": ["cs.CL", "cs.LG", "68T01, 60J10, 91D30, 05C82, 68T50, 68W20, 94A15", "I.2.7; I.2.11; G.3"], "comment": "42 pages, 4 figures, 4 tables, 3 algorithm, 61 references", "summary": "Large language models (LLMs) turn writing into a live exchange between humans\nand software. We characterize this new medium as a discursive network that\ntreats people and LLMs as equal nodes and tracks how their statements\ncirculate. We define the generation of erroneous information as invalidation\n(any factual, logical, or structural breach) and show it follows four hazards:\ndrift from truth, self-repair, fresh fabrication, and external detection. We\ndevelop a general mathematical model of discursive networks that shows that a\nnetwork governed only by drift and self-repair stabilizes at a modest error\nrate. Giving each false claim even a small chance of peer review shifts the\nsystem to a truth-dominant state. We operationalize peer review with the\nopen-source Flaws-of-Others (FOO) algorithm: a configurable loop in which any\nset of agents critique one another while a harmonizer merges their verdicts. We\nidentify an ethical transgression, epithesis, that occurs when humans fail to\nengage in the discursive network. The takeaway is practical and cultural:\nreliability in this new medium comes not from perfecting single models but from\nconnecting imperfect ones into networks that enforce mutual accountability."}
{"id": "2507.09205", "pdf": "https://arxiv.org/pdf/2507.09205.pdf", "abs": "https://arxiv.org/abs/2507.09205", "title": "Advancing Large Language Models for Tibetan with Curated Data and Continual Pre-Training", "authors": ["Leiyu Pan", "Bojian Xiong", "Lei Yang", "Renren Jin", "Shaowei Zhang", "Yue Chen", "Ling Shi", "Jiang Zhou", "Junru Wu", "Zhen Wang", "Jianxiang Peng", "Juesi Xiao", "Tianyu Dong", "Zhuowen Han", "Zhuo Chen", "Yuqi Ren", "Deyi Xiong"], "categories": ["cs.CL"], "comment": null, "summary": "Large language models have achieved remarkable progress across many\nlanguages. However, Tibetan, as a representative low-resource language, is\nparticularly underrepresented in existing models due to the scarcity of\nhigh-quality training corpora. To address this gap, we curate the largest\nTibetan pre-training corpus to date, aggregating data from diverse sources and\napplying a dedicated data cleaning and processing pipeline tailored for\nTibetan. With the curated data, we continue pre/post-training a multilingual\nbase model to enhance its generative capabilities in Tibetan. To evaluate the\nTibetan capabilities of the model, we create new high-quality Tibetan\nbenchmarks, and complement them with existing public benchmarks. Experimental\nresults demonstrate that our model consistently and significantly outperforms\nboth open-source models of similar scale and Tibetan-tailored models across a\nwide range of tasks."}
{"id": "2507.14871", "pdf": "https://arxiv.org/pdf/2507.14871.pdf", "abs": "https://arxiv.org/abs/2507.14871", "title": "Tiny language models", "authors": ["Ronit D. Gross", "Yarden Tzach", "Tal Halevi", "Ella Koresh", "Ido Kanter"], "categories": ["cs.CL"], "comment": "23 pages, 1 figure and 12 tables, The data and code that support the\n  findings of this study are openly available in a GitHub repository at\n  https://github.com/Rg32601/Tiny-Language-Models", "summary": "A prominent achievement of natural language processing (NLP) is its ability\nto understand and generate meaningful human language. This capability relies on\ncomplex feedforward transformer block architectures pre-trained on large\nlanguage models (LLMs). However, LLM pre-training is currently feasible only\nfor a few dominant companies due to the immense computational resources\nrequired, limiting broader research participation. This creates a critical need\nfor more accessible alternatives. In this study, we explore whether tiny\nlanguage models (TLMs) exhibit the same key qualitative features of LLMs. We\ndemonstrate that TLMs exhibit a clear performance gap between pre-trained and\nnon-pre-trained models across classification tasks, indicating the\neffectiveness of pre-training, even at a tiny scale. The performance gap\nincreases with the size of the pre-training dataset and with greater overlap\nbetween tokens in the pre-training and classification datasets. Furthermore,\nthe classification accuracy achieved by a pre-trained deep TLM architecture can\nbe replicated through a soft committee of multiple, independently pre-trained\nshallow architectures, enabling low-latency TLMs without affecting\nclassification accuracy. Our results are based on pre-training BERT-6 and\nvariants of BERT-1 on subsets of the Wikipedia dataset and evaluating their\nperformance on FewRel, AGNews, and DBPedia classification tasks. Future\nresearch on TLM is expected to further illuminate the mechanisms underlying\nNLP, especially given that its biologically inspired models suggest that TLMs\nmay be sufficient for children or adolescents to develop language. The data and\ncode that support the findings of this study are openly available on\nhttps://github.com/Rg32601/Tiny-Language-Models ."}
{"id": "2507.14900", "pdf": "https://arxiv.org/pdf/2507.14900.pdf", "abs": "https://arxiv.org/abs/2507.14900", "title": "From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment", "authors": ["Chongxuan Huang", "Yongshi Ye", "Biao Fu", "Qifeng Su", "Xiaodong Shi"], "categories": ["cs.CL"], "comment": "ACL main 2025", "summary": "Large language models (LLMs) have demonstrated remarkable multilingual\ncapabilities, however, how to evaluate cross-lingual alignment remains\nunderexplored. Existing alignment benchmarks primarily focus on sentence\nembeddings, but prior research has shown that neural models tend to induce a\nnon-smooth representation space, which impact of semantic alignment evaluation\non low-resource languages. Inspired by neuroscientific findings that similar\ninformation activates overlapping neuronal regions, we propose a novel Neuron\nState-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual a\nlignment capabilities of LLMs, which offers a more semantically grounded\napproach to assess cross-lingual alignment. We evaluate NeuronXA on several\nprominent multilingual LLMs (LLaMA, Qwen, Mistral, GLM, and OLMo) across two\ntransfer tasks and three multilingual benchmarks. The results demonstrate that\nwith only 100 parallel sentence pairs, NeuronXA achieves a Pearson correlation\nof 0.9556 with downstream tasks performance and 0.8514 with transferability.\nThese findings demonstrate NeuronXA's effectiveness in assessing both\ncross-lingual alignment and transferability, even with a small dataset. This\nhighlights its potential to advance cross-lingual alignment research and to\nimprove the semantic understanding of multilingual LLMs."}
{"id": "2507.15586", "pdf": "https://arxiv.org/pdf/2507.15586.pdf", "abs": "https://arxiv.org/abs/2507.15586", "title": "Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation", "authors": ["Xinping Zhao", "Shouzheng Huang", "Yan Zhong", "Xinshuo Hu", "Meishan Zhang", "Baotian Hu", "Min Zhang"], "categories": ["cs.CL"], "comment": "16 pages, 7 Figures, 10 Tables", "summary": "Retrieval-Augmented Generation (RAG) effectively improves the accuracy of\nLarge Language Models (LLMs). However, retrieval noises significantly impact\nthe quality of LLMs' generation, necessitating the development of denoising\nmechanisms. Previous methods extract evidence straightforwardly without\nexplicit thinking, which risks filtering out key clues and struggles with\ngeneralization. To this end, we propose LEAR, which learns to extract rational\nevidence by (1) explicitly reasoning to identify potential cues within\nretrieval contents first, and then (2) consciously extracting to avoid omitting\nany key cues helpful for answering questions. Specifically, we frame evidence\nreasoning and evidence extraction into one unified response for end-to-end\ntraining; apply knowledge token masks for disentanglement to derive\nreasoning-based and extraction-based answers; and devise three types of\nverifiable reward functions, including answer, length, and format, to update\nthe model via the policy optimization algorithm. Extensive experiments on three\nbenchmark datasets show the effectiveness of LEAR, providing compact and\nhigh-quality evidence, improving the accuracy of downstream tasks, and\npromoting effective application in online RAG systems."}
{"id": "2507.15850", "pdf": "https://arxiv.org/pdf/2507.15850.pdf", "abs": "https://arxiv.org/abs/2507.15850", "title": "3LM: Bridging Arabic, STEM, and Code through Benchmarking", "authors": ["Basma El Amel Boussaha", "Leen AlQadi", "Mugariya Farooq", "Shaikha Alsuwaidi", "Giulia Campesan", "Ahmed Alzubaidi", "Mohammed Alyafeai", "Hakim Hacid"], "categories": ["cs.CL"], "comment": null, "summary": "Arabic is one of the most widely spoken languages in the world, yet efforts\nto develop and evaluate Large Language Models (LLMs) for Arabic remain\nrelatively limited. Most existing Arabic benchmarks focus on linguistic,\ncultural, or religious content, leaving a significant gap in domains like STEM\nand code which are increasingly relevant for real-world LLM applications. To\nhelp bridge this gap, we present 3LM, a suite of three benchmarks designed\nspecifically for Arabic. The first is a set of STEM-related question-answer\npairs, naturally sourced from Arabic textbooks and educational worksheets. The\nsecond consists of synthetically generated STEM questions, created using the\nsame sources. The third benchmark focuses on code generation, built through a\ncareful translation of two widely used code benchmarks, incorporating a\nhuman-in-the-loop process with several rounds of review to ensure high-quality\nand faithful translations. We release all three benchmarks publicly to support\nthe growth of Arabic LLM research in these essential but underrepresented\nareas."}
{"id": "2507.16199", "pdf": "https://arxiv.org/pdf/2507.16199.pdf", "abs": "https://arxiv.org/abs/2507.16199", "title": "WAKENLLM: Evaluating Reasoning Potential and Stability in LLMs via Fine-Grained Benchmarking", "authors": ["Zipeng Ling", "Yuehao Tang", "Shuliang Liu", "Junqi Yang", "Shenghong Fu", "Yao Wan", "Kejia Huang", "Chen Huang", "Zhichao Hou", "Xuming Hu"], "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) frequently output the label Unknown, yet current\nevaluations focus almost exclusively on whether such answers are honest rather\nthan why they arise. This blurs two distinct cases: (i) an input that is\ngenuinely indeterminate and (ii) a solvable problem that the model fails to\nresolve. We call this phenomenon Vague Perception. And thus we introduce a\nframework that quantifies the proportion of Unknown responses attributable to\nmodel incapacity and tests whether guided stimulation can convert them into\neither correct Known or correct Unknown with valid reasoning. By separating\nthese sources of uncertainty, our method provides a clearer picture of LLM\nreasoning limits and their potential for improvement. As we get a theoretical\naccuracy of reasoning task on different LLMs, we apply different methods to\ntest whether the model can reach the accuracy given a baseline framework. Our\nwork is meaningful in exploring the potential reasoning ability of LLMs and\nproviding a new perspective on solving the Vague Perception phenomenon."}
{"id": "2507.16284", "pdf": "https://arxiv.org/pdf/2507.16284.pdf", "abs": "https://arxiv.org/abs/2507.16284", "title": "Language Detection by Means of the Minkowski Norm: Identification Through Character Bigrams and Frequency Analysis", "authors": ["Paul-Andrei Pogăcean", "Sanda-Maria Avram"], "categories": ["cs.CL"], "comment": null, "summary": "The debate surrounding language identification has gained renewed attention\nin recent years, especially with the rapid evolution of AI-powered language\nmodels. However, the non-AI-based approaches to language identification have\nbeen overshadowed. This research explores a mathematical implementation of an\nalgorithm for language determinism by leveraging monograms and bigrams\nfrequency rankings derived from established linguistic research. The datasets\nused comprise texts varying in length, historical period, and genre, including\nshort stories, fairy tales, and poems. Despite these variations, the method\nachieves over 80\\% accuracy on texts shorter than 150 characters and reaches\n100\\% accuracy for longer texts. These results demonstrate that classical\nfrequency-based approaches remain effective and scalable alternatives to\nAI-driven models for language detection."}
{"id": "2507.16799", "pdf": "https://arxiv.org/pdf/2507.16799.pdf", "abs": "https://arxiv.org/abs/2507.16799", "title": "Test-Time-Matching: Decouple Personality, Memory, and Linguistic Style in LLM-based Role-Playing Language Agent", "authors": ["Xiaoyu Zhan", "Xinyu Fu", "Hao Sun", "Yuanqi Li", "Jie Guo", "Yanwen Guo"], "categories": ["cs.CL"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has enabled\nrole-playing language agents to demonstrate significant potential in various\napplications. However, relying solely on prompts and contextual inputs often\nproves insufficient for achieving deep immersion in specific roles,\nparticularly well-known fictional or public figures. On the other hand,\nfine-tuning-based approaches face limitations due to the challenges associated\nwith data collection and the computational resources required for training,\nthereby restricting their broader applicability. To address these issues, we\npropose Test-Time-Matching (TTM), a training-free role-playing framework\nthrough test-time scaling and context engineering. TTM uses LLM agents to\nautomatically decouple a character's features into personality, memory, and\nlinguistic style. Our framework involves a structured, three-stage generation\npipeline that utilizes these features for controlled role-playing. It achieves\nhigh-fidelity role-playing performance, also enables seamless combinations\nacross diverse linguistic styles and even variations in personality and memory.\nWe evaluate our framework through human assessment, and the results demonstrate\nthat our method achieves the outstanding performance in generating expressive\nand stylistically consistent character dialogues."}
{"id": "2507.16802", "pdf": "https://arxiv.org/pdf/2507.16802.pdf", "abs": "https://arxiv.org/abs/2507.16802", "title": "Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning", "authors": ["Yanjun Zheng", "Xiyang Du", "Longfei Liao", "Xiaoke Zhao", "Zhaowen Zhou", "Bo Zhang", "Jiawei Liu", "Xiang Qi", "Zhe Li", "Zhiqiang Zhang", "Wei Wang", "Peng Zhang"], "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) exhibit considerable promise in financial\napplications; however, prevailing models frequently demonstrate limitations\nwhen confronted with scenarios that necessitate sophisticated reasoning\ncapabilities, stringent trustworthiness criteria, and efficient adaptation to\ndomain-specific requirements. We introduce the Agentar-Fin-R1 series of\nfinancial large language models (8B and 32B parameters), specifically\nengineered based on the Qwen3 foundation model to enhance reasoning\ncapabilities, reliability, and domain specialization for financial\napplications. Our optimization approach integrates a high-quality, systematic\nfinancial task label system with a comprehensive multi-layered trustworthiness\nassurance framework. This framework encompasses high-quality trustworthy\nknowledge engineering, multi-agent trustworthy data synthesis, and rigorous\ndata validation governance. Through label-guided automated difficulty-aware\noptimization, tow-stage training pipeline, and dynamic attribution systems, we\nachieve substantial improvements in training efficiency. Our models undergo\ncomprehensive evaluation on mainstream financial benchmarks including Fineva,\nFinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500\nand GPQA-diamond. To thoroughly assess real-world deployment capabilities, we\ninnovatively propose the Finova evaluation benchmark, which focuses on\nagent-level financial reasoning and compliance verification. Experimental\nresults demonstrate that Agentar-Fin-R1 not only achieves state-of-the-art\nperformance on financial tasks but also exhibits exceptional general reasoning\ncapabilities, validating its effectiveness as a trustworthy solution for\nhigh-stakes financial applications. The Finova bench is available at\nhttps://github.com/antgroup/Finova."}
{"id": "2501.13926", "pdf": "https://arxiv.org/pdf/2501.13926.pdf", "abs": "https://arxiv.org/abs/2501.13926", "title": "Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step", "authors": ["Ziyu Guo", "Renrui Zhang", "Chengzhuo Tong", "Zhizheng Zhao", "Rui Huang", "Haoquan Zhang", "Manyuan Zhang", "Jiaming Liu", "Shanghang Zhang", "Peng Gao", "Hongsheng Li", "Pheng-Ann Heng"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Journal Version. Code and models are released at\n  https://github.com/ZiyuGuo99/Image-Generation-CoT", "summary": "Chain-of-Thought (CoT) reasoning has been extensively explored in large\nmodels to tackle complex understanding tasks. However, it still remains an open\nquestion whether such strategies can be applied to verifying and reinforcing\nimage generation scenarios. In this paper, we provide the first comprehensive\ninvestigation of the potential of CoT reasoning to enhance autoregressive image\ngeneration. We focus on three techniques: scaling test-time computation for\nverification, aligning model preferences with Direct Preference Optimization\n(DPO), and integrating these techniques for complementary effects. Our results\ndemonstrate that these approaches can be effectively adapted and combined to\nsignificantly improve image generation performance. Furthermore, given the\npivotal role of reward models in our findings, we propose the Potential\nAssessment Reward Model (PARM) and PARM++, specialized for autoregressive image\ngeneration. PARM adaptively assesses each generation step through a potential\nassessment approach, merging the strengths of existing reward models, and\nPARM++ further introduces a reflection mechanism to self-correct the generated\nunsatisfactory image, which is the first to incorporate reflection in\nautoregressive image generation. Using our investigated reasoning strategies,\nwe enhance a baseline model, Show-o, to achieve superior results, with a\nsignificant +24% improvement on the GenEval benchmark, surpassing Stable\nDiffusion 3 by +15%. We hope our study provides unique insights and paves a new\npath for integrating CoT reasoning with autoregressive image generation. Code\nand models are released at https://github.com/ZiyuGuo99/Image-Generation-CoT"}
{"id": "2503.01424", "pdf": "https://arxiv.org/pdf/2503.01424.pdf", "abs": "https://arxiv.org/abs/2503.01424", "title": "From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems", "authors": ["Zekun Zhou", "Xiaocheng Feng", "Lei Huang", "Xiachong Feng", "Ziyun Song", "Ruihan Chen", "Liang Zhao", "Weitao Ma", "Yuxuan Gu", "Baoxin Wang", "Dayong Wu", "Guoping Hu", "Ting Liu", "Bing Qin"], "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Research is a fundamental process driving the advancement of human\ncivilization, yet it demands substantial time and effort from researchers. In\nrecent years, the rapid development of artificial intelligence (AI)\ntechnologies has inspired researchers to explore how AI can accelerate and\nenhance research. To monitor relevant advancements, this paper presents a\nsystematic review of the progress in this domain. Specifically, we organize the\nrelevant studies into three main categories: hypothesis formulation, hypothesis\nvalidation, and manuscript publication. Hypothesis formulation involves\nknowledge synthesis and hypothesis generation. Hypothesis validation includes\nthe verification of scientific claims, theorem proving, and experiment\nvalidation. Manuscript publication encompasses manuscript writing and the peer\nreview process. Furthermore, we identify and discuss the current challenges\nfaced in these areas, as well as potential future directions for research.\nFinally, we also offer a comprehensive overview of existing benchmarks and\ntools across various domains that support the integration of AI into the\nresearch process. We hope this paper serves as an introduction for beginners\nand fosters future research. Resources have been made publicly available at\nhttps://github.com/zkzhou126/AI-for-Research."}
{"id": "2503.17352", "pdf": "https://arxiv.org/pdf/2503.17352.pdf", "abs": "https://arxiv.org/abs/2503.17352", "title": "OpenVLThinker: Complex Vision-Language Reasoning via Iterative SFT-RL Cycles", "authors": ["Yihe Deng", "Hritik Bansal", "Fan Yin", "Nanyun Peng", "Wei Wang", "Kai-Wei Chang"], "categories": ["cs.CV", "cs.CL"], "comment": "23 pages, 11 figures, 8 tables", "summary": "We introduce OpenVLThinker, one of the first open-source large\nvision-language models (LVLMs) to exhibit sophisticated chain-of-thought\nreasoning, achieving notable performance gains on challenging visual reasoning\ntasks. While text-based reasoning models (e.g., Deepseek R1) show promising\nresults in text-only tasks, distilling their reasoning into LVLMs via\nsupervised fine-tuning (SFT) often results in performance degradation due to\nimprecise visual grounding. Conversely, purely reinforcement learning\n(RL)-based methods face a large search space, hindering the emergence of\nreflective behaviors in smaller models (e.g., 7B LVLMs). Surprisingly,\nalternating between SFT and RL ultimately results in significant performance\nimprovements after a few iterations. Our analysis reveals that the base model\nrarely exhibits reasoning behaviors initially, but SFT effectively surfaces\nthese latent actions and narrows the RL search space, accelerating the\ndevelopment of reasoning capabilities. Each subsequent RL stage further refines\nthe model's reasoning skills, producing higher-quality SFT data for continued\nself-improvement. OpenVLThinker-7B consistently advances performance across six\nbenchmarks demanding mathematical and general reasoning, notably improving\nMathVista by 3.8%, EMMA by 2.4%, and HallusionBench by 1.6%. Beyond\ndemonstrating the synergy between SFT and RL for complex reasoning tasks, our\nfindings provide early evidence towards achieving R1-style reasoning in\nmultimodal contexts. The code, model and data are held at\nhttps://github.com/yihedeng9/OpenVLThinker."}
{"id": "2504.10352", "pdf": "https://arxiv.org/pdf/2504.10352.pdf", "abs": "https://arxiv.org/abs/2504.10352", "title": "Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis", "authors": ["Yifan Yang", "Shujie Liu", "Jinyu Li", "Yuxuan Hu", "Haibin Wu", "Hui Wang", "Jianwei Yu", "Lingwei Meng", "Haiyang Sun", "Yanqing Liu", "Yan Lu", "Kai Yu", "Xie Chen"], "categories": ["eess.AS", "cs.CL"], "comment": "Accepted in ACM MM 2025", "summary": "Recent zero-shot text-to-speech (TTS) systems face a common dilemma:\nautoregressive (AR) models suffer from slow generation and lack duration\ncontrollability, while non-autoregressive (NAR) models lack temporal modeling\nand typically require complex designs. In this paper, we introduce a novel\npseudo-autoregressive (PAR) codec language modeling approach that unifies AR\nand NAR modeling. Combining explicit temporal modeling from AR with parallel\ngeneration from NAR, PAR generates dynamic-length spans at fixed time steps.\nBuilding on PAR, we propose PALLE, a two-stage TTS system that leverages PAR\nfor initial generation followed by NAR refinement. In the first stage, PAR\nprogressively generates speech tokens along the time dimension, with each step\npredicting all positions in parallel but only retaining the left-most span. In\nthe second stage, low-confidence tokens are iteratively refined in parallel,\nleveraging the global contextual information.Experiments demonstrate that\nPALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on\nlarge-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech\ntest-clean set in terms of speech quality, speaker similarity, and\nintelligibility, while achieving up to ten times faster inference speed. Audio\nsamples are available at https://microsoft.com/research/project/vall-e-x/palle."}
{"id": "2505.04457", "pdf": "https://arxiv.org/pdf/2505.04457.pdf", "abs": "https://arxiv.org/abs/2505.04457", "title": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration", "authors": ["Shigeki Karita", "Yuma Koizumi", "Heiga Zen", "Haruko Ishikawa", "Robin Scheibler", "Michiel Bacchiani"], "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "Accepted to IEEE WASPAA2025", "summary": "Training data cleaning is a new application for generative model-based speech\nrestoration (SR). This paper introduces Miipher-2, an SR model designed for\nmillion-hour scale data, for training data cleaning for large-scale generative\nmodels like large language models. Key challenges addressed include\ngeneralization to unseen languages, operation without explicit conditioning\n(e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a\nfrozen, pre-trained Universal Speech Model (USM), supporting over 300\nlanguages, as a robust, conditioning-free feature extractor. To optimize\nefficiency and minimize memory, Miipher-2 incorporates parallel adapters for\npredicting clean USM features from noisy inputs and employs the WaveFit neural\nvocoder for waveform synthesis. These components were trained on 3,000 hours of\nmulti-lingual, studio-quality recordings with augmented degradations, while USM\nparameters remained fixed. Experimental results demonstrate Miipher-2's\nsuperior or comparable performance to conventional SR models in\nword-error-rate, speaker similarity, and both objective and subjective sound\nquality scores across all tested languages. Miipher-2 operates efficiently on\nconsumer-grade accelerators, achieving a real-time factor of 0.0078, enabling\nthe processing of a million-hour speech dataset in approximately three days\nusing only 100 such accelerators."}
{"id": "2505.18079", "pdf": "https://arxiv.org/pdf/2505.18079.pdf", "abs": "https://arxiv.org/abs/2505.18079", "title": "Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding", "authors": ["Xiaoyi Zhang", "Zhaoyang Jia", "Zongyu Guo", "Jiahao Li", "Bin Li", "Houqiang Li", "Yan Lu"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "V3 draft. Under review", "summary": "Long-form video understanding presents significant challenges due to\nextensive temporal-spatial complexity and the difficulty of question answering\nunder such extended contexts. While Large Language Models (LLMs) have\ndemonstrated considerable advancements in video analysis capabilities and long\ncontext handling, they continue to exhibit limitations when processing\ninformation-dense hour-long videos. To overcome such limitations, we propose\nthe Deep Video Discovery agent to leverage an agentic search strategy over\nsegmented video clips. Different from previous video agents manually designing\na rigid workflow, our approach emphasizes the autonomous nature of agents. By\nproviding a set of search-centric tools on multi-granular video database, our\nDVD agent leverages the advanced reasoning capability of LLM to plan on its\ncurrent observation state, strategically selects tools, formulates appropriate\nparameters for actions, and iteratively refines its internal reasoning in light\nof the gathered information. We perform comprehensive evaluation on multiple\nlong video understanding benchmarks that demonstrates the advantage of the\nentire system design. Our DVD agent achieves SOTA performance, significantly\nsurpassing prior works by a large margin on the challenging LVBench dataset.\nComprehensive ablation studies and in-depth tool analyses are also provided,\nyielding insights to further advance intelligent agents tailored for long-form\nvideo understanding tasks. The code has been released in\nhttps://github.com/microsoft/DeepVideoDiscovery."}
{"id": "2506.15606", "pdf": "https://arxiv.org/pdf/2506.15606.pdf", "abs": "https://arxiv.org/abs/2506.15606", "title": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning", "authors": ["Gabriel J. Perin", "Runjin Chen", "Xuxi Chen", "Nina S. T. Hirata", "Zhangyang Wang", "Junyuan Hong"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have become indispensable in real-world\napplications. However, their widespread adoption raises significant safety\nconcerns, particularly in responding to socially harmful questions. Despite\nsubstantial efforts to improve model safety through alignment, aligned models\ncan still have their safety protections undermined by subsequent fine-tuning -\neven when the additional training data appears benign. In this paper, we\nempirically demonstrate that this vulnerability stems from the sensitivity of\nsafety-critical low-rank subspaces in LLM parameters to fine-tuning. Building\non this insight, we propose a novel training-free method, termed Low-Rank\nExtrapolation (LoX), to enhance safety robustness by extrapolating the safety\nsubspace of an aligned LLM. Our experimental results confirm the effectiveness\nof LoX, demonstrating significant improvements in robustness against both\nbenign and malicious fine-tuning attacks while preserving the model's\nadaptability to new tasks. For instance, LoX leads to 11% to 54% absolute\nreductions in attack success rates (ASR) facing benign or malicious fine-tuning\nattacks. By investigating the ASR landscape of parameters, we attribute the\nsuccess of LoX to that the extrapolation moves LLM parameters to a flatter\nzone, thereby less sensitive to perturbations. The code is available at\ngithub.com/VITA-Group/LoX."}
{"id": "2507.05515", "pdf": "https://arxiv.org/pdf/2507.05515.pdf", "abs": "https://arxiv.org/abs/2507.05515", "title": "LEGO Co-builder: Exploring Fine-Grained Vision-Language Modeling for Multimodal LEGO Assembly Assistants", "authors": ["Haochen Huang", "Jiahuan Pei", "Mohammad Aliannejadi", "Xin Sun", "Moonisa Ahsan", "Chuang Yu", "Zhaochun Ren", "Pablo Cesar", "Junxiao Wang"], "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "This version has been anonymized for double-blind review", "summary": "Vision-language models (VLMs) are facing the challenges of understanding and\nfollowing multimodal assembly instructions, particularly when fine-grained\nspatial reasoning and precise object state detection are required. In this\nwork, we explore LEGO Co-builder, a hybrid benchmark combining real-world LEGO\nassembly logic with programmatically generated multimodal scenes. The dataset\ncaptures stepwise visual states and procedural instructions, allowing\ncontrolled evaluation of instruction-following, object detection, and state\ndetection. We introduce a unified framework and assess leading VLMs such as\nGPT-4o, Gemini, and Qwen-VL, under zero-shot and fine-tuned settings. Our\nresults reveal that even advanced models like GPT-4o struggle with fine-grained\nassembly tasks, with a maximum F1 score of just 40.54\\% on state detection,\nhighlighting gaps in fine-grained visual understanding. We release the\nbenchmark, codebase, and generation pipeline to support future research on\nmultimodal assembly assistants grounded in real-world workflows."}
{"id": "2507.14534", "pdf": "https://arxiv.org/pdf/2507.14534.pdf", "abs": "https://arxiv.org/abs/2507.14534", "title": "Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion", "authors": ["Yu Zhang", "Baotong Tian", "Zhiyao Duan"], "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": null, "summary": "Zero-shot online voice conversion (VC) holds significant promise for\nreal-time communications and entertainment. However, current VC models struggle\nto preserve semantic fidelity under real-time constraints, deliver\nnatural-sounding conversions, and adapt effectively to unseen speaker\ncharacteristics. To address these challenges, we introduce Conan, a chunkwise\nonline zero-shot voice conversion model that preserves the content of the\nsource while matching the voice timbre and styles of reference speech. Conan\ncomprises three core components: 1) a Stream Content Extractor that leverages\nEmformer for low-latency streaming content encoding; 2) an Adaptive Style\nEncoder that extracts fine-grained stylistic features from reference speech for\nenhanced style adaptation; 3) a Causal Shuffle Vocoder that implements a fully\ncausal HiFiGAN using a pixel-shuffle mechanism. Experimental evaluations\ndemonstrate that Conan outperforms baseline models in subjective and objective\nmetrics. Audio samples can be found at https://aaronz345.github.io/ConanDemo."}
