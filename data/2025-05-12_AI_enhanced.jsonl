{"id": "2505.05583", "pdf": "https://arxiv.org/pdf/2505.05583.pdf", "abs": "https://arxiv.org/abs/2505.05583", "title": "KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification", "authors": ["Qianbo Zang", "Christophe Zgrzendek", "Igor Tchappi", "Afshin Khadangi", "Johannes Sedlmeir"], "categories": ["cs.CL"], "comment": null, "summary": "Hierarchical Text Classification (HTC) involves assigning documents to labels\norganized within a taxonomy. Most previous research on HTC has focused on\nsupervised methods. However, in real-world scenarios, employing supervised HTC\ncan be challenging due to a lack of annotated data. Moreover, HTC often faces\nissues with large label spaces and long-tail distributions. In this work, we\npresent Knowledge Graphs for zero-shot Hierarchical Text Classification\n(KG-HTC), which aims to address these challenges of HTC in applications by\nintegrating knowledge graphs with Large Language Models (LLMs) to provide\nstructured semantic context during classification. Our method retrieves\nrelevant subgraphs from knowledge graphs related to the input text using a\nRetrieval-Augmented Generation (RAG) approach. Our KG-HTC can enhance LLMs to\nunderstand label semantics at various hierarchy levels. We evaluate KG-HTC on\nthree open-source HTC datasets: WoS, DBpedia, and Amazon. Our experimental\nresults show that KG-HTC significantly outperforms three baselines in the\nstrict zero-shot setting, particularly achieving substantial improvements at\ndeeper levels of the hierarchy. This evaluation demonstrates the effectiveness\nof incorporating structured knowledge into LLMs to address HTC's challenges in\nlarge label spaces and long-tailed label distributions. Our code is available\nat: https://github.com/QianboZang/KG-HTC.", "AI": {"tldr": "This paper presents KG-HTC, a method that integrates knowledge graphs with LLMs for zero-shot hierarchical text classification to address challenges associated with label spaces and long-tailed distributions.", "motivation": "Hierarchical Text Classification (HTC) often struggles with supervised methods due to the lack of annotated data and challenges related to large label spaces and long-tail distributions.", "method": "The proposed KG-HTC utilizes knowledge graphs and a Retrieval-Augmented Generation (RAG) approach to retrieve relevant subgraphs, providing semantic context to improve LLMs’ understanding of hierarchical label semantics.", "result": "KG-HTC outperforms three baselines in strict zero-shot settings across three datasets (WoS, DBpedia, Amazon), showing significant improvements especially at deeper levels of hierarchy.", "conclusion": "Integrating structured knowledge into LLMs enhances their performance in hierarchical text classification, particularly in addressing challenges posed by large label spaces and long-tailed distributions.", "key_contributions": ["Introduction of KG-HTC for zero-shot HTC using knowledge graphs", "Demonstration of substantial performance improvements in chained hierarchies", "Provision of open-source code for algorithm implementation"], "limitations": "", "keywords": ["Hierarchical Text Classification", "Knowledge Graphs", "Large Language Models", "Zero-Shot Learning", "Retrieval-Augmented Generation"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2505.05648", "pdf": "https://arxiv.org/pdf/2505.05648.pdf", "abs": "https://arxiv.org/abs/2505.05648", "title": "Privacy-Preserving Transformers: SwiftKey's Differential Privacy Implementation", "authors": ["Abdelrahman Abouelenin", "Mohamed Abdelrehim", "Raffy Fahim", "Amr Hendy", "Mohamed Afify"], "categories": ["cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "In this paper we train a transformer using differential privacy (DP) for\nlanguage modeling in SwiftKey. We run multiple experiments to balance the\ntrade-off between the model size, run-time speed and accuracy. We show that we\nget small and consistent gains in the next-word-prediction and accuracy with\ngraceful increase in memory and speed compared to the production GRU. This is\nobtained by scaling down a GPT2 architecture to fit the required size and a two\nstage training process that builds a seed model on general data and DP\nfinetunes it on typing data. The transformer is integrated using ONNX offering\nboth flexibility and efficiency.", "AI": {"tldr": "This paper demonstrates the training of a differential privacy transformer for language modeling, focusing on balancing model size, speed, and accuracy via an adapted GPT-2 architecture.", "motivation": "To improve language modeling for SwiftKey while ensuring user privacy through differential privacy techniques.", "method": "A transformer model based on a scaled-down GPT-2 architecture is trained in two stages: building a seed model on general data followed by differential privacy fine-tuning on typing data, integrated via ONNX for flexibility and efficiency.", "result": "Achieved small and consistent gains in next-word prediction and accuracy, with improvements in memory and speed over the production GRU model.", "conclusion": "The differential privacy transformer provides an effective approach to enhance language modeling while maintaining user privacy.", "key_contributions": ["Introduction of differential privacy in transformer-based language modeling", "Development of a two-stage training process for model refinement", "Integration of the model using ONNX for flexible deployment"], "limitations": "The study may be limited by the specific datasets used for fine-tuning and the inherent trade-offs in privacy and model performance.", "keywords": ["Differential Privacy", "Transformer", "Language Modeling", "GPT-2", "SwiftKey"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2505.05687", "pdf": "https://arxiv.org/pdf/2505.05687.pdf", "abs": "https://arxiv.org/abs/2505.05687", "title": "Exploration of COVID-19 Discourse on Twitter: American Politician Edition", "authors": ["Cindy Kim", "Daniela Puchall", "Jiangyi Liang", "Jiwon Kim"], "categories": ["cs.CL"], "comment": null, "summary": "The advent of the COVID-19 pandemic has undoubtedly affected the political\nscene worldwide and the introduction of new terminology and public opinions\nregarding the virus has further polarized partisan stances. Using a collection\nof tweets gathered from leading American political figures online (Republican\nand Democratic), we explored the partisan differences in approach, response,\nand attitude towards handling the international crisis. Implementation of the\nbag-of-words, bigram, and TF-IDF models was used to identify and analyze\nkeywords, topics, and overall sentiments from each party. Results suggest that\nDemocrats are more concerned with the casualties of the pandemic, and give more\nmedical precautions and recommendations to the public whereas Republicans are\nmore invested in political responsibilities such as keeping the public updated\nthrough media and carefully watching the progress of the virus. We propose a\nsystematic approach to predict and distinguish a tweet's political stance (left\nor right leaning) based on its COVID-19 related terms using different\nclassification algorithms on different language models.", "AI": {"tldr": "The paper analyzes partisan differences in responses to COVID-19 through a study of tweets from political figures, employing NLP models to distinguish political stances.", "motivation": "To explore how the COVID-19 pandemic has influenced political discourse and public opinion, highlighting differences between Republican and Democratic responses.", "method": "The study uses bag-of-words, bigram, and TF-IDF models to analyze tweets from political figures, identifying keywords, topics, and sentiments related to COVID-19.", "result": "The analysis reveals that Democrats focus more on health concerns and recommendations, while Republicans emphasize political responsibilities and media updates regarding the virus.", "conclusion": "The paper proposes a systematic approach to classify tweets by political stance based on COVID-19 terminology using various classification algorithms.", "key_contributions": ["Analysis of political discourse during COVID-19 using tweet data", "Application of NLP techniques to identify sentiments and topics in political tweets", "Proposed classification model for predicting political stance based on COVID-19 terms"], "limitations": "The study focuses only on tweets from American political figures, which may not represent broader public sentiments or responses.", "keywords": ["COVID-19", "sentiment analysis", "political stance", "NLP", "tweet analysis"], "importance_score": 4, "read_time_minutes": 10}}
{"id": "2505.05704", "pdf": "https://arxiv.org/pdf/2505.05704.pdf", "abs": "https://arxiv.org/abs/2505.05704", "title": "Assessing Robustness to Spurious Correlations in Post-Training Language Models", "authors": ["Julia Shuieh", "Prasann Singhal", "Apaar Shanker", "John Heyer", "George Pu", "Samuel Denton"], "categories": ["cs.CL", "cs.AI"], "comment": "ICLR '25 Workshop on Spurious Correlation and Shortcut Learning", "summary": "Supervised and preference-based fine-tuning techniques have become popular\nfor aligning large language models (LLMs) with user intent and correctness\ncriteria. However, real-world training data often exhibits spurious\ncorrelations -- arising from biases, dataset artifacts, or other \"shortcut\"\nfeatures -- that can compromise a model's performance or generalization. In\nthis paper, we systematically evaluate three post-training algorithms --\nSupervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and KTO\n(Kahneman-Tversky Optimization) -- across a diverse set of synthetic tasks and\nspuriousness conditions. Our tasks span mathematical reasoning, constrained\ninstruction-following, and document-grounded question answering. We vary the\ndegree of spurious correlation (10% vs. 90%) and investigate two forms of\nartifacts: \"Feature Ambiguity\" and \"Distributional Narrowness.\" Our results\nshow that the models often but not always degrade under higher spuriousness.\nThe preference-based methods (DPO/KTO) can demonstrate relative robustness in\nmathematical reasoning tasks. By contrast, SFT maintains stronger performance\nin complex, context-intensive tasks. These findings highlight that no single\npost-training strategy universally outperforms in all scenarios; the best\nchoice depends on the type of target task and the nature of spurious\ncorrelations.", "AI": {"tldr": "This paper evaluates three post-training algorithms for aligning large language models with user intent while addressing issues of spurious correlations in training data.", "motivation": "To address the impact of spurious correlations in training data on the performance of large language models (LLMs).", "method": "Systematic evaluation of Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Kahneman-Tversky Optimization (KTO) across synthetic tasks and different spuriousness conditions.", "result": "Models generally degrade in performance under higher spuriousness, but preference-based methods (DPO/KTO) show robustness in mathematical reasoning tasks, while SFT excels in complex tasks.", "conclusion": "No single post-training strategy is universally superior; the best approach depends on the target task and nature of spurious correlations.", "key_contributions": ["Evaluation of post-training algorithms under varying degrees of spurious correlation", "Insights on the performance of SFT, DPO, and KTO in different scenarios", "Identification of task-dependent strategies for LLM alignment"], "limitations": "Focus on synthetic tasks may limit generalizability to real-world applications.", "keywords": ["large language models", "spurious correlations", "Supervised Fine-Tuning", "Direct Preference Optimization", "Kahneman-Tversky Optimization"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2505.05543", "pdf": "https://arxiv.org/pdf/2505.05543.pdf", "abs": "https://arxiv.org/abs/2505.05543", "title": "Would You Rely on an Eerie Agent? A Systematic Review of the Impact of the Uncanny Valley Effect on Trust in Human-Agent Interaction", "authors": ["Ahdiyeh Alipour", "Tilo Hartmann", "Maryam Alimardani"], "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "75 pages, Figure 11, Table 5", "summary": "Trust is a fundamental component of human-agent interaction. With the\nincreasing presence of artificial agents in daily life, it is essential to\nunderstand how people perceive and trust these agents. One of the key\nchallenges affecting this perception is the Uncanny Valley Effect (UVE), where\nincreasingly human-like artificial beings can be perceived as eerie or\nrepelling. Despite growing interest in trust and the UVE, existing research\nvaries widely in terms of how these concepts are defined and operationalized.\nThis inconsistency raises important questions about how and under what\nconditions the UVE influences trust in agents. A systematic understanding of\ntheir relationship is currently lacking. This review aims to examine the impact\nof the UVE on human trust in agents and to identify methodological patterns,\nlimitations, and gaps in the existing empirical literature. Following PRISMA\nguidelines, a systematic search identified 53 empirical studies that\ninvestigated both UVE-related constructs and trust or trust-related outcomes.\nStudies were analyzed based on a structured set of categories, including types\nof agents and interactions, methodological and measurement approaches, and key\nfindings. The results of our systematic review reveal that most studies rely on\nstatic images or hypothetical scenarios with limited real-time interaction, and\nthe majority use subjective trust measures. This review offers a novel\nframework for classifying trust measurement approaches with regard to the\nbest-practice criteria for empirically investigating the UVE. As the first\nsystematic attempt to map the intersection of UVE and trust, this review\ncontributes to a deeper understanding of their interplay and offers a\nfoundation for future research. Keywords: the uncanny valley effect, trust,\nhuman-likeness, affinity response, human-agent interaction", "AI": {"tldr": "This review explores the relationship between the Uncanny Valley Effect (UVE) and trust in human-agent interactions, analyzing empirical studies to identify methodological patterns and gaps.", "motivation": "To understand how the Uncanny Valley Effect influences trust in artificial agents, given its implications for human-agent interactions in an increasingly automated world.", "method": "Systematic review following PRISMA guidelines, analyzing 53 empirical studies related to UVE and trust within various contexts.", "result": "The review finds that most studies use static images or hypothetical scenarios, with limited real-time interaction, primarily measuring subjective trust.", "conclusion": "This review offers a novel framework for classifying trust measurement approaches, highlighting the need for better empirical methods and setting the groundwork for future research.", "key_contributions": ["Identification of methodological gaps in the study of UVE and trust", "Framework for classifying trust measurement approaches", "First systematic review mapping the intersection of UVE and trust"], "limitations": "Most studies depend on non-interactive scenarios and subjective measures that may not reflect real-world interactions.", "keywords": ["uncanny valley effect", "trust", "human-likeness", "affinity response", "human-agent interaction"], "importance_score": 8, "read_time_minutes": 75}}
{"id": "2505.05714", "pdf": "https://arxiv.org/pdf/2505.05714.pdf", "abs": "https://arxiv.org/abs/2505.05714", "title": "TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine Translation for Documentaries", "authors": ["Jinze Lv", "Jian Chen", "Zi Long", "Xianghua Fu", "Yin Chen"], "categories": ["cs.CL"], "comment": "NLDB 2025", "summary": "Most existing multimodal machine translation (MMT) datasets are predominantly\ncomposed of static images or short video clips, lacking extensive video data\nacross diverse domains and topics. As a result, they fail to meet the demands\nof real-world MMT tasks, such as documentary translation. In this study, we\ndeveloped TopicVD, a topic-based dataset for video-supported multimodal machine\ntranslation of documentaries, aiming to advance research in this field. We\ncollected video-subtitle pairs from documentaries and categorized them into\neight topics, such as economy and nature, to facilitate research on domain\nadaptation in video-guided MMT. Additionally, we preserved their contextual\ninformation to support research on leveraging the global context of\ndocumentaries in video-guided MMT. To better capture the shared semantics\nbetween text and video, we propose an MMT model based on a cross-modal\nbidirectional attention module. Extensive experiments on the TopicVD dataset\ndemonstrate that visual information consistently improves the performance of\nthe NMT model in documentary translation. However, the MMT model's performance\nsignificantly declines in out-of-domain scenarios, highlighting the need for\neffective domain adaptation methods. Additionally, experiments demonstrate that\nglobal context can effectively improve translation performance. % Dataset and\nour implementations are available at https://github.com/JinzeLv/TopicVD", "AI": {"tldr": "This paper presents TopicVD, a dataset for video-supported multimodal machine translation of documentaries, and an MMT model leveraging cross-modal bidirectional attention.", "motivation": "To address the lack of extensive video data in existing multimodal machine translation datasets for real-world applications like documentary translation.", "method": "The authors collected video-subtitle pairs from documentaries, categorized them into eight topics, and proposed an MMT model using a cross-modal bidirectional attention module.", "result": "Experiments showed that visual information enhances the performance of the NMT model in documentary translation, but performance declines in out-of-domain scenarios.", "conclusion": "The study highlights the importance of domain adaptation methods and demonstrates that global context improves translation performance.", "key_contributions": ["Introduction of TopicVD, a diverse video-supported MMT dataset for documentary translation", "Development of a cross-modal bidirectional attention-based MMT model", "Empirical evaluation of the impact of visual information and global context on translation performance"], "limitations": "MMT model performance is significantly weakened in out-of-domain situations.", "keywords": ["multimodal machine translation", "documentary", "video data", "domain adaptation", "cross-modal attention"], "importance_score": 6, "read_time_minutes": 15}}
{"id": "2505.05660", "pdf": "https://arxiv.org/pdf/2505.05660.pdf", "abs": "https://arxiv.org/abs/2505.05660", "title": "Not Like Us, Hunty: Measuring Perceptions and Behavioral Effects of Minoritized Anthropomorphic Cues in LLMs", "authors": ["Jeffrey Basoah", "Daniel Chechelnitsky", "Tao Long", "Katharina Reinecke", "Chrysoula Zerva", "Kaitlyn Zhou", "Mark Díaz", "Maarten Sap"], "categories": ["cs.HC"], "comment": "Accepted to FAccT 2025", "summary": "As large language models (LLMs) increasingly adapt and personalize to diverse\nsets of users, there is an increased risk of systems appropriating sociolects,\ni.e., language styles or dialects that are associated with specific minoritized\nlived experiences (e.g., African American English, Queer slang). In this work,\nwe examine whether sociolect usage by an LLM agent affects user reliance on its\noutputs and user perception (satisfaction, frustration, trust, and social\npresence). We designed and conducted user studies where 498 African American\nEnglish (AAE) speakers and 487 Queer slang speakers performed a set of\nquestion-answering tasks with LLM-based suggestions in either standard American\nEnglish (SAE) or their self-identified sociolect. Our findings showed that\nsociolect usage by LLMs influenced both reliance and perceptions, though in\nsome surprising ways. Results suggest that both AAE and Queer slang speakers\nrelied more on the SAE agent, and had more positive perceptions of the SAE\nagent. Yet, only Queer slang speakers felt more social presence from the Queer\nslang agent over the SAE one, whereas only AAE speakers preferred and trusted\nthe SAE agent over the AAE one. These findings emphasize the need to test for\nbehavioral outcomes rather than simply assume that personalization would lead\nto a better and safer reliance outcome. They also highlight the nuanced\ndynamics of minoritized language in machine interactions, underscoring the need\nfor LLMs to be carefully designed to respect cultural and linguistic boundaries\nwhile fostering genuine user engagement and trust.", "AI": {"tldr": "This paper explores the impact of large language models (LLMs) using sociolects on user trust and satisfaction among speakers of African American English and Queer slang.", "motivation": "With the rise of LLMs, there is a risk of appropriating specific linguistic styles associated with minoritized cultures, leading to questions about user trust and satisfaction.", "method": "User studies were conducted with 498 African American English speakers and 487 Queer slang speakers who interacted with LLMs providing responses in either their sociolect or standard American English (SAE).", "result": "The findings revealed that both groups generally relied more on the SAE responses and perceived them more positively, while preferences varied; Queer slang speakers connected more with the Queer slang agent, whereas AAE speakers preferred the SAE agent.", "conclusion": "The results indicate that personalization in LLMs does not inherently lead to increased user reliance or satisfaction, highlighting the need for careful design that respects cultural and linguistic boundaries.", "key_contributions": ["Examined the effects of sociolect usage in LLM interactions on user perception and trust.", "Highlighted the unexpected reliance and trust dynamics in responses from different linguistic styles.", "Called for thoughtful design of LLMs to respect cultural nuances and enhance user engagement."], "limitations": "The study's results may not generalize beyond the specific user groups and tasks examined.", "keywords": ["large language models", "sociolects", "user experience", "trust", "cultural appropriateness"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2505.05755", "pdf": "https://arxiv.org/pdf/2505.05755.pdf", "abs": "https://arxiv.org/abs/2505.05755", "title": "Insertion Language Models: Sequence Generation with Arbitrary-Position Insertions", "authors": ["Dhruvesh Patel", "Aishwarya Sahoo", "Avinash Amballa", "Tahira Naseem", "Tim G. J. Rudner", "Andrew McCallum"], "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Autoregressive models (ARMs), which predict subsequent tokens one-by-one\n``from left to right,'' have achieved significant success across a wide range\nof sequence generation tasks. However, they struggle to accurately represent\nsequences that require satisfying sophisticated constraints or whose sequential\ndependencies are better addressed by out-of-order generation. Masked Diffusion\nModels (MDMs) address some of these limitations, but the process of unmasking\nmultiple tokens simultaneously in MDMs can introduce incoherences, and MDMs\ncannot handle arbitrary infilling constraints when the number of tokens to be\nfilled in is not known in advance. In this work, we introduce Insertion\nLanguage Models (ILMs), which learn to insert tokens at arbitrary positions in\na sequence -- that is, they select jointly both the position and the vocabulary\nelement to be inserted. By inserting tokens one at a time, ILMs can represent\nstrong dependencies between tokens, and their ability to generate sequences in\narbitrary order allows them to accurately model sequences where token\ndependencies do not follow a left-to-right sequential structure. To train ILMs,\nwe propose a tailored network parameterization and use a simple denoising\nobjective. Our empirical evaluation demonstrates that ILMs outperform both ARMs\nand MDMs on common planning tasks. Furthermore, we show that ILMs outperform\nMDMs and perform on par with ARMs in an unconditional text generation task\nwhile offering greater flexibility than MDMs in arbitrary-length text\ninfilling.", "AI": {"tldr": "This paper introduces Insertion Language Models (ILMs) for improved sequence generation by allowing token insertion at arbitrary positions, addressing limitations of existing autoregressive and masked diffusion models.", "motivation": "The motivation of the paper is to overcome the limitations of autoregressive models (ARMs) and masked diffusion models (MDMs) in accurately generating sequences that require sophisticated constraints or non-linear dependencies.", "method": "The paper proposes Insertion Language Models (ILMs) which learn to insert tokens at arbitrary positions in a sequence, controlling both the position and the vocabulary element to be inserted, thus handling dependencies better than previous models.", "result": "Empirical evaluations show that ILMs outperform both ARMs and MDMs on common planning tasks and perform similarly to ARMs in unconditional text generation while providing greater flexibility.", "conclusion": "ILMs present a viable solution for sequence generation, effectively managing complex dependencies and arbitrary-length infilling situations.", "key_contributions": ["Introduction of Insertion Language Models (ILMs) for token insertion at arbitrary positions", "Demonstration of ILMs outperforming ARMs and MDMs in various tasks", "Proposed tailored network parameterization and simple denoising objective for training ILMs"], "limitations": "", "keywords": ["Insertion Language Models", "sequence generation", "masked diffusion models"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2505.05694", "pdf": "https://arxiv.org/pdf/2505.05694.pdf", "abs": "https://arxiv.org/abs/2505.05694", "title": "Extending Stress Detection Reproducibility to Consumer Wearable Sensors", "authors": ["Ohida Binte Amin", "Varun Mishra", "Tinashe M. Tapera", "Robert Volpe", "Aarti Sathyanarayana"], "categories": ["cs.HC", "cs.LG"], "comment": "Accepted at IEEE EMBC 2025", "summary": "Wearable sensors are widely used to collect physiological data and develop\nstress detection models. However, most studies focus on a single dataset,\nrarely evaluating model reproducibility across devices, populations, or study\nconditions. We previously assessed the reproducibility of stress detection\nmodels across multiple studies, testing models trained on one dataset against\nothers using heart rate (with R-R interval) and electrodermal activity (EDA).\nIn this study, we extended our stress detection reproducibility to consumer\nwearable sensors. We compared validated research-grade devices, to consumer\nwearables - Biopac MP160, Polar H10, Empatica E4, to the Garmin Forerunner 55s,\nassessing device-specific stress detection performance by conducting a new\nstress study on undergraduate students. Thirty-five students completed three\nstandardized stress-induction tasks in a lab setting. Biopac MP160 performed\nthe best, being consistent with our expectations of it as the gold standard,\nthough performance varied across devices and models. Combining heart rate\nvariability (HRV) and EDA enhanced stress prediction across most scenarios.\nHowever, Empatica E4 showed variability; while HRV and EDA improved stress\ndetection in leave-one-subject-out (LOSO) evaluations (AUROC up to 0.953),\ndevice-specific limitations led to underperformance when tested with our\npre-trained stress detection tool (AUROC 0.723), highlighting generalizability\nchallenges related to hardware-model compatibility. Garmin Forerunner 55s\ndemonstrated strong potential for real-world stress monitoring, achieving the\nbest mental arithmetic stress detection performance in LOSO (AUROC up to 0.961)\ncomparable to research-grade devices like Polar H10 (AUROC 0.954), and Empatica\nE4 (AUROC 0.905 with HRV-only model and AUROC 0.953 with HRV+EDA model), with\nthe added advantage of consumer-friendly wearability for free-living contexts.", "AI": {"tldr": "This study evaluates the reproducibility of stress detection models using consumer wearable sensors compared to research-grade devices, highlighting the performance variability and implications for real-world application.", "motivation": "To assess the reproducibility of stress detection models across different wearable devices and settings, addressing the gap in previous studies that focused on single datasets and lack of cross-device generalizability.", "method": "The study involved validated research devices (Biopac MP160, Polar H10, Empatica E4) and consumer wearables (Garmin Forerunner 55s), with 35 undergraduate students completing standardized stress-induction tasks to evaluate device-specific performance in stress detection.", "result": "Biopac MP160 outperformed other devices, while the Garmin Forerunner 55s demonstrated strong performance in real-world scenarios. Combining heart rate variability and EDA improved stress prediction overall, but device-specific limitations affected the reliability of certain setups.", "conclusion": "Consumer wearables can effectively monitor stress in real-world settings, though device-specific performance and compatibility with pre-trained models present challenges that need to be addressed for broader application.", "key_contributions": ["Evaluation of stress detection accuracy across a range of wearable sensors", "Identification of performance variability and generalizability issues in stress detection models", "Highlighting the potential of consumer wearables for real-time stress monitoring"], "limitations": "The study mainly assessed a limited number of consumer devices and specific stress-induction tasks, which may not represent all possible scenarios or devices.", "keywords": ["wearable sensors", "stress detection", "HRV", "electrodermal activity", "reproducibility"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2505.05772", "pdf": "https://arxiv.org/pdf/2505.05772.pdf", "abs": "https://arxiv.org/abs/2505.05772", "title": "Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM", "authors": ["Zehao Fan", "Garrett Gagnon", "Zhenyu Liu", "Liu Liu"], "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Transformer-based models are the foundation of modern machine learning, but\ntheir execution, particularly during autoregressive decoding in large language\nmodels (LLMs), places significant pressure on memory systems due to frequent\nmemory accesses and growing key-value (KV) caches. This creates a bottleneck in\nmemory bandwidth, especially as context lengths increase. Processing-in-memory\n(PIM) architectures are a promising solution, offering high internal bandwidth\nand compute parallelism near memory. However, current PIM designs are primarily\noptimized for dense attention and struggle with the dynamic, irregular access\npatterns introduced by modern KV cache sparsity techniques. Consequently, they\nsuffer from workload imbalance, reducing throughput and resource utilization.\nIn this work, we propose STARC, a novel sparsity-optimized data mapping scheme\ntailored specifically for efficient LLM decoding on PIM architectures. STARC\nclusters KV pairs by semantic similarity and maps them to contiguous memory\nregions aligned with PIM bank structures. During decoding, queries retrieve\nrelevant tokens at cluster granularity by matching against precomputed\ncentroids, enabling selective attention and parallel processing without\nfrequent reclustering or data movement overhead. Experiments on the HBM-PIM\nsystem show that, compared to common token-wise sparsity methods, STARC reduces\nattention-layer latency by 19%--31% and energy consumption by 19%--27%. Under a\nKV cache budget of 1024, it achieves up to 54%--74% latency reduction and\n45%--67% energy reduction compared to full KV cache retrieval. Meanwhile, STARC\nmaintains model accuracy comparable to state-of-the-art sparse attention\nmethods, demonstrating its effectiveness in enabling efficient and\nhardware-friendly long-context LLM inference on PIM architectures.", "AI": {"tldr": "This paper introduces STARC, a novel data mapping scheme that optimizes transformer model decoding on processing-in-memory (PIM) architectures, significantly reducing latency and energy consumption during autoregressive decoding.", "motivation": "Large language models (LLMs) face memory bandwidth bottlenecks during autoregressive decoding due to frequent memory accesses and large key-value (KV) caches. Processing-in-memory (PIM) architectures could alleviate these issues but struggle with irregular access patterns.", "method": "STARC groups KV pairs by semantic similarity and maps them to contiguous memory regions. This allows queries to retrieve tokens at cluster granularity during decoding, reducing data movement overhead and improving processing efficiency.", "result": "STARC reduces attention-layer latency by 19%–31% and energy consumption by 19%–27% compared to token-wise sparsity methods. It achieves latency reduction of 54%–74% and energy reduction of 45%–67% under specific KV cache budgets.", "conclusion": "STARC demonstrates effective hardware-friendly LLM inference on PIM architectures while maintaining model accuracy similar to existing sparse attention methods.", "key_contributions": ["Novel sparsity-optimized data mapping scheme for LLMs", "Reduction of latency and energy consumption during decoding", "Maintaining model accuracy while improving efficiency"], "limitations": "", "keywords": ["Transformers", "Processing-in-memory", "Large language models", "Sparsity methods", "Memory architecture"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2505.05786", "pdf": "https://arxiv.org/pdf/2505.05786.pdf", "abs": "https://arxiv.org/abs/2505.05786", "title": "A Day in Their Shoes: Using LLM-Based Perspective-Taking Interactive Fiction to Reduce Stigma Toward Dirty Work", "authors": ["Xiangzhe Yuan", "Jiajun Wang", "Qian Wan", "Siying Hu"], "categories": ["cs.HC", "cs.CY"], "comment": "Conference paper for FAccT '25", "summary": "Occupations referred to as \"dirty work\" often face entrenched social stigma,\nwhich adversely affects the mental health of workers in these fields and\nimpedes occupational equity. In this study, we propose a novel Interactive\nFiction (IF) framework powered by Large Language Models (LLMs) to encourage\nperspective-taking and reduce biases against these stigmatized yet essential\nroles. Through an experiment with participants (n = 100) across four such\noccupations, we observed a significant increase in participants' understanding\nof these occupations, as well as a high level of empathy and a strong sense of\nconnection to individuals in these roles. Additionally, qualitative interviews\nwith participants (n = 15) revealed that the LLM-based perspective-taking IF\nenhanced immersion, deepened emotional resonance and empathy toward \"dirty\nwork,\" and allowed participants to experience a sense of professional\nfulfillment in these occupations. However, participants also highlighted\nongoing challenges, such as limited contextual details generated by the LLM and\nthe unintentional reinforcement of existing stereotypes. Overall, our findings\nunderscore that an LLM-based perspective-taking IF framework offers a promising\nand scalable strategy for mitigating stigma and promoting social equity in\nmarginalized professions.", "AI": {"tldr": "This study presents an Interactive Fiction framework using Large Language Models to reduce stigma associated with 'dirty work' occupations through perspective-taking, demonstrating significant increases in understanding and empathy among participants.", "motivation": "To address the social stigma faced by 'dirty work' occupations, which negatively impacts the mental health of workers and challenges occupational equity.", "method": "An interactive fiction framework powered by large language models was tested with 100 participants across four stigmatized occupations to assess empathetic engagement.", "result": "Participants showed a significant increase in understanding, empathy, and connection to workers in these roles, although some limitations in LLM context were noted.", "conclusion": "The LLM-based framework is seen as a viable method for reducing stigma and promoting social equity in marginalized professions, despite some challenges in context generation.", "key_contributions": ["Introduction of an LLM-powered Interactive Fiction framework for perspective-taking.", "Demonstrated empirical evidence of increased empathy and understanding for stigmatized professions.", "Identified both the potential and limitations of LLMs in promoting social equity."], "limitations": "Participants noted limited contextual details from the LLM and potential reinforcement of stereotypes.", "keywords": ["Interactive Fiction", "Large Language Models", "Stigma", "Empathy", "Occupational Equity"], "importance_score": 7, "read_time_minutes": 5}}
{"id": "2505.05815", "pdf": "https://arxiv.org/pdf/2505.05815.pdf", "abs": "https://arxiv.org/abs/2505.05815", "title": "Tell Me Who Your Students Are: GPT Can Generate Valid Multiple-Choice Questions When Students' (Mis)Understanding Is Hinted", "authors": ["Machi Shimmei", "Masaki Uto", "Yuichiroh Matsubayashi", "Kentaro Inui", "Aditi Mallavarapu", "Noboru Matsuda"], "categories": ["cs.CL"], "comment": "This is a pre-print version of a paper to appear in AIED2025", "summary": "The primary goal of this study is to develop and evaluate an innovative\nprompting technique, AnaQuest, for generating multiple-choice questions (MCQs)\nusing a pre-trained large language model. In AnaQuest, the choice items are\nsentence-level assertions about complex concepts. The technique integrates\nformative and summative assessments. In the formative phase, students answer\nopen-ended questions for target concepts in free text. For summative\nassessment, AnaQuest analyzes these responses to generate both correct and\nincorrect assertions. To evaluate the validity of the generated MCQs, Item\nResponse Theory (IRT) was applied to compare item characteristics between MCQs\ngenerated by AnaQuest, a baseline ChatGPT prompt, and human-crafted items. An\nempirical study found that expert instructors rated MCQs generated by both AI\nmodels to be as valid as those created by human instructors. However, IRT-based\nanalysis revealed that AnaQuest-generated questions - particularly those with\nincorrect assertions (foils) - more closely resembled human-crafted items in\nterms of difficulty and discrimination than those produced by ChatGPT.", "AI": {"tldr": "The study develops AnaQuest, a prompting technique using large language models to create valid multiple-choice questions with effective assessments.", "motivation": "To innovate the generation of multiple-choice questions using AI and enhance assessment validity.", "method": "AnaQuest integrates formative and summative assessments, utilizing open-ended student responses to generate MCQ items through IRT analysis.", "result": "Empirical study reveals expert ratings of AI-generated MCQs match those of human-crafted items, with AnaQuest showing better alignment in difficulty and discrimination.", "conclusion": "AnaQuest is a promising technique for valid MCQ generation using language models, particularly in education.", "key_contributions": ["Introduction of AnaQuest for MCQ generation using AI", "Evaluation against human-crafted questions", "Findings indicate AnaQuest's superiority in question quality"], "limitations": "", "keywords": ["large language model", "multiple-choice questions", "assessment techniques", "AnaQuest", "Item Response Theory"], "importance_score": 8, "read_time_minutes": 5}}
{"id": "2505.05817", "pdf": "https://arxiv.org/pdf/2505.05817.pdf", "abs": "https://arxiv.org/abs/2505.05817", "title": "The Experience of Running: Recommending Routes Using Sensory Mapping in Urban Environments", "authors": ["Katrin Hänsel", "Luca Maria Aiello", "Daniele Quercia", "Rossano Schifanella", "Krisztian Zsolt Varga", "Linus W. Dietz", "Marios Constantinides"], "categories": ["cs.HC"], "comment": "45 pages, 6 figures, 6 tables", "summary": "Depending on the route, runners may experience frustration, freedom, or\nfulfilment. However, finding routes that are conducive to the psychological\nexperience of running remains an unresolved task in the literature. In a\nmixed-method study, we interviewed 7 runners to identify themes contributing to\nrunning experience, and quantitatively examined these themes in an online\nsurvey with 387 runners. Using Principal Component Analysis on the survey\nresponses, we developed a short experience sampling questionnaire that captures\nthe three most important dimensions of running experience: \\emph{performance \\&\nachievement}, \\emph{environment}, and \\emph{mind \\& social connectedness}.\nUsing path preferences obtained from the online survey, we clustered them into\ntwo types of routes: \\emph{scenic} (associated with nature and greenery) and\n\\emph{urban} (characterized by the presence of people); and developed a routing\nengine for path recommendations. We discuss challenges faced in developing the\nrouting engine, and provide guidelines to integrate it into mobile and wearable\nrunning apps.", "AI": {"tldr": "The paper explores the psychological experiences of runners through a mixed-method study, identifying key themes related to running experiences and developing a routing engine for path recommendations based on these themes.", "motivation": "To address the unresolved task of finding running routes that foster positive psychological experiences for runners.", "method": "A mixed-method study involving interviews with 7 runners followed by a quantitative survey of 387 runners, utilizing Principal Component Analysis to identify themes and dimensions of running experience.", "result": "Developed a short experience sampling questionnaire capturing three dimensions of running experience and clustered path preferences into scenic and urban types for routing recommendations.", "conclusion": "The paper discusses the challenges in developing the routing engine and provides guidelines for integrating it into mobile and wearable running apps.", "key_contributions": ["Identification of key themes in runners' psychological experiences", "Development of a short experience sampling questionnaire for running", "Creation of a routing engine for path recommendations based on runner preferences"], "limitations": "Limited to runners in the study; may not generalize to all runners or regions.", "keywords": ["running experience", "routing engine", "psychological well-being", "experience sampling", "path recommendations"], "importance_score": 5, "read_time_minutes": 15}}
{"id": "2505.05864", "pdf": "https://arxiv.org/pdf/2505.05864.pdf", "abs": "https://arxiv.org/abs/2505.05864", "title": "Symbol-based entity marker highlighting for enhanced text mining in materials science with generative AI", "authors": ["Junhyeong Lee", "Jong Min Yuk", "Chan-Woo Lee"], "categories": ["cs.CL"], "comment": "29 pages", "summary": "The construction of experimental datasets is essential for expanding the\nscope of data-driven scientific discovery. Recent advances in natural language\nprocessing (NLP) have facilitated automatic extraction of structured data from\nunstructured scientific literature. While existing approaches-multi-step and\ndirect methods-offer valuable capabilities, they also come with limitations\nwhen applied independently. Here, we propose a novel hybrid text-mining\nframework that integrates the advantages of both methods to convert\nunstructured scientific text into structured data. Our approach first\ntransforms raw text into entity-recognized text, and subsequently into\nstructured form. Furthermore, beyond the overall data structuring framework, we\nalso enhance entity recognition performance by introducing an entity marker-a\nsimple yet effective technique that uses symbolic annotations to highlight\ntarget entities. Specifically, our entity marker-based hybrid approach not only\nconsistently outperforms previous entity recognition approaches across three\nbenchmark datasets (MatScholar, SOFC, and SOFC slot NER) but also improve the\nquality of final structured data-yielding up to a 58% improvement in\nentity-level F1 score and up to 83% improvement in relation-level F1 score\ncompared to direct approach.", "AI": {"tldr": "A hybrid text-mining framework combines multi-step and direct methods for entity recognition, improving the extraction of structured data from scientific literature.", "motivation": "To address the limitations of existing multi-step and direct methods in converting unstructured scientific text into structured data.", "method": "The framework employs a hybrid approach that first recognizes entities in the text and then converts them into a structured format, utilizing an entity marker technique to enhance recognition accuracy.", "result": "The hybrid approach outperforms previous methods by achieving up to 58% improvement in entity-level F1 score and up to 83% improvement in relation-level F1 score on three benchmark datasets.", "conclusion": "Integrating entity recognition and structuring methods enhances data extraction processes, providing more accurate structured outputs for scientific research.", "key_contributions": ["Development of a novel hybrid text-mining framework", "Introduction of an effective entity marker technique", "Demonstrated significant improvements in data extraction accuracy across benchmark datasets"], "limitations": "", "keywords": ["text mining", "entity recognition", "structured data", "natural language processing", "hybrid approach"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2505.05828", "pdf": "https://arxiv.org/pdf/2505.05828.pdf", "abs": "https://arxiv.org/abs/2505.05828", "title": "An empathic GPT-based chatbot to talk about mental disorders with Spanish teenagers", "authors": ["Alba María Mármol-Romero", "Manuel García-Vega", "Miguel Ángel García-Cumbreras", "Arturo Montejo-Ráez"], "categories": ["cs.HC", "cs.CL"], "comment": "This is an Accepted Manuscript version of the following article,\n  accepted for publication in International Journal of Human-Computer\n  Interaction. It is deposited under the terms of the Creative Commons\n  Attribution-NonCommercial-NoDerivatives License", "summary": "This paper presents a chatbot-based system to engage young Spanish people in\nthe awareness of certain mental disorders through a self-disclosure technique.\nThe study was carried out in a population of teenagers aged between 12 and 18\nyears. The dialogue engine mixes closed and open conversations, so certain\ncontrolled messages are sent to focus the chat on a specific disorder, which\nwill change over time. Once a set of trial questions is answered, the system\ncan initiate the conversation on the disorder under the focus according to the\nuser's sensibility to that disorder, in an attempt to establish a more\nempathetic communication. Then, an open conversation based on the GPT-3\nlanguage model is initiated, allowing the user to express themselves with more\nfreedom. The results show that these systems are of interest to young people\nand could help them become aware of certain mental disorders.", "AI": {"tldr": "A chatbot system engages young Spanish users in mental disorder awareness through guided self-disclosure and open conversations using the GPT-3 language model.", "motivation": "To raise awareness among teenagers about mental disorders using an interactive and empathetic approach.", "method": "A chatbot combines closed and open dialogue techniques to guide conversations about specific mental disorders based on user's responses and sensibility.", "result": "The chatbot effectively captured the interest of young users and facilitated discussions about mental disorders, promoting awareness.", "conclusion": "Chatbot systems can be valuable tools for mental health awareness among teenagers by fostering empathetic communication.", "key_contributions": ["Introduce a chatbot-based system for mental disorder awareness in teenagers", "Utilize self-disclosure techniques to engage users", "Implement a dialogue engine that combines structured and open conversations"], "limitations": "Study is limited to a specific age group (12-18 years) and focused solely on Spanish youth.", "keywords": ["chatbot", "mental health", "self-disclosure", "GPT-3", "teenagers"], "importance_score": 7, "read_time_minutes": 5}}
{"id": "2505.05946", "pdf": "https://arxiv.org/pdf/2505.05946.pdf", "abs": "https://arxiv.org/abs/2505.05946", "title": "Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2", "authors": ["Vytenis Šliogeris", "Povilas Daniušis", "Artūras Nakvosas"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "8 pages, 4 figures", "summary": "This technical report describes an experiment on autoregressive pre-training\nof Gemma2 2 billion parameter large language model (LLM) with 10\\% on the\nLithuanian language component of CulturaX from the point of view of continual\nlearning. We apply elastic weight consolidation (EWC) to the full set of the\nmodel's parameters and investigate language understanding benchmarks,\nconsisting of Arc, Belebele, Gsm8K, Hellaswag, MMLU, TruthfulQA, and Winogrande\nsets (both in English and Lithuanian versions), and perplexity benchmarks. We\nempirically demonstrate that EWC regularisation allows us not only to mitigate\ncatastrophic forgetting effects but also that it is potentially beneficial for\nlearning of the new task with LLMs.", "AI": {"tldr": "The report explores autoregressive pre-training of the Gemma2 LLM with a focus on continual learning using elastic weight consolidation (EWC) to mitigate catastrophic forgetting effects.", "motivation": "To investigate how EWC regularization can improve continual learning in LLMs, specifically for language understanding tasks in Lithuanian and English.", "method": "An experiment was conducted using the 2 billion parameter Gemma2 LLM, applying EWC to the model's parameters during autoregressive pre-training. The model was evaluated on various language understanding benchmarks and perplexity metrics.", "result": "EWC regularization proved effective in reducing catastrophic forgetting while also enhancing the model's performance on new tasks.", "conclusion": "The findings suggest that EWC can be a valuable technique in continual learning for LLMs, providing benefits beyond just mitigating forgetting.", "key_contributions": ["Demonstrated the effectiveness of EWC in LLMs for continual learning.", "Evaluated the performance of a large language model specifically on language understanding tasks in Lithuanian.", "Provided empirical evidence on the impact of EWC on task learning and perplexity metrics."], "limitations": "The study is limited to one specific model and language component, and results may not generalize to other languages or models.", "keywords": ["Large Language Model", "Continual Learning", "Elastic Weight Consolidation", "Language Understanding", "Autoregressive Pre-training"], "importance_score": 6, "read_time_minutes": 8}}
{"id": "2505.05832", "pdf": "https://arxiv.org/pdf/2505.05832.pdf", "abs": "https://arxiv.org/abs/2505.05832", "title": "Augmented Body Communicator: Enhancing daily body expression for people with upper limb limitations through LLM and a robotic arm", "authors": ["Songchen Zhou", "Mark Armstrong", "Giulia Barbareschi", "Toshihiro Ajioka", "Zheng Hu", "Ryoichi Ando", "Kentaro Yoshifuji", "Masatane Muto", "Kouta Minamizawa"], "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "Individuals with upper limb movement limitations face challenges in\ninteracting with others. Although robotic arms are currently used primarily for\nfunctional tasks, there is considerable potential to explore ways to enhance\nusers' body language capabilities during social interactions. This paper\nintroduces an Augmented Body Communicator system that integrates robotic arms\nand a large language model. Through the incorporation of kinetic memory,\ndisabled users and their supporters can collaboratively design actions for the\nrobot arm. The LLM system then provides suggestions on the most suitable action\nbased on contextual cues during interactions. The system underwent thorough\nuser testing with six participants who have conditions affecting upper limb\nmobility. Results indicate that the system improves users' ability to express\nthemselves. Based on our findings, we offer recommendations for developing\nrobotic arms that support disabled individuals with body language capabilities\nand functional tasks.", "AI": {"tldr": "The paper presents the Augmented Body Communicator system that enhances body language in social interactions for individuals with upper limb movement limitations using robotic arms and a large language model.", "motivation": "To address the challenges faced by individuals with upper limb movement limitations in social interactions and to explore the potential of robotic arms in enhancing body language.", "method": "The system integrates robotic arms and a large language model to allow users to collaboratively design actions, using contextual cues to suggest suitable actions during interactions.", "result": "User testing with six participants showed that the system improved their capability to express themselves during social interactions.", "conclusion": "The findings suggest that robotic arms can be developed to better support body language capabilities alongside functional tasks for disabled individuals.", "key_contributions": ["Introduction of the Augmented Body Communicator system combining robotics and LLM.", "User testing demonstrates improved expression capabilities for participants with upper limb limitations.", "Recommendations for future development of robotic systems that assist with body language."], "limitations": "", "keywords": ["augmented communication", "robotic arms", "body language", "human-robot interaction", "assistive technology"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2505.05947", "pdf": "https://arxiv.org/pdf/2505.05947.pdf", "abs": "https://arxiv.org/abs/2505.05947", "title": "Summarisation of German Judgments in conjunction with a Class-based Evaluation", "authors": ["Bianca Steffes", "Nils Torben Wiedemann", "Alexander Gratz", "Pamela Hochreither", "Jana Elina Meyer", "Katharina Luise Schilke"], "categories": ["cs.CL"], "comment": null, "summary": "The automated summarisation of long legal documents can be a great aid for\nlegal experts in their daily work. We automatically create summaries (guiding\nprinciples) of German judgments by fine-tuning a decoder-based large language\nmodel. We enrich the judgments with information about legal entities before the\ntraining. For the evaluation of the created summaries, we define a set of\nevaluation classes which allows us to measure their language, pertinence,\ncompleteness and correctness. Our results show that employing legal entities\nhelps the generative model to find the relevant content, but the quality of the\ncreated summaries is not yet sufficient for a use in practice.", "AI": {"tldr": "The paper discusses the automated summarization of German legal judgments using a fine-tuned LLM, emphasizing the enhancement of summaries through the inclusion of legal entities, while highlighting the insufficiency of the summary quality for practical use.", "motivation": "To assist legal experts in summarizing long legal documents efficiently, particularly German judgments.", "method": "Fine-tuning a decoder-based large language model while enriching training data with information about legal entities.", "result": "Incorporating legal entities improves the generative model's ability to identify relevant content, although the overall summary quality is still inadequate for practical application.", "conclusion": "The integration of legal entities aids in content relevance, but the generated summaries require further improvement for them to be practically useful.", "key_contributions": ["Development of a method to summarize legal judgments using LLMs", "Demonstration of the impact of legal entities on summary generation", "Establishment of evaluation classes for assessing summary quality"], "limitations": "The quality of the generated summaries is not yet sufficient for practical use.", "keywords": ["automated summarisation", "legal documents", "large language model", "German judgments", "summary quality"], "importance_score": 3, "read_time_minutes": 10}}
{"id": "2505.05923", "pdf": "https://arxiv.org/pdf/2505.05923.pdf", "abs": "https://arxiv.org/abs/2505.05923", "title": "Human causal perception in a cube-stacking task", "authors": ["Nikolai Bahr", "Christoph Zetzsche", "Jaime Maldonado"], "categories": ["cs.HC"], "comment": "7 pages, 6 figures", "summary": "In intuitive physics the process of stacking cubes has become a paradigmatic,\ncanonical task. Even though it gets employed in various shades and\ncomplexities, the very fundamental setting with two cubes has not been\nthoroughly investigated. Furthermore, the majority of settings feature only a\nreduced, one dimensional (1D) decision space. In this paper an experiment is\nconducted in which participants judge the stability of two cubes stacked on top\nof each other. It is performed in the full 3D setting which features a 2D\ndecision surface. The analysis yield a shape of a rotated square for the\nperceived stability area instead of the commonly reported safety margin in 1D.\nThis implies a more complex decision behavior in human than previously assumed.", "AI": {"tldr": "This paper investigates the stability judgments of stacked cubes in a full 3D setting, revealing more complex human decision behavior.", "motivation": "The study aims to explore the intuitive physics of stability judgments in a fuller dimensional context, beyond the traditional 1D settings.", "method": "An experiment was conducted where participants judged the stability of two cubes stacked vertically in a 3D environment, utilizing a 2D decision surface for analysis.", "result": "The analysis showed a rotated square shape for the perceived stability area, contrasting with the expected safety margin typically observed in 1D environments.", "conclusion": "These findings suggest a more intricate understanding of human decision-making regarding physical stability than previously thought, indicating that human perceptual judgments are not merely linear.", "key_contributions": ["Investigates stability judgments in 3D instead of 1D.", "Finds a rotated square shape for perceived stability area.", "Challenges assumptions about human decision behavior in intuitive physics."], "limitations": "The experiment only focuses on a specific configuration of two cubes and may not generalize to more complex stacking scenarios.", "keywords": ["intuitive physics", "stability judgments", "3D decision making", "human decision behavior", "cube stacking"], "importance_score": 4, "read_time_minutes": 7}}
{"id": "2505.05949", "pdf": "https://arxiv.org/pdf/2505.05949.pdf", "abs": "https://arxiv.org/abs/2505.05949", "title": "NeoQA: Evidence-based Question Answering with Generated News Events", "authors": ["Max Glockner", "Xiang Jiang", "Leonardo F. R. Ribeiro", "Iryna Gurevych", "Markus Dreyer"], "categories": ["cs.CL"], "comment": null, "summary": "Evaluating Retrieval-Augmented Generation (RAG) in large language models\n(LLMs) is challenging because benchmarks can quickly become stale. Questions\ninitially requiring retrieval may become answerable from pretraining knowledge\nas newer models incorporate more recent information during pretraining, making\nit difficult to distinguish evidence-based reasoning from recall. We introduce\nNeoQA (News Events for Out-of-training Question Answering), a benchmark\ndesigned to address this issue. To construct NeoQA, we generated timelines and\nknowledge bases of fictional news events and entities along with news articles\nand Q\\&A pairs to prevent LLMs from leveraging pretraining knowledge, ensuring\nthat no prior evidence exists in their training data. We propose our dataset as\na new platform for evaluating evidence-based question answering, as it requires\nLLMs to generate responses exclusively from retrieved evidence and only when\nsufficient evidence is available. NeoQA enables controlled evaluation across\nvarious evidence scenarios, including cases with missing or misleading details.\nOur findings indicate that LLMs struggle to distinguish subtle mismatches\nbetween questions and evidence, and suffer from short-cut reasoning when key\ninformation required to answer a question is missing from the evidence,\nunderscoring key limitations in evidence-based reasoning.", "AI": {"tldr": "NeoQA is a benchmark for evaluating LLMs in question answering where pretraining knowledge cannot be used, focusing on evidence-based reasoning.", "motivation": "The challenge in evaluating Retrieval-Augmented Generation (RAG) in LLMs due to stale benchmarks and LLMs potentially answering from pretraining knowledge rather than retrieval.", "method": "Introduced NeoQA benchmark, generating fictional news event timelines, knowledge bases, articles, and Q&A pairs to isolate retrieval from pretraining knowledge.", "result": "LLMs showed difficulty in distinguishing between questions and evidence and exhibited shortcut reasoning when key information was absent.", "conclusion": "NeoQA serves as a platform for assessing evidence-based question answering capabilities in LLMs with controlled evaluation of evidence scenarios.", "key_contributions": ["Introduction of NeoQA benchmark for evidence-based Q&A", "Creation of controlled scenarios preventing pretraining knowledge usage", "Insights into limitations of LLMs in evidence-based reasoning"], "limitations": "The dataset is fictional, which may not fully represent real-world complexities.", "keywords": ["Retrieval-Augmented Generation", "NeoQA", "Large Language Models", "Evidence-based Reasoning", "Question Answering"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2505.05937", "pdf": "https://arxiv.org/pdf/2505.05937.pdf", "abs": "https://arxiv.org/abs/2505.05937", "title": "MER-CLIP: AU-Guided Vision-Language Alignment for Micro-Expression Recognition", "authors": ["Shifeng Liu", "Xinglong Mao", "Sirui Zhao", "Peiming Li", "Tong Xu", "Enhong Chen"], "categories": ["cs.HC"], "comment": null, "summary": "As a critical psychological stress response, micro-expressions (MEs) are\nfleeting and subtle facial movements revealing genuine emotions. Automatic ME\nrecognition (MER) holds valuable applications in fields such as criminal\ninvestigation and psychological diagnosis. The Facial Action Coding System\n(FACS) encodes expressions by identifying activations of specific facial action\nunits (AUs), serving as a key reference for ME analysis. However, current MER\nmethods typically limit AU utilization to defining regions of interest (ROIs)\nor relying on specific prior knowledge, often resulting in limited performance\nand poor generalization. To address this, we integrate the CLIP model's\npowerful cross-modal semantic alignment capability into MER and propose a novel\napproach namely MER-CLIP. Specifically, we convert AU labels into detailed\ntextual descriptions of facial muscle movements, guiding fine-grained\nspatiotemporal ME learning by aligning visual dynamics and textual AU-based\nrepresentations. Additionally, we introduce an Emotion Inference Module to\ncapture the nuanced relationships between ME patterns and emotions with\nhigher-level semantic understanding. To mitigate overfitting caused by the\nscarcity of ME data, we put forward LocalStaticFaceMix, an effective data\naugmentation strategy blending facial images to enhance facial diversity while\npreserving critical ME features. Finally, comprehensive experiments on four\nbenchmark ME datasets confirm the superiority of MER-CLIP. Notably, UF1 scores\non CAS(ME)3 reach 0.7832, 0.6544, and 0.4997 for 3-, 4-, and 7-class\nclassification tasks, significantly outperforming previous methods.", "AI": {"tldr": "The paper proposes a novel approach for micro-expression recognition (MER) utilizing the CLIP model for better semantic alignment, along with a new data augmentation strategy.", "motivation": "Micro-expressions reveal genuine emotions and have applications in criminal investigations and psychological diagnoses, but current recognition methods suffer from performance limitations due to inadequate use of facial action units (AUs).", "method": "The authors propose MER-CLIP, which integrates CLIP's cross-modal capabilities to convert AU labels into textual descriptions that guide ME learning. Additionally, they introduce an Emotion Inference Module for improved emotional understanding and use a data augmentation strategy called LocalStaticFaceMix to enhance ME data.", "result": "Comprehensive experiments indicate that MER-CLIP significantly outperforms previous methods, achieving UF1 scores of 0.7832, 0.6544, and 0.4997 on CAS(ME)3 across different classification tasks.", "conclusion": "The proposed approach demonstrates superior performance in micro-expression recognition by leveraging advanced semantic understanding and effective data augmentation.", "key_contributions": ["Introduction of MER-CLIP for micro-expression recognition using CLIP model.", "Development of an Emotion Inference Module for enhanced understanding of emotional cues from micro-expressions.", "Implementation of LocalStaticFaceMix data augmentation strategy to improve data quality."], "limitations": "", "keywords": ["micro-expressions", "CLIP model", "facial action units", "data augmentation", "emotion recognition"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2505.05970", "pdf": "https://arxiv.org/pdf/2505.05970.pdf", "abs": "https://arxiv.org/abs/2505.05970", "title": "Towards Developmentally Plausible Rewards: Communicative Success as a Learning Signal for Interactive Language Models", "authors": ["Lennart Stöpler", "Rufat Asadli", "Mitja Nikolaus", "Ryan Cotterell", "Alex Warstadt"], "categories": ["cs.CL"], "comment": null, "summary": "We propose a method for training language models in an interactive setting\ninspired by child language acquisition. In our setting, a speaker attempts to\ncommunicate some information to a listener in a single-turn dialogue and\nreceives a reward if communicative success is achieved. Unlike earlier related\nwork using image--caption data for interactive reference games, we\noperationalize communicative success in a more abstract language-only\nquestion--answering setting. First, we present a feasibility study\ndemonstrating that our reward provides an indirect signal about grammaticality.\nSecond, we conduct experiments using reinforcement learning to fine-tune\nlanguage models. We observe that cognitively plausible constraints on the\ncommunication channel lead to interpretable changes in speaker behavior.\nHowever, we do not yet see improvements on linguistic evaluations from our\ntraining regime. We outline potential modifications to the task design and\ntraining configuration that could better position future work to use our\nmethodology to observe the benefits of interaction on language learning in\ncomputational cognitive models.", "AI": {"tldr": "A method for training language models through interactive dialogue inspired by child language acquisition is proposed, focusing on communicative success in language-only question-answering.", "motivation": "To operationalize communicative success in language models, inspired by child language acquisition and to enhance the learning process through interactive dialogue.", "method": "A feasibility study is conducted to gauge the effectiveness of a reward system in signaling grammaticality, followed by reinforcement learning experiments to fine-tune language models based on speaker behavior.", "result": "While cognitively plausible constraints affected speaker behavior, improvements in linguistic evaluations were not observed from the training regime.", "conclusion": "Future modifications to task design and training configurations may help realize the benefits of interaction on language learning in computational models.", "key_contributions": ["Introduction of an interactive training method for language models inspired by child language acquisition.", "Feasibility study demonstrating the reward system's indirect signal for grammaticality.", "Use of reinforcement learning to fine-tune language models based on communicative success."], "limitations": "Improvements in linguistic evaluations were not observed, indicating potential issues with the current training regime or task design.", "keywords": ["language models", "interactive learning", "reinforcement learning", "natural language processing", "child language acquisition"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2505.06045", "pdf": "https://arxiv.org/pdf/2505.06045.pdf", "abs": "https://arxiv.org/abs/2505.06045", "title": "Designing RoutScape: Geospatial Prototyping with XR for Flood Evacuation Planning", "authors": ["Johndayll Lewis Arizala", "Joshua Permito", "Steven Errol Escopete", "John Kovie Niño", "Jordan Aiko Deja"], "categories": ["cs.HC"], "comment": "6 pages, 3 figures", "summary": "Flood response planning in local communities is often hindered by fragmented\ncommunication across Disaster Risk Reduction and Management (DRRM) councils. In\nthis work, we explore how extended reality (XR) can support more effective\nplanning through narrative-driven design. We present Routscape, an XR prototype\nfor visualizing flood scenarios and evacuation routes, developed through\niterative prototyping and user-centered design with DRRM officers. By grounding\nthe system in real-world experiences and localized narratives, we highlight how\nXR can aid in fostering shared understanding and spatial sensemaking in\ndisaster preparedness efforts.", "AI": {"tldr": "This paper explores the use of extended reality (XR) for effective flood response planning via narrative-driven design, introducing Routscape as an XR prototype for visualizing flood scenarios and evacuation routes.", "motivation": "To address the challenges of fragmented communication in Disaster Risk Reduction and Management (DRRM) councils during flood response planning.", "method": "The authors developed an XR prototype named Routscape through iterative prototyping and user-centered design, involving DRRM officers to ground the system in real-world experiences and localized narratives.", "result": "Routscape enables effective visualization of flood scenarios and evacuation routes, facilitating shared understanding and spatial sensemaking among users.", "conclusion": "The study demonstrates the potential of XR technologies in enhancing disaster preparedness through improved communication and planning tools.", "key_contributions": ["Introduction of Routscape, an XR prototype for flood scenario visualization", "Demonstration of narrative-driven design in XR for local disaster management", "Highlighting the importance of user-centered design in developing emergency response tools"], "limitations": "", "keywords": ["extended reality", "disaster management", "flood response", "user-centered design", "narrative design"], "importance_score": 5, "read_time_minutes": 6}}
{"id": "2505.05973", "pdf": "https://arxiv.org/pdf/2505.05973.pdf", "abs": "https://arxiv.org/abs/2505.05973", "title": "An Exploratory Analysis on the Explanatory Potential of Embedding-Based Measures of Semantic Transparency for Malay Word Recognition", "authors": ["M. Maziyah Mohamed", "R. H. Baayen"], "categories": ["cs.CL"], "comment": "24 pages, 5 figures, and 9 tables. Submitted to the Journal of\n  Morphology", "summary": "Studies of morphological processing have shown that semantic transparency is\ncrucial for word recognition. Its computational operationalization is still\nunder discussion. Our primary objectives are to explore embedding-based\nmeasures of semantic transparency, and assess their impact on reading. First,\nwe explored the geometry of complex words in semantic space. To do so, we\nconducted a t-distributed Stochastic Neighbor Embedding clustering analysis on\n4,226 Malay prefixed words. Several clusters were observed for complex words\nvaried by their prefix class. Then, we derived five simple measures, and\ninvestigated whether they were significant predictors of lexical decision\nlatencies. Two sets of Linear Discriminant Analyses were run in which the\nprefix of a word is predicted from either word embeddings or shift vectors\n(i.e., a vector subtraction of the base word from the derived word). The\naccuracy with which the model predicts the prefix of a word indicates the\ndegree of transparency of the prefix. Three further measures were obtained by\ncomparing embeddings between each word and all other words containing the same\nprefix (i.e., centroid), between each word and the shift from their base word,\nand between each word and the predicted word of the Functional Representations\nof Affixes in Compositional Semantic Space model. In a series of Generalized\nAdditive Mixed Models, all measures predicted decision latencies after\naccounting for word frequency, word length, and morphological family size. The\nmodel that included the correlation between each word and their centroid as a\npredictor provided the best fit to the data.", "AI": {"tldr": "This study investigates the role of semantic transparency in word recognition using embedding-based measures, focusing on lexical decision latencies.", "motivation": "To explore how semantic transparency impacts word recognition and to operationalize this concept computationally.", "method": "Utilized t-distributed Stochastic Neighbor Embedding to analyze 4,226 Malay prefixed words, derived measures of semantic transparency, and conducted Linear Discriminant Analyses to predict prefix identification.", "result": "The model that incorporated the correlation between each word and its centroid predicted decision latencies most effectively, revealing that semantic measures can indeed predict lexical processing times.", "conclusion": "Embedding-based measures of semantic transparency significantly predict word recognition latency, demonstrating the relevance of semantic relationships in morphological processing.", "key_contributions": ["Introduced embedding-based measures of semantic transparency.", "Conducted a comprehensive analysis of Malay prefixed words using clustering techniques.", "Demonstrated the predictive capability of semantic measures on lexical decision latencies."], "limitations": "Focus on Malay language; results may not generalize to other languages or morphological structures.", "keywords": ["semantic transparency", "word recognition", "embedding measures", "morphological processing", "lexical decision"], "importance_score": 4, "read_time_minutes": 20}}
{"id": "2505.06064", "pdf": "https://arxiv.org/pdf/2505.06064.pdf", "abs": "https://arxiv.org/abs/2505.06064", "title": "Context Informed Incremental Learning Improves Myoelectric Control Performance in Virtual Reality Object Manipulation Tasks", "authors": ["Gabriel Gagné", "Anisha Azad", "Thomas Labbé", "Evan Campbell", "Xavier Isabel", "Erik Scheme", "Ulysse Côté-Allard", "Benoit Gosselin"], "categories": ["cs.HC"], "comment": "5 pages, 6 figures, 3 tables, conference", "summary": "Electromyography (EMG)-based gesture recognition is a promising approach for\ndesigning intuitive human-computer interfaces. However, while these systems\ntypically perform well in controlled laboratory settings, their usability in\nreal-world applications is compromised by declining performance during\nreal-time control. This decline is largely due to goal-directed behaviors that\nare not captured in static, offline scenarios. To address this issue, we use\n\\textit{Context Informed Incremental Learning} (CIIL) - marking its first\ndeployment in an object-manipulation scenario - to continuously adapt the\nclassifier using contextual cues. Nine participants without upper limb\ndifferences completed a functional task in a virtual reality (VR) environment\ninvolving transporting objects with life-like grips. We compared two scenarios:\none where the classifier was adapted in real-time using contextual information,\nand the other using a traditional open-loop approach without adaptation. The\nCIIL-based approach not only enhanced task success rates and efficiency, but\nalso reduced the perceived workload by 7.1 %, despite causing a 5.8 % reduction\nin offline classification accuracy. This study highlights the potential of\nreal-time contextualized adaptation to enhance user experience and usability of\nEMG-based systems for practical, goal-oriented applications, crucial elements\ntowards their long-term adoption. The source code for this study is available\nat: https://github.com/BiomedicalITS/ciil-emg-vr.", "AI": {"tldr": "This paper presents an approach using Context Informed Incremental Learning (CIIL) for enhancing EMG-based gesture recognition in real-time applications.", "motivation": "Improve the usability of EMG-based gesture recognition systems in real-world applications affected by declining performance during goal-directed tasks.", "method": "Implemented Context Informed Incremental Learning (CIIL) in a VR environment with participants completing a task involving object transportation, comparing real-time adaptation to a traditional approach.", "result": "The CIIL method improved task success rates and efficiency, reducing perceived workload by 7.1 %, despite a 5.8 % decline in offline classification accuracy.", "conclusion": "Real-time contextual adaptation can significantly enhance user experience and usability of EMG-based systems for practical applications.", "key_contributions": ["First deployment of CIIL in an object-manipulation scenario for EMG-based interfaces.", "Real-time adaptation improved user task efficiency and reduced workload.", "Source code made available for community exploration."], "limitations": "Decline in offline classification accuracy during adaptation could impact initial deployment effectiveness.", "keywords": ["EMG", "gesture recognition", "real-time adaptation", "Context Informed Incremental Learning", "human-computer interaction"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2505.06004", "pdf": "https://arxiv.org/pdf/2505.06004.pdf", "abs": "https://arxiv.org/abs/2505.06004", "title": "Exploring the Feasibility of Multilingual Grammatical Error Correction with a Single LLM up to 9B parameters: A Comparative Study of 17 Models", "authors": ["Dawid Wisniewski", "Antoni Solarski", "Artur Nowakowski"], "categories": ["cs.CL"], "comment": "Accepted at MTSummit 2025 (The 20th Machine Translation Summit)", "summary": "Recent language models can successfully solve various language-related tasks,\nand many understand inputs stated in different languages. In this paper, we\nexplore the performance of 17 popular models used to correct grammatical issues\nin texts stated in English, German, Italian, and Swedish when using a single\nmodel to correct texts in all those languages. We analyze the outputs generated\nby these models, focusing on decreasing the number of grammatical errors while\nkeeping the changes small. The conclusions drawn help us understand what\nproblems occur among those models and which models can be recommended for\nmultilingual grammatical error correction tasks. We list six models that\nimprove grammatical correctness in all four languages and show that Gemma 9B is\ncurrently the best performing one for the languages considered.", "AI": {"tldr": "The paper evaluates 17 language models for multilingual grammatical error correction, demonstrating Gemma 9B as the best performing model across English, German, Italian, and Swedish.", "motivation": "With the rise of multilingual applications, understanding how language models perform in grammatical error correction across different languages is essential for creating effective tools.", "method": "The performance of 17 language models was examined to correct grammatical issues in texts written in four languages using a single model approach.", "result": "Analysis revealed six models that effectively corrected grammatical errors in all four languages, with Gemma 9B being the highest performer.", "conclusion": "The findings will guide recommendations for models to be used in multilingual grammatical error correction tasks and highlight the strengths and weaknesses of different approaches.", "key_contributions": ["Evaluation of 17 language models for multilingual tasks", "Identification of the best performing model (Gemma 9B)", "Insights into common grammatical error correction challenges across languages."], "limitations": "", "keywords": ["language models", "grammatical error correction", "multilingual", "NLP", "Machine Translation"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2505.06010", "pdf": "https://arxiv.org/pdf/2505.06010.pdf", "abs": "https://arxiv.org/abs/2505.06010", "title": "Do Not Change Me: On Transferring Entities Without Modification in Neural Machine Translation -- a Multilingual Perspective", "authors": ["Dawid Wisniewski", "Mikolaj Pokrywka", "Zofia Rostek"], "categories": ["cs.CL"], "comment": "Accepted at MTSummit 2025 (The 20th Machine Translation Summit)", "summary": "Current machine translation models provide us with high-quality outputs in\nmost scenarios. However, they still face some specific problems, such as\ndetecting which entities should not be changed during translation. In this\npaper, we explore the abilities of popular NMT models, including models from\nthe OPUS project, Google Translate, MADLAD, and EuroLLM, to preserve entities\nsuch as URL addresses, IBAN numbers, or emails when producing translations\nbetween four languages: English, German, Polish, and Ukrainian. We investigate\nthe quality of popular NMT models in terms of accuracy, discuss errors made by\nthe models, and examine the reasons for errors. Our analysis highlights\nspecific categories, such as emojis, that pose significant challenges for many\nmodels considered. In addition to the analysis, we propose a new multilingual\nsynthetic dataset of 36,000 sentences that can help assess the quality of\nentity transfer across nine categories and four aforementioned languages.", "AI": {"tldr": "This paper explores the effectiveness of various NMT models in preserving specific entities during translation across multiple languages and proposes a new dataset for evaluation.", "motivation": "To address the persistent challenges faced by machine translation models in accurately preserving specific entities such as URLs and emails during the translation process.", "method": "The study evaluates several popular NMT models, including those from the OPUS project, Google Translate, MADLAD, and EuroLLM, comparing their performance in translating entities between English, German, Polish, and Ukrainian.", "result": "The analysis reveals notable errors in entity preservation, particularly with certain categories like emojis, and demonstrates varying performance among the evaluated models.", "conclusion": "The findings highlight the limitations of current NMT models in entity transfer and introduce a new synthetic dataset to facilitate future research in this area.", "key_contributions": ["Investigation of entity preservation in NMT", "Error analysis of popular machine translation models", "Development of a multilingual synthetic dataset for evaluation"], "limitations": "The study focuses on only four languages and specific entity categories, which may limit generalizability.", "keywords": ["machine translation", "entity preservation", "NMT models", "multilingual dataset", "error analysis"], "importance_score": 6, "read_time_minutes": 15}}
{"id": "2505.06027", "pdf": "https://arxiv.org/pdf/2505.06027.pdf", "abs": "https://arxiv.org/abs/2505.06027", "title": "Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation", "authors": ["Stefan Vasilev", "Christian Herold", "Baohao Liao", "Seyyed Hadi Hashemi", "Shahram Khadivi", "Christof Monz"], "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "comment": "16 pages, 6 figures, 5 tables, under review at ACL", "summary": "This paper introduces Unilogit, a novel self-distillation method for machine\nunlearning in Large Language Models. Unilogit addresses the challenge of\nselectively forgetting specific information while maintaining overall model\nutility, a critical task in compliance with data privacy regulations like GDPR.\nUnlike prior methods that rely on static hyperparameters or starting model\noutputs, Unilogit dynamically adjusts target logits to achieve a uniform\nprobability for the target token, leveraging the current model's outputs for\nmore accurate self-distillation targets. This approach not only eliminates the\nneed for additional hyperparameters but also enhances the model's ability to\napproximate the golden targets. Extensive experiments on public benchmarks and\nan in-house e-commerce dataset demonstrate Unilogit's superior performance in\nbalancing forget and retain objectives, outperforming state-of-the-art methods\nsuch as NPO and UnDIAL. Our analysis further reveals Unilogit's robustness\nacross various scenarios, highlighting its practical applicability and\neffectiveness in achieving efficacious machine unlearning.", "AI": {"tldr": "Unilogit is a self-distillation method for machine unlearning in Large Language Models, allowing for selective forgetting while retaining model utility.", "motivation": "To address the need for selective forgetting of information in machine learning models for data privacy compliance, specifically in adherence to GDPR.", "method": "Unilogit dynamically adjusts target logits based on the model's current outputs, allowing for accurate self-distillation without the need for additional hyperparameters.", "result": "Unilogit demonstrates superior performance in balancing forget and retain objectives compared to state-of-the-art methods like NPO and UnDIAL, based on extensive experiments.", "conclusion": "Unilogit effectively achieves machine unlearning while maintaining model performance, showcasing robustness across various scenarios and applications.", "key_contributions": ["Introduces a self-distillation method for machine unlearning in LLMs.", "Dynamically adjusts target logits for better forgetting without extra hyperparameters.", "Demonstrates superior performance on public benchmarks compared to existing methods."], "limitations": "", "keywords": ["self-distillation", "machine unlearning", "large language models", "data privacy", "GDPR"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2505.06046", "pdf": "https://arxiv.org/pdf/2505.06046.pdf", "abs": "https://arxiv.org/abs/2505.06046", "title": "Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information", "authors": ["Joshua Harris", "Fan Grayson", "Felix Feldman", "Timothy Laurence", "Toby Nonnenmacher", "Oliver Higgins", "Leo Loman", "Selina Patel", "Thomas Finnie", "Samuel Collins", "Michael Borowitz"], "categories": ["cs.CL", "cs.LG", "68T50"], "comment": "24 pages, 10 pages main text", "summary": "As Large Language Models (LLMs) become widely accessible, a detailed\nunderstanding of their knowledge within specific domains becomes necessary for\nsuccessful real world use. This is particularly critical in public health,\nwhere failure to retrieve relevant, accurate, and current information could\nsignificantly impact UK residents. However, currently little is known about LLM\nknowledge of UK Government public health information. To address this issue,\nthis paper introduces a new benchmark, PubHealthBench, with over 8000 questions\nfor evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form\nresponses to public health queries, created via an automated pipeline. We also\nrelease a new dataset of the extracted UK Government public health guidance\ndocuments used as source text for PubHealthBench. Assessing 24 LLMs on\nPubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a\nhigh degree of knowledge, achieving >90% in the MCQA setup, and outperform\nhumans with cursory search engine use. However, in the free form setup we see\nlower performance with no model scoring >75%. Therefore, whilst there are\npromising signs that state of the art (SOTA) LLMs are an increasingly accurate\nsource of public health information, additional safeguards or tools may still\nbe needed when providing free form responses on public health topics.", "AI": {"tldr": "The paper evaluates the knowledge of Large Language Models (LLMs) on UK public health information using a benchmark called PubHealthBench, finding high performance in Multiple Choice Question Answering but lower performance in free form responses.", "motivation": "To understand the knowledge of LLMs in the public health domain, which is critical for accurate information dissemination that impacts UK residents.", "method": "The authors created a benchmark, PubHealthBench, with over 8000 questions to evaluate LLMs' performance on Multiple Choice Question Answering and free form responses, alongside a dataset of UK Government public health guidance documents.", "result": "24 LLMs were assessed against the benchmark, showing that while the latest private LLMs have >90% accuracy in MCQA, their free form responses did not exceed 75% accuracy.", "conclusion": "Although SOTA LLMs show promise in accurately providing public health information, further safeguards may be necessary for free form responses.", "key_contributions": ["Introduction of the PubHealthBench benchmark for evaluating LLMs on public health queries", "Release of a dataset containing UK Government public health guidance documents", "Demonstration of LLM performance discrepancies between MCQA and free form responses."], "limitations": "Free form responses yielded lower performance, highlighting the need for improved accuracy in this area.", "keywords": ["Large Language Models", "public health", "benchmark", "MCQA", "free form responses"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2505.06120", "pdf": "https://arxiv.org/pdf/2505.06120.pdf", "abs": "https://arxiv.org/abs/2505.06120", "title": "LLMs Get Lost In Multi-Turn Conversation", "authors": ["Philippe Laban", "Hiroaki Hayashi", "Yingbo Zhou", "Jennifer Neville"], "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) are conversational interfaces. As such, LLMs\nhave the potential to assist their users not only when they can fully specify\nthe task at hand, but also to help them define, explore, and refine what they\nneed through multi-turn conversational exchange. Although analysis of LLM\nconversation logs has confirmed that underspecification occurs frequently in\nuser instructions, LLM evaluation has predominantly focused on the single-turn,\nfully-specified instruction setting. In this work, we perform large-scale\nsimulation experiments to compare LLM performance in single- and multi-turn\nsettings. Our experiments confirm that all the top open- and closed-weight LLMs\nwe test exhibit significantly lower performance in multi-turn conversations\nthan single-turn, with an average drop of 39% across six generation tasks.\nAnalysis of 200,000+ simulated conversations decomposes the performance\ndegradation into two components: a minor loss in aptitude and a significant\nincrease in unreliability. We find that LLMs often make assumptions in early\nturns and prematurely attempt to generate final solutions, on which they overly\nrely. In simpler terms, we discover that *when LLMs take a wrong turn in a\nconversation, they get lost and do not recover*.", "AI": {"tldr": "This paper evaluates the performance of Large Language Models (LLMs) in single-turn versus multi-turn conversational settings, revealing significant performance drops in multi-turn scenarios.", "motivation": "To understand how LLMs perform in multi-turn settings where users may underspecify tasks and require iterative clarification.", "method": "Large-scale simulation experiments comparing LLM performance across single-turn and multi-turn conversations, analyzing over 200,000 simulated conversations.", "result": "LLMs exhibited an average performance drop of 39% in multi-turn conversations, with findings showing reduced reliability and premature final solutions in earlier conversation turns.", "conclusion": "The study highlights the challenges LLMs face in maintaining reliable performance during multi-turn dialogues and suggests areas for improvement.", "key_contributions": ["Performance comparison of LLMs in single-turn vs multi-turn contexts", "Identification of performance degradation components", "Insight into the unreliability of LLMs in conversations"], "limitations": "Focused on simulation experiments, may not fully capture real-world conversational dynamics.", "keywords": ["Large Language Models", "Conversational interfaces", "Multi-turn conversations"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2505.06062", "pdf": "https://arxiv.org/pdf/2505.06062.pdf", "abs": "https://arxiv.org/abs/2505.06062", "title": "Attention on Multiword Expressions: A Multilingual Study of BERT-based Models with Regard to Idiomaticity and Microsyntax", "authors": ["Iuliia Zaitova", "Vitalii Hirak", "Badr M. Abdullah", "Dietrich Klakow", "Bernd Möbius", "Tania Avgustinova"], "categories": ["cs.CL"], "comment": "10 pages, 3 figures. Findings 2025", "summary": "This study analyzes the attention patterns of fine-tuned encoder-only models\nbased on the BERT architecture (BERT-based models) towards two distinct types\nof Multiword Expressions (MWEs): idioms and microsyntactic units (MSUs). Idioms\npresent challenges in semantic non-compositionality, whereas MSUs demonstrate\nunconventional syntactic behavior that does not conform to standard grammatical\ncategorizations. We aim to understand whether fine-tuning BERT-based models on\nspecific tasks influences their attention to MWEs, and how this attention\ndiffers between semantic and syntactic tasks. We examine attention scores to\nMWEs in both pre-trained and fine-tuned BERT-based models. We utilize\nmonolingual models and datasets in six Indo-European languages - English,\nGerman, Dutch, Polish, Russian, and Ukrainian. Our results show that\nfine-tuning significantly influences how models allocate attention to MWEs.\nSpecifically, models fine-tuned on semantic tasks tend to distribute attention\nto idiomatic expressions more evenly across layers. Models fine-tuned on\nsyntactic tasks show an increase in attention to MSUs in the lower layers,\ncorresponding with syntactic processing requirements.", "AI": {"tldr": "This study investigates how fine-tuning BERT-based models affects their attention patterns towards idioms and microsyntactic units across six Indo-European languages.", "motivation": "Understanding the impact of model fine-tuning on attention allocation to Multiword Expressions (MWEs) like idioms and microsyntactic units (MSUs) in natural language processing.", "method": "We analyzed attention scores from pre-trained and fine-tuned BERT-based models on semantic and syntactic tasks using datasets in English, German, Dutch, Polish, Russian, and Ukrainian.", "result": "Fine-tuning significantly alters attention patterns; semantic task models distribute attention to idioms across layers, while syntactic task models focus on MSUs in lower layers.", "conclusion": "The findings suggest that the type of task a BERT model is fine-tuned on has a substantial impact on its attention behavior towards different types of MWEs.", "key_contributions": ["Analysis of attention patterns in fine-tuned BERT-based models", "Comparison of attention between idioms and microsyntactic units", "Multilingual approach utilizing six Indo-European languages"], "limitations": "", "keywords": ["BERT", "Multiword Expressions", "attention mechanisms", "semantics", "syntax"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2505.06110", "pdf": "https://arxiv.org/pdf/2505.06110.pdf", "abs": "https://arxiv.org/abs/2505.06110", "title": "Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models", "authors": ["Jugal Gajjar", "Kaustik Ranaware"], "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, 2 figures, 5 tables, and 19 references", "summary": "This project performs multimodal sentiment analysis using the CMU-MOSEI\ndataset, using transformer-based models with early fusion to integrate text,\naudio, and visual modalities. We employ BERT-based encoders for each modality,\nextracting embeddings that are concatenated before classification. The model\nachieves strong performance, with 97.87\\% 7-class accuracy and a 0.9682\nF1-score on the test set, demonstrating the effectiveness of early fusion in\ncapturing cross-modal interactions. The training utilized Adam optimization\n(lr=1e-4), dropout (0.3), and early stopping to ensure generalization and\nrobustness. Results highlight the superiority of transformer architectures in\nmodeling multimodal sentiment, with a low MAE (0.1060) indicating precise\nsentiment intensity prediction. Future work may compare fusion strategies or\nenhance interpretability. This approach utilizes multimodal learning by\neffectively combining linguistic, acoustic, and visual cues for sentiment\nanalysis.", "AI": {"tldr": "This project focuses on multimodal sentiment analysis using early fusion of text, audio, and visual modalities through transformer-based models, achieving strong accuracy and F1 scores.", "motivation": "To explore the effectiveness of early fusion in multimodal sentiment analysis by integrating text, audio, and visual data.", "method": "Used BERT-based encoders for each modality to extract embeddings, which were concatenated before classification with a focus on Adam optimization and dropout techniques.", "result": "Achieved 97.87% 7-class accuracy and a 0.9682 F1-score; demonstrated low MAE (0.1060) for sentiment intensity prediction, indicating strong model performance.", "conclusion": "The study confirms transformer architectures' superior capability in modeling multimodal sentiment and suggests future investigations into different fusion strategies and interpretability enhancements.", "key_contributions": ["Demonstrated the effectiveness of early fusion in multimodal sentiment analysis.", "Achieved high accuracy and F1-score using a transformer-based model.", "Highlighted low MAE in sentiment intensity prediction."], "limitations": "", "keywords": ["multimodal sentiment analysis", "transformer-based models", "CMU-MOSEI dataset"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2401.14362", "pdf": "https://arxiv.org/pdf/2401.14362.pdf", "abs": "https://arxiv.org/abs/2401.14362", "title": "The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support", "authors": ["Inhwa Song", "Sachin R. Pendse", "Neha Kumar", "Munmun De Choudhury"], "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "The first two authors contributed equally to this work; typos\n  corrected and post-review revisions incorporated", "summary": "People experiencing severe distress increasingly use Large Language Model\n(LLM) chatbots as mental health support tools. Discussions on social media have\ndescribed how engagements were lifesaving for some, but evidence suggests that\ngeneral-purpose LLM chatbots also have notable risks that could endanger the\nwelfare of users if not designed responsibly. In this study, we investigate the\nlived experiences of people who have used LLM chatbots for mental health\nsupport. We build on interviews with 21 individuals from globally diverse\nbackgrounds to analyze how users create unique support roles for their\nchatbots, fill in gaps in everyday care, and navigate associated cultural\nlimitations when seeking support from chatbots. We ground our analysis in\npsychotherapy literature around effective support, and introduce the concept of\ntherapeutic alignment, or aligning AI with therapeutic values for mental health\ncontexts. Our study offers recommendations for how designers can approach the\nethical and effective use of LLM chatbots and other AI mental health support\ntools in mental health care.", "AI": {"tldr": "This paper explores the use of LLM chatbots for mental health support, analyzing user experiences and introducing the concept of therapeutic alignment.", "motivation": "As LLM chatbots are increasingly used for mental health support, there is a need to understand their impact and ensure they are designed responsibly to avoid risks to users.", "method": "The authors conducted interviews with 21 people from diverse backgrounds who used LLM chatbots for mental health support, analyzing their experiences and interactions.", "result": "The study identifies unique support roles users create for chatbots, their experiences in filling care gaps, and the cultural limitations they face; it emphasizes the importance of therapeutic alignment.", "conclusion": "The findings stress the need for ethical design recommendations for LLM chatbots in mental health, considering how these tools can align with therapeutic values.", "key_contributions": ["Introduction of the concept of therapeutic alignment for AI in mental health care", "In-depth qualitative analysis of user experiences with LLM chatbots for mental health support", "Recommendations for ethical AI design in mental health contexts."], "limitations": "The study is based on a limited sample size of 21 individuals and may not represent broader populations.", "keywords": ["LLM chatbots", "mental health support", "therapeutic alignment", "user experiences", "AI ethics"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2505.06120", "pdf": "https://arxiv.org/pdf/2505.06120.pdf", "abs": "https://arxiv.org/abs/2505.06120", "title": "LLMs Get Lost In Multi-Turn Conversation", "authors": ["Philippe Laban", "Hiroaki Hayashi", "Yingbo Zhou", "Jennifer Neville"], "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) are conversational interfaces. As such, LLMs\nhave the potential to assist their users not only when they can fully specify\nthe task at hand, but also to help them define, explore, and refine what they\nneed through multi-turn conversational exchange. Although analysis of LLM\nconversation logs has confirmed that underspecification occurs frequently in\nuser instructions, LLM evaluation has predominantly focused on the single-turn,\nfully-specified instruction setting. In this work, we perform large-scale\nsimulation experiments to compare LLM performance in single- and multi-turn\nsettings. Our experiments confirm that all the top open- and closed-weight LLMs\nwe test exhibit significantly lower performance in multi-turn conversations\nthan single-turn, with an average drop of 39% across six generation tasks.\nAnalysis of 200,000+ simulated conversations decomposes the performance\ndegradation into two components: a minor loss in aptitude and a significant\nincrease in unreliability. We find that LLMs often make assumptions in early\nturns and prematurely attempt to generate final solutions, on which they overly\nrely. In simpler terms, we discover that *when LLMs take a wrong turn in a\nconversation, they get lost and do not recover*.", "AI": {"tldr": "The study analyzes the performance of Large Language Models (LLMs) in single-turn vs multi-turn conversations, revealing significant performance drops in multi-turn settings due to unreliability and premature assumptions.", "motivation": "To understand how LLMs perform in conversational interfaces, especially considering the frequent underspecification in user instructions.", "method": "Large-scale simulation experiments compared LLM performance across single-turn and multi-turn conversations, analyzing over 200,000 simulated conversations.", "result": "All tested LLMs showed an average performance drop of 39% in multi-turn settings compared to single-turn, with unreliability increasing significantly.", "conclusion": "LLMs struggle in multi-turn conversations, often making early incorrect assumptions that lead to a failure to recover, demonstrating the need for improved conversational capabilities.", "key_contributions": ["Identification of performance differences between single-turn and multi-turn instructions for LLMs.", "Detailed analysis of the causes of performance degradation, highlighting unreliability and early assumptions.", "Insights into LLM behavior in dynamic conversation settings that inform design improvements."], "limitations": "Focused solely on LLMs and may not generalize to other conversational AI systems; limited to the specific tasks tested.", "keywords": ["Large Language Models", "Multi-turn conversations", "Instruction underspecification", "Performance evaluation", "Conversational AI"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2504.12236", "pdf": "https://arxiv.org/pdf/2504.12236.pdf", "abs": "https://arxiv.org/abs/2504.12236", "title": "Towards Human-Centered Early Prediction Models for Academic Performance in Real-World Contexts", "authors": ["Han Zhang", "Yiyi Ren", "Paula S. Nurius", "Jennifer Mankoff", "Anind K. Dey"], "categories": ["cs.HC", "68U35", "H.5.0; I.2.m"], "comment": "Accepted to CSCW", "summary": "Supporting student success requires collaboration among multiple\nstakeholders. Researchers have explored machine learning models for academic\nperformance prediction; yet key challenges remain in ensuring these models are\ninterpretable, equitable, and actionable within real-world educational support\nsystems. First, many models prioritize predictive accuracy but overlook\nhuman-centered machine learning principles, limiting trust among students and\nreducing their usefulness for educators and institutional decision-makers.\nSecond, most models require at least a month of data before making reliable\npredictions, delaying opportunities for early intervention. Third, current\nmodels primarily rely on sporadically collected, classroom-derived data,\nmissing broader behavioral patterns that could provide more continuous and\nactionable insights. To address these gaps, we present three modeling\napproaches-LR, 1D-CNN, and MTL-1D-CNN-to classify students as low or high\nacademic performers. We evaluate them based on explainability, fairness, and\ngeneralizability to assess their alignment with key social values. Using\nbehavioral and self-reported data collected within the first week of two Spring\nterms, we demonstrate that these models can identify at-risk students as early\nas week one. However, trade-offs across human-centered machine learning\nprinciples highlight the complexity of designing predictive models that\neffectively support multi-stakeholder decision-making and intervention\nstrategies. We discuss these trade-offs and their implications for different\nstakeholders, outlining how predictive models can be integrated into student\nsupport systems. Finally, we examine broader socio-technical challenges in\ndeploying these models and propose future directions for advancing\nhuman-centered, collaborative academic prediction systems.", "AI": {"tldr": "The paper discusses machine learning models for predicting student academic performance, focusing on interpretability, fairness, and early intervention using early behavioral data.", "motivation": "To improve student support systems by integrating machine learning models that are interpretable, equitable, and actionable.", "method": "Three modeling approaches: LR, 1D-CNN, and MTL-1D-CNN were evaluated based on explainability, fairness, and generalizability using early behavioral and self-reported data.", "result": "The models could identify at-risk students as early as the first week of the term, highlighting their potential for timely interventions.", "conclusion": "While offering early predictions, there are trade-offs among human-centered principles that need consideration for effective deployment in educational contexts.", "key_contributions": ["Development of three modeling approaches for academic performance prediction", "Assessment based on explainability, fairness, and generalizability", "Discussion on the socio-technical challenges and future directions for predictive modeling in education"], "limitations": "Trade-offs across human-centered machine learning principles can complicate model design for multi-stakeholder decision-making.", "keywords": ["Machine Learning", "Academic Performance Prediction", "Human-Centered Design"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2505.06145", "pdf": "https://arxiv.org/pdf/2505.06145.pdf", "abs": "https://arxiv.org/abs/2505.06145", "title": "Towards Robust Few-Shot Text Classification Using Transformer Architectures and Dual Loss Strategies", "authors": ["Xu Han", "Yumeng Sun", "Weiqiang Huang", "Hongye Zheng", "Junliang Du"], "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Few-shot text classification has important application value in low-resource\nenvironments. This paper proposes a strategy that combines adaptive\nfine-tuning, contrastive learning, and regularization optimization to improve\nthe classification performance of Transformer-based models. Experiments on the\nFewRel 2.0 dataset show that T5-small, DeBERTa-v3, and RoBERTa-base perform\nwell in few-shot tasks, especially in the 5-shot setting, which can more\neffectively capture text features and improve classification accuracy. The\nexperiment also found that there are significant differences in the\nclassification difficulty of different relationship categories. Some categories\nhave fuzzy semantic boundaries or complex feature distributions, making it\ndifficult for the standard cross entropy loss to learn the discriminative\ninformation required to distinguish categories. By introducing contrastive loss\nand regularization loss, the generalization ability of the model is enhanced,\neffectively alleviating the overfitting problem in few-shot environments. In\naddition, the research results show that the use of Transformer models or\ngenerative architectures with stronger self-attention mechanisms can help\nimprove the stability and accuracy of few-shot classification.", "AI": {"tldr": "The paper presents a strategy integrating adaptive fine-tuning, contrastive learning, and regularization optimization to enhance few-shot text classification accuracy using Transformer models.", "motivation": "Few-shot text classification is crucial in low-resource settings, and improving model performance in these situations is necessary.", "method": "The proposed strategy combines adaptive fine-tuning, contrastive learning, and regularization optimization, tested on the FewRel 2.0 dataset with models like T5-small, DeBERTa-v3, and RoBERTa-base.", "result": "Experiments show improved classification performance, particularly in 5-shot settings, highlighting challenges with certain relationship categories due to complex feature distributions.", "conclusion": "Introducing contrastive loss and regularization loss enhances generalization and mitigates overfitting in few-shot classification scenarios.", "key_contributions": ["Adaptive fine-tuning for few-shot tasks", "Integration of contrastive and regularization losses", "Demonstration of Transformer model capabilities in classification accuracy"], "limitations": "The study emphasizes challenges with specific relationship categories due to fuzzy semantics and feature distribution complexities.", "keywords": ["few-shot classification", "Transformer models", "contrastive learning", "adaptive fine-tuning", "regularization"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2505.06149", "pdf": "https://arxiv.org/pdf/2505.06149.pdf", "abs": "https://arxiv.org/abs/2505.06149", "title": "Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study", "authors": ["Faeze Ghorbanpour", "Daryna Dementieva", "Alexander Fraser"], "categories": ["cs.CL", "cs.CY", "cs.MM"], "comment": null, "summary": "Despite growing interest in automated hate speech detection, most existing\napproaches overlook the linguistic diversity of online content. Multilingual\ninstruction-tuned large language models such as LLaMA, Aya, Qwen, and BloomZ\noffer promising capabilities across languages, but their effectiveness in\nidentifying hate speech through zero-shot and few-shot prompting remains\nunderexplored. This work evaluates LLM prompting-based detection across eight\nnon-English languages, utilizing several prompting techniques and comparing\nthem to fine-tuned encoder models. We show that while zero-shot and few-shot\nprompting lag behind fine-tuned encoder models on most of the real-world\nevaluation sets, they achieve better generalization on functional tests for\nhate speech detection. Our study also reveals that prompt design plays a\ncritical role, with each language often requiring customized prompting\ntechniques to maximize performance.", "AI": {"tldr": "This work evaluates multilingual hate speech detection using LLMs with zero-shot and few-shot prompting, highlighting the importance of prompt design across languages.", "motivation": "To address the neglect of linguistic diversity in automated hate speech detection approaches and explore the effectiveness of multilingual LLMs.", "method": "Evaluation of LLM prompting techniques across eight non-English languages, comparing them to fine-tuned encoder models in real-world and functional tests.", "result": "Zero-shot and few-shot prompting methods generally underperform compared to fine-tuned models but show better generalization on functional tests for hate speech detection; the need for customized prompts was identified for each language.", "conclusion": "Prompt design is crucial for enhancing hate speech detection performance across languages, emphasizing the necessity for tailored approaches in multilingual contexts.", "key_contributions": ["Evaluation of hate speech detection capabilities of LLMs across multiple languages", "Comparison of prompting techniques against fine-tuned models", "Identification of critical role of customized prompting for language-specific performance"], "limitations": "", "keywords": ["hate speech detection", "multilingual LLMs", "prompt engineering", "zero-shot learning", "few-shot learning"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2505.06150", "pdf": "https://arxiv.org/pdf/2505.06150.pdf", "abs": "https://arxiv.org/abs/2505.06150", "title": "A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets", "authors": ["Ryan Lagasse", "Aidan Kiernans", "Avijit Ghosh", "Shiri Dori-Hacohen"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce a scaling law for fine-tuning large language models (LLMs) under\nfixed compute budgets that explicitly accounts for data composition.\nConventional approaches measure training data solely by total tokens, yet the\nnumber of examples and their average token length -- what we term \\emph{dataset\nvolume} -- play a decisive role in model performance. Our formulation is tuned\nfollowing established procedures. Experiments on the BRICC dataset\n\\cite{salavati2024reducing} and subsets of the MMLU dataset\n\\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple\nsubsampling strategies, reveal that data composition significantly affects\ntoken efficiency. These results motivate refined scaling laws for practical LLM\nfine-tuning in resource-constrained settings.", "AI": {"tldr": "The paper introduces a scaling law for fine-tuning large language models, emphasizing the importance of data composition in addition to total tokens.", "motivation": "To refine conventional fine-tuning approaches for large language models by incorporating dataset volume, which includes example counts and average token lengths.", "method": "Experiments conducted on the BRICC and MMLU datasets, applying various subsampling strategies to assess the effects of data composition on training efficiency.", "result": "Data composition was found to significantly influence token efficiency when fine-tuning large language models.", "conclusion": "Refined scaling laws for LLM fine-tuning can lead to better performance in resource-constrained environments by accounting for data composition.", "key_contributions": ["Introduced a new scaling law for fine-tuning LLMs considering data composition.", "Demonstrated the impact of dataset volume on model performance.", "Provided insights for practical LLM fine-tuning under compute constraints."], "limitations": "", "keywords": ["Large Language Models", "Fine-tuning", "Data Composition", "Token Efficiency", "Scaling Laws"], "importance_score": 8, "read_time_minutes": 5}}
{"id": "2505.06151", "pdf": "https://arxiv.org/pdf/2505.06151.pdf", "abs": "https://arxiv.org/abs/2505.06151", "title": "Estimating Quality in Therapeutic Conversations: A Multi-Dimensional Natural Language Processing Framework", "authors": ["Alice Rueda", "Argyrios Perivolaris", "Niloy Roy", "Dylan Weston", "Sarmed Shaya", "Zachary Cote", "Martin Ivanov", "Bazen G. Teferra", "Yuqi Wu", "Sirisha Rambhatla", "Divya Sharma", "Andrew Greenshaw", "Rakesh Jetly", "Yanbo Zhang", "Bo Cao", "Reza Samavi", "Sridhar Krishnan", "Venkat Bhat"], "categories": ["cs.CL"], "comment": "12 pages, 4 figures, 7 tables", "summary": "Engagement between client and therapist is a critical determinant of\ntherapeutic success. We propose a multi-dimensional natural language processing\n(NLP) framework that objectively classifies engagement quality in counseling\nsessions based on textual transcripts. Using 253 motivational interviewing\ntranscripts (150 high-quality, 103 low-quality), we extracted 42 features\nacross four domains: conversational dynamics, semantic similarity as topic\nalignment, sentiment classification, and question detection. Classifiers,\nincluding Random Forest (RF), Cat-Boost, and Support Vector Machines (SVM),\nwere hyperparameter tuned and trained using a stratified 5-fold\ncross-validation and evaluated on a holdout test set. On balanced\n(non-augmented) data, RF achieved the highest classification accuracy (76.7%),\nand SVM achieved the highest AUC (85.4%). After SMOTE-Tomek augmentation,\nperformance improved significantly: RF achieved up to 88.9% accuracy, 90.0%\nF1-score, and 94.6% AUC, while SVM reached 81.1% accuracy, 83.1% F1-score, and\n93.6% AUC. The augmented data results reflect the potential of the framework in\nfuture larger-scale applications. Feature contribution revealed conversational\ndynamics and semantic similarity between clients and therapists were among the\ntop contributors, led by words uttered by the client (mean and standard\ndeviation). The framework was robust across the original and augmented datasets\nand demonstrated consistent improvements in F1 scores and recall. While\ncurrently text-based, the framework supports future multimodal extensions\n(e.g., vocal tone, facial affect) for more holistic assessments. This work\nintroduces a scalable, data-driven method for evaluating engagement quality of\nthe therapy session, offering clinicians real-time feedback to enhance the\nquality of both virtual and in-person therapeutic interactions.", "AI": {"tldr": "This paper presents a multi-dimensional NLP framework for classifying the quality of engagement in counseling sessions using textual transcripts.", "motivation": "To improve therapeutic success by objectively measuring client-therapist engagement during therapy sessions.", "method": "The framework extracts 42 features across four domains (conversational dynamics, semantic similarity, sentiment classification, and question detection) from 253 motivational interviewing transcripts and uses classifiers such as Random Forest, Cat-Boost, and Support Vector Machines to evaluate engagement quality.", "result": "Random Forest achieved the highest accuracy of 88.9% and SVM reached an AUC of 94.6% after data augmentation, demonstrating the framework's effectiveness.", "conclusion": "The proposed method allows for real-time feedback for clinicians, with potential for multimodal applications in the future.", "key_contributions": ["Introduction of a scalable NLP framework for measuring therapeutic engagement", "Demonstration of significant accuracy improvements with data augmentation", "Identification of key features impacting engagement quality"], "limitations": "Currently limited to text-based data; lacks multimodal integration.", "keywords": ["NLP", "therapeutic engagement", "machine learning", "counseling", "data augmentation"], "importance_score": 8, "read_time_minutes": 12}}
{"id": "2505.06186", "pdf": "https://arxiv.org/pdf/2505.06186.pdf", "abs": "https://arxiv.org/abs/2505.06186", "title": "Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies", "authors": ["Massimiliano Pronesti", "Joao Bettencourt-Silva", "Paul Flanagan", "Alessandra Pascale", "Oisin Redmond", "Anya Belz", "Yufang Hou"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Extracting scientific evidence from biomedical studies for clinical research\nquestions (e.g., Does stem cell transplantation improve quality of life in\npatients with medically refractory Crohn's disease compared to placebo?) is a\ncrucial step in synthesising biomedical evidence. In this paper, we focus on\nthe task of document-level scientific evidence extraction for clinical\nquestions with conflicting evidence. To support this task, we create a dataset\ncalled CochraneForest, leveraging forest plots from Cochrane systematic\nreviews. It comprises 202 annotated forest plots, associated clinical research\nquestions, full texts of studies, and study-specific conclusions. Building on\nCochraneForest, we propose URCA (Uniform Retrieval Clustered Augmentation), a\nretrieval-augmented generation framework designed to tackle the unique\nchallenges of evidence extraction. Our experiments show that URCA outperforms\nthe best existing methods by up to 10.3% in F1 score on this task. However, the\nresults also underscore the complexity of CochraneForest, establishing it as a\nchallenging testbed for advancing automated evidence synthesis systems.", "AI": {"tldr": "This paper introduces a new dataset and a framework for extracting scientific evidence from biomedical studies, outperforming existing methods in F1 score.", "motivation": "The motivation is to improve evidence extraction for clinical research questions with conflicting evidence, which is critical in synthesizing biomedical evidence.", "method": "The authors created the CochraneForest dataset from forest plots of Cochrane systematic reviews and proposed URCA, a retrieval-augmented generation framework for evidence extraction.", "result": "URCA improved performance over existing methods by up to 10.3% in F1 score for document-level scientific evidence extraction tasks.", "conclusion": "The complexity of CochraneForest presents a significant challenge for advancing automated evidence synthesis systems, indicating further research is needed.", "key_contributions": ["Creation of CochraneForest dataset with 202 annotated forest plots", "Introduction of URCA framework for evidence extraction", "Demonstration of performance improvement over existing methods in F1 score"], "limitations": "The CochraneForest is complex, which may pose challenges for fully automated evidence synthesis systems.", "keywords": ["evidence extraction", "CochraneForest", "retrieval-augmented generation", "clinical research", "biomedical studies"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2505.05828", "pdf": "https://arxiv.org/pdf/2505.05828.pdf", "abs": "https://arxiv.org/abs/2505.05828", "title": "An empathic GPT-based chatbot to talk about mental disorders with Spanish teenagers", "authors": ["Alba María Mármol-Romero", "Manuel García-Vega", "Miguel Ángel García-Cumbreras", "Arturo Montejo-Ráez"], "categories": ["cs.HC", "cs.CL"], "comment": "This is an Accepted Manuscript version of the following article,\n  accepted for publication in International Journal of Human-Computer\n  Interaction. It is deposited under the terms of the Creative Commons\n  Attribution-NonCommercial-NoDerivatives License", "summary": "This paper presents a chatbot-based system to engage young Spanish people in\nthe awareness of certain mental disorders through a self-disclosure technique.\nThe study was carried out in a population of teenagers aged between 12 and 18\nyears. The dialogue engine mixes closed and open conversations, so certain\ncontrolled messages are sent to focus the chat on a specific disorder, which\nwill change over time. Once a set of trial questions is answered, the system\ncan initiate the conversation on the disorder under the focus according to the\nuser's sensibility to that disorder, in an attempt to establish a more\nempathetic communication. Then, an open conversation based on the GPT-3\nlanguage model is initiated, allowing the user to express themselves with more\nfreedom. The results show that these systems are of interest to young people\nand could help them become aware of certain mental disorders.", "AI": {"tldr": "This paper presents a chatbot that engages Spanish teenagers in conversations about mental disorders using a self-disclosure technique and GPT-3.", "motivation": "To increase awareness of mental disorders among young Spanish people through engaging dialogue.", "method": "The system employs a dialogue engine that combines closed and open conversations, adapted to users' responses and sensitivity to specific disorders.", "result": "The chatbot was found to be of interest to young users and could facilitate awareness of mental disorders.", "conclusion": "These chatbot systems can effectively engage teenagers in discussions about mental health, promoting awareness and understanding.", "key_contributions": ["Development of a chatbot tailored for mental health awareness among teenagers", "Utilization of a self-disclosure technique to engage users", "Integration of GPT-3 for open-ended conversations"], "limitations": "The study is limited to a specific age group (12-18 years) and demographic (Spanish youth).", "keywords": ["chatbot", "mental health", "self-disclosure", "GPT-3", "teenagers"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2209.15373", "pdf": "https://arxiv.org/pdf/2209.15373.pdf", "abs": "https://arxiv.org/abs/2209.15373", "title": "PART: Pre-trained Authorship Representation Transformer", "authors": ["Javier Huertas-Tato", "Alejandro Martin", "David Camacho"], "categories": ["cs.CL"], "comment": null, "summary": "Authors writing documents imprint identifying information within their texts:\nvocabulary, registry, punctuation, misspellings, or even emoji usage. Previous\nworks use hand-crafted features or classification tasks to train their\nauthorship models, leading to poor performance on out-of-domain authors. Using\nstylometric representations is more suitable, but this by itself is an open\nresearch challenge. In this paper, we propose PART, a contrastively trained\nmodel fit to learn \\textbf{authorship embeddings} instead of semantics. We\ntrain our model on ~1.5M texts belonging to 1162 literature authors, 17287 blog\nposters and 135 corporate email accounts; a heterogeneous set with identifiable\nwriting styles. We evaluate the model on current challenges, achieving\ncompetitive performance. We also evaluate our model on test splits of the\ndatasets achieving zero-shot 72.39\\% accuracy when bounded to 250 authors, a\n54\\% and 56\\% higher than RoBERTa embeddings. We qualitatively assess the\nrepresentations with different data visualizations on the available datasets,\nobserving features such as gender, age, or occupation of the author.", "AI": {"tldr": "The paper presents PART, a contrastively trained model for learning authorship embeddings using a diverse dataset, achieving notable results in identifying authorship traits.", "motivation": "Prior works on authorship attribution struggled with out-of-domain authors due to reliance on hand-crafted features; this paper aims to improve authorship identification through stylometric representations.", "method": "The authors developed a contrastively trained model named PART, trained on approximately 1.5 million texts spanning various authors and contexts to create authorship embeddings.", "result": "PART achieved zero-shot 72.39% accuracy on 250 authors, outperforming RoBERTa embeddings by 54% and 56% in two different tests.", "conclusion": "The proposed model demonstrates a significant advancement in authorship identification, with capabilities to assess authorship features like gender and occupation through data visualization.", "key_contributions": ["Introduction of the method PART for learning authorship embeddings", "Large-scale training on diverse author datasets", "Competitive zero-shot performance compared to existing models"], "limitations": "The effectiveness of the model may depend on the diversity of the training dataset and may require further validation on different types of texts.", "keywords": ["authorship attribution", "embeddings", "stylometry", "contrastive learning", "machine learning"], "importance_score": 5, "read_time_minutes": 15}}
{"id": "2406.09519", "pdf": "https://arxiv.org/pdf/2406.09519.pdf", "abs": "https://arxiv.org/abs/2406.09519", "title": "Talking Heads: Understanding Inter-layer Communication in Transformer Language Models", "authors": ["Jack Merullo", "Carsten Eickhoff", "Ellie Pavlick"], "categories": ["cs.CL", "cs.AI"], "comment": "Neurips 2024", "summary": "Although it is known that transformer language models (LMs) pass features\nfrom early layers to later layers, it is not well understood how this\ninformation is represented and routed by the model. We analyze a mechanism used\nin two LMs to selectively inhibit items in a context in one task, and find that\nit underlies a commonly used abstraction across many context-retrieval\nbehaviors. Specifically, we find that models write into low-rank subspaces of\nthe residual stream to represent features which are then read out by later\nlayers, forming low-rank communication channels (Elhage et al., 2021) between\nlayers. A particular 3D subspace in model activations in GPT-2 can be traversed\nto positionally index items in lists, and we show that this mechanism can\nexplain an otherwise arbitrary-seeming sensitivity of the model to the order of\nitems in the prompt. That is, the model has trouble copying the correct\ninformation from context when many items ``crowd\" this limited space. By\ndecomposing attention heads with the Singular Value Decomposition (SVD), we\nfind that previously described interactions between heads separated by one or\nmore layers can be predicted via analysis of their weight matrices alone. We\nshow that it is possible to manipulate the internal model representations as\nwell as edit model weights based on the mechanism we discover in order to\nsignificantly improve performance on our synthetic Laundry List task, which\nrequires recall from a list, often improving task accuracy by over 20%. Our\nanalysis reveals a surprisingly intricate interpretable structure learned from\nlanguage model pretraining, and helps us understand why sophisticated LMs\nsometimes fail in simple domains, facilitating future analysis of more complex\nbehaviors.", "AI": {"tldr": "The paper analyzes how transformer language models route information across layers, focusing on the low-rank subspace mechanism that impacts context retrieval and performance on list-based tasks.", "motivation": "To understand the representation and routing of information in transformer language models, particularly how they manage context retrieval tasks.", "method": "The authors analyze two language models, studying their use of low-rank communication channels and decomposing attention heads using Singular Value Decomposition (SVD) to uncover interactions between heads across layers.", "result": "The study reveals that models utilize low-rank subspaces to manage context, explaining performance variability in responding to item order in prompts, and showing a way to improve task accuracy by over 20% on a list recall task.", "conclusion": "The findings highlight a complex and interpretable structure in language models that emerges from pretraining, shedding light on why these models may struggle in simpler domains, which could inform future research on more complex behaviors.", "key_contributions": ["Identified low-rank communication channels in transformer models.", "Explained performance inconsistencies related to item order using subspace analysis.", "Demonstrated a method to enhance model performance on context retrieval tasks."], "limitations": "", "keywords": ["transformer language models", "context retrieval", "low-rank subspaces"], "importance_score": 8, "read_time_minutes": 20}}
{"id": "2407.11963", "pdf": "https://arxiv.org/pdf/2407.11963.pdf", "abs": "https://arxiv.org/abs/2407.11963", "title": "NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context?", "authors": ["Mo Li", "Songyang Zhang", "Taolin Zhang", "Haodong Duan", "Yunxin Liu", "Kai Chen"], "categories": ["cs.CL"], "comment": "v2: updated with tested models and Multi-Needle Reasoning\n  implementation", "summary": "The capability of large language models to handle long-context information is\ncrucial across various real-world applications. Existing evaluation methods\noften rely either on real-world long texts, making it difficult to exclude the\ninfluence of models' inherent knowledge, or introduce irrelevant filler content\nto artificially achieve target lengths, reducing assessment effectiveness. To\naddress these limitations, we introduce NeedleBench, a synthetic framework for\nassessing retrieval and reasoning performance in bilingual long-context tasks\nwith adaptive context lengths. NeedleBench systematically embeds key data\npoints at varying depths to rigorously test model capabilities. Tasks are\ncategorized into two scenarios: information-sparse, featuring minimal relevant\ndetails within extensive irrelevant text to simulate simple retrieval tasks;\nand information-dense (the Ancestral Trace Challenge), where relevant\ninformation is continuously distributed throughout the context to simulate\ncomplex reasoning tasks. Our experiments reveal that although recent reasoning\nmodels like Deepseek-R1 and OpenAI's o3 excel in mathematical reasoning, they\nstruggle with continuous retrieval and reasoning in information-dense\nscenarios, even at shorter context lengths. We also characterize a phenomenon\ntermed 'under-thinking', where models prematurely conclude reasoning despite\navailable information. NeedleBench thus provides critical insights and targeted\ntools essential for evaluating and improving LLMs' long-context capabilities.\nAll resources are available at OpenCompass:\nhttps://github.com/open-compass/opencompass.", "AI": {"tldr": "NeedleBench is a synthetic framework designed to evaluate retrieval and reasoning capabilities in bilingual long-context tasks, addressing limitations of existing evaluation methods.", "motivation": "To effectively assess the performance of large language models (LLMs) on long-context tasks without the biases introduced by real-world texts or irrelevant filler content.", "method": "NeedleBench embeds key data points at various depths to create two types of tasks: information-sparse and information-dense, systematically testing models on their retrieval and reasoning capabilities.", "result": "Models like Deepseek-R1 and OpenAI's o3 performed well in mathematical reasoning but struggled with information-dense retrieval and reasoning, revealing a phenomenon of 'under-thinking'.", "conclusion": "NeedleBench provides vital insights for evaluating long-context capabilities of LLMs and is made available as an open-source resource.", "key_contributions": ["Introduction of a new framework for evaluating LLMs' long-context performance", "Identification of the 'under-thinking' phenomenon in models", "Categorization of tasks into information-sparse and information-dense scenarios"], "limitations": "", "keywords": ["large language models", "long-context evaluation", "retrieval and reasoning", "NeedleBench", "under-thinking"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2408.00103", "pdf": "https://arxiv.org/pdf/2408.00103.pdf", "abs": "https://arxiv.org/abs/2408.00103", "title": "ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget", "authors": ["Riccardo Orlando", "Pere-Lluis Huguet Cabot", "Edoardo Barba", "Roberto Navigli"], "categories": ["cs.CL", "cs.AI"], "comment": "Findings of the Association for Computational Linguistics ACL 2024", "summary": "Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in\nNatural Language Processing, serving as critical components in a wide range of\napplications. In this paper, we propose ReLiK, a Retriever-Reader architecture\nfor both EL and RE, where, given an input text, the Retriever module undertakes\nthe identification of candidate entities or relations that could potentially\nappear within the text. Subsequently, the Reader module is tasked to discern\nthe pertinent retrieved entities or relations and establish their alignment\nwith the corresponding textual spans. Notably, we put forward an innovative\ninput representation that incorporates the candidate entities or relations\nalongside the text, making it possible to link entities or extract relations in\na single forward pass and to fully leverage pre-trained language models\ncontextualization capabilities, in contrast with previous\nRetriever-Reader-based methods, which require a forward pass for each\ncandidate. Our formulation of EL and RE achieves state-of-the-art performance\nin both in-domain and out-of-domain benchmarks while using academic budget\ntraining and with up to 40x inference speed compared to competitors. Finally,\nwe show how our architecture can be used seamlessly for Information Extraction\n(cIE), i.e. EL + RE, and setting a new state of the art by employing a shared\nReader that simultaneously extracts entities and relations.", "AI": {"tldr": "The paper introduces ReLiK, a novel Retriever-Reader architecture for Entity Linking (EL) and Relation Extraction (RE) that enhances efficiency and performance by integrating candidate entities with input text.", "motivation": "Entity Linking (EL) and Relation Extraction (RE) are vital tasks in NLP with numerous applications, thus improvements in these tasks can significantly enhance various systems.", "method": "ReLiK employs a Retriever module to identify potential entities or relations in the input text, followed by a Reader module that aligns these entities or relations with specific textual spans, utilizing a new input representation to function in a single forward pass.", "result": "The proposed method achieves state-of-the-art performance on both in-domain and out-of-domain benchmarks while demonstrating up to 40x faster inference speed compared to existing methods.", "conclusion": "ReLiK advances the state of the art in EL and RE and shows potential for streamlined Information Extraction by employing a unified Reader for simultaneous entity and relation extraction.", "key_contributions": ["Introduction of the ReLiK architecture for combined EL and RE tasks", "Innovative input representation for efficiency in processing", "Achieving state-of-the-art performance with significant speed improvements"], "limitations": "", "keywords": ["Entity Linking", "Relation Extraction", "Natural Language Processing", "Retriever-Reader architecture", "Information Extraction"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2410.18234", "pdf": "https://arxiv.org/pdf/2410.18234.pdf", "abs": "https://arxiv.org/abs/2410.18234", "title": "Multi-Draft Speculative Sampling: Canonical Decomposition and Theoretical Limits", "authors": ["Ashish Khisti", "M. Reza Ebrahimi", "Hassan Dbouk", "Arash Behboodi", "Roland Memisevic", "Christos Louizos"], "categories": ["cs.CL", "cs.DC", "cs.IT", "cs.LG", "math.IT"], "comment": "Published as a (spotlight) conference paper at ICLR 2025", "summary": "We consider multi-draft speculative sampling, where the proposal sequences\nare sampled independently from different draft models. At each step, a\ntoken-level draft selection scheme takes a list of valid tokens as input and\nproduces an output token whose distribution matches that of the target model.\nPrevious works have demonstrated that the optimal scheme (which maximizes the\nprobability of accepting one of the input tokens) can be cast as a solution to\na linear program. In this work we show that the optimal scheme can be\ndecomposed into a two-step solution: in the first step an importance sampling\n(IS) type scheme is used to select one intermediate token; in the second step\n(single-draft) speculative sampling is applied to generate the output token.\nFor the case of two identical draft models we further 1) establish a necessary\nand sufficient condition on the distributions of the target and draft models\nfor the acceptance probability to equal one and 2) provide an explicit\nexpression for the optimal acceptance probability. Our theoretical analysis\nalso motives a new class of token-level selection schemes based on weighted\nimportance sampling. Our experimental results demonstrate consistent\nimprovements in the achievable block efficiency and token rates over baseline\nschemes in a number of scenarios.", "AI": {"tldr": "This paper presents a two-step solution for multi-draft speculative sampling in token generation, improving block efficiency and token rates.", "motivation": "To improve the efficiency of token-level draft selection in language models by optimizing the acceptance probability of generated tokens.", "method": "A two-step approach is proposed: first, an importance sampling scheme selects an intermediate token, followed by single-draft speculative sampling to generate the output token, with theoretical foundations establishing conditions for optimal acceptance probability.", "result": "The proposed method shows consistent improvements in block efficiency and token rates compared to baseline schemes across various scenarios.", "conclusion": "The findings highlight a new class of token-level selection schemes based on weighted importance sampling that enhance token generation in multi-draft contexts.", "key_contributions": ["Decomposed optimal scheme into two steps for improved token generation", "Established conditions for maximum acceptance probability", "Introduced new token-level selection schemes based on weighted importance sampling"], "limitations": "", "keywords": ["multi-draft sampling", "token-level selection", "importance sampling"], "importance_score": 6, "read_time_minutes": 15}}
{"id": "2411.11053", "pdf": "https://arxiv.org/pdf/2411.11053.pdf", "abs": "https://arxiv.org/abs/2411.11053", "title": "SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation", "authors": ["Bin Xu", "Yiguan Lin", "Yinghao Li", "Yang Gao"], "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by IJCAI2025", "summary": "Large language models demonstrate exceptional performance in simple code\ngeneration tasks but still face challenges in tackling complex problems. These\nchallenges may stem from insufficient reasoning and problem decomposition\ncapabilities. To address this issue, we propose a reasoning-augmented data\ngeneration process, SRA-MCTS, which guides the model to autonomously generate\nhigh-quality intermediate reasoning paths. This creates a positive feedback\nloop, enabling continuous improvement. Our method operates entirely through the\nmodel itself without requiring additional supervision. By synthesizing natural\nlanguage reasoning paths and translating them into executable code, the\napproach ensures analytical accuracy and enhances the success rate in solving\ncomplex tasks. Experimental results show that, even without additional\nsupervisory signals, our method achieves performance improvements across\ndifferent model scales, demonstrating the significant potential of\nself-improvement in small models. Furthermore, the method remains robust when\ntraditional Chain-of-Thought (CoT) approaches exhibit performance degradation,\nwith notable improvements observed in diversity metrics such as pass@10. We\nencourage further exploration of reasoning processes within training data to\nenhance the ability of language models to address complex problems. Our code\nand data are public at https://github.com/DIRECT-BIT/SRA-MCTS.", "AI": {"tldr": "This paper introduces SRA-MCTS, a reasoning-augmented data generation process that improves complex problem solving in large language models by autonomously generating reasoning paths.", "motivation": "Large language models struggle with complex problem-solving due to inadequate reasoning and problem decomposition, prompting the need for improved strategies.", "method": "The proposed method, SRA-MCTS, utilizes a self-guided process to generate high-quality intermediate reasoning paths without additional supervision.", "result": "Experimental results indicate that SRA-MCTS leads to improved performance in solving complex tasks across various model scales, even as traditional methods falter.", "conclusion": "The research suggests that enhancing training data with reasoning processes can significantly advance language models' capabilities in tackling complex problems.", "key_contributions": ["Introduction of SRA-MCTS for reasoning-augmented data generation.", "Demonstrated improvements in solving complex tasks without extra supervision.", "Robust performance even when traditional methods degrade."], "limitations": "", "keywords": ["Large Language Models", "Reasoning", "Data Generation", "Machine Learning", "Complex Problem Solving"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2501.12106", "pdf": "https://arxiv.org/pdf/2501.12106.pdf", "abs": "https://arxiv.org/abs/2501.12106", "title": "Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes", "authors": ["Stefan Lenz", "Arsenij Ustjanzew", "Marco Jeray", "Meike Ressing", "Torsten Panholzer"], "categories": ["cs.CL", "cs.AI"], "comment": "53 pages, 5 figures", "summary": "Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP.", "AI": {"tldr": "This paper evaluates eleven open source large language models (LLMs) for automating tumor documentation in Germany, testing tasks such as diagnosis identification and ICD-10 code assignment.", "motivation": "To improve the efficiency and reliability of tumor documentation, which is currently done manually in Germany.", "method": "The study tested eleven open source LLMs ranging from 1-70 billion parameters on tasks of tumor diagnosis identification, ICD-10 code assignment, and extraction of diagnosis dates, using a specially prepared dataset from urology notes.", "result": "The models Llama 3.1 8B, Mistral 7B, and Mistral NeMo 12 B performed comparably well, while smaller models showed lower performance. Few-shot prompting with different medical examples improved outcomes.", "conclusion": "Open source LLMs have strong potential to automate tumor documentation with optimal models in the 7-12 billion parameter range, suggesting these could be effective tools for clinical documentation with further fine-tuning and prompting.", "key_contributions": ["Evaluation of multiple LLMs for medical documentation tasks", "Creation of a new dataset for German-language medical NLP", "Recommendations for optimal model sizes and prompting strategies"], "limitations": "", "keywords": ["large language models", "tumor documentation", "medical NLP"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2501.14851", "pdf": "https://arxiv.org/pdf/2501.14851.pdf", "abs": "https://arxiv.org/abs/2501.14851", "title": "JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models", "authors": ["Michael K. Chen", "Xikun Zhang", "Dacheng Tao"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "Logical reasoning is a critical component of Large Language Models (LLMs),\nand substantial research efforts in recent years have aimed to enhance their\ndeductive reasoning capabilities. However, existing deductive reasoning\nbenchmarks, which are crucial for evaluating and advancing LLMs, are inadequate\ndue to their lack of task complexity, presence of prior knowledge as a\nconfounder, and superficial error analysis. To address these deficiencies, we\nintroduce JustLogic, a synthetically generated deductive reasoning benchmark\ndesigned for rigorous evaluation of LLMs. JustLogic is (i) highly complex,\ncapable of generating a diverse range of linguistic patterns, vocabulary, and\nargument structures; (ii) prior knowledge independent, eliminating the\nadvantage of models possessing prior knowledge and ensuring that only deductive\nreasoning is used to answer questions; and (iii) capable of in-depth error\nanalysis on the heterogeneous effects of reasoning depth and argument form on\nmodel accuracy. Our experimental results on JustLogic reveal that (i)\nstate-of-the-art (SOTA) reasoning LLMs perform on par or better than the human\naverage but significantly worse than the human ceiling, and (ii) SOTA\nnon-reasoning models still underperform the human average. All code and data\nare available at https://github.com/michaelchen-lab/JustLogic", "AI": {"tldr": "JustLogic is a new deductive reasoning benchmark for evaluating LLMs, addressing inadequacies in existing benchmarks by emphasizing complexity and independence from prior knowledge.", "motivation": "To improve the evaluation and advancement of Large Language Models' deductive reasoning capabilities, which are currently hampered by inadequate benchmarks.", "method": "JustLogic provides a synthetically generated benchmark that is highly complex and allows for diverse linguistic patterns and argument structures while being independent of prior knowledge.", "result": "Experimental results indicate that state-of-the-art reasoning models perform comparably to but worse than humans, and non-reasoning models perform below human averages.", "conclusion": "JustLogic offers a more rigorous evaluation framework for LLMs, with insights into reasoning depth and argument form affecting model accuracy.", "key_contributions": ["Introduction of JustLogic as a new benchmark", "Focus on task complexity and linguistic diversity", "Error analysis on reasoning depth and argument structure"], "limitations": "", "keywords": ["Large Language Models", "deductive reasoning", "benchmark", "Natural Language Processing"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2501.16154", "pdf": "https://arxiv.org/pdf/2501.16154.pdf", "abs": "https://arxiv.org/abs/2501.16154", "title": "AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought", "authors": ["Xin Huang", "Tarun Kumar Vangani", "Zhengyuan Liu", "Bowei Zou", "Ai Ti Aw"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models have shown impressive multilingual capabilities through\npretraining on diverse corpora. While these models show strong reasoning\nabilities, their performance varies significantly across languages due to\nimbalanced training data distribution. Existing approaches using sample-level\ntranslation for extensive multilingual pretraining and cross-lingual tuning\nface scalability challenges and often fail to capture nuanced reasoning\nprocesses across languages. In this paper, we introduce AdaCoT (Adaptive\nChain-of-Thought), a framework that enhances multilingual factual reasoning by\ndynamically routing thought processes in intermediary ``thinking languages''\nbefore generating target-language responses. AdaCoT leverages a\nlanguage-agnostic core and incorporates an adaptive, reward-based mechanism for\nselecting optimal reasoning pathways without requiring additional pretraining.\nOur comprehensive evaluation across multiple benchmarks demonstrates\nsubstantial improvements in both factual reasoning quality and cross-lingual\nconsistency, with particularly strong performance gains in low-resource\nlanguage settings. The results suggest that adaptive reasoning paths can\neffectively bridge the performance gap between high and low-resource languages\nwhile maintaining cultural and linguistic nuances.", "AI": {"tldr": "The paper introduces AdaCoT, a framework for enhancing multilingual factual reasoning in large language models by dynamically routing thought processes through intermediary languages before producing responses, demonstrating improved performance especially in low-resource languages.", "motivation": "To address performance disparities in multilingual reasoning due to imbalanced training data and existing limitations in cross-lingual tuning techniques.", "method": "AdaCoT uses an adaptive, reward-based mechanism to dynamically select reasoning pathways in intermediary languages without requiring additional pretraining.", "result": "Substantial improvements in factual reasoning quality and cross-lingual consistency were observed, particularly benefiting low-resource languages.", "conclusion": "AdaCoT effectively narrows the performance gap between high and low-resource languages while preserving cultural and linguistic nuances.", "key_contributions": ["Introduction of the AdaCoT framework for multilingual reasoning", "Demonstrated significant performance improvements in low-resource languages", "Adaptive mechanism for optimal reasoning pathway selection"], "limitations": "", "keywords": ["multilingual reasoning", "large language models", "adaptive reasoning"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2502.01210", "pdf": "https://arxiv.org/pdf/2502.01210.pdf", "abs": "https://arxiv.org/abs/2502.01210", "title": "Phonetic accommodation and inhibition in a dynamic neural field model", "authors": ["Sam Kirkham", "Patrycja Strycharczuk", "Rob Davies", "Danielle Welburn"], "categories": ["cs.CL"], "comment": null, "summary": "Short-term phonetic accommodation is a fundamental driver behind accent\nchange, but how does real-time input from another speaker's voice shape the\nspeech planning representations of an interlocutor? We advance a computational\nmodel of change in speech planning representations during phonetic\naccommodation, grounded in dynamic neural field equations for movement planning\nand memory dynamics. A dual-layer planning/memory field predicts that\nconvergence to a model talker on one trial can trigger divergence on subsequent\ntrials, due to a delayed inhibitory effect in the more slowly evolving memory\nfield. The model's predictions are compared with empirical patterns of\naccommodation from an experimental pilot study. We show that observed empirical\nphenomena may correspond to variation in the magnitude of inhibitory memory\ndynamics, which could reflect resistance to accommodation due to phonological\nand/or sociolinguistic pressures. We discuss the implications of these results\nfor the relations between short-term phonetic accommodation and sound change.", "AI": {"tldr": "The paper presents a computational model for understanding how real-time speech input from one speaker influences the speech planning of another, focusing on phonetic accommodation.", "motivation": "The study investigates how short-term phonetic accommodation affects accent change and how another speaker’s voice influences speech planning representations.", "method": "A computational model based on dynamic neural field equations is used to explore changes in speech planning representations during phonetic accommodation, predicting how memory dynamics influence these changes.", "result": "The model predicts that convergence to a model talker's voice can lead to divergence in speech planning due to delayed inhibitory effects in memory, with empirical data supporting these predictions.", "conclusion": "The findings highlight the complex interplay between phonetic accommodation and sound change, suggesting that resistance to accommodation may be influenced by external pressures.", "key_contributions": ["Introduces a computational model for phonetic accommodation based on neural field equations.", "Demonstrates the impact of memory dynamics on speech planning.", "Provides empirical support for the model through a pilot study."], "limitations": "The study is based on a pilot experiment, which may have limitations in representativeness and scope.", "keywords": ["phonetic accommodation", "speech planning", "neural fields", "memory dynamics", "accent change"], "importance_score": 4, "read_time_minutes": 15}}
{"id": "2502.04134", "pdf": "https://arxiv.org/pdf/2502.04134.pdf", "abs": "https://arxiv.org/abs/2502.04134", "title": "The Order Effect: Investigating Prompt Sensitivity to Input Order in LLMs", "authors": ["Bryan Guan", "Tanya Roosta", "Peyman Passban", "Mehdi Rezagholizadeh"], "categories": ["cs.CL"], "comment": "The first 3 authors have contributed equally", "summary": "As large language models (LLMs) become integral to diverse applications,\nensuring their reliability under varying input conditions is crucial. One key\nissue affecting this reliability is order sensitivity, wherein slight\nvariations in the input arrangement can lead to inconsistent or biased outputs.\nAlthough recent advances have reduced this sensitivity, the problem remains\nunresolved. This paper investigates the extent of order sensitivity in LLMs\nwhose internal components are hidden from users (such as closed-source models\nor those accessed via API calls). We conduct experiments across multiple tasks,\nincluding paraphrasing, relevance judgment, and multiple-choice questions. Our\nresults show that input order significantly affects performance across tasks,\nwith shuffled inputs leading to measurable declines in output accuracy.\nFew-shot prompting demonstrates mixed effectiveness and offers partial\nmitigation; however, fails to fully resolve the problem. These findings\nhighlight persistent risks, particularly in high-stakes applications, and point\nto the need for more robust LLMs or improved input-handling techniques in\nfuture development.", "AI": {"tldr": "This paper examines the issue of order sensitivity in large language models (LLMs), revealing that input arrangement significantly impacts output accuracy across various tasks.", "motivation": "To address the reliability issues of LLMs affected by order sensitivity, which can lead to inconsistent or biased outputs, especially in high-stakes applications.", "method": "The study conducts experiments on multiple tasks (paraphrasing, relevance judgment, and multiple-choice questions) to analyze how variations in input order affect performance.", "result": "Results indicate that shuffled inputs result in measurable declines in output accuracy, with few-shot prompting showing only mixed effectiveness in mitigation.", "conclusion": "There is a need for more robust LLMs or improved input-handling techniques to enhance reliability, particularly in critical applications.", "key_contributions": ["Investigates order sensitivity in LLMs", "Demonstrates significant impact of input arrangement on task performance", "Highlights the need for improved input-handling techniques"], "limitations": "Focuses on specific tasks and does not fully resolve the issue of order sensitivity across all potential applications.", "keywords": ["large language models", "order sensitivity", "input arrangement", "reliability", "high-stakes applications"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2502.09667", "pdf": "https://arxiv.org/pdf/2502.09667.pdf", "abs": "https://arxiv.org/abs/2502.09667", "title": "k-LLMmeans: Scalable, Stable, and Interpretable Text Clustering via LLM-based Centroids", "authors": ["Jairo Diaz-Rodriguez"], "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "We introduce k-LLMmeans, a novel modification of the k-means algorithm for\ntext clustering that leverages LLM-generated summaries as cluster centroids,\ncapturing semantic nuances often missed by purely numerical averages. This\ndesign preserves the core optimization properties of k-means while enhancing\nsemantic interpretability and avoiding the scalability and instability issues\ntypical of modern LLM-based clustering. Unlike existing methods, our approach\ndoes not increase LLM usage with dataset size and produces transparent\nintermediate outputs. We further extend it with a mini-batch variant for\nefficient, real-time clustering of streaming text. Extensive experiments across\nmultiple datasets, embeddings, and LLMs show that k-LLMmeans consistently\noutperforms k-means and other traditional baselines and achieves results\ncomparable to state-of-the-art LLM-based clustering, with a fraction of the LLM\ncalls. Finally, we present a case study on sequential text streams and\nintroduce a new benchmark dataset constructed from StackExchange to evaluate\ntext-stream clustering methods.", "AI": {"tldr": "Introduction of k-LLMmeans, a novel algorithm for text clustering using LLM-generated summaries as centroids to enhance semantic interpretability.", "motivation": "To improve text clustering by leveraging LLM-generated summaries, capturing semantic nuances missed by traditional k-means methods while maintaining optimization properties.", "method": "The proposed k-LLMmeans algorithm modifies the k-means algorithm to use LLM-generated summaries as cluster centroids, also introducing a mini-batch variant for efficient, real-time clustering.", "result": "k-LLMmeans consistently outperforms traditional k-means and other baselines, achieving results comparable to state-of-the-art LLM-based clustering with fewer LLM calls.", "conclusion": "The k-LLMmeans approach provides efficient, interpretable text clustering applicable to streaming text, validated through extensive experiments and a new benchmark dataset.", "key_contributions": ["Novel text clustering algorithm using LLM summaries as centroids", "Mini-batch variant for real-time clustering", "New benchmark dataset for text-stream clustering"], "limitations": "", "keywords": ["text clustering", "LLM", "k-means", "semantic interpretability", "benchmark dataset"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2502.20364", "pdf": "https://arxiv.org/pdf/2502.20364.pdf", "abs": "https://arxiv.org/abs/2502.20364", "title": "Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization", "authors": ["Ryan C. Barron", "Maksim E. Eren", "Olga M. Serafimova", "Cynthia Matuszek", "Boian S. Alexandrov"], "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 8 figures, 5 tables", "summary": "Agentic Generative AI, powered by Large Language Models (LLMs) with\nRetrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores\n(VSs), represents a transformative technology applicable to specialized domains\nsuch as legal systems, research, recommender systems, cybersecurity, and global\nsecurity, including proliferation research. This technology excels at inferring\nrelationships within vast unstructured or semi-structured datasets. The legal\ndomain here comprises complex data characterized by extensive, interrelated,\nand semi-structured knowledge systems with complex relations. It comprises\nconstitutions, statutes, regulations, and case law. Extracting insights and\nnavigating the intricate networks of legal documents and their relations is\ncrucial for effective legal research. Here, we introduce a generative AI system\nthat integrates RAG, VS, and KG, constructed via Non-Negative Matrix\nFactorization (NMF), to enhance legal information retrieval and AI reasoning\nand minimize hallucinations. In the legal system, these technologies empower AI\nagents to identify and analyze complex connections among cases, statutes, and\nlegal precedents, uncovering hidden relationships and predicting legal\ntrends-challenging tasks that are essential for ensuring justice and improving\noperational efficiency. Our system employs web scraping techniques to\nsystematically collect legal texts, such as statutes, constitutional\nprovisions, and case law, from publicly accessible platforms like Justia. It\nbridges the gap between traditional keyword-based searches and contextual\nunderstanding by leveraging advanced semantic representations, hierarchical\nrelationships, and latent topic discovery. This framework supports legal\ndocument clustering, summarization, and cross-referencing, for scalable,\ninterpretable, and accurate retrieval for semi-structured data while advancing\ncomputational law and AI.", "AI": {"tldr": "This paper presents a generative AI system that enhances legal information retrieval by integrating Retrieval-Augmented Generation, Vector Stores, and Knowledge Graphs, along with Non-Negative Matrix Factorization, aimed at improving AI reasoning and minimizing hallucinations in complex legal data.", "motivation": "To improve legal research by efficiently extracting insights from complex, semi-structured legal data such as statutes and case law, thereby enhancing the operational efficiency of legal systems.", "method": "The proposed system integrates Retrieval-Augmented Generation, Vector Stores, and Knowledge Graphs, constructed using Non-Negative Matrix Factorization, and employs web scraping to collect legal texts from public platforms.", "result": "The integrated system successfully identifies complex relationships among legal documents, enhances contextual understanding, and minimizes AI hallucinations while improving the efficiency of legal information retrieval.", "conclusion": "The framework supports scalable and interpretable retrieval of legal documents and contributes to advancements in computational law and AI, providing a more effective approach to legal research than traditional methods.", "key_contributions": ["Integration of RAG, VS, and KG in legal AI systems", "Use of Non-Negative Matrix Factorization for knowledge construction", "Application of web scraping for systematic legal text collection"], "limitations": "The approach may require continuous updates to the knowledge graph to maintain accuracy and relevance in rapidly evolving legal contexts.", "keywords": ["Generative AI", "Legal Information Retrieval", "Large Language Models", "Knowledge Graphs", "Retrieval-Augmented Generation"], "importance_score": 6, "read_time_minutes": 15}}
{"id": "2503.17460", "pdf": "https://arxiv.org/pdf/2503.17460.pdf", "abs": "https://arxiv.org/abs/2503.17460", "title": "ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach", "authors": ["Reem Gody", "Mahmoud Goudy", "Ahmed Y. Tawfik"], "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we present ConvoGen: an innovative framework for generating\nsynthetic conversational data using multi-agent systems. Our method leverages\nfew-shot learning and introduces iterative sampling from a dynamically updated\nfew-shot hub to create diverse and realistic conversational scenarios. The\ngenerated data has numerous applications, including training and evaluating\nconversational AI models, and augmenting existing datasets for tasks like\nconversational intent classification or conversation summarization. Our\nexperiments demonstrate the effectiveness of this method in producing\nhigh-quality diverse synthetic conversational data, highlighting its potential\nto enhance the development and evaluation of conversational AI systems.", "AI": {"tldr": "ConvoGen is a framework for generating diverse synthetic conversational data through multi-agent systems and few-shot learning.", "motivation": "To create high-quality synthetic conversational data for training and evaluating conversational AI models.", "method": "Utilizes few-shot learning and iterative sampling from a dynamically updated few-shot hub.", "result": "Demonstrated effectiveness in producing diverse and realistic conversational scenarios beneficial for various conversational AI tasks.", "conclusion": "ConvoGen shows great potential in enhancing the development and evaluation of conversational AI systems by providing high-quality synthetic data.", "key_contributions": ["Introduction of the ConvoGen framework for synthetic conversational data generation", "Application of few-shot learning in multi-agent systems for data diversity", "Potential to augment existing datasets for conversational AI tasks."], "limitations": "", "keywords": ["synthetic data", "conversational AI", "few-shot learning"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2504.12345", "pdf": "https://arxiv.org/pdf/2504.12345.pdf", "abs": "https://arxiv.org/abs/2504.12345", "title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models", "authors": ["Yutong Xia", "Ao Qu", "Yunhan Zheng", "Yihong Tang", "Dingyi Zhuang", "Yuxuan Liang", "Shenhao Wang", "Cathy Wu", "Lijun Sun", "Roger Zimmermann", "Jinhua Zhao"], "categories": ["cs.CL", "cs.CY", "cs.MA"], "comment": null, "summary": "Urban causal research is essential for understanding the complex dynamics of\ncities and informing evidence-based policies. However, it is challenged by the\ninefficiency and bias of hypothesis generation, barriers to multimodal data\ncomplexity, and the methodological fragility of causal experimentation. Recent\nadvances in large language models (LLMs) present an opportunity to rethink how\nurban causal analysis is conducted. This Perspective examines current urban\ncausal research by analyzing taxonomies that categorize research topics, data\nsources, and methodological approaches to identify structural gaps. We then\nintroduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four\ndistinct modular agents responsible for hypothesis generation, data\nengineering, experiment design and execution, and results interpretation with\npolicy recommendations. We propose evaluation criteria for rigor and\ntransparency and reflect on implications for human-AI collaboration, equity,\nand accountability. We call for a new research agenda that embraces\nAI-augmented workflows not as replacements for human expertise but as tools to\nbroaden participation, improve reproducibility, and unlock more inclusive forms\nof urban causal reasoning.", "AI": {"tldr": "This paper presents AutoUrbanCI, a framework that utilizes large language models to enhance urban causal research by automating key processes and promoting equity and accountability.", "motivation": "Urban causal research faces inefficiencies and biases due to traditional hypothesis generation and the complexity of multimodal data. LLMs offer a new way to improve urban causal analysis.", "method": "The paper introduces AutoUrbanCI, which consists of four modular agents for hypothesis generation, data engineering, experiment design and execution, and results interpretation.", "result": "AutoUrbanCI aims to improve urban causal research through enhanced workflows that integrate AI while maintaining a focus on human expertise.", "conclusion": "The paper calls for a shift towards AI-augmented urban causal research to increase inclusivity, reproducibility, and collaborative human-AI efforts in policymaking.", "key_contributions": ["Introduction of AutoUrbanCI framework leveraging LLMs for urban causal research", "Proposal of modular agents for different stages of causal analysis", "Emphasis on human-AI collaboration and inclusivity in research processes"], "limitations": "", "keywords": ["urban causal research", "large language models", "AI-augmented workflows", "human-AI collaboration", "policy recommendations"], "importance_score": 8, "read_time_minutes": 15}}
