{"id": "2505.05583", "pdf": "https://arxiv.org/pdf/2505.05583.pdf", "abs": "https://arxiv.org/abs/2505.05583", "title": "KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification", "authors": ["Qianbo Zang", "Christophe Zgrzendek", "Igor Tchappi", "Afshin Khadangi", "Johannes Sedlmeir"], "categories": ["cs.CL"], "comment": null, "summary": "Hierarchical Text Classification (HTC) involves assigning documents to labels\norganized within a taxonomy. Most previous research on HTC has focused on\nsupervised methods. However, in real-world scenarios, employing supervised HTC\ncan be challenging due to a lack of annotated data. Moreover, HTC often faces\nissues with large label spaces and long-tail distributions. In this work, we\npresent Knowledge Graphs for zero-shot Hierarchical Text Classification\n(KG-HTC), which aims to address these challenges of HTC in applications by\nintegrating knowledge graphs with Large Language Models (LLMs) to provide\nstructured semantic context during classification. Our method retrieves\nrelevant subgraphs from knowledge graphs related to the input text using a\nRetrieval-Augmented Generation (RAG) approach. Our KG-HTC can enhance LLMs to\nunderstand label semantics at various hierarchy levels. We evaluate KG-HTC on\nthree open-source HTC datasets: WoS, DBpedia, and Amazon. Our experimental\nresults show that KG-HTC significantly outperforms three baselines in the\nstrict zero-shot setting, particularly achieving substantial improvements at\ndeeper levels of the hierarchy. This evaluation demonstrates the effectiveness\nof incorporating structured knowledge into LLMs to address HTC's challenges in\nlarge label spaces and long-tailed label distributions. Our code is available\nat: https://github.com/QianboZang/KG-HTC."}
{"id": "2505.05648", "pdf": "https://arxiv.org/pdf/2505.05648.pdf", "abs": "https://arxiv.org/abs/2505.05648", "title": "Privacy-Preserving Transformers: SwiftKey's Differential Privacy Implementation", "authors": ["Abdelrahman Abouelenin", "Mohamed Abdelrehim", "Raffy Fahim", "Amr Hendy", "Mohamed Afify"], "categories": ["cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "In this paper we train a transformer using differential privacy (DP) for\nlanguage modeling in SwiftKey. We run multiple experiments to balance the\ntrade-off between the model size, run-time speed and accuracy. We show that we\nget small and consistent gains in the next-word-prediction and accuracy with\ngraceful increase in memory and speed compared to the production GRU. This is\nobtained by scaling down a GPT2 architecture to fit the required size and a two\nstage training process that builds a seed model on general data and DP\nfinetunes it on typing data. The transformer is integrated using ONNX offering\nboth flexibility and efficiency."}
{"id": "2505.05687", "pdf": "https://arxiv.org/pdf/2505.05687.pdf", "abs": "https://arxiv.org/abs/2505.05687", "title": "Exploration of COVID-19 Discourse on Twitter: American Politician Edition", "authors": ["Cindy Kim", "Daniela Puchall", "Jiangyi Liang", "Jiwon Kim"], "categories": ["cs.CL"], "comment": null, "summary": "The advent of the COVID-19 pandemic has undoubtedly affected the political\nscene worldwide and the introduction of new terminology and public opinions\nregarding the virus has further polarized partisan stances. Using a collection\nof tweets gathered from leading American political figures online (Republican\nand Democratic), we explored the partisan differences in approach, response,\nand attitude towards handling the international crisis. Implementation of the\nbag-of-words, bigram, and TF-IDF models was used to identify and analyze\nkeywords, topics, and overall sentiments from each party. Results suggest that\nDemocrats are more concerned with the casualties of the pandemic, and give more\nmedical precautions and recommendations to the public whereas Republicans are\nmore invested in political responsibilities such as keeping the public updated\nthrough media and carefully watching the progress of the virus. We propose a\nsystematic approach to predict and distinguish a tweet's political stance (left\nor right leaning) based on its COVID-19 related terms using different\nclassification algorithms on different language models."}
{"id": "2505.05704", "pdf": "https://arxiv.org/pdf/2505.05704.pdf", "abs": "https://arxiv.org/abs/2505.05704", "title": "Assessing Robustness to Spurious Correlations in Post-Training Language Models", "authors": ["Julia Shuieh", "Prasann Singhal", "Apaar Shanker", "John Heyer", "George Pu", "Samuel Denton"], "categories": ["cs.CL", "cs.AI"], "comment": "ICLR '25 Workshop on Spurious Correlation and Shortcut Learning", "summary": "Supervised and preference-based fine-tuning techniques have become popular\nfor aligning large language models (LLMs) with user intent and correctness\ncriteria. However, real-world training data often exhibits spurious\ncorrelations -- arising from biases, dataset artifacts, or other \"shortcut\"\nfeatures -- that can compromise a model's performance or generalization. In\nthis paper, we systematically evaluate three post-training algorithms --\nSupervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and KTO\n(Kahneman-Tversky Optimization) -- across a diverse set of synthetic tasks and\nspuriousness conditions. Our tasks span mathematical reasoning, constrained\ninstruction-following, and document-grounded question answering. We vary the\ndegree of spurious correlation (10% vs. 90%) and investigate two forms of\nartifacts: \"Feature Ambiguity\" and \"Distributional Narrowness.\" Our results\nshow that the models often but not always degrade under higher spuriousness.\nThe preference-based methods (DPO/KTO) can demonstrate relative robustness in\nmathematical reasoning tasks. By contrast, SFT maintains stronger performance\nin complex, context-intensive tasks. These findings highlight that no single\npost-training strategy universally outperforms in all scenarios; the best\nchoice depends on the type of target task and the nature of spurious\ncorrelations."}
{"id": "2505.05543", "pdf": "https://arxiv.org/pdf/2505.05543.pdf", "abs": "https://arxiv.org/abs/2505.05543", "title": "Would You Rely on an Eerie Agent? A Systematic Review of the Impact of the Uncanny Valley Effect on Trust in Human-Agent Interaction", "authors": ["Ahdiyeh Alipour", "Tilo Hartmann", "Maryam Alimardani"], "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "75 pages, Figure 11, Table 5", "summary": "Trust is a fundamental component of human-agent interaction. With the\nincreasing presence of artificial agents in daily life, it is essential to\nunderstand how people perceive and trust these agents. One of the key\nchallenges affecting this perception is the Uncanny Valley Effect (UVE), where\nincreasingly human-like artificial beings can be perceived as eerie or\nrepelling. Despite growing interest in trust and the UVE, existing research\nvaries widely in terms of how these concepts are defined and operationalized.\nThis inconsistency raises important questions about how and under what\nconditions the UVE influences trust in agents. A systematic understanding of\ntheir relationship is currently lacking. This review aims to examine the impact\nof the UVE on human trust in agents and to identify methodological patterns,\nlimitations, and gaps in the existing empirical literature. Following PRISMA\nguidelines, a systematic search identified 53 empirical studies that\ninvestigated both UVE-related constructs and trust or trust-related outcomes.\nStudies were analyzed based on a structured set of categories, including types\nof agents and interactions, methodological and measurement approaches, and key\nfindings. The results of our systematic review reveal that most studies rely on\nstatic images or hypothetical scenarios with limited real-time interaction, and\nthe majority use subjective trust measures. This review offers a novel\nframework for classifying trust measurement approaches with regard to the\nbest-practice criteria for empirically investigating the UVE. As the first\nsystematic attempt to map the intersection of UVE and trust, this review\ncontributes to a deeper understanding of their interplay and offers a\nfoundation for future research. Keywords: the uncanny valley effect, trust,\nhuman-likeness, affinity response, human-agent interaction"}
{"id": "2505.05714", "pdf": "https://arxiv.org/pdf/2505.05714.pdf", "abs": "https://arxiv.org/abs/2505.05714", "title": "TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine Translation for Documentaries", "authors": ["Jinze Lv", "Jian Chen", "Zi Long", "Xianghua Fu", "Yin Chen"], "categories": ["cs.CL"], "comment": "NLDB 2025", "summary": "Most existing multimodal machine translation (MMT) datasets are predominantly\ncomposed of static images or short video clips, lacking extensive video data\nacross diverse domains and topics. As a result, they fail to meet the demands\nof real-world MMT tasks, such as documentary translation. In this study, we\ndeveloped TopicVD, a topic-based dataset for video-supported multimodal machine\ntranslation of documentaries, aiming to advance research in this field. We\ncollected video-subtitle pairs from documentaries and categorized them into\neight topics, such as economy and nature, to facilitate research on domain\nadaptation in video-guided MMT. Additionally, we preserved their contextual\ninformation to support research on leveraging the global context of\ndocumentaries in video-guided MMT. To better capture the shared semantics\nbetween text and video, we propose an MMT model based on a cross-modal\nbidirectional attention module. Extensive experiments on the TopicVD dataset\ndemonstrate that visual information consistently improves the performance of\nthe NMT model in documentary translation. However, the MMT model's performance\nsignificantly declines in out-of-domain scenarios, highlighting the need for\neffective domain adaptation methods. Additionally, experiments demonstrate that\nglobal context can effectively improve translation performance. % Dataset and\nour implementations are available at https://github.com/JinzeLv/TopicVD"}
{"id": "2505.05660", "pdf": "https://arxiv.org/pdf/2505.05660.pdf", "abs": "https://arxiv.org/abs/2505.05660", "title": "Not Like Us, Hunty: Measuring Perceptions and Behavioral Effects of Minoritized Anthropomorphic Cues in LLMs", "authors": ["Jeffrey Basoah", "Daniel Chechelnitsky", "Tao Long", "Katharina Reinecke", "Chrysoula Zerva", "Kaitlyn Zhou", "Mark Díaz", "Maarten Sap"], "categories": ["cs.HC"], "comment": "Accepted to FAccT 2025", "summary": "As large language models (LLMs) increasingly adapt and personalize to diverse\nsets of users, there is an increased risk of systems appropriating sociolects,\ni.e., language styles or dialects that are associated with specific minoritized\nlived experiences (e.g., African American English, Queer slang). In this work,\nwe examine whether sociolect usage by an LLM agent affects user reliance on its\noutputs and user perception (satisfaction, frustration, trust, and social\npresence). We designed and conducted user studies where 498 African American\nEnglish (AAE) speakers and 487 Queer slang speakers performed a set of\nquestion-answering tasks with LLM-based suggestions in either standard American\nEnglish (SAE) or their self-identified sociolect. Our findings showed that\nsociolect usage by LLMs influenced both reliance and perceptions, though in\nsome surprising ways. Results suggest that both AAE and Queer slang speakers\nrelied more on the SAE agent, and had more positive perceptions of the SAE\nagent. Yet, only Queer slang speakers felt more social presence from the Queer\nslang agent over the SAE one, whereas only AAE speakers preferred and trusted\nthe SAE agent over the AAE one. These findings emphasize the need to test for\nbehavioral outcomes rather than simply assume that personalization would lead\nto a better and safer reliance outcome. They also highlight the nuanced\ndynamics of minoritized language in machine interactions, underscoring the need\nfor LLMs to be carefully designed to respect cultural and linguistic boundaries\nwhile fostering genuine user engagement and trust."}
{"id": "2505.05755", "pdf": "https://arxiv.org/pdf/2505.05755.pdf", "abs": "https://arxiv.org/abs/2505.05755", "title": "Insertion Language Models: Sequence Generation with Arbitrary-Position Insertions", "authors": ["Dhruvesh Patel", "Aishwarya Sahoo", "Avinash Amballa", "Tahira Naseem", "Tim G. J. Rudner", "Andrew McCallum"], "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Autoregressive models (ARMs), which predict subsequent tokens one-by-one\n``from left to right,'' have achieved significant success across a wide range\nof sequence generation tasks. However, they struggle to accurately represent\nsequences that require satisfying sophisticated constraints or whose sequential\ndependencies are better addressed by out-of-order generation. Masked Diffusion\nModels (MDMs) address some of these limitations, but the process of unmasking\nmultiple tokens simultaneously in MDMs can introduce incoherences, and MDMs\ncannot handle arbitrary infilling constraints when the number of tokens to be\nfilled in is not known in advance. In this work, we introduce Insertion\nLanguage Models (ILMs), which learn to insert tokens at arbitrary positions in\na sequence -- that is, they select jointly both the position and the vocabulary\nelement to be inserted. By inserting tokens one at a time, ILMs can represent\nstrong dependencies between tokens, and their ability to generate sequences in\narbitrary order allows them to accurately model sequences where token\ndependencies do not follow a left-to-right sequential structure. To train ILMs,\nwe propose a tailored network parameterization and use a simple denoising\nobjective. Our empirical evaluation demonstrates that ILMs outperform both ARMs\nand MDMs on common planning tasks. Furthermore, we show that ILMs outperform\nMDMs and perform on par with ARMs in an unconditional text generation task\nwhile offering greater flexibility than MDMs in arbitrary-length text\ninfilling."}
{"id": "2505.05694", "pdf": "https://arxiv.org/pdf/2505.05694.pdf", "abs": "https://arxiv.org/abs/2505.05694", "title": "Extending Stress Detection Reproducibility to Consumer Wearable Sensors", "authors": ["Ohida Binte Amin", "Varun Mishra", "Tinashe M. Tapera", "Robert Volpe", "Aarti Sathyanarayana"], "categories": ["cs.HC", "cs.LG"], "comment": "Accepted at IEEE EMBC 2025", "summary": "Wearable sensors are widely used to collect physiological data and develop\nstress detection models. However, most studies focus on a single dataset,\nrarely evaluating model reproducibility across devices, populations, or study\nconditions. We previously assessed the reproducibility of stress detection\nmodels across multiple studies, testing models trained on one dataset against\nothers using heart rate (with R-R interval) and electrodermal activity (EDA).\nIn this study, we extended our stress detection reproducibility to consumer\nwearable sensors. We compared validated research-grade devices, to consumer\nwearables - Biopac MP160, Polar H10, Empatica E4, to the Garmin Forerunner 55s,\nassessing device-specific stress detection performance by conducting a new\nstress study on undergraduate students. Thirty-five students completed three\nstandardized stress-induction tasks in a lab setting. Biopac MP160 performed\nthe best, being consistent with our expectations of it as the gold standard,\nthough performance varied across devices and models. Combining heart rate\nvariability (HRV) and EDA enhanced stress prediction across most scenarios.\nHowever, Empatica E4 showed variability; while HRV and EDA improved stress\ndetection in leave-one-subject-out (LOSO) evaluations (AUROC up to 0.953),\ndevice-specific limitations led to underperformance when tested with our\npre-trained stress detection tool (AUROC 0.723), highlighting generalizability\nchallenges related to hardware-model compatibility. Garmin Forerunner 55s\ndemonstrated strong potential for real-world stress monitoring, achieving the\nbest mental arithmetic stress detection performance in LOSO (AUROC up to 0.961)\ncomparable to research-grade devices like Polar H10 (AUROC 0.954), and Empatica\nE4 (AUROC 0.905 with HRV-only model and AUROC 0.953 with HRV+EDA model), with\nthe added advantage of consumer-friendly wearability for free-living contexts."}
{"id": "2505.05772", "pdf": "https://arxiv.org/pdf/2505.05772.pdf", "abs": "https://arxiv.org/abs/2505.05772", "title": "Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM", "authors": ["Zehao Fan", "Garrett Gagnon", "Zhenyu Liu", "Liu Liu"], "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Transformer-based models are the foundation of modern machine learning, but\ntheir execution, particularly during autoregressive decoding in large language\nmodels (LLMs), places significant pressure on memory systems due to frequent\nmemory accesses and growing key-value (KV) caches. This creates a bottleneck in\nmemory bandwidth, especially as context lengths increase. Processing-in-memory\n(PIM) architectures are a promising solution, offering high internal bandwidth\nand compute parallelism near memory. However, current PIM designs are primarily\noptimized for dense attention and struggle with the dynamic, irregular access\npatterns introduced by modern KV cache sparsity techniques. Consequently, they\nsuffer from workload imbalance, reducing throughput and resource utilization.\nIn this work, we propose STARC, a novel sparsity-optimized data mapping scheme\ntailored specifically for efficient LLM decoding on PIM architectures. STARC\nclusters KV pairs by semantic similarity and maps them to contiguous memory\nregions aligned with PIM bank structures. During decoding, queries retrieve\nrelevant tokens at cluster granularity by matching against precomputed\ncentroids, enabling selective attention and parallel processing without\nfrequent reclustering or data movement overhead. Experiments on the HBM-PIM\nsystem show that, compared to common token-wise sparsity methods, STARC reduces\nattention-layer latency by 19%--31% and energy consumption by 19%--27%. Under a\nKV cache budget of 1024, it achieves up to 54%--74% latency reduction and\n45%--67% energy reduction compared to full KV cache retrieval. Meanwhile, STARC\nmaintains model accuracy comparable to state-of-the-art sparse attention\nmethods, demonstrating its effectiveness in enabling efficient and\nhardware-friendly long-context LLM inference on PIM architectures."}
{"id": "2505.05786", "pdf": "https://arxiv.org/pdf/2505.05786.pdf", "abs": "https://arxiv.org/abs/2505.05786", "title": "A Day in Their Shoes: Using LLM-Based Perspective-Taking Interactive Fiction to Reduce Stigma Toward Dirty Work", "authors": ["Xiangzhe Yuan", "Jiajun Wang", "Qian Wan", "Siying Hu"], "categories": ["cs.HC", "cs.CY"], "comment": "Conference paper for FAccT '25", "summary": "Occupations referred to as \"dirty work\" often face entrenched social stigma,\nwhich adversely affects the mental health of workers in these fields and\nimpedes occupational equity. In this study, we propose a novel Interactive\nFiction (IF) framework powered by Large Language Models (LLMs) to encourage\nperspective-taking and reduce biases against these stigmatized yet essential\nroles. Through an experiment with participants (n = 100) across four such\noccupations, we observed a significant increase in participants' understanding\nof these occupations, as well as a high level of empathy and a strong sense of\nconnection to individuals in these roles. Additionally, qualitative interviews\nwith participants (n = 15) revealed that the LLM-based perspective-taking IF\nenhanced immersion, deepened emotional resonance and empathy toward \"dirty\nwork,\" and allowed participants to experience a sense of professional\nfulfillment in these occupations. However, participants also highlighted\nongoing challenges, such as limited contextual details generated by the LLM and\nthe unintentional reinforcement of existing stereotypes. Overall, our findings\nunderscore that an LLM-based perspective-taking IF framework offers a promising\nand scalable strategy for mitigating stigma and promoting social equity in\nmarginalized professions."}
{"id": "2505.05815", "pdf": "https://arxiv.org/pdf/2505.05815.pdf", "abs": "https://arxiv.org/abs/2505.05815", "title": "Tell Me Who Your Students Are: GPT Can Generate Valid Multiple-Choice Questions When Students' (Mis)Understanding Is Hinted", "authors": ["Machi Shimmei", "Masaki Uto", "Yuichiroh Matsubayashi", "Kentaro Inui", "Aditi Mallavarapu", "Noboru Matsuda"], "categories": ["cs.CL"], "comment": "This is a pre-print version of a paper to appear in AIED2025", "summary": "The primary goal of this study is to develop and evaluate an innovative\nprompting technique, AnaQuest, for generating multiple-choice questions (MCQs)\nusing a pre-trained large language model. In AnaQuest, the choice items are\nsentence-level assertions about complex concepts. The technique integrates\nformative and summative assessments. In the formative phase, students answer\nopen-ended questions for target concepts in free text. For summative\nassessment, AnaQuest analyzes these responses to generate both correct and\nincorrect assertions. To evaluate the validity of the generated MCQs, Item\nResponse Theory (IRT) was applied to compare item characteristics between MCQs\ngenerated by AnaQuest, a baseline ChatGPT prompt, and human-crafted items. An\nempirical study found that expert instructors rated MCQs generated by both AI\nmodels to be as valid as those created by human instructors. However, IRT-based\nanalysis revealed that AnaQuest-generated questions - particularly those with\nincorrect assertions (foils) - more closely resembled human-crafted items in\nterms of difficulty and discrimination than those produced by ChatGPT."}
{"id": "2505.05817", "pdf": "https://arxiv.org/pdf/2505.05817.pdf", "abs": "https://arxiv.org/abs/2505.05817", "title": "The Experience of Running: Recommending Routes Using Sensory Mapping in Urban Environments", "authors": ["Katrin Hänsel", "Luca Maria Aiello", "Daniele Quercia", "Rossano Schifanella", "Krisztian Zsolt Varga", "Linus W. Dietz", "Marios Constantinides"], "categories": ["cs.HC"], "comment": "45 pages, 6 figures, 6 tables", "summary": "Depending on the route, runners may experience frustration, freedom, or\nfulfilment. However, finding routes that are conducive to the psychological\nexperience of running remains an unresolved task in the literature. In a\nmixed-method study, we interviewed 7 runners to identify themes contributing to\nrunning experience, and quantitatively examined these themes in an online\nsurvey with 387 runners. Using Principal Component Analysis on the survey\nresponses, we developed a short experience sampling questionnaire that captures\nthe three most important dimensions of running experience: \\emph{performance \\&\nachievement}, \\emph{environment}, and \\emph{mind \\& social connectedness}.\nUsing path preferences obtained from the online survey, we clustered them into\ntwo types of routes: \\emph{scenic} (associated with nature and greenery) and\n\\emph{urban} (characterized by the presence of people); and developed a routing\nengine for path recommendations. We discuss challenges faced in developing the\nrouting engine, and provide guidelines to integrate it into mobile and wearable\nrunning apps."}
{"id": "2505.05864", "pdf": "https://arxiv.org/pdf/2505.05864.pdf", "abs": "https://arxiv.org/abs/2505.05864", "title": "Symbol-based entity marker highlighting for enhanced text mining in materials science with generative AI", "authors": ["Junhyeong Lee", "Jong Min Yuk", "Chan-Woo Lee"], "categories": ["cs.CL"], "comment": "29 pages", "summary": "The construction of experimental datasets is essential for expanding the\nscope of data-driven scientific discovery. Recent advances in natural language\nprocessing (NLP) have facilitated automatic extraction of structured data from\nunstructured scientific literature. While existing approaches-multi-step and\ndirect methods-offer valuable capabilities, they also come with limitations\nwhen applied independently. Here, we propose a novel hybrid text-mining\nframework that integrates the advantages of both methods to convert\nunstructured scientific text into structured data. Our approach first\ntransforms raw text into entity-recognized text, and subsequently into\nstructured form. Furthermore, beyond the overall data structuring framework, we\nalso enhance entity recognition performance by introducing an entity marker-a\nsimple yet effective technique that uses symbolic annotations to highlight\ntarget entities. Specifically, our entity marker-based hybrid approach not only\nconsistently outperforms previous entity recognition approaches across three\nbenchmark datasets (MatScholar, SOFC, and SOFC slot NER) but also improve the\nquality of final structured data-yielding up to a 58% improvement in\nentity-level F1 score and up to 83% improvement in relation-level F1 score\ncompared to direct approach."}
{"id": "2505.05828", "pdf": "https://arxiv.org/pdf/2505.05828.pdf", "abs": "https://arxiv.org/abs/2505.05828", "title": "An empathic GPT-based chatbot to talk about mental disorders with Spanish teenagers", "authors": ["Alba María Mármol-Romero", "Manuel García-Vega", "Miguel Ángel García-Cumbreras", "Arturo Montejo-Ráez"], "categories": ["cs.HC", "cs.CL"], "comment": "This is an Accepted Manuscript version of the following article,\n  accepted for publication in International Journal of Human-Computer\n  Interaction. It is deposited under the terms of the Creative Commons\n  Attribution-NonCommercial-NoDerivatives License", "summary": "This paper presents a chatbot-based system to engage young Spanish people in\nthe awareness of certain mental disorders through a self-disclosure technique.\nThe study was carried out in a population of teenagers aged between 12 and 18\nyears. The dialogue engine mixes closed and open conversations, so certain\ncontrolled messages are sent to focus the chat on a specific disorder, which\nwill change over time. Once a set of trial questions is answered, the system\ncan initiate the conversation on the disorder under the focus according to the\nuser's sensibility to that disorder, in an attempt to establish a more\nempathetic communication. Then, an open conversation based on the GPT-3\nlanguage model is initiated, allowing the user to express themselves with more\nfreedom. The results show that these systems are of interest to young people\nand could help them become aware of certain mental disorders."}
{"id": "2505.05946", "pdf": "https://arxiv.org/pdf/2505.05946.pdf", "abs": "https://arxiv.org/abs/2505.05946", "title": "Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2", "authors": ["Vytenis Šliogeris", "Povilas Daniušis", "Artūras Nakvosas"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "8 pages, 4 figures", "summary": "This technical report describes an experiment on autoregressive pre-training\nof Gemma2 2 billion parameter large language model (LLM) with 10\\% on the\nLithuanian language component of CulturaX from the point of view of continual\nlearning. We apply elastic weight consolidation (EWC) to the full set of the\nmodel's parameters and investigate language understanding benchmarks,\nconsisting of Arc, Belebele, Gsm8K, Hellaswag, MMLU, TruthfulQA, and Winogrande\nsets (both in English and Lithuanian versions), and perplexity benchmarks. We\nempirically demonstrate that EWC regularisation allows us not only to mitigate\ncatastrophic forgetting effects but also that it is potentially beneficial for\nlearning of the new task with LLMs."}
{"id": "2505.05832", "pdf": "https://arxiv.org/pdf/2505.05832.pdf", "abs": "https://arxiv.org/abs/2505.05832", "title": "Augmented Body Communicator: Enhancing daily body expression for people with upper limb limitations through LLM and a robotic arm", "authors": ["Songchen Zhou", "Mark Armstrong", "Giulia Barbareschi", "Toshihiro Ajioka", "Zheng Hu", "Ryoichi Ando", "Kentaro Yoshifuji", "Masatane Muto", "Kouta Minamizawa"], "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "Individuals with upper limb movement limitations face challenges in\ninteracting with others. Although robotic arms are currently used primarily for\nfunctional tasks, there is considerable potential to explore ways to enhance\nusers' body language capabilities during social interactions. This paper\nintroduces an Augmented Body Communicator system that integrates robotic arms\nand a large language model. Through the incorporation of kinetic memory,\ndisabled users and their supporters can collaboratively design actions for the\nrobot arm. The LLM system then provides suggestions on the most suitable action\nbased on contextual cues during interactions. The system underwent thorough\nuser testing with six participants who have conditions affecting upper limb\nmobility. Results indicate that the system improves users' ability to express\nthemselves. Based on our findings, we offer recommendations for developing\nrobotic arms that support disabled individuals with body language capabilities\nand functional tasks."}
{"id": "2505.05947", "pdf": "https://arxiv.org/pdf/2505.05947.pdf", "abs": "https://arxiv.org/abs/2505.05947", "title": "Summarisation of German Judgments in conjunction with a Class-based Evaluation", "authors": ["Bianca Steffes", "Nils Torben Wiedemann", "Alexander Gratz", "Pamela Hochreither", "Jana Elina Meyer", "Katharina Luise Schilke"], "categories": ["cs.CL"], "comment": null, "summary": "The automated summarisation of long legal documents can be a great aid for\nlegal experts in their daily work. We automatically create summaries (guiding\nprinciples) of German judgments by fine-tuning a decoder-based large language\nmodel. We enrich the judgments with information about legal entities before the\ntraining. For the evaluation of the created summaries, we define a set of\nevaluation classes which allows us to measure their language, pertinence,\ncompleteness and correctness. Our results show that employing legal entities\nhelps the generative model to find the relevant content, but the quality of the\ncreated summaries is not yet sufficient for a use in practice."}
{"id": "2505.05923", "pdf": "https://arxiv.org/pdf/2505.05923.pdf", "abs": "https://arxiv.org/abs/2505.05923", "title": "Human causal perception in a cube-stacking task", "authors": ["Nikolai Bahr", "Christoph Zetzsche", "Jaime Maldonado"], "categories": ["cs.HC"], "comment": "7 pages, 6 figures", "summary": "In intuitive physics the process of stacking cubes has become a paradigmatic,\ncanonical task. Even though it gets employed in various shades and\ncomplexities, the very fundamental setting with two cubes has not been\nthoroughly investigated. Furthermore, the majority of settings feature only a\nreduced, one dimensional (1D) decision space. In this paper an experiment is\nconducted in which participants judge the stability of two cubes stacked on top\nof each other. It is performed in the full 3D setting which features a 2D\ndecision surface. The analysis yield a shape of a rotated square for the\nperceived stability area instead of the commonly reported safety margin in 1D.\nThis implies a more complex decision behavior in human than previously assumed."}
{"id": "2505.05949", "pdf": "https://arxiv.org/pdf/2505.05949.pdf", "abs": "https://arxiv.org/abs/2505.05949", "title": "NeoQA: Evidence-based Question Answering with Generated News Events", "authors": ["Max Glockner", "Xiang Jiang", "Leonardo F. R. Ribeiro", "Iryna Gurevych", "Markus Dreyer"], "categories": ["cs.CL"], "comment": null, "summary": "Evaluating Retrieval-Augmented Generation (RAG) in large language models\n(LLMs) is challenging because benchmarks can quickly become stale. Questions\ninitially requiring retrieval may become answerable from pretraining knowledge\nas newer models incorporate more recent information during pretraining, making\nit difficult to distinguish evidence-based reasoning from recall. We introduce\nNeoQA (News Events for Out-of-training Question Answering), a benchmark\ndesigned to address this issue. To construct NeoQA, we generated timelines and\nknowledge bases of fictional news events and entities along with news articles\nand Q\\&A pairs to prevent LLMs from leveraging pretraining knowledge, ensuring\nthat no prior evidence exists in their training data. We propose our dataset as\na new platform for evaluating evidence-based question answering, as it requires\nLLMs to generate responses exclusively from retrieved evidence and only when\nsufficient evidence is available. NeoQA enables controlled evaluation across\nvarious evidence scenarios, including cases with missing or misleading details.\nOur findings indicate that LLMs struggle to distinguish subtle mismatches\nbetween questions and evidence, and suffer from short-cut reasoning when key\ninformation required to answer a question is missing from the evidence,\nunderscoring key limitations in evidence-based reasoning."}
{"id": "2505.05937", "pdf": "https://arxiv.org/pdf/2505.05937.pdf", "abs": "https://arxiv.org/abs/2505.05937", "title": "MER-CLIP: AU-Guided Vision-Language Alignment for Micro-Expression Recognition", "authors": ["Shifeng Liu", "Xinglong Mao", "Sirui Zhao", "Peiming Li", "Tong Xu", "Enhong Chen"], "categories": ["cs.HC"], "comment": null, "summary": "As a critical psychological stress response, micro-expressions (MEs) are\nfleeting and subtle facial movements revealing genuine emotions. Automatic ME\nrecognition (MER) holds valuable applications in fields such as criminal\ninvestigation and psychological diagnosis. The Facial Action Coding System\n(FACS) encodes expressions by identifying activations of specific facial action\nunits (AUs), serving as a key reference for ME analysis. However, current MER\nmethods typically limit AU utilization to defining regions of interest (ROIs)\nor relying on specific prior knowledge, often resulting in limited performance\nand poor generalization. To address this, we integrate the CLIP model's\npowerful cross-modal semantic alignment capability into MER and propose a novel\napproach namely MER-CLIP. Specifically, we convert AU labels into detailed\ntextual descriptions of facial muscle movements, guiding fine-grained\nspatiotemporal ME learning by aligning visual dynamics and textual AU-based\nrepresentations. Additionally, we introduce an Emotion Inference Module to\ncapture the nuanced relationships between ME patterns and emotions with\nhigher-level semantic understanding. To mitigate overfitting caused by the\nscarcity of ME data, we put forward LocalStaticFaceMix, an effective data\naugmentation strategy blending facial images to enhance facial diversity while\npreserving critical ME features. Finally, comprehensive experiments on four\nbenchmark ME datasets confirm the superiority of MER-CLIP. Notably, UF1 scores\non CAS(ME)3 reach 0.7832, 0.6544, and 0.4997 for 3-, 4-, and 7-class\nclassification tasks, significantly outperforming previous methods."}
{"id": "2505.05970", "pdf": "https://arxiv.org/pdf/2505.05970.pdf", "abs": "https://arxiv.org/abs/2505.05970", "title": "Towards Developmentally Plausible Rewards: Communicative Success as a Learning Signal for Interactive Language Models", "authors": ["Lennart Stöpler", "Rufat Asadli", "Mitja Nikolaus", "Ryan Cotterell", "Alex Warstadt"], "categories": ["cs.CL"], "comment": null, "summary": "We propose a method for training language models in an interactive setting\ninspired by child language acquisition. In our setting, a speaker attempts to\ncommunicate some information to a listener in a single-turn dialogue and\nreceives a reward if communicative success is achieved. Unlike earlier related\nwork using image--caption data for interactive reference games, we\noperationalize communicative success in a more abstract language-only\nquestion--answering setting. First, we present a feasibility study\ndemonstrating that our reward provides an indirect signal about grammaticality.\nSecond, we conduct experiments using reinforcement learning to fine-tune\nlanguage models. We observe that cognitively plausible constraints on the\ncommunication channel lead to interpretable changes in speaker behavior.\nHowever, we do not yet see improvements on linguistic evaluations from our\ntraining regime. We outline potential modifications to the task design and\ntraining configuration that could better position future work to use our\nmethodology to observe the benefits of interaction on language learning in\ncomputational cognitive models."}
{"id": "2505.06045", "pdf": "https://arxiv.org/pdf/2505.06045.pdf", "abs": "https://arxiv.org/abs/2505.06045", "title": "Designing RoutScape: Geospatial Prototyping with XR for Flood Evacuation Planning", "authors": ["Johndayll Lewis Arizala", "Joshua Permito", "Steven Errol Escopete", "John Kovie Niño", "Jordan Aiko Deja"], "categories": ["cs.HC"], "comment": "6 pages, 3 figures", "summary": "Flood response planning in local communities is often hindered by fragmented\ncommunication across Disaster Risk Reduction and Management (DRRM) councils. In\nthis work, we explore how extended reality (XR) can support more effective\nplanning through narrative-driven design. We present Routscape, an XR prototype\nfor visualizing flood scenarios and evacuation routes, developed through\niterative prototyping and user-centered design with DRRM officers. By grounding\nthe system in real-world experiences and localized narratives, we highlight how\nXR can aid in fostering shared understanding and spatial sensemaking in\ndisaster preparedness efforts."}
{"id": "2505.05973", "pdf": "https://arxiv.org/pdf/2505.05973.pdf", "abs": "https://arxiv.org/abs/2505.05973", "title": "An Exploratory Analysis on the Explanatory Potential of Embedding-Based Measures of Semantic Transparency for Malay Word Recognition", "authors": ["M. Maziyah Mohamed", "R. H. Baayen"], "categories": ["cs.CL"], "comment": "24 pages, 5 figures, and 9 tables. Submitted to the Journal of\n  Morphology", "summary": "Studies of morphological processing have shown that semantic transparency is\ncrucial for word recognition. Its computational operationalization is still\nunder discussion. Our primary objectives are to explore embedding-based\nmeasures of semantic transparency, and assess their impact on reading. First,\nwe explored the geometry of complex words in semantic space. To do so, we\nconducted a t-distributed Stochastic Neighbor Embedding clustering analysis on\n4,226 Malay prefixed words. Several clusters were observed for complex words\nvaried by their prefix class. Then, we derived five simple measures, and\ninvestigated whether they were significant predictors of lexical decision\nlatencies. Two sets of Linear Discriminant Analyses were run in which the\nprefix of a word is predicted from either word embeddings or shift vectors\n(i.e., a vector subtraction of the base word from the derived word). The\naccuracy with which the model predicts the prefix of a word indicates the\ndegree of transparency of the prefix. Three further measures were obtained by\ncomparing embeddings between each word and all other words containing the same\nprefix (i.e., centroid), between each word and the shift from their base word,\nand between each word and the predicted word of the Functional Representations\nof Affixes in Compositional Semantic Space model. In a series of Generalized\nAdditive Mixed Models, all measures predicted decision latencies after\naccounting for word frequency, word length, and morphological family size. The\nmodel that included the correlation between each word and their centroid as a\npredictor provided the best fit to the data."}
{"id": "2505.06064", "pdf": "https://arxiv.org/pdf/2505.06064.pdf", "abs": "https://arxiv.org/abs/2505.06064", "title": "Context Informed Incremental Learning Improves Myoelectric Control Performance in Virtual Reality Object Manipulation Tasks", "authors": ["Gabriel Gagné", "Anisha Azad", "Thomas Labbé", "Evan Campbell", "Xavier Isabel", "Erik Scheme", "Ulysse Côté-Allard", "Benoit Gosselin"], "categories": ["cs.HC"], "comment": "5 pages, 6 figures, 3 tables, conference", "summary": "Electromyography (EMG)-based gesture recognition is a promising approach for\ndesigning intuitive human-computer interfaces. However, while these systems\ntypically perform well in controlled laboratory settings, their usability in\nreal-world applications is compromised by declining performance during\nreal-time control. This decline is largely due to goal-directed behaviors that\nare not captured in static, offline scenarios. To address this issue, we use\n\\textit{Context Informed Incremental Learning} (CIIL) - marking its first\ndeployment in an object-manipulation scenario - to continuously adapt the\nclassifier using contextual cues. Nine participants without upper limb\ndifferences completed a functional task in a virtual reality (VR) environment\ninvolving transporting objects with life-like grips. We compared two scenarios:\none where the classifier was adapted in real-time using contextual information,\nand the other using a traditional open-loop approach without adaptation. The\nCIIL-based approach not only enhanced task success rates and efficiency, but\nalso reduced the perceived workload by 7.1 %, despite causing a 5.8 % reduction\nin offline classification accuracy. This study highlights the potential of\nreal-time contextualized adaptation to enhance user experience and usability of\nEMG-based systems for practical, goal-oriented applications, crucial elements\ntowards their long-term adoption. The source code for this study is available\nat: https://github.com/BiomedicalITS/ciil-emg-vr."}
{"id": "2505.06004", "pdf": "https://arxiv.org/pdf/2505.06004.pdf", "abs": "https://arxiv.org/abs/2505.06004", "title": "Exploring the Feasibility of Multilingual Grammatical Error Correction with a Single LLM up to 9B parameters: A Comparative Study of 17 Models", "authors": ["Dawid Wisniewski", "Antoni Solarski", "Artur Nowakowski"], "categories": ["cs.CL"], "comment": "Accepted at MTSummit 2025 (The 20th Machine Translation Summit)", "summary": "Recent language models can successfully solve various language-related tasks,\nand many understand inputs stated in different languages. In this paper, we\nexplore the performance of 17 popular models used to correct grammatical issues\nin texts stated in English, German, Italian, and Swedish when using a single\nmodel to correct texts in all those languages. We analyze the outputs generated\nby these models, focusing on decreasing the number of grammatical errors while\nkeeping the changes small. The conclusions drawn help us understand what\nproblems occur among those models and which models can be recommended for\nmultilingual grammatical error correction tasks. We list six models that\nimprove grammatical correctness in all four languages and show that Gemma 9B is\ncurrently the best performing one for the languages considered."}
{"id": "2505.05516", "pdf": "https://arxiv.org/pdf/2505.05516.pdf", "abs": "https://arxiv.org/abs/2505.05516", "title": "AI-powered virtual eye: perspective, challenges and opportunities", "authors": ["Yue Wu", "Yibo Guo", "Yulong Yan", "Jiancheng Yang", "Xin Zhou", "Ching-Yu Cheng", "Danli Shi", "Mingguang He"], "categories": ["q-bio.TO", "cs.AI", "cs.HC"], "comment": "30 Pages, 3 figures, 1 table", "summary": "We envision the \"virtual eye\" as a next-generation, AI-powered platform that\nuses interconnected foundation models to simulate the eye's intricate structure\nand biological function across all scales. Advances in AI, imaging, and\nmultiomics provide a fertile ground for constructing a universal, high-fidelity\ndigital replica of the human eye. This perspective traces the evolution from\nearly mechanistic and rule-based models to contemporary AI-driven approaches,\nintegrating in a unified model with multimodal, multiscale, dynamic predictive\ncapabilities and embedded feedback mechanisms. We propose a development roadmap\nemphasizing the roles of large-scale multimodal datasets, generative AI,\nfoundation models, agent-based architectures, and interactive interfaces.\nDespite challenges in interpretability, ethics, data processing and evaluation,\nthe virtual eye holds the potential to revolutionize personalized ophthalmic\ncare and accelerate research into ocular health and disease."}
{"id": "2505.06010", "pdf": "https://arxiv.org/pdf/2505.06010.pdf", "abs": "https://arxiv.org/abs/2505.06010", "title": "Do Not Change Me: On Transferring Entities Without Modification in Neural Machine Translation -- a Multilingual Perspective", "authors": ["Dawid Wisniewski", "Mikolaj Pokrywka", "Zofia Rostek"], "categories": ["cs.CL"], "comment": "Accepted at MTSummit 2025 (The 20th Machine Translation Summit)", "summary": "Current machine translation models provide us with high-quality outputs in\nmost scenarios. However, they still face some specific problems, such as\ndetecting which entities should not be changed during translation. In this\npaper, we explore the abilities of popular NMT models, including models from\nthe OPUS project, Google Translate, MADLAD, and EuroLLM, to preserve entities\nsuch as URL addresses, IBAN numbers, or emails when producing translations\nbetween four languages: English, German, Polish, and Ukrainian. We investigate\nthe quality of popular NMT models in terms of accuracy, discuss errors made by\nthe models, and examine the reasons for errors. Our analysis highlights\nspecific categories, such as emojis, that pose significant challenges for many\nmodels considered. In addition to the analysis, we propose a new multilingual\nsynthetic dataset of 36,000 sentences that can help assess the quality of\nentity transfer across nine categories and four aforementioned languages."}
{"id": "2505.05773", "pdf": "https://arxiv.org/pdf/2505.05773.pdf", "abs": "https://arxiv.org/abs/2505.05773", "title": "Human-Robot Collaboration for the Remote Control of Mobile Humanoid Robots with Torso-Arm Coordination", "authors": ["Nikita Boguslavskii", "Lorena Maria Genua", "Zhi Li"], "categories": ["cs.RO", "cs.HC"], "comment": "This work has been accepted for publication in 2025 IEEE\n  International Conference on Robotics and Automation (ICRA 2025). The final\n  published version will be available via IEEE Xplore", "summary": "Recently, many humanoid robots have been increasingly deployed in various\nfacilities, including hospitals and assisted living environments, where they\nare often remotely controlled by human operators. Their kinematic redundancy\nenhances reachability and manipulability, enabling them to navigate complex,\ncluttered environments and perform a wide range of tasks. However, this\nredundancy also presents significant control challenges, particularly in\ncoordinating the movements of the robot's macro-micro structure (torso and\narms). Therefore, we propose various human-robot collaborative (HRC) methods\nfor coordinating the torso and arm of remotely controlled mobile humanoid\nrobots, aiming to balance autonomy and human input to enhance system efficiency\nand task execution. The proposed methods include human-initiated approaches,\nwhere users manually control torso movements, and robot-initiated approaches,\nwhich autonomously coordinate torso and arm based on factors such as\nreachability, task goal, or inferred human intent. We conducted a user study\nwith N=17 participants to compare the proposed approaches in terms of task\nperformance, manipulability, and energy efficiency, and analyzed which methods\nwere preferred by participants."}
{"id": "2505.06027", "pdf": "https://arxiv.org/pdf/2505.06027.pdf", "abs": "https://arxiv.org/abs/2505.06027", "title": "Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation", "authors": ["Stefan Vasilev", "Christian Herold", "Baohao Liao", "Seyyed Hadi Hashemi", "Shahram Khadivi", "Christof Monz"], "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "comment": "16 pages, 6 figures, 5 tables, under review at ACL", "summary": "This paper introduces Unilogit, a novel self-distillation method for machine\nunlearning in Large Language Models. Unilogit addresses the challenge of\nselectively forgetting specific information while maintaining overall model\nutility, a critical task in compliance with data privacy regulations like GDPR.\nUnlike prior methods that rely on static hyperparameters or starting model\noutputs, Unilogit dynamically adjusts target logits to achieve a uniform\nprobability for the target token, leveraging the current model's outputs for\nmore accurate self-distillation targets. This approach not only eliminates the\nneed for additional hyperparameters but also enhances the model's ability to\napproximate the golden targets. Extensive experiments on public benchmarks and\nan in-house e-commerce dataset demonstrate Unilogit's superior performance in\nbalancing forget and retain objectives, outperforming state-of-the-art methods\nsuch as NPO and UnDIAL. Our analysis further reveals Unilogit's robustness\nacross various scenarios, highlighting its practical applicability and\neffectiveness in achieving efficacious machine unlearning."}
{"id": "2505.05851", "pdf": "https://arxiv.org/pdf/2505.05851.pdf", "abs": "https://arxiv.org/abs/2505.05851", "title": "Collecting Human Motion Data in Large and Occlusion-Prone Environments using Ultra-Wideband Localization", "authors": ["Janik Kaden", "Maximilian Hilger", "Tim Schreiter", "Marius Schaab", "Thomas Graichen", "Andrey Rudenko", "Ulrich Heinkel", "Achim J. Lilienthal"], "categories": ["cs.RO", "cs.HC", "cs.LG"], "comment": "accepted for presentation at the 7th Workshop on Long-term Human\n  Motion Prediction (LHMP) at International Conference on Robotics and\n  Automation (ICRA) 2025", "summary": "With robots increasingly integrating into human environments, understanding\nand predicting human motion is essential for safe and efficient interactions.\nModern human motion and activity prediction approaches require high quality and\nquantity of data for training and evaluation, usually collected from motion\ncapture systems, onboard or stationary sensors. Setting up these systems is\nchallenging due to the intricate setup of hardware components, extensive\ncalibration procedures, occlusions, and substantial costs. These constraints\nmake deploying such systems in new and large environments difficult and limit\ntheir usability for in-the-wild measurements. In this paper we investigate the\npossibility to apply the novel Ultra-Wideband (UWB) localization technology as\na scalable alternative for human motion capture in crowded and occlusion-prone\nenvironments. We include additional sensing modalities such as eye-tracking,\nonboard robot LiDAR and radar sensors, and record motion capture data as ground\ntruth for evaluation and comparison. The environment imitates a museum setup,\nwith up to four active participants navigating toward random goals in a natural\nway, and offers more than 130 minutes of multi-modal data. Our investigation\nprovides a step toward scalable and accurate motion data collection beyond\nvision-based systems, laying a foundation for evaluating sensing modalities\nlike UWB in larger and complex environments like warehouses, airports, or\nconvention centers."}
{"id": "2505.06046", "pdf": "https://arxiv.org/pdf/2505.06046.pdf", "abs": "https://arxiv.org/abs/2505.06046", "title": "Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information", "authors": ["Joshua Harris", "Fan Grayson", "Felix Feldman", "Timothy Laurence", "Toby Nonnenmacher", "Oliver Higgins", "Leo Loman", "Selina Patel", "Thomas Finnie", "Samuel Collins", "Michael Borowitz"], "categories": ["cs.CL", "cs.LG", "68T50"], "comment": "24 pages, 10 pages main text", "summary": "As Large Language Models (LLMs) become widely accessible, a detailed\nunderstanding of their knowledge within specific domains becomes necessary for\nsuccessful real world use. This is particularly critical in public health,\nwhere failure to retrieve relevant, accurate, and current information could\nsignificantly impact UK residents. However, currently little is known about LLM\nknowledge of UK Government public health information. To address this issue,\nthis paper introduces a new benchmark, PubHealthBench, with over 8000 questions\nfor evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form\nresponses to public health queries, created via an automated pipeline. We also\nrelease a new dataset of the extracted UK Government public health guidance\ndocuments used as source text for PubHealthBench. Assessing 24 LLMs on\nPubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a\nhigh degree of knowledge, achieving >90% in the MCQA setup, and outperform\nhumans with cursory search engine use. However, in the free form setup we see\nlower performance with no model scoring >75%. Therefore, whilst there are\npromising signs that state of the art (SOTA) LLMs are an increasingly accurate\nsource of public health information, additional safeguards or tools may still\nbe needed when providing free form responses on public health topics."}
{"id": "2505.06120", "pdf": "https://arxiv.org/pdf/2505.06120.pdf", "abs": "https://arxiv.org/abs/2505.06120", "title": "LLMs Get Lost In Multi-Turn Conversation", "authors": ["Philippe Laban", "Hiroaki Hayashi", "Yingbo Zhou", "Jennifer Neville"], "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) are conversational interfaces. As such, LLMs\nhave the potential to assist their users not only when they can fully specify\nthe task at hand, but also to help them define, explore, and refine what they\nneed through multi-turn conversational exchange. Although analysis of LLM\nconversation logs has confirmed that underspecification occurs frequently in\nuser instructions, LLM evaluation has predominantly focused on the single-turn,\nfully-specified instruction setting. In this work, we perform large-scale\nsimulation experiments to compare LLM performance in single- and multi-turn\nsettings. Our experiments confirm that all the top open- and closed-weight LLMs\nwe test exhibit significantly lower performance in multi-turn conversations\nthan single-turn, with an average drop of 39% across six generation tasks.\nAnalysis of 200,000+ simulated conversations decomposes the performance\ndegradation into two components: a minor loss in aptitude and a significant\nincrease in unreliability. We find that LLMs often make assumptions in early\nturns and prematurely attempt to generate final solutions, on which they overly\nrely. In simpler terms, we discover that *when LLMs take a wrong turn in a\nconversation, they get lost and do not recover*."}
{"id": "2505.06062", "pdf": "https://arxiv.org/pdf/2505.06062.pdf", "abs": "https://arxiv.org/abs/2505.06062", "title": "Attention on Multiword Expressions: A Multilingual Study of BERT-based Models with Regard to Idiomaticity and Microsyntax", "authors": ["Iuliia Zaitova", "Vitalii Hirak", "Badr M. Abdullah", "Dietrich Klakow", "Bernd Möbius", "Tania Avgustinova"], "categories": ["cs.CL"], "comment": "10 pages, 3 figures. Findings 2025", "summary": "This study analyzes the attention patterns of fine-tuned encoder-only models\nbased on the BERT architecture (BERT-based models) towards two distinct types\nof Multiword Expressions (MWEs): idioms and microsyntactic units (MSUs). Idioms\npresent challenges in semantic non-compositionality, whereas MSUs demonstrate\nunconventional syntactic behavior that does not conform to standard grammatical\ncategorizations. We aim to understand whether fine-tuning BERT-based models on\nspecific tasks influences their attention to MWEs, and how this attention\ndiffers between semantic and syntactic tasks. We examine attention scores to\nMWEs in both pre-trained and fine-tuned BERT-based models. We utilize\nmonolingual models and datasets in six Indo-European languages - English,\nGerman, Dutch, Polish, Russian, and Ukrainian. Our results show that\nfine-tuning significantly influences how models allocate attention to MWEs.\nSpecifically, models fine-tuned on semantic tasks tend to distribute attention\nto idiomatic expressions more evenly across layers. Models fine-tuned on\nsyntactic tasks show an increase in attention to MSUs in the lower layers,\ncorresponding with syntactic processing requirements."}
{"id": "2505.06134", "pdf": "https://arxiv.org/pdf/2505.06134.pdf", "abs": "https://arxiv.org/abs/2505.06134", "title": "Realistic Adversarial Attacks for Robustness Evaluation of Trajectory Prediction Models via Future State Perturbation", "authors": ["Julian F. Schumann", "Jeroen Hagenus", "Frederik Baymler Mathiesen", "Arkady Zgonnikov"], "categories": ["cs.LG", "cs.HC"], "comment": "20 pages, 3 figures", "summary": "Trajectory prediction is a key element of autonomous vehicle systems,\nenabling them to anticipate and react to the movements of other road users.\nEvaluating the robustness of prediction models against adversarial attacks is\nessential to ensure their reliability in real-world traffic. However, current\napproaches tend to focus on perturbing the past positions of surrounding\nagents, which can generate unrealistic scenarios and overlook critical\nvulnerabilities. This limitation may result in overly optimistic assessments of\nmodel performance in real-world conditions.\n  In this work, we demonstrate that perturbing not just past but also future\nstates of adversarial agents can uncover previously undetected weaknesses and\nthereby provide a more rigorous evaluation of model robustness. Our novel\napproach incorporates dynamic constraints and preserves tactical behaviors,\nenabling more effective and realistic adversarial attacks. We introduce new\nperformance measures to assess the realism and impact of these adversarial\ntrajectories. Testing our method on a state-of-the-art prediction model\nrevealed significant increases in prediction errors and collision rates under\nadversarial conditions. Qualitative analysis further showed that our attacks\ncan expose critical weaknesses, such as the inability of the model to detect\npotential collisions in what appear to be safe predictions. These results\nunderscore the need for more comprehensive adversarial testing to better\nevaluate and improve the reliability of trajectory prediction models for\nautonomous vehicles."}
{"id": "2505.06110", "pdf": "https://arxiv.org/pdf/2505.06110.pdf", "abs": "https://arxiv.org/abs/2505.06110", "title": "Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models", "authors": ["Jugal Gajjar", "Kaustik Ranaware"], "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, 2 figures, 5 tables, and 19 references", "summary": "This project performs multimodal sentiment analysis using the CMU-MOSEI\ndataset, using transformer-based models with early fusion to integrate text,\naudio, and visual modalities. We employ BERT-based encoders for each modality,\nextracting embeddings that are concatenated before classification. The model\nachieves strong performance, with 97.87\\% 7-class accuracy and a 0.9682\nF1-score on the test set, demonstrating the effectiveness of early fusion in\ncapturing cross-modal interactions. The training utilized Adam optimization\n(lr=1e-4), dropout (0.3), and early stopping to ensure generalization and\nrobustness. Results highlight the superiority of transformer architectures in\nmodeling multimodal sentiment, with a low MAE (0.1060) indicating precise\nsentiment intensity prediction. Future work may compare fusion strategies or\nenhance interpretability. This approach utilizes multimodal learning by\neffectively combining linguistic, acoustic, and visual cues for sentiment\nanalysis."}
{"id": "2401.14362", "pdf": "https://arxiv.org/pdf/2401.14362.pdf", "abs": "https://arxiv.org/abs/2401.14362", "title": "The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support", "authors": ["Inhwa Song", "Sachin R. Pendse", "Neha Kumar", "Munmun De Choudhury"], "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "The first two authors contributed equally to this work; typos\n  corrected and post-review revisions incorporated", "summary": "People experiencing severe distress increasingly use Large Language Model\n(LLM) chatbots as mental health support tools. Discussions on social media have\ndescribed how engagements were lifesaving for some, but evidence suggests that\ngeneral-purpose LLM chatbots also have notable risks that could endanger the\nwelfare of users if not designed responsibly. In this study, we investigate the\nlived experiences of people who have used LLM chatbots for mental health\nsupport. We build on interviews with 21 individuals from globally diverse\nbackgrounds to analyze how users create unique support roles for their\nchatbots, fill in gaps in everyday care, and navigate associated cultural\nlimitations when seeking support from chatbots. We ground our analysis in\npsychotherapy literature around effective support, and introduce the concept of\ntherapeutic alignment, or aligning AI with therapeutic values for mental health\ncontexts. Our study offers recommendations for how designers can approach the\nethical and effective use of LLM chatbots and other AI mental health support\ntools in mental health care."}
{"id": "2505.06120", "pdf": "https://arxiv.org/pdf/2505.06120.pdf", "abs": "https://arxiv.org/abs/2505.06120", "title": "LLMs Get Lost In Multi-Turn Conversation", "authors": ["Philippe Laban", "Hiroaki Hayashi", "Yingbo Zhou", "Jennifer Neville"], "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) are conversational interfaces. As such, LLMs\nhave the potential to assist their users not only when they can fully specify\nthe task at hand, but also to help them define, explore, and refine what they\nneed through multi-turn conversational exchange. Although analysis of LLM\nconversation logs has confirmed that underspecification occurs frequently in\nuser instructions, LLM evaluation has predominantly focused on the single-turn,\nfully-specified instruction setting. In this work, we perform large-scale\nsimulation experiments to compare LLM performance in single- and multi-turn\nsettings. Our experiments confirm that all the top open- and closed-weight LLMs\nwe test exhibit significantly lower performance in multi-turn conversations\nthan single-turn, with an average drop of 39% across six generation tasks.\nAnalysis of 200,000+ simulated conversations decomposes the performance\ndegradation into two components: a minor loss in aptitude and a significant\nincrease in unreliability. We find that LLMs often make assumptions in early\nturns and prematurely attempt to generate final solutions, on which they overly\nrely. In simpler terms, we discover that *when LLMs take a wrong turn in a\nconversation, they get lost and do not recover*."}
{"id": "2504.12236", "pdf": "https://arxiv.org/pdf/2504.12236.pdf", "abs": "https://arxiv.org/abs/2504.12236", "title": "Towards Human-Centered Early Prediction Models for Academic Performance in Real-World Contexts", "authors": ["Han Zhang", "Yiyi Ren", "Paula S. Nurius", "Jennifer Mankoff", "Anind K. Dey"], "categories": ["cs.HC", "68U35", "H.5.0; I.2.m"], "comment": "Accepted to CSCW", "summary": "Supporting student success requires collaboration among multiple\nstakeholders. Researchers have explored machine learning models for academic\nperformance prediction; yet key challenges remain in ensuring these models are\ninterpretable, equitable, and actionable within real-world educational support\nsystems. First, many models prioritize predictive accuracy but overlook\nhuman-centered machine learning principles, limiting trust among students and\nreducing their usefulness for educators and institutional decision-makers.\nSecond, most models require at least a month of data before making reliable\npredictions, delaying opportunities for early intervention. Third, current\nmodels primarily rely on sporadically collected, classroom-derived data,\nmissing broader behavioral patterns that could provide more continuous and\nactionable insights. To address these gaps, we present three modeling\napproaches-LR, 1D-CNN, and MTL-1D-CNN-to classify students as low or high\nacademic performers. We evaluate them based on explainability, fairness, and\ngeneralizability to assess their alignment with key social values. Using\nbehavioral and self-reported data collected within the first week of two Spring\nterms, we demonstrate that these models can identify at-risk students as early\nas week one. However, trade-offs across human-centered machine learning\nprinciples highlight the complexity of designing predictive models that\neffectively support multi-stakeholder decision-making and intervention\nstrategies. We discuss these trade-offs and their implications for different\nstakeholders, outlining how predictive models can be integrated into student\nsupport systems. Finally, we examine broader socio-technical challenges in\ndeploying these models and propose future directions for advancing\nhuman-centered, collaborative academic prediction systems."}
{"id": "2505.06145", "pdf": "https://arxiv.org/pdf/2505.06145.pdf", "abs": "https://arxiv.org/abs/2505.06145", "title": "Towards Robust Few-Shot Text Classification Using Transformer Architectures and Dual Loss Strategies", "authors": ["Xu Han", "Yumeng Sun", "Weiqiang Huang", "Hongye Zheng", "Junliang Du"], "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Few-shot text classification has important application value in low-resource\nenvironments. This paper proposes a strategy that combines adaptive\nfine-tuning, contrastive learning, and regularization optimization to improve\nthe classification performance of Transformer-based models. Experiments on the\nFewRel 2.0 dataset show that T5-small, DeBERTa-v3, and RoBERTa-base perform\nwell in few-shot tasks, especially in the 5-shot setting, which can more\neffectively capture text features and improve classification accuracy. The\nexperiment also found that there are significant differences in the\nclassification difficulty of different relationship categories. Some categories\nhave fuzzy semantic boundaries or complex feature distributions, making it\ndifficult for the standard cross entropy loss to learn the discriminative\ninformation required to distinguish categories. By introducing contrastive loss\nand regularization loss, the generalization ability of the model is enhanced,\neffectively alleviating the overfitting problem in few-shot environments. In\naddition, the research results show that the use of Transformer models or\ngenerative architectures with stronger self-attention mechanisms can help\nimprove the stability and accuracy of few-shot classification."}
{"id": "2505.04210", "pdf": "https://arxiv.org/pdf/2505.04210.pdf", "abs": "https://arxiv.org/abs/2505.04210", "title": "Sick of being driven? -- Prevalence and modulating factors of carsickness in the European population in context of automated driving", "authors": ["Myriam Metzulat", "Barbara Metz", "Aaron Edelmann", "Alexandra Neukum", "Wilfried Kunde"], "categories": ["cs.HC"], "comment": "Preprint", "summary": "As in automated driving the driver becomes a passenger, carsickness might\nreduce comfort for susceptible individuals. Insights in the prevalence of\ncarsickness and its modulating factors are considered useful for the\ndevelopment of automated vehicles to mitigate or prevent its occurrence. An\nonline survey was conducted with N = 3999 participants in Spain, Sweden,\nPoland, and Germany. 30% of participants reported to have already experienced\ncarsickness as adult. The frequency of carsickness was modulated not only by\ndemographic factors (country, gender, age), but also by frequency of being a\npassenger, type of non-driving related task, road type, and the seating\nposition in car. Furthermore, the efficiency of applied countermeasures,\ntemporal aspects of carsickness development, as well as the relation of\ncarsickness with the acceptability of automated driving and the effect on\nsubjective fitness to drive was investigated. The results are discussed with\nfocus on automated driving."}
{"id": "2505.06149", "pdf": "https://arxiv.org/pdf/2505.06149.pdf", "abs": "https://arxiv.org/abs/2505.06149", "title": "Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study", "authors": ["Faeze Ghorbanpour", "Daryna Dementieva", "Alexander Fraser"], "categories": ["cs.CL", "cs.CY", "cs.MM"], "comment": null, "summary": "Despite growing interest in automated hate speech detection, most existing\napproaches overlook the linguistic diversity of online content. Multilingual\ninstruction-tuned large language models such as LLaMA, Aya, Qwen, and BloomZ\noffer promising capabilities across languages, but their effectiveness in\nidentifying hate speech through zero-shot and few-shot prompting remains\nunderexplored. This work evaluates LLM prompting-based detection across eight\nnon-English languages, utilizing several prompting techniques and comparing\nthem to fine-tuned encoder models. We show that while zero-shot and few-shot\nprompting lag behind fine-tuned encoder models on most of the real-world\nevaluation sets, they achieve better generalization on functional tests for\nhate speech detection. Our study also reveals that prompt design plays a\ncritical role, with each language often requiring customized prompting\ntechniques to maximize performance."}
{"id": "2504.06751", "pdf": "https://arxiv.org/pdf/2504.06751.pdf", "abs": "https://arxiv.org/abs/2504.06751", "title": "Visualization of a multidimensional point cloud as a 3D swarm of avatars", "authors": ["Leszek Luchowski", "Dariusz Pojda"], "categories": ["cs.CV", "cs.HC"], "comment": "24 pages, 11 figures", "summary": "The article presents an innovative approach to the visualization of\nmultidimensional data, using icons inspired by Chernoff faces. The approach\nmerges classical projection techniques with the assignment of particular data\ndimensions to mimic features, capitalizing on the natural ability of the human\nbrain to interpret facial expressions. We introduce a semantic division of data\ndimensions into intuitive and technical categories, assigning the former to\navatar features and projecting the latter into a hyperspace of four, or\npotentially more dimensions. The technique is implemented as a plugin to the\ndpVision open-source image handling platform. The plugin allows the data to be\ninteractively explored in the form of a swarm of avatars whose position in\nhyperspace as well as facial features represent various aspects of the data.\nSample visualizations, based on synthetic test data as well as the\n12-dimensional database on Portuguese Vinho Verde wines, confirm the usefulness\nof our approach to the analysis of complex data structures."}
{"id": "2505.06150", "pdf": "https://arxiv.org/pdf/2505.06150.pdf", "abs": "https://arxiv.org/abs/2505.06150", "title": "A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets", "authors": ["Ryan Lagasse", "Aidan Kiernans", "Avijit Ghosh", "Shiri Dori-Hacohen"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce a scaling law for fine-tuning large language models (LLMs) under\nfixed compute budgets that explicitly accounts for data composition.\nConventional approaches measure training data solely by total tokens, yet the\nnumber of examples and their average token length -- what we term \\emph{dataset\nvolume} -- play a decisive role in model performance. Our formulation is tuned\nfollowing established procedures. Experiments on the BRICC dataset\n\\cite{salavati2024reducing} and subsets of the MMLU dataset\n\\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple\nsubsampling strategies, reveal that data composition significantly affects\ntoken efficiency. These results motivate refined scaling laws for practical LLM\nfine-tuning in resource-constrained settings."}
{"id": "2505.06151", "pdf": "https://arxiv.org/pdf/2505.06151.pdf", "abs": "https://arxiv.org/abs/2505.06151", "title": "Estimating Quality in Therapeutic Conversations: A Multi-Dimensional Natural Language Processing Framework", "authors": ["Alice Rueda", "Argyrios Perivolaris", "Niloy Roy", "Dylan Weston", "Sarmed Shaya", "Zachary Cote", "Martin Ivanov", "Bazen G. Teferra", "Yuqi Wu", "Sirisha Rambhatla", "Divya Sharma", "Andrew Greenshaw", "Rakesh Jetly", "Yanbo Zhang", "Bo Cao", "Reza Samavi", "Sridhar Krishnan", "Venkat Bhat"], "categories": ["cs.CL"], "comment": "12 pages, 4 figures, 7 tables", "summary": "Engagement between client and therapist is a critical determinant of\ntherapeutic success. We propose a multi-dimensional natural language processing\n(NLP) framework that objectively classifies engagement quality in counseling\nsessions based on textual transcripts. Using 253 motivational interviewing\ntranscripts (150 high-quality, 103 low-quality), we extracted 42 features\nacross four domains: conversational dynamics, semantic similarity as topic\nalignment, sentiment classification, and question detection. Classifiers,\nincluding Random Forest (RF), Cat-Boost, and Support Vector Machines (SVM),\nwere hyperparameter tuned and trained using a stratified 5-fold\ncross-validation and evaluated on a holdout test set. On balanced\n(non-augmented) data, RF achieved the highest classification accuracy (76.7%),\nand SVM achieved the highest AUC (85.4%). After SMOTE-Tomek augmentation,\nperformance improved significantly: RF achieved up to 88.9% accuracy, 90.0%\nF1-score, and 94.6% AUC, while SVM reached 81.1% accuracy, 83.1% F1-score, and\n93.6% AUC. The augmented data results reflect the potential of the framework in\nfuture larger-scale applications. Feature contribution revealed conversational\ndynamics and semantic similarity between clients and therapists were among the\ntop contributors, led by words uttered by the client (mean and standard\ndeviation). The framework was robust across the original and augmented datasets\nand demonstrated consistent improvements in F1 scores and recall. While\ncurrently text-based, the framework supports future multimodal extensions\n(e.g., vocal tone, facial affect) for more holistic assessments. This work\nintroduces a scalable, data-driven method for evaluating engagement quality of\nthe therapy session, offering clinicians real-time feedback to enhance the\nquality of both virtual and in-person therapeutic interactions."}
{"id": "2505.06186", "pdf": "https://arxiv.org/pdf/2505.06186.pdf", "abs": "https://arxiv.org/abs/2505.06186", "title": "Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies", "authors": ["Massimiliano Pronesti", "Joao Bettencourt-Silva", "Paul Flanagan", "Alessandra Pascale", "Oisin Redmond", "Anya Belz", "Yufang Hou"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Extracting scientific evidence from biomedical studies for clinical research\nquestions (e.g., Does stem cell transplantation improve quality of life in\npatients with medically refractory Crohn's disease compared to placebo?) is a\ncrucial step in synthesising biomedical evidence. In this paper, we focus on\nthe task of document-level scientific evidence extraction for clinical\nquestions with conflicting evidence. To support this task, we create a dataset\ncalled CochraneForest, leveraging forest plots from Cochrane systematic\nreviews. It comprises 202 annotated forest plots, associated clinical research\nquestions, full texts of studies, and study-specific conclusions. Building on\nCochraneForest, we propose URCA (Uniform Retrieval Clustered Augmentation), a\nretrieval-augmented generation framework designed to tackle the unique\nchallenges of evidence extraction. Our experiments show that URCA outperforms\nthe best existing methods by up to 10.3% in F1 score on this task. However, the\nresults also underscore the complexity of CochraneForest, establishing it as a\nchallenging testbed for advancing automated evidence synthesis systems."}
{"id": "2505.05528", "pdf": "https://arxiv.org/pdf/2505.05528.pdf", "abs": "https://arxiv.org/abs/2505.05528", "title": "X-Transfer Attacks: Towards Super Transferable Adversarial Attacks on CLIP", "authors": ["Hanxun Huang", "Sarah Erfani", "Yige Li", "Xingjun Ma", "James Bailey"], "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "ICML 2025", "summary": "As Contrastive Language-Image Pre-training (CLIP) models are increasingly\nadopted for diverse downstream tasks and integrated into large vision-language\nmodels (VLMs), their susceptibility to adversarial perturbations has emerged as\na critical concern. In this work, we introduce \\textbf{X-Transfer}, a novel\nattack method that exposes a universal adversarial vulnerability in CLIP.\nX-Transfer generates a Universal Adversarial Perturbation (UAP) capable of\ndeceiving various CLIP encoders and downstream VLMs across different samples,\ntasks, and domains. We refer to this property as \\textbf{super\ntransferability}--a single perturbation achieving cross-data, cross-domain,\ncross-model, and cross-task adversarial transferability simultaneously. This is\nachieved through \\textbf{surrogate scaling}, a key innovation of our approach.\nUnlike existing methods that rely on fixed surrogate models, which are\ncomputationally intensive to scale, X-Transfer employs an efficient surrogate\nscaling strategy that dynamically selects a small subset of suitable surrogates\nfrom a large search space. Extensive evaluations demonstrate that X-Transfer\nsignificantly outperforms previous state-of-the-art UAP methods, establishing a\nnew benchmark for adversarial transferability across CLIP models. The code is\npublicly available in our\n\\href{https://github.com/HanxunH/XTransferBench}{GitHub repository}."}
{"id": "2505.05665", "pdf": "https://arxiv.org/pdf/2505.05665.pdf", "abs": "https://arxiv.org/abs/2505.05665", "title": "Adaptive Stress Testing Black-Box LLM Planners", "authors": ["Neeloy Chakraborty", "John Pohovey", "Melkior Ornik", "Katherine Driggs-Campbell"], "categories": ["cs.RO", "cs.AI", "cs.CL"], "comment": "26 pages, 16 figures, 4 tables", "summary": "Large language models (LLMs) have recently demonstrated success in\ngeneralizing across decision-making tasks including planning, control and\nprediction, but their tendency to hallucinate unsafe and undesired outputs\nposes risks. We argue that detecting such failures is necessary, especially in\nsafety-critical scenarios. Existing black-box methods often detect\nhallucinations by identifying inconsistencies across multiple samples. Many of\nthese approaches typically introduce prompt perturbations like randomizing\ndetail order or generating adversarial inputs, with the intuition that a\nconfident model should produce stable outputs. We first perform a manual case\nstudy showing that other forms of perturbations (e.g., adding noise, removing\nsensor details) cause LLMs to hallucinate in a driving environment. We then\npropose a novel method for efficiently searching the space of prompt\nperturbations using Adaptive Stress Testing (AST) with Monte-Carlo Tree Search\n(MCTS). Our AST formulation enables discovery of scenarios and prompts that\ncause language models to act with high uncertainty. By generating MCTS prompt\nperturbation trees across diverse scenarios, we show that offline analyses can\nbe used at runtime to automatically generate prompts that influence model\nuncertainty, and to inform real-time trust assessments of an LLM."}
{"id": "2505.05684", "pdf": "https://arxiv.org/pdf/2505.05684.pdf", "abs": "https://arxiv.org/abs/2505.05684", "title": "Prompted Meta-Learning for Few-shot Knowledge Graph Completion", "authors": ["Han Wu", "Jie Yin"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Few-shot knowledge graph completion (KGC) has obtained significant attention\ndue to its practical applications in real-world scenarios, where new knowledge\noften emerges with limited available data. While most existing methods for\nfew-shot KGC have predominantly focused on leveraging relational information,\nrich semantics inherent in KGs have been largely overlooked. To address this\ngap, we propose a novel prompted meta-learning (PromptMeta) framework that\nseamlessly integrates meta-semantics with relational information for few-shot\nKGC. PrompMeta has two key innovations: (1) a meta-semantic prompt pool that\ncaptures and consolidates high-level meta-semantics, enabling effective\nknowledge transfer and adaptation to rare and newly emerging relations. (2) a\nlearnable fusion prompt that dynamically combines meta-semantic information\nwith task-specific relational information tailored to different few-shot tasks.\nBoth components are optimized together with model parameters within a\nmeta-learning framework. Extensive experiments on two benchmark datasets\ndemonstrate the effectiveness of our approach."}
{"id": "2505.05736", "pdf": "https://arxiv.org/pdf/2505.05736.pdf", "abs": "https://arxiv.org/abs/2505.05736", "title": "Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications", "authors": ["Da Wu", "Zhanliang Wang", "Quan Nguyen", "Zhuoran Xu", "Kai Wang"], "categories": ["q-bio.QM", "cs.CL", "cs.CV", "cs.LG"], "comment": "First Draft", "summary": "The scarcity of high-quality multimodal biomedical data limits the ability to\neffectively fine-tune pretrained Large Language Models (LLMs) for specialized\nbiomedical tasks. To address this challenge, we introduce MINT (Multimodal\nIntegrated kNowledge Transfer), a framework that aligns unimodal large decoder\nmodels with domain-specific decision patterns from multimodal biomedical data\nthrough preference optimization. While MINT supports different optimization\ntechniques, we primarily implement it with the Odds Ratio Preference\nOptimization (ORPO) framework as its backbone. This strategy enables the\naligned LLMs to perform predictive tasks using text-only or image-only inputs\nwhile retaining knowledge learnt from multimodal data. MINT leverages an\nupstream multimodal machine learning (MML) model trained on high-quality\nmultimodal data to transfer domain-specific insights to downstream text-only or\nimage-only LLMs. We demonstrate its effectiveness through two key applications:\n(1) Rare genetic disease prediction from texts, where MINT uses a multimodal\nencoder model, trained on facial photos and clinical notes, to generate a\npreference dataset for aligning a lightweight Llama 3.2-3B-Instruct. Despite\nrelying on text input only, the MINT-derived model outperforms models trained\nwith SFT, RAG, or DPO, and even outperforms Llama 3.1-405B-Instruct. (2) Tissue\ntype classification using cell nucleus images, where MINT uses a\nvision-language foundation model as the preference generator, containing\nknowledge learnt from both text and histopathological images to align\ndownstream image-only models. The resulting MINT-derived model significantly\nimproves the performance of Llama 3.2-Vision-11B-Instruct on tissue type\nclassification. In summary, MINT provides an effective strategy to align\nunimodal LLMs with high-quality multimodal expertise through preference\noptimization."}
{"id": "2505.05744", "pdf": "https://arxiv.org/pdf/2505.05744.pdf", "abs": "https://arxiv.org/abs/2505.05744", "title": "Harnessing LLMs Explanations to Boost Surrogate Models in Tabular Data Classification", "authors": ["Ruxue Shi", "Hengrui Gu", "Xu Shen", "Xin Wang"], "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable ability in solving complex\ntasks, making them a promising tool for enhancing tabular learning. However,\nexisting LLM-based methods suffer from high resource requirements, suboptimal\ndemonstration selection, and limited interpretability, which largely hinder\ntheir prediction performance and application in the real world. To overcome\nthese problems, we propose a novel in-context learning framework for tabular\nprediction. The core idea is to leverage the explanations generated by LLMs to\nguide a smaller, locally deployable Surrogate Language Model (SLM) to make\ninterpretable tabular predictions. Specifically, our framework mainly involves\nthree stages: (i) Post Hoc Explanation Generation, where LLMs are utilized to\ngenerate explanations for question-answer pairs in candidate demonstrations,\nproviding insights into the reasoning behind the answer. (ii) Post Hoc\nExplanation-Guided Demonstrations Selection, which utilizes explanations\ngenerated by LLMs to guide the process of demonstration selection from\ncandidate demonstrations. (iii) Post Hoc Explanation-Guided Interpretable SLM\nPrediction, which utilizes the demonstrations obtained in step (ii) as\nin-context and merges corresponding explanations as rationales to improve the\nperformance of SLM and guide the model to generate interpretable outputs.\nExperimental results highlight the framework's effectiveness, with an average\naccuracy improvement of 5.31% across various tabular datasets in diverse\ndomains."}
{"id": "2505.05763", "pdf": "https://arxiv.org/pdf/2505.05763.pdf", "abs": "https://arxiv.org/abs/2505.05763", "title": "BMMDetect: A Multimodal Deep Learning Framework for Comprehensive Biomedical Misconduct Detection", "authors": ["Yize Zhou", "Jie Zhang", "Meijie Wang", "Lun Yu"], "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Academic misconduct detection in biomedical research remains challenging due\nto algorithmic narrowness in existing methods and fragmented analytical\npipelines. We present BMMDetect, a multimodal deep learning framework that\nintegrates journal metadata (SJR, institutional data), semantic embeddings\n(PubMedBERT), and GPT-4o-mined textual attributes (methodological statistics,\ndata anomalies) for holistic manuscript evaluation. Key innovations include:\n(1) multimodal fusion of domain-specific features to reduce detection bias; (2)\nquantitative evaluation of feature importance, identifying journal authority\nmetrics (e.g., SJR-index) and textual anomalies (e.g., statistical outliers) as\ndominant predictors; and (3) the BioMCD dataset, a large-scale benchmark with\n13,160 retracted articles and 53,411 controls. BMMDetect achieves 74.33% AUC,\noutperforming single-modality baselines by 8.6%, and demonstrates\ntransferability across biomedical subfields. This work advances scalable,\ninterpretable tools for safeguarding research integrity."}
{"id": "2505.05828", "pdf": "https://arxiv.org/pdf/2505.05828.pdf", "abs": "https://arxiv.org/abs/2505.05828", "title": "An empathic GPT-based chatbot to talk about mental disorders with Spanish teenagers", "authors": ["Alba María Mármol-Romero", "Manuel García-Vega", "Miguel Ángel García-Cumbreras", "Arturo Montejo-Ráez"], "categories": ["cs.HC", "cs.CL"], "comment": "This is an Accepted Manuscript version of the following article,\n  accepted for publication in International Journal of Human-Computer\n  Interaction. It is deposited under the terms of the Creative Commons\n  Attribution-NonCommercial-NoDerivatives License", "summary": "This paper presents a chatbot-based system to engage young Spanish people in\nthe awareness of certain mental disorders through a self-disclosure technique.\nThe study was carried out in a population of teenagers aged between 12 and 18\nyears. The dialogue engine mixes closed and open conversations, so certain\ncontrolled messages are sent to focus the chat on a specific disorder, which\nwill change over time. Once a set of trial questions is answered, the system\ncan initiate the conversation on the disorder under the focus according to the\nuser's sensibility to that disorder, in an attempt to establish a more\nempathetic communication. Then, an open conversation based on the GPT-3\nlanguage model is initiated, allowing the user to express themselves with more\nfreedom. The results show that these systems are of interest to young people\nand could help them become aware of certain mental disorders."}
{"id": "2505.05863", "pdf": "https://arxiv.org/pdf/2505.05863.pdf", "abs": "https://arxiv.org/abs/2505.05863", "title": "Evolutionary ecology of words", "authors": ["Reiji Suzuki", "Takaya Arita"], "categories": ["q-bio.PE", "cs.AI", "cs.CL", "92B20"], "comment": "8 pages, 5 figures. Preprint of the paper published in Proceedings of\n  2025 IEEE Symposium on Computational Intelligence in Artificial Life and\n  Cooperative Intelligent Systems (ALIFE-CIS)", "summary": "We propose a model for the evolutionary ecology of words as one attempt to\nextend evolutionary game theory and agent-based models by utilizing the rich\nlinguistic expressions of Large Language Models (LLMs). Our model enables the\nemergence and evolution of diverse and infinite options for interactions among\nagents. Within the population, each agent possesses a short word (or phrase)\ngenerated by an LLM and moves within a spatial environment. When agents become\nadjacent, the outcome of their interaction is determined by the LLM based on\nthe relationship between their words, with the loser's word being replaced by\nthe winner's. Word mutations, also based on LLM outputs, may occur. We\nconducted preliminary experiments assuming that ``strong animal species\" would\nsurvive. The results showed that from an initial population consisting of\nwell-known species, many species emerged both gradually and in a punctuated\nequilibrium manner. Each trial demonstrated the unique evolution of diverse\npopulations, with one type of large species becoming dominant, such as\nterrestrial animals, marine life, or extinct species, which were ecologically\nspecialized and adapted ones across diverse extreme habitats. We also conducted\na long-term experiment with a large population, demonstrating the emergence and\ncoexistence of diverse species."}
{"id": "2505.06032", "pdf": "https://arxiv.org/pdf/2505.06032.pdf", "abs": "https://arxiv.org/abs/2505.06032", "title": "Short-circuiting Shortcuts: Mechanistic Investigation of Shortcuts in Text Classification", "authors": ["Leon Eshuijs", "Shihan Wang", "Antske Fokkens"], "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reliance on spurious correlations (shortcuts) has been shown to underlie many\nof the successes of language models. Previous work focused on identifying the\ninput elements that impact prediction. We investigate how shortcuts are\nactually processed within the model's decision-making mechanism. We use actor\nnames in movie reviews as controllable shortcuts with known impact on the\noutcome. We use mechanistic interpretability methods and identify specific\nattention heads that focus on shortcuts. These heads gear the model towards a\nlabel before processing the complete input, effectively making premature\ndecisions that bypass contextual analysis. Based on these findings, we\nintroduce Head-based Token Attribution (HTA), which traces intermediate\ndecisions back to input tokens. We show that HTA is effective in detecting\nshortcuts in LLMs and enables targeted mitigation by selectively deactivating\nshortcut-related attention heads."}
{"id": "2505.06107", "pdf": "https://arxiv.org/pdf/2505.06107.pdf", "abs": "https://arxiv.org/abs/2505.06107", "title": "Differentiating Emigration from Return Migration of Scholars Using Name-Based Nationality Detection Models", "authors": ["Faeze Ghorbanpour", "Thiago Zordan Malaguth", "Aliakbar Akbaritabar"], "categories": ["cs.DL", "cs.CL", "cs.MM"], "comment": "Accepted to appear @ ICWSM 2025. The link to the camera-ready paper\n  will be added soon", "summary": "Most web and digital trace data do not include information about an\nindividual's nationality due to privacy concerns. The lack of data on\nnationality can create challenges for migration research. It can lead to a\nleft-censoring issue since we are uncertain about the migrant's country of\norigin. Once we observe an emigration event, if we know the nationality, we can\ndifferentiate it from return migration. We propose methods to detect the\nnationality with the least available data, i.e., full names. We use the\ndetected nationality in comparison with the country of academic origin, which\nis a common approach in studying the migration of researchers. We gathered 2.6\nmillion unique name-nationality pairs from Wikipedia and categorized them into\nfamilies of nationalities with three granularity levels to use as our training\ndata. Using a character-based machine learning model, we achieved a weighted F1\nscore of 84% for the broadest and 67% for the most granular, country-level\ncategorization. In our empirical study, we used the trained and tested model to\nassign nationality to 8+ million scholars' full names in Scopus data. Our\nresults show that using the country of first publication as a proxy for\nnationality underestimates the size of return flows, especially for countries\nwith a more diverse academic workforce, such as the USA, Australia, and Canada.\nWe found that around 48% of emigration from the USA was return migration once\nwe used the country of name origin, in contrast to 33% based on academic\norigin. In the most recent period, 79% of scholars whose affiliation has\nconsistently changed from the USA to China, and are considered emigrants, have\nChinese names in contrast to 41% with a Chinese academic origin. Our proposed\nmethods for addressing left-censoring issues are beneficial for other research\nthat uses digital trace data to study migration."}
{"id": "2505.06184", "pdf": "https://arxiv.org/pdf/2505.06184.pdf", "abs": "https://arxiv.org/abs/2505.06184", "title": "From Millions of Tweets to Actionable Insights: Leveraging LLMs for User Profiling", "authors": ["Vahid Rahimzadeh", "Ali Hamzehpour", "Azadeh Shakery", "Masoud Asadpour"], "categories": ["cs.SI", "cs.CL", "cs.IR", "I.2.7"], "comment": "Accepted at MisD @ AAAI ICWSM 2025", "summary": "Social media user profiling through content analysis is crucial for tasks\nlike misinformation detection, engagement prediction, hate speech monitoring,\nand user behavior modeling. However, existing profiling techniques, including\ntweet summarization, attribute-based profiling, and latent representation\nlearning, face significant limitations: they often lack transferability,\nproduce non-interpretable features, require large labeled datasets, or rely on\nrigid predefined categories that limit adaptability. We introduce a novel large\nlanguage model (LLM)-based approach that leverages domain-defining statements,\nwhich serve as key characteristics outlining the important pillars of a domain\nas foundations for profiling. Our two-stage method first employs\nsemi-supervised filtering with a domain-specific knowledge base, then generates\nboth abstractive (synthesized descriptions) and extractive (representative\ntweet selections) user profiles. By harnessing LLMs' inherent knowledge with\nminimal human validation, our approach is adaptable across domains while\nreducing the need for large labeled datasets. Our method generates\ninterpretable natural language user profiles, condensing extensive user data\ninto a scale that unlocks LLMs' reasoning and knowledge capabilities for\ndownstream social network tasks. We contribute a Persian political Twitter (X)\ndataset and an LLM-based evaluation framework with human validation.\nExperimental results show our method significantly outperforms state-of-the-art\nLLM-based and traditional methods by 9.8%, demonstrating its effectiveness in\ncreating flexible, adaptable, and interpretable user profiles."}
{"id": "2505.06191", "pdf": "https://arxiv.org/pdf/2505.06191.pdf", "abs": "https://arxiv.org/abs/2505.06191", "title": "Neuro-Symbolic Concepts", "authors": ["Jiayuan Mao", "Joshua B. Tenenbaum", "Jiajun Wu"], "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.RO"], "comment": "To appear in Communications of the ACM", "summary": "This article presents a concept-centric paradigm for building agents that can\nlearn continually and reason flexibly. The concept-centric agent utilizes a\nvocabulary of neuro-symbolic concepts. These concepts, such as object,\nrelation, and action concepts, are grounded on sensory inputs and actuation\noutputs. They are also compositional, allowing for the creation of novel\nconcepts through their structural combination. To facilitate learning and\nreasoning, the concepts are typed and represented using a combination of\nsymbolic programs and neural network representations. Leveraging such\nneuro-symbolic concepts, the agent can efficiently learn and recombine them to\nsolve various tasks across different domains, ranging from 2D images, videos,\n3D scenes, and robotic manipulation tasks. This concept-centric framework\noffers several advantages, including data efficiency, compositional\ngeneralization, continual learning, and zero-shot transfer."}
{"id": "2209.15373", "pdf": "https://arxiv.org/pdf/2209.15373.pdf", "abs": "https://arxiv.org/abs/2209.15373", "title": "PART: Pre-trained Authorship Representation Transformer", "authors": ["Javier Huertas-Tato", "Alejandro Martin", "David Camacho"], "categories": ["cs.CL"], "comment": null, "summary": "Authors writing documents imprint identifying information within their texts:\nvocabulary, registry, punctuation, misspellings, or even emoji usage. Previous\nworks use hand-crafted features or classification tasks to train their\nauthorship models, leading to poor performance on out-of-domain authors. Using\nstylometric representations is more suitable, but this by itself is an open\nresearch challenge. In this paper, we propose PART, a contrastively trained\nmodel fit to learn \\textbf{authorship embeddings} instead of semantics. We\ntrain our model on ~1.5M texts belonging to 1162 literature authors, 17287 blog\nposters and 135 corporate email accounts; a heterogeneous set with identifiable\nwriting styles. We evaluate the model on current challenges, achieving\ncompetitive performance. We also evaluate our model on test splits of the\ndatasets achieving zero-shot 72.39\\% accuracy when bounded to 250 authors, a\n54\\% and 56\\% higher than RoBERTa embeddings. We qualitatively assess the\nrepresentations with different data visualizations on the available datasets,\nobserving features such as gender, age, or occupation of the author."}
{"id": "2403.19346", "pdf": "https://arxiv.org/pdf/2403.19346.pdf", "abs": "https://arxiv.org/abs/2403.19346", "title": "Large Language Models Are Struggle to Cope with Unreasonability in Math Problems", "authors": ["Jingyuan Ma", "Damai Dai", "Zihang Yuan", "Rui li", "Weilin Luo", "Bin Wang", "Qun Liu", "Lei Sha", "Zhifang Sui"], "categories": ["cs.CL"], "comment": "32 pages, 8 figures", "summary": "Recent research have demonstrated LLMs' impressive performance in math and\nreasoning. However, the capacity of LLMs to address math problems under\nunconventional conditions, such as internal inconsistencies and flawed\nassumptions, remains largely unexplored. In this paper, we propose a novel\nbenchmark Unreasonable Math Problem (UMP) designed to assess LLMs' ability to\nrecognize and respond to unreasonability in math problem. The benchmark\nconsists of a carefully curated collection of unreasonable math questions\nacross diverse types. Based on extensive experiments covering 19 LLMs, we\nobserve that even state-of-the-art models such as GPT-4o achieve only limited\nperformance of 0.6 in UMP, while reasoning models such as DeepSeek-R1 are prone\nto overthinking and unstable. We further explore strategies for improving the\nrecognition of unreasonable inputs, shedding light on both the possibility and\nlimitations of LLMs in this challenging setting."}
{"id": "2406.09519", "pdf": "https://arxiv.org/pdf/2406.09519.pdf", "abs": "https://arxiv.org/abs/2406.09519", "title": "Talking Heads: Understanding Inter-layer Communication in Transformer Language Models", "authors": ["Jack Merullo", "Carsten Eickhoff", "Ellie Pavlick"], "categories": ["cs.CL", "cs.AI"], "comment": "Neurips 2024", "summary": "Although it is known that transformer language models (LMs) pass features\nfrom early layers to later layers, it is not well understood how this\ninformation is represented and routed by the model. We analyze a mechanism used\nin two LMs to selectively inhibit items in a context in one task, and find that\nit underlies a commonly used abstraction across many context-retrieval\nbehaviors. Specifically, we find that models write into low-rank subspaces of\nthe residual stream to represent features which are then read out by later\nlayers, forming low-rank communication channels (Elhage et al., 2021) between\nlayers. A particular 3D subspace in model activations in GPT-2 can be traversed\nto positionally index items in lists, and we show that this mechanism can\nexplain an otherwise arbitrary-seeming sensitivity of the model to the order of\nitems in the prompt. That is, the model has trouble copying the correct\ninformation from context when many items ``crowd\" this limited space. By\ndecomposing attention heads with the Singular Value Decomposition (SVD), we\nfind that previously described interactions between heads separated by one or\nmore layers can be predicted via analysis of their weight matrices alone. We\nshow that it is possible to manipulate the internal model representations as\nwell as edit model weights based on the mechanism we discover in order to\nsignificantly improve performance on our synthetic Laundry List task, which\nrequires recall from a list, often improving task accuracy by over 20%. Our\nanalysis reveals a surprisingly intricate interpretable structure learned from\nlanguage model pretraining, and helps us understand why sophisticated LMs\nsometimes fail in simple domains, facilitating future analysis of more complex\nbehaviors."}
{"id": "2407.11963", "pdf": "https://arxiv.org/pdf/2407.11963.pdf", "abs": "https://arxiv.org/abs/2407.11963", "title": "NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context?", "authors": ["Mo Li", "Songyang Zhang", "Taolin Zhang", "Haodong Duan", "Yunxin Liu", "Kai Chen"], "categories": ["cs.CL"], "comment": "v2: updated with tested models and Multi-Needle Reasoning\n  implementation", "summary": "The capability of large language models to handle long-context information is\ncrucial across various real-world applications. Existing evaluation methods\noften rely either on real-world long texts, making it difficult to exclude the\ninfluence of models' inherent knowledge, or introduce irrelevant filler content\nto artificially achieve target lengths, reducing assessment effectiveness. To\naddress these limitations, we introduce NeedleBench, a synthetic framework for\nassessing retrieval and reasoning performance in bilingual long-context tasks\nwith adaptive context lengths. NeedleBench systematically embeds key data\npoints at varying depths to rigorously test model capabilities. Tasks are\ncategorized into two scenarios: information-sparse, featuring minimal relevant\ndetails within extensive irrelevant text to simulate simple retrieval tasks;\nand information-dense (the Ancestral Trace Challenge), where relevant\ninformation is continuously distributed throughout the context to simulate\ncomplex reasoning tasks. Our experiments reveal that although recent reasoning\nmodels like Deepseek-R1 and OpenAI's o3 excel in mathematical reasoning, they\nstruggle with continuous retrieval and reasoning in information-dense\nscenarios, even at shorter context lengths. We also characterize a phenomenon\ntermed 'under-thinking', where models prematurely conclude reasoning despite\navailable information. NeedleBench thus provides critical insights and targeted\ntools essential for evaluating and improving LLMs' long-context capabilities.\nAll resources are available at OpenCompass:\nhttps://github.com/open-compass/opencompass."}
{"id": "2408.00103", "pdf": "https://arxiv.org/pdf/2408.00103.pdf", "abs": "https://arxiv.org/abs/2408.00103", "title": "ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget", "authors": ["Riccardo Orlando", "Pere-Lluis Huguet Cabot", "Edoardo Barba", "Roberto Navigli"], "categories": ["cs.CL", "cs.AI"], "comment": "Findings of the Association for Computational Linguistics ACL 2024", "summary": "Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in\nNatural Language Processing, serving as critical components in a wide range of\napplications. In this paper, we propose ReLiK, a Retriever-Reader architecture\nfor both EL and RE, where, given an input text, the Retriever module undertakes\nthe identification of candidate entities or relations that could potentially\nappear within the text. Subsequently, the Reader module is tasked to discern\nthe pertinent retrieved entities or relations and establish their alignment\nwith the corresponding textual spans. Notably, we put forward an innovative\ninput representation that incorporates the candidate entities or relations\nalongside the text, making it possible to link entities or extract relations in\na single forward pass and to fully leverage pre-trained language models\ncontextualization capabilities, in contrast with previous\nRetriever-Reader-based methods, which require a forward pass for each\ncandidate. Our formulation of EL and RE achieves state-of-the-art performance\nin both in-domain and out-of-domain benchmarks while using academic budget\ntraining and with up to 40x inference speed compared to competitors. Finally,\nwe show how our architecture can be used seamlessly for Information Extraction\n(cIE), i.e. EL + RE, and setting a new state of the art by employing a shared\nReader that simultaneously extracts entities and relations."}
{"id": "2410.18234", "pdf": "https://arxiv.org/pdf/2410.18234.pdf", "abs": "https://arxiv.org/abs/2410.18234", "title": "Multi-Draft Speculative Sampling: Canonical Decomposition and Theoretical Limits", "authors": ["Ashish Khisti", "M. Reza Ebrahimi", "Hassan Dbouk", "Arash Behboodi", "Roland Memisevic", "Christos Louizos"], "categories": ["cs.CL", "cs.DC", "cs.IT", "cs.LG", "math.IT"], "comment": "Published as a (spotlight) conference paper at ICLR 2025", "summary": "We consider multi-draft speculative sampling, where the proposal sequences\nare sampled independently from different draft models. At each step, a\ntoken-level draft selection scheme takes a list of valid tokens as input and\nproduces an output token whose distribution matches that of the target model.\nPrevious works have demonstrated that the optimal scheme (which maximizes the\nprobability of accepting one of the input tokens) can be cast as a solution to\na linear program. In this work we show that the optimal scheme can be\ndecomposed into a two-step solution: in the first step an importance sampling\n(IS) type scheme is used to select one intermediate token; in the second step\n(single-draft) speculative sampling is applied to generate the output token.\nFor the case of two identical draft models we further 1) establish a necessary\nand sufficient condition on the distributions of the target and draft models\nfor the acceptance probability to equal one and 2) provide an explicit\nexpression for the optimal acceptance probability. Our theoretical analysis\nalso motives a new class of token-level selection schemes based on weighted\nimportance sampling. Our experimental results demonstrate consistent\nimprovements in the achievable block efficiency and token rates over baseline\nschemes in a number of scenarios."}
{"id": "2411.11053", "pdf": "https://arxiv.org/pdf/2411.11053.pdf", "abs": "https://arxiv.org/abs/2411.11053", "title": "SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation", "authors": ["Bin Xu", "Yiguan Lin", "Yinghao Li", "Yang Gao"], "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by IJCAI2025", "summary": "Large language models demonstrate exceptional performance in simple code\ngeneration tasks but still face challenges in tackling complex problems. These\nchallenges may stem from insufficient reasoning and problem decomposition\ncapabilities. To address this issue, we propose a reasoning-augmented data\ngeneration process, SRA-MCTS, which guides the model to autonomously generate\nhigh-quality intermediate reasoning paths. This creates a positive feedback\nloop, enabling continuous improvement. Our method operates entirely through the\nmodel itself without requiring additional supervision. By synthesizing natural\nlanguage reasoning paths and translating them into executable code, the\napproach ensures analytical accuracy and enhances the success rate in solving\ncomplex tasks. Experimental results show that, even without additional\nsupervisory signals, our method achieves performance improvements across\ndifferent model scales, demonstrating the significant potential of\nself-improvement in small models. Furthermore, the method remains robust when\ntraditional Chain-of-Thought (CoT) approaches exhibit performance degradation,\nwith notable improvements observed in diversity metrics such as pass@10. We\nencourage further exploration of reasoning processes within training data to\nenhance the ability of language models to address complex problems. Our code\nand data are public at https://github.com/DIRECT-BIT/SRA-MCTS."}
{"id": "2501.12106", "pdf": "https://arxiv.org/pdf/2501.12106.pdf", "abs": "https://arxiv.org/abs/2501.12106", "title": "Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes", "authors": ["Stefan Lenz", "Arsenij Ustjanzew", "Marco Jeray", "Meike Ressing", "Torsten Panholzer"], "categories": ["cs.CL", "cs.AI"], "comment": "53 pages, 5 figures", "summary": "Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP."}
{"id": "2501.14851", "pdf": "https://arxiv.org/pdf/2501.14851.pdf", "abs": "https://arxiv.org/abs/2501.14851", "title": "JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models", "authors": ["Michael K. Chen", "Xikun Zhang", "Dacheng Tao"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "Logical reasoning is a critical component of Large Language Models (LLMs),\nand substantial research efforts in recent years have aimed to enhance their\ndeductive reasoning capabilities. However, existing deductive reasoning\nbenchmarks, which are crucial for evaluating and advancing LLMs, are inadequate\ndue to their lack of task complexity, presence of prior knowledge as a\nconfounder, and superficial error analysis. To address these deficiencies, we\nintroduce JustLogic, a synthetically generated deductive reasoning benchmark\ndesigned for rigorous evaluation of LLMs. JustLogic is (i) highly complex,\ncapable of generating a diverse range of linguistic patterns, vocabulary, and\nargument structures; (ii) prior knowledge independent, eliminating the\nadvantage of models possessing prior knowledge and ensuring that only deductive\nreasoning is used to answer questions; and (iii) capable of in-depth error\nanalysis on the heterogeneous effects of reasoning depth and argument form on\nmodel accuracy. Our experimental results on JustLogic reveal that (i)\nstate-of-the-art (SOTA) reasoning LLMs perform on par or better than the human\naverage but significantly worse than the human ceiling, and (ii) SOTA\nnon-reasoning models still underperform the human average. All code and data\nare available at https://github.com/michaelchen-lab/JustLogic"}
{"id": "2501.16154", "pdf": "https://arxiv.org/pdf/2501.16154.pdf", "abs": "https://arxiv.org/abs/2501.16154", "title": "AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought", "authors": ["Xin Huang", "Tarun Kumar Vangani", "Zhengyuan Liu", "Bowei Zou", "Ai Ti Aw"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models have shown impressive multilingual capabilities through\npretraining on diverse corpora. While these models show strong reasoning\nabilities, their performance varies significantly across languages due to\nimbalanced training data distribution. Existing approaches using sample-level\ntranslation for extensive multilingual pretraining and cross-lingual tuning\nface scalability challenges and often fail to capture nuanced reasoning\nprocesses across languages. In this paper, we introduce AdaCoT (Adaptive\nChain-of-Thought), a framework that enhances multilingual factual reasoning by\ndynamically routing thought processes in intermediary ``thinking languages''\nbefore generating target-language responses. AdaCoT leverages a\nlanguage-agnostic core and incorporates an adaptive, reward-based mechanism for\nselecting optimal reasoning pathways without requiring additional pretraining.\nOur comprehensive evaluation across multiple benchmarks demonstrates\nsubstantial improvements in both factual reasoning quality and cross-lingual\nconsistency, with particularly strong performance gains in low-resource\nlanguage settings. The results suggest that adaptive reasoning paths can\neffectively bridge the performance gap between high and low-resource languages\nwhile maintaining cultural and linguistic nuances."}
{"id": "2502.00290", "pdf": "https://arxiv.org/pdf/2502.00290.pdf", "abs": "https://arxiv.org/abs/2502.00290", "title": "Estimating LLM Uncertainty with Evidence", "authors": ["Huan Ma", "Jingdong Chen", "Joey Tianyi Zhou", "Guangyu Wang", "Changqing Zhang"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Over the past few years, Large Language Models (LLMs) have developed rapidly\nand are widely applied in various domains. However, LLMs face the issue of\nhallucinations, generating responses that may be unreliable when the models\nlack relevant knowledge. To be aware of potential hallucinations, uncertainty\nestimation methods have been introduced, and most of them have confirmed that\nreliability lies in critical tokens. However, probability-based methods perform\npoorly in identifying token reliability, limiting their practical utility. In\nthis paper, we reveal that the probability-based method fails to estimate token\nreliability due to the loss of evidence strength information which is\naccumulated in the training stage. Therefore, we present Logits-induced token\nuncertainty (LogTokU), a framework for estimating decoupled token uncertainty\nin LLMs, enabling real-time uncertainty estimation without requiring multiple\nsampling processes. We employ evidence modeling to implement LogTokU and use\nthe estimated uncertainty to guide downstream tasks. The experimental results\ndemonstrate that LogTokU has significant effectiveness and promise."}
{"id": "2502.01210", "pdf": "https://arxiv.org/pdf/2502.01210.pdf", "abs": "https://arxiv.org/abs/2502.01210", "title": "Phonetic accommodation and inhibition in a dynamic neural field model", "authors": ["Sam Kirkham", "Patrycja Strycharczuk", "Rob Davies", "Danielle Welburn"], "categories": ["cs.CL"], "comment": null, "summary": "Short-term phonetic accommodation is a fundamental driver behind accent\nchange, but how does real-time input from another speaker's voice shape the\nspeech planning representations of an interlocutor? We advance a computational\nmodel of change in speech planning representations during phonetic\naccommodation, grounded in dynamic neural field equations for movement planning\nand memory dynamics. A dual-layer planning/memory field predicts that\nconvergence to a model talker on one trial can trigger divergence on subsequent\ntrials, due to a delayed inhibitory effect in the more slowly evolving memory\nfield. The model's predictions are compared with empirical patterns of\naccommodation from an experimental pilot study. We show that observed empirical\nphenomena may correspond to variation in the magnitude of inhibitory memory\ndynamics, which could reflect resistance to accommodation due to phonological\nand/or sociolinguistic pressures. We discuss the implications of these results\nfor the relations between short-term phonetic accommodation and sound change."}
{"id": "2502.04134", "pdf": "https://arxiv.org/pdf/2502.04134.pdf", "abs": "https://arxiv.org/abs/2502.04134", "title": "The Order Effect: Investigating Prompt Sensitivity to Input Order in LLMs", "authors": ["Bryan Guan", "Tanya Roosta", "Peyman Passban", "Mehdi Rezagholizadeh"], "categories": ["cs.CL"], "comment": "The first 3 authors have contributed equally", "summary": "As large language models (LLMs) become integral to diverse applications,\nensuring their reliability under varying input conditions is crucial. One key\nissue affecting this reliability is order sensitivity, wherein slight\nvariations in the input arrangement can lead to inconsistent or biased outputs.\nAlthough recent advances have reduced this sensitivity, the problem remains\nunresolved. This paper investigates the extent of order sensitivity in LLMs\nwhose internal components are hidden from users (such as closed-source models\nor those accessed via API calls). We conduct experiments across multiple tasks,\nincluding paraphrasing, relevance judgment, and multiple-choice questions. Our\nresults show that input order significantly affects performance across tasks,\nwith shuffled inputs leading to measurable declines in output accuracy.\nFew-shot prompting demonstrates mixed effectiveness and offers partial\nmitigation; however, fails to fully resolve the problem. These findings\nhighlight persistent risks, particularly in high-stakes applications, and point\nto the need for more robust LLMs or improved input-handling techniques in\nfuture development."}
{"id": "2502.09667", "pdf": "https://arxiv.org/pdf/2502.09667.pdf", "abs": "https://arxiv.org/abs/2502.09667", "title": "k-LLMmeans: Scalable, Stable, and Interpretable Text Clustering via LLM-based Centroids", "authors": ["Jairo Diaz-Rodriguez"], "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "We introduce k-LLMmeans, a novel modification of the k-means algorithm for\ntext clustering that leverages LLM-generated summaries as cluster centroids,\ncapturing semantic nuances often missed by purely numerical averages. This\ndesign preserves the core optimization properties of k-means while enhancing\nsemantic interpretability and avoiding the scalability and instability issues\ntypical of modern LLM-based clustering. Unlike existing methods, our approach\ndoes not increase LLM usage with dataset size and produces transparent\nintermediate outputs. We further extend it with a mini-batch variant for\nefficient, real-time clustering of streaming text. Extensive experiments across\nmultiple datasets, embeddings, and LLMs show that k-LLMmeans consistently\noutperforms k-means and other traditional baselines and achieves results\ncomparable to state-of-the-art LLM-based clustering, with a fraction of the LLM\ncalls. Finally, we present a case study on sequential text streams and\nintroduce a new benchmark dataset constructed from StackExchange to evaluate\ntext-stream clustering methods."}
{"id": "2502.14338", "pdf": "https://arxiv.org/pdf/2502.14338.pdf", "abs": "https://arxiv.org/abs/2502.14338", "title": "English Please: Evaluating Machine Translation with Large Language Models for Multilingual Bug Reports", "authors": ["Avinash Patil", "Siru Tao", "Aryan Jadon"], "categories": ["cs.CL", "cs.SE"], "comment": "8 Pages, 4 Figures, 3 Tables", "summary": "Accurate translation of bug reports is critical for efficient collaboration\nin global software development. In this study, we conduct the first\ncomprehensive evaluation of machine translation (MT) performance on bug\nreports, analyzing the capabilities of DeepL, AWS Translate, and large language\nmodels such as ChatGPT, Claude, Gemini, LLaMA, and Mistral using data from the\nVisual Studio Code GitHub repository, specifically focusing on reports labeled\nwith the english-please tag. To assess both translation quality and source\nlanguage identification accuracy, we employ a range of MT evaluation\nmetrics-including BLEU, BERTScore, COMET, METEOR, and ROUGE-alongside\nclassification metrics such as accuracy, precision, recall, and F1-score. Our\nfindings reveal that while ChatGPT (gpt-4o) excels in semantic and lexical\ntranslation quality, it does not lead in source language identification. Claude\nand Mistral achieve the highest F1-scores (0.7182 and 0.7142, respectively),\nand Gemini records the best precision (0.7414). AWS Translate shows the highest\naccuracy (0.4717) in identifying source languages. These results highlight that\nno single system dominates across all tasks, reinforcing the importance of\ntask-specific evaluations. This study underscores the need for domain\nadaptation when translating technical content and provides actionable insights\nfor integrating MT into bug-triaging workflows. The code and dataset for this\npaper are available at GitHub-https://github.com/av9ash/English-Please"}
{"id": "2502.20364", "pdf": "https://arxiv.org/pdf/2502.20364.pdf", "abs": "https://arxiv.org/abs/2502.20364", "title": "Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization", "authors": ["Ryan C. Barron", "Maksim E. Eren", "Olga M. Serafimova", "Cynthia Matuszek", "Boian S. Alexandrov"], "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 8 figures, 5 tables", "summary": "Agentic Generative AI, powered by Large Language Models (LLMs) with\nRetrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores\n(VSs), represents a transformative technology applicable to specialized domains\nsuch as legal systems, research, recommender systems, cybersecurity, and global\nsecurity, including proliferation research. This technology excels at inferring\nrelationships within vast unstructured or semi-structured datasets. The legal\ndomain here comprises complex data characterized by extensive, interrelated,\nand semi-structured knowledge systems with complex relations. It comprises\nconstitutions, statutes, regulations, and case law. Extracting insights and\nnavigating the intricate networks of legal documents and their relations is\ncrucial for effective legal research. Here, we introduce a generative AI system\nthat integrates RAG, VS, and KG, constructed via Non-Negative Matrix\nFactorization (NMF), to enhance legal information retrieval and AI reasoning\nand minimize hallucinations. In the legal system, these technologies empower AI\nagents to identify and analyze complex connections among cases, statutes, and\nlegal precedents, uncovering hidden relationships and predicting legal\ntrends-challenging tasks that are essential for ensuring justice and improving\noperational efficiency. Our system employs web scraping techniques to\nsystematically collect legal texts, such as statutes, constitutional\nprovisions, and case law, from publicly accessible platforms like Justia. It\nbridges the gap between traditional keyword-based searches and contextual\nunderstanding by leveraging advanced semantic representations, hierarchical\nrelationships, and latent topic discovery. This framework supports legal\ndocument clustering, summarization, and cross-referencing, for scalable,\ninterpretable, and accurate retrieval for semi-structured data while advancing\ncomputational law and AI."}
{"id": "2503.17460", "pdf": "https://arxiv.org/pdf/2503.17460.pdf", "abs": "https://arxiv.org/abs/2503.17460", "title": "ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach", "authors": ["Reem Gody", "Mahmoud Goudy", "Ahmed Y. Tawfik"], "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we present ConvoGen: an innovative framework for generating\nsynthetic conversational data using multi-agent systems. Our method leverages\nfew-shot learning and introduces iterative sampling from a dynamically updated\nfew-shot hub to create diverse and realistic conversational scenarios. The\ngenerated data has numerous applications, including training and evaluating\nconversational AI models, and augmenting existing datasets for tasks like\nconversational intent classification or conversation summarization. Our\nexperiments demonstrate the effectiveness of this method in producing\nhigh-quality diverse synthetic conversational data, highlighting its potential\nto enhance the development and evaluation of conversational AI systems."}
{"id": "2504.12345", "pdf": "https://arxiv.org/pdf/2504.12345.pdf", "abs": "https://arxiv.org/abs/2504.12345", "title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models", "authors": ["Yutong Xia", "Ao Qu", "Yunhan Zheng", "Yihong Tang", "Dingyi Zhuang", "Yuxuan Liang", "Shenhao Wang", "Cathy Wu", "Lijun Sun", "Roger Zimmermann", "Jinhua Zhao"], "categories": ["cs.CL", "cs.CY", "cs.MA"], "comment": null, "summary": "Urban causal research is essential for understanding the complex dynamics of\ncities and informing evidence-based policies. However, it is challenged by the\ninefficiency and bias of hypothesis generation, barriers to multimodal data\ncomplexity, and the methodological fragility of causal experimentation. Recent\nadvances in large language models (LLMs) present an opportunity to rethink how\nurban causal analysis is conducted. This Perspective examines current urban\ncausal research by analyzing taxonomies that categorize research topics, data\nsources, and methodological approaches to identify structural gaps. We then\nintroduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four\ndistinct modular agents responsible for hypothesis generation, data\nengineering, experiment design and execution, and results interpretation with\npolicy recommendations. We propose evaluation criteria for rigor and\ntransparency and reflect on implications for human-AI collaboration, equity,\nand accountability. We call for a new research agenda that embraces\nAI-augmented workflows not as replacements for human expertise but as tools to\nbroaden participation, improve reproducibility, and unlock more inclusive forms\nof urban causal reasoning."}
{"id": "2504.17480", "pdf": "https://arxiv.org/pdf/2504.17480.pdf", "abs": "https://arxiv.org/abs/2504.17480", "title": "Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation", "authors": ["Xin Yi", "Yue Li", "Shunfan Zheng", "Linlin Wang", "Xiaoling Wang", "Liang He"], "categories": ["cs.CL"], "comment": null, "summary": "Watermarking has emerged as a critical technique for combating misinformation\nand protecting intellectual property in large language models (LLMs). A recent\ndiscovery, termed watermark radioactivity, reveals that watermarks embedded in\nteacher models can be inherited by student models through knowledge\ndistillation. On the positive side, this inheritance allows for the detection\nof unauthorized knowledge distillation by identifying watermark traces in\nstudent models. However, the robustness of watermarks against scrubbing attacks\nand their unforgeability in the face of spoofing attacks under unauthorized\nknowledge distillation remain largely unexplored. Existing watermark attack\nmethods either assume access to model internals or fail to simultaneously\nsupport both scrubbing and spoofing attacks. In this work, we propose\nContrastive Decoding-Guided Knowledge Distillation (CDG-KD), a unified\nframework that enables bidirectional attacks under unauthorized knowledge\ndistillation. Our approach employs contrastive decoding to extract corrupted or\namplified watermark texts via comparing outputs from the student model and\nweakly watermarked references, followed by bidirectional distillation to train\nnew student models capable of watermark removal and watermark forgery,\nrespectively. Extensive experiments show that CDG-KD effectively performs\nattacks while preserving the general performance of the distilled model. Our\nfindings underscore critical need for developing watermarking schemes that are\nrobust and unforgeable."}
{"id": "2504.21463", "pdf": "https://arxiv.org/pdf/2504.21463.pdf", "abs": "https://arxiv.org/abs/2504.21463", "title": "RWKV-X: A Linear Complexity Hybrid Language Model", "authors": ["Haowen Hou", "Zhiyi Huang", "Kaifeng Tan", "Rongchang Lu", "Fei Richard Yu"], "categories": ["cs.CL"], "comment": "12 pages, typos corrected", "summary": "In this paper, we introduce RWKV-X, a novel hybrid architecture that combines\nthe efficiency of RWKV for short-range modeling with a sparse attention\nmechanism designed to capture long-range context. Unlike previous hybrid\napproaches that rely on full attention layers and retain quadratic complexity,\nRWKV-X achieves linear-time complexity in training and constant-time complexity\nin inference decoding. We demonstrate that RWKV-X, when continually pretrained\non 64K-token sequences, achieves near-perfect accuracy on the 64K passkey\nretrieval benchmark. It consistently outperforms prior RWKV-7 models on\nlong-context benchmarks, while maintaining strong performance on short-context\ntasks. These results highlight RWKV-X as a scalable and efficient backbone for\ngeneral-purpose language modeling, capable of decoding sequences up to 1\nmillion tokens with stable speed and memory usage. To facilitate further\nresearch and analysis, we have made the checkpoints and the associated code\npublicly accessible at: https://github.com/howard-hou/RWKV-X."}
{"id": "2505.00679", "pdf": "https://arxiv.org/pdf/2505.00679.pdf", "abs": "https://arxiv.org/abs/2505.00679", "title": "Steering Large Language Models with Register Analysis for Arbitrary Style Transfer", "authors": ["Xinchen Yang", "Marine Carpuat"], "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in\nrewriting text across various styles. However, effectively leveraging this\nability for example-based arbitrary style transfer, where an input text is\nrewritten to match the style of a given exemplar, remains an open challenge. A\nkey question is how to describe the style of the exemplar to guide LLMs toward\nhigh-quality rewrites. In this work, we propose a prompting method based on\nregister analysis to guide LLMs to perform this task. Empirical evaluations\nacross multiple style transfer tasks show that our prompting approach enhances\nstyle transfer strength while preserving meaning more effectively than existing\nprompting strategies."}
{"id": "2505.02410", "pdf": "https://arxiv.org/pdf/2505.02410.pdf", "abs": "https://arxiv.org/abs/2505.02410", "title": "Bielik 11B v2 Technical Report", "authors": ["Krzysztof Ociepa", "Łukasz Flis", "Krzysztof Wróbel", "Adrian Gwoździej", "Remigiusz Kinas"], "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "comment": null, "summary": "We present Bielik 11B v2, a state-of-the-art language model optimized for\nPolish text processing. Built on the Mistral 7B v0.2 architecture and scaled to\n11B parameters using depth up-scaling, this model demonstrates exceptional\nperformance across Polish language benchmarks while maintaining strong\ncross-lingual capabilities. We introduce two key technical innovations:\nWeighted Instruction Cross-Entropy Loss, which optimizes learning across\ndiverse instruction types by assigning quality-based weights to training\nexamples, and Adaptive Learning Rate, which dynamically adjusts based on\ncontext length. Comprehensive evaluation across multiple benchmarks\ndemonstrates that Bielik 11B v2 outperforms many larger models, including those\nwith 2-6 times more parameters, and significantly surpasses other specialized\nPolish language models on tasks ranging from linguistic understanding to\ncomplex reasoning. The model's parameter efficiency and extensive quantization\noptions enable deployment across various hardware configurations, advancing\nPolish language AI capabilities and establishing new benchmarks for\nresource-efficient language modeling in less-represented languages."}
{"id": "2505.02819", "pdf": "https://arxiv.org/pdf/2505.02819.pdf", "abs": "https://arxiv.org/abs/2505.02819", "title": "ReplaceMe: Network Simplification via Layer Pruning and Linear Transformations", "authors": ["Dmitriy Shopkhoev", "Ammar Ali", "Magauiya Zhussip", "Valentin Malykh", "Stamatios Lefkimmiatis", "Nikos Komodakis", "Sergey Zagoruyko"], "categories": ["cs.CL"], "comment": null, "summary": "We introduce ReplaceMe, a generalized training-free depth pruning method that\neffectively replaces transformer blocks with a linear operation, while\nmaintaining high performance for low compression ratios. In contrast to\nconventional pruning approaches that require additional training or\nfine-tuning, our approach requires only a small calibration dataset that is\nused to estimate a linear transformation to approximate the pruned blocks. This\nestimated linear mapping can be seamlessly merged with the remaining\ntransformer blocks, eliminating the need for any additional network parameters.\nOur experiments show that ReplaceMe consistently outperforms other\ntraining-free approaches and remains highly competitive with state-of-the-art\npruning methods that involve extensive retraining/fine-tuning and architectural\nmodifications. Applied to several large language models (LLMs), ReplaceMe\nachieves up to 25% pruning while retaining approximately 90% of the original\nmodel's performance on open benchmarks - without any training or healing steps,\nresulting in minimal computational overhead (see Fig.1). We provide an\nopen-source library implementing ReplaceMe alongside several state-of-the-art\ndepth pruning techniques, available at this repository."}
{"id": "2505.02847", "pdf": "https://arxiv.org/pdf/2505.02847.pdf", "abs": "https://arxiv.org/abs/2505.02847", "title": "Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models", "authors": ["Bang Zhang", "Ruotian Ma", "Qingxuan Jiang", "Peisong Wang", "Jiaqi Chen", "Zheng Xie", "Xingyu Chen", "Yue Wang", "Fanghua Ye", "Jian Li", "Yifan Yang", "Zhaopeng Tu", "Xiaolong Li"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "code: https://github.com/Tencent/digitalhuman/tree/main/SAGE", "summary": "Assessing how well a large language model (LLM) understands human, rather\nthan merely text, remains an open challenge. To bridge the gap, we introduce\nSentient Agent as a Judge (SAGE), an automated evaluation framework that\nmeasures an LLM's higher-order social cognition. SAGE instantiates a Sentient\nAgent that simulates human-like emotional changes and inner thoughts during\ninteraction, providing a more realistic evaluation of the tested model in\nmulti-turn conversations. At every turn, the agent reasons about (i) how its\nemotion changes, (ii) how it feels, and (iii) how it should reply, yielding a\nnumerical emotion trajectory and interpretable inner thoughts. Experiments on\n100 supportive-dialogue scenarios show that the final Sentient emotion score\ncorrelates strongly with Barrett-Lennard Relationship Inventory (BLRI) ratings\nand utterance-level empathy metrics, validating psychological fidelity. We also\nbuild a public Sentient Leaderboard covering 18 commercial and open-source\nmodels that uncovers substantial gaps (up to 4x) between frontier systems\n(GPT-4o-Latest, Gemini2.5-Pro) and earlier baselines, gaps not reflected in\nconventional leaderboards (e.g., Arena). SAGE thus provides a principled,\nscalable and interpretable tool for tracking progress toward genuinely\nempathetic and socially adept language agents."}
{"id": "2505.05026", "pdf": "https://arxiv.org/pdf/2505.05026.pdf", "abs": "https://arxiv.org/abs/2505.05026", "title": "G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness", "authors": ["Jaehyun Jeon", "Jang Han Yoon", "Min Soo Kim", "Sumin Shim", "Yejin Choi", "Hanbin Kim", "Youngjae Yu"], "categories": ["cs.CL", "cs.LG"], "comment": "31 pages, 17 figures", "summary": "Evaluating user interface (UI) design effectiveness extends beyond aesthetics\nto influencing user behavior, a principle central to Design Persuasiveness. A/B\ntesting is the predominant method for determining which UI variations drive\nhigher user engagement, but it is costly and time-consuming. While recent\nVision-Language Models (VLMs) can process automated UI analysis, current\napproaches focus on isolated design attributes rather than comparative\npersuasiveness-the key factor in optimizing user interactions. To address this,\nwe introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design\nPersuasiveness Assessment task, featuring 300 real-world UI image pairs labeled\nwith A/B test results and expert rationales. Additionally, we propose G-FOCUS,\na novel inference-time reasoning strategy that enhances VLM-based\npersuasiveness assessment by reducing position bias and improving evaluation\naccuracy. Experimental results show that G-FOCUS surpasses existing inference\nstrategies in consistency and accuracy for pairwise UI evaluation. Through\npromoting VLM-driven evaluation of UI persuasiveness, our work offers an\napproach to complement A/B testing, propelling progress in scalable UI\npreference modeling and design optimization. Code and data will be released\npublicly."}
{"id": "2505.05423", "pdf": "https://arxiv.org/pdf/2505.05423.pdf", "abs": "https://arxiv.org/abs/2505.05423", "title": "LiTransProQA: an LLM-based Literary Translation evaluation metric with Professional Question Answering", "authors": ["Ran Zhang", "Wei Zhao", "Lieve Macken", "Steffen Eger"], "categories": ["cs.CL", "cs.AI"], "comment": "Update WIP", "summary": "The impact of Large Language Models (LLMs) has extended into literary\ndomains. However, existing evaluation metrics prioritize mechanical accuracy\nover artistic expression and tend to overrate machine translation (MT) as being\nsuperior to experienced professional human translation. In the long run, this\nbias could result in a permanent decline in translation quality and cultural\nauthenticity. In response to the urgent need for a specialized literary\nevaluation metric, we introduce LiTransProQA, a novel, reference-free,\nLLM-based question-answering framework designed specifically for literary\ntranslation evaluation. LiTransProQA uniquely integrates insights from\nprofessional literary translators and researchers, focusing on critical\nelements in literary quality assessment such as literary devices, cultural\nunderstanding, and authorial voice. Our extensive evaluation shows that while\nliterary-finetuned XCOMET-XL yields marginal gains, LiTransProQA substantially\noutperforms current metrics, achieving up to 0.07 gain in correlation (ACC-EQ\nand Kendall's tau) and surpassing the best state-of-the-art metrics by over 15\npoints in adequacy assessments. Incorporating professional translator insights\nas weights further improves performance, highlighting the value of translator\ninputs. Notably, LiTransProQA approaches human-level evaluation performance\ncomparable to trained linguistic annotators. It demonstrates broad\napplicability to open-source models such as LLaMA3.3-70b and Qwen2.5-32b,\nindicating its potential as an accessible and training-free literary evaluation\nmetric and a valuable tool for evaluating texts that require local processing\ndue to copyright or ethical considerations."}
{"id": "2406.06600", "pdf": "https://arxiv.org/pdf/2406.06600.pdf", "abs": "https://arxiv.org/abs/2406.06600", "title": "HORAE: A Domain-Agnostic Language for Automated Service Regulation", "authors": ["Yutao Sun", "Mingshuai Chen", "Tiancheng Zhao", "Kangjia Zhao", "He Li", "Jintao Chen", "Zhongyi Wang", "Liqiang Lu", "Xinkui Zhao", "Shuiguang Deng", "Jianwei Yin"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Full version of IJCAI 2025", "summary": "Artificial intelligence is rapidly encroaching on the field of service\nregulation. However, existing AI-based regulation techniques are often tailored\nto specific application domains and thus are difficult to generalize in an\nautomated manner. This paper presents Horae, a unified specification language\nfor modeling (multimodal) regulation rules across a diverse set of domains. We\nshowcase how Horae facilitates an intelligent service regulation pipeline by\nfurther exploiting a fine-tuned large language model named RuleGPT that\nautomates the Horae modeling process, thereby yielding an end-to-end framework\nfor fully automated intelligent service regulation. The feasibility and\neffectiveness of our framework are demonstrated over a benchmark of various\nreal-world regulation domains. In particular, we show that our open-sourced,\nfine-tuned RuleGPT with 7B parameters suffices to outperform GPT-3.5 and\nperform on par with GPT-4o."}
{"id": "2406.09831", "pdf": "https://arxiv.org/pdf/2406.09831.pdf", "abs": "https://arxiv.org/abs/2406.09831", "title": "Recent Advances in Federated Learning Driven Large Language Models: A Survey on Architecture, Performance, and Security", "authors": ["Youyang Qu", "Ming Liu", "Tianqing Zhu", "Longxiang Gao", "Shui Yu", "Wanlei Zhou"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "comment": null, "summary": "Federated Learning (FL) offers a promising paradigm for training Large\nLanguage Models (LLMs) in a decentralized manner while preserving data privacy\nand minimizing communication overhead. This survey examines recent advancements\nin FL-driven LLMs, with a particular emphasis on architectural designs,\nperformance optimization, and security concerns, including the emerging area of\nmachine unlearning. In this context, machine unlearning refers to the\nsystematic removal of specific data contributions from trained models to comply\nwith privacy regulations such as the Right to be Forgotten. We review a range\nof strategies enabling unlearning in federated LLMs, including\nperturbation-based methods, model decomposition, and incremental retraining,\nwhile evaluating their trade-offs in terms of efficiency, privacy guarantees,\nand model utility. Through selected case studies and empirical evaluations, we\nanalyze how these methods perform in practical FL scenarios. This survey\nidentifies critical research directions toward developing secure, adaptable,\nand high-performing federated LLM systems for real-world deployment."}
{"id": "2503.24289", "pdf": "https://arxiv.org/pdf/2503.24289.pdf", "abs": "https://arxiv.org/abs/2503.24289", "title": "Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning", "authors": ["Jiacheng Lin", "Tian Wang", "Kun Qian"], "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "We propose Rec-R1, a general reinforcement learning framework that bridges\nlarge language models (LLMs) with recommendation systems through closed-loop\noptimization. Unlike prompting and supervised fine-tuning (SFT), Rec-R1\ndirectly optimizes LLM generation using feedback from a fixed black-box\nrecommendation model, without relying on synthetic SFT data from proprietary\nmodels such as GPT-4o. This avoids the substantial cost and effort required for\ndata distillation. To verify the effectiveness of Rec-R1, we evaluate it on two\nrepresentative tasks: product search and sequential recommendation.\nExperimental results demonstrate that Rec-R1 not only consistently outperforms\nprompting- and SFT-based methods, but also achieves significant gains over\nstrong discriminative baselines, even when used with simple retrievers such as\nBM25. Moreover, Rec-R1 preserves the general-purpose capabilities of the LLM,\nunlike SFT, which often impairs instruction-following and reasoning. These\nfindings suggest Rec-R1 as a promising foundation for continual task-specific\nadaptation without catastrophic forgetting."}
{"id": "2505.02550", "pdf": "https://arxiv.org/pdf/2505.02550.pdf", "abs": "https://arxiv.org/abs/2505.02550", "title": "Bielik v3 Small: Technical Report", "authors": ["Krzysztof Ociepa", "Łukasz Flis", "Remigiusz Kinas", "Krzysztof Wróbel", "Adrian Gwoździej"], "categories": ["cs.LG", "cs.AI", "cs.CL", "68T50", "I.2.7"], "comment": null, "summary": "We introduce Bielik v3, a series of parameter-efficient generative text\nmodels (1.5B and 4.5B) optimized for Polish language processing. These models\ndemonstrate that smaller, well-optimized architectures can achieve performance\ncomparable to much larger counterparts while requiring substantially fewer\ncomputational resources. Our approach incorporates several key innovations: a\ncustom Polish tokenizer (APT4) that significantly improves token efficiency,\nWeighted Instruction Cross-Entropy Loss to balance learning across instruction\ntypes, and Adaptive Learning Rate that dynamically adjusts based on training\nprogress. Trained on a meticulously curated corpus of 292 billion tokens\nspanning 303 million documents, these models excel across multiple benchmarks,\nincluding the Open PL LLM Leaderboard, Complex Polish Text Understanding\nBenchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter\nmodel achieves results competitive with models 2-3 times its size, while the\n1.5B model delivers strong performance despite its extremely compact profile.\nThese advances establish new benchmarks for parameter-efficient language\nmodeling in less-represented languages, making high-quality Polish language AI\nmore accessible for resource-constrained applications."}
{"id": "2505.02835", "pdf": "https://arxiv.org/pdf/2505.02835.pdf", "abs": "https://arxiv.org/abs/2505.02835", "title": "R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning", "authors": ["Yi-Fan Zhang", "Xingyu Lu", "Xiao Hu", "Chaoyou Fu", "Bin Wen", "Tianke Zhang", "Changyi Liu", "Kaiyu Jiang", "Kaibing Chen", "Kaiyu Tang", "Haojie Ding", "Jiankang Chen", "Fan Yang", "Zhang Zhang", "Tingting Gao", "Liang Wang"], "categories": ["cs.CV", "cs.CL"], "comment": "Home page: https://github.com/yfzhang114/r1_reward", "summary": "Multimodal Reward Models (MRMs) play a crucial role in enhancing the\nperformance of Multimodal Large Language Models (MLLMs). While recent\nadvancements have primarily focused on improving the model structure and\ntraining data of MRMs, there has been limited exploration into the\neffectiveness of long-term reasoning capabilities for reward modeling and how\nto activate these capabilities in MRMs. In this paper, we explore how\nReinforcement Learning (RL) can be used to improve reward modeling.\nSpecifically, we reformulate the reward modeling problem as a rule-based RL\ntask. However, we observe that directly applying existing RL algorithms, such\nas Reinforce++, to reward modeling often leads to training instability or even\ncollapse due to the inherent limitations of these algorithms. To address this\nissue, we propose the StableReinforce algorithm, which refines the training\nloss, advantage estimation strategy, and reward design of existing RL methods.\nThese refinements result in more stable training dynamics and superior\nperformance. To facilitate MRM training, we collect 200K preference data from\ndiverse datasets. Our reward model, R1-Reward, trained using the\nStableReinforce algorithm on this dataset, significantly improves performance\non multimodal reward modeling benchmarks. Compared to previous SOTA models,\nR1-Reward achieves a $8.4\\%$ improvement on the VL Reward-Bench and a $14.3\\%$\nimprovement on the Multimodal Reward Bench. Moreover, with more inference\ncompute, R1-Reward's performance is further enhanced, highlighting the\npotential of RL algorithms in optimizing MRMs."}
{"id": "2505.03414", "pdf": "https://arxiv.org/pdf/2505.03414.pdf", "abs": "https://arxiv.org/abs/2505.03414", "title": "Enhancing Target-unspecific Tasks through a Features Matrix", "authors": ["Fangming Cui", "Yonggang Zhang", "Xuan Wang", "Xinmei Tian", "Jun Yu"], "categories": ["cs.CV", "cs.CL"], "comment": "ICML 2025", "summary": "Recent developments in prompt learning of large vision-language models have\nsignificantly improved performance in target-specific tasks. However, these\nprompt optimizing methods often struggle to tackle the target-unspecific or\ngeneralizable tasks effectively. It may be attributed to the fact that\noverfitting training causes the model to forget its general knowledge having\nstrong promotion on target-unspecific tasks. To alleviate this issue, we\npropose a novel Features Matrix (FM) regularization approach designed to\nenhance these models on target-unspecific tasks. Our method extracts and\nleverages general knowledge, shaping a Features Matrix (FM). Specifically, the\nFM captures the semantics of diverse inputs from a deep and fine perspective,\npreserving essential general knowledge, which mitigates the risk of\noverfitting. Representative evaluations demonstrate that: 1) the FM is\ncompatible with existing frameworks as a generic and flexible module, and 2)\nthe FM significantly showcases its effectiveness in enhancing target-unspecific\ntasks, achieving state-of-the-art performance."}
{"id": "2505.04457", "pdf": "https://arxiv.org/pdf/2505.04457.pdf", "abs": "https://arxiv.org/abs/2505.04457", "title": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration", "authors": ["Shigeki Karita", "Yuma Koizumi", "Heiga Zen", "Haruko Ishikawa", "Robin Scheibler", "Michiel Bacchiani"], "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Training data cleaning is a new application for generative model-based speech\nrestoration (SR). This paper introduces Miipher-2, an SR model designed for\nmillion-hour scale data, for training data cleaning for large-scale generative\nmodels like large language models. Key challenges addressed include\ngeneralization to unseen languages, operation without explicit conditioning\n(e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a\nfrozen, pre-trained Universal Speech Model (USM), supporting over 300\nlanguages, as a robust, conditioning-free feature extractor. To optimize\nefficiency and minimize memory, Miipher-2 incorporates parallel adapters for\npredicting clean USM features from noisy inputs and employs the WaveFit neural\nvocoder for waveform synthesis. These components were trained on 3,000 hours of\nmulti-lingual, studio-quality recordings with augmented degradations, while USM\nparameters remained fixed. Experimental results demonstrate Miipher-2's\nsuperior or comparable performance to conventional SR models in\nword-error-rate, speaker similarity, and both objective and subjective sound\nquality scores across all tested languages. Miipher-2 operates efficiently on\nconsumer-grade accelerators, achieving a real-time factor of 0.0078, enabling\nthe processing of a million-hour speech dataset in approximately three days\nusing only 100 such accelerators."}
