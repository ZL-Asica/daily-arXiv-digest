{"id": "2504.21240", "pdf": "https://arxiv.org/pdf/2504.21240.pdf", "abs": "https://arxiv.org/abs/2504.21240", "title": "Countering underproduction of peer produced goods", "authors": ["Kaylea Champion", "Benjamin Mako Hill"], "categories": ["cs.HC"], "comment": "New Media & Society, 2024", "summary": "Peer produced goods such as online knowledge bases and free/libre open source\nsoftware rely on contributors who often choose their tasks regardless of\nconsumer needs. These goods are susceptible to underproduction: when popular\ngoods are relatively low quality. Although underproduction is a common feature\nof peer production, very little is known about how to counteract it. We use a\ndetailed longitudinal dataset from English Wikipedia to show that more\nexperienced contributors -- including those who contribute without an account\n-- tend to contribute to underproduced goods. A within-person analysis shows\nthat contributors' efforts shift toward underproduced goods over time. These\nfindings illustrate the value of retaining contributors in peer production,\nincluding those contributing without accounts, as a means to counter\nunderproduction.", "AI": {"tldr": "This paper examines how experienced contributors in peer production, particularly in Wikipedia, tend to contribute to underproduced goods and highlights the importance of retaining these contributors to counteract underproduction.", "motivation": "To understand the phenomenon of underproduction in peer-produced goods and explore ways to mitigate it.", "method": "Utilized a longitudinal dataset from English Wikipedia to analyze contributor behavior over time, particularly focusing on experienced contributors and their contributions to underproduced goods.", "result": "Findings indicate that more experienced contributors are inclined to focus their efforts on underproduced goods, demonstrating a shift in their contributions over time.", "conclusion": "Retaining experienced contributors, including those without accounts, is essential for addressing underproduction in peer production environments.", "key_contributions": ["Identifies the tendency of experienced contributors to engage with underproduced goods.", "Highlights the evolution of contributors' efforts towards underproduction over time.", "Emphasizes the significance of contributor retention in mitigating underproduction."], "limitations": "The study focuses specifically on Wikipedia, which may limit the generalizability of the findings to other peer production platforms.", "future_work": "Investigating strategies for improving the quality of contributions to underproduced goods and understanding the engagement of new contributors.", "keywords": ["peer production", "underproduction", "Wikipedia", "contributor behavior", "experienced contributors"], "importance_score": 4, "read_time_minutes": 8}}
{"id": "2504.21242", "pdf": "https://arxiv.org/pdf/2504.21242.pdf", "abs": "https://arxiv.org/abs/2504.21242", "title": "Passive Measurement of Autonomic Arousal in Real-World Settings", "authors": ["Samy Abdel-Ghaffar", "Isaac Galatzer-Levy", "Conor Heneghan", "Xin Liu", "Sarah Kernasovskiy", "Brennan Garrett", "Andrew Barakat", "Daniel McDuff"], "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "The autonomic nervous system (ANS) is activated during stress, which can have\nnegative effects on cardiovascular health, sleep, the immune system, and mental\nhealth. While there are ways to quantify ANS activity in laboratories, there is\na paucity of methods that have been validated in real-world contexts. We\npresent the Fitbit Body Response Algorithm, an approach to continuous remote\nmeasurement of ANS activation through widely available remote wrist-based\nsensors. The design was validated via two experiments, a Trier Social Stress\nTest (n = 45) and ecological momentary assessments (EMA) of perceived stress\n(n=87), providing both controlled and ecologically valid test data. Model\nperformance predicting perceived stress when using all available sensor\nmodalities was consistent with expectations (accuracy=0.85) and outperformed\nmodels with access to only a subset of the signals. We discuss and address\nchallenges to sensing that arise in real world settings that do not present in\nconventional lab environments.", "AI": {"tldr": "The paper presents the Fitbit Body Response Algorithm for continuous remote measurement of autonomic nervous system (ANS) activation using wrist-based sensors, validated through stress tests and assessments.", "motivation": "To address the lack of validated methods for measuring ANS activity in real-world contexts, which is important for understanding stress effects on health.", "method": "The Fitbit Body Response Algorithm was validated through two experiments: a Trier Social Stress Test and ecological momentary assessments, analyzing data from 132 participants.", "result": "The model achieved an accuracy of 0.85 in predicting perceived stress when using all available sensor modalities, outperforming models with limited signal access.", "conclusion": "The study demonstrates the feasibility of using wrist-based sensors for effective monitoring of ANS activity in everyday environments, while discussing real-world sensing challenges.", "key_contributions": ["Introduction of the Fitbit Body Response Algorithm for measuring ANS activation remotely.", "Validation via real-world experiments demonstrating high model accuracy.", "Discussion on challenges faced when sensing in non-laboratory settings."], "limitations": "The study may be limited by the specific populations tested and the contexts in which stress was measured.", "future_work": "Future research could explore additional sensor modalities and apply the algorithm across diverse populations and stress-inducing scenarios.", "keywords": ["autonomic nervous system", "stress measurement", "Fitbit Body Response Algorithm", "real-world validation", "health monitoring"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2504.21332", "pdf": "https://arxiv.org/pdf/2504.21332.pdf", "abs": "https://arxiv.org/abs/2504.21332", "title": "MagicCraft: Natural Language-Driven Generation of Dynamic and Interactive 3D Objects for Commercial Metaverse Platforms", "authors": ["Ryutaro Kurai", "Takefumi Hiraki", "Yuichi Hiroi", "Yutaro Hirao", "Monica Perusquía-Hernández", "Hideaki Uchiyama", "Kiyoshi Kiyokawa"], "categories": ["cs.HC"], "comment": "16 pages. Preprint for submission to IEEE Access", "summary": "Metaverse platforms are rapidly evolving to provide immersive spaces for user\ninteraction and content creation. However, the generation of dynamic and\ninteractive 3D objects remains challenging due to the need for advanced 3D\nmodeling and programming skills. To address this challenge, we present\nMagicCraft, a system that generates functional 3D objects from natural language\nprompts for metaverse platforms. MagicCraft uses generative AI models to manage\nthe entire content creation pipeline: converting user text descriptions into\nimages, transforming images into 3D models, predicting object behavior, and\nassigning necessary attributes and scripts. It also provides an interactive\ninterface for users to refine generated objects by adjusting features such as\norientation, scale, seating positions, and grip points.\n  Implemented on Cluster, a commercial metaverse platform, MagicCraft was\nevaluated by 7 expert CG designers and 51 general users. Results show that\nMagicCraft significantly reduces the time and skill required to create 3D\nobjects. Users with no prior experience in 3D modeling or programming\nsuccessfully created complex, interactive objects and deployed them in the\nmetaverse. Expert feedback highlighted the system's potential to improve\ncontent creation workflows and support rapid prototyping. By integrating\nAI-generated content into metaverse platforms, MagicCraft makes 3D content\ncreation more accessible.", "AI": {"tldr": "MagicCraft enables users to generate 3D objects from natural language prompts, simplifying 3D content creation for metaverse platforms.", "motivation": "To address the challenge of creating dynamic and interactive 3D objects without requiring advanced modeling and programming skills.", "method": "MagicCraft uses generative AI models to convert text descriptions into images, which are then transformed into 3D models, while also predicting object behavior and assigning attributes and scripts. It includes an interface for users to refine the generated objects.", "result": "Users with no prior experience successfully created complex, interactive objects, significantly reducing the time and skill required for 3D model creation. Evaluations by experts highlighted improvements in content creation workflows.", "conclusion": "MagicCraft enhances accessibility in 3D content creation on metaverse platforms, allowing broader participation in the design process.", "key_contributions": ["Development of MagicCraft system for generating 3D objects from natural language prompts.", "Significant reduction in the skill threshold for 3D content creation.", "Positive feedback from both expert designers and novice users on the system's usability."], "limitations": "", "future_work": "", "keywords": ["3D modeling", "metaverse", "generative AI", "user interface", "content creation"], "importance_score": 6, "read_time_minutes": 16}}
{"id": "2504.21337", "pdf": "https://arxiv.org/pdf/2504.21337.pdf", "abs": "https://arxiv.org/abs/2504.21337", "title": "Cross-Reality Lifestyle: Integrating Physical and Virtual Lives through Multi-Platform Metaverse", "authors": ["Yuichi Hiroi", "Yuji Hatada", "Takefumi Hiraki"], "categories": ["cs.HC"], "comment": "9 pages, preprint for submission to IEEE Pervasive Computing Special\n  Issue", "summary": "Technological advances are redefining the relationship between physical and\nvirtual space. Traditionally, when users engage in virtual reality (VR), they\nare completely cut off from the physical space; similarly, they are unable to\naccess virtual experiences while engaged in physical activities. However,\nmodern multi-platform metaverse environments allow simultaneous participation\nthrough mobile devices, creating new opportunities for integrated experiences.\nThis study introduces the concept of \"cross-reality lifestyles\" to examine how\nusers actively combine their physical and virtual activities. We identify three\npatterns of integration: 1) amplification: one space enhances experiences in\nthe other; 2) complementary: spaces offer different but equally valuable\nalternatives; and 3) emergence: simultaneous engagement creates entirely new\nexperiences. By analyzing commercial platforms, we create a technical framework\nthat addresses content design, platform infrastructure, and device interfaces.\nThis framework guides the development of cross-reality applications while\ndemonstrating how metaverse technologies blur the traditional boundaries\nbetween physical and virtual experiences.", "AI": {"tldr": "The paper explores the integration of physical and virtual activities in cross-reality environments, proposing a framework for developing applications that enhance user experiences using metaverse technologies.", "motivation": "The study investigates how technology is reshaping the interaction between physical and virtual spaces, particularly in the context of modern multi-platform metaverse environments.", "method": "The paper introduces the concept of 'cross-reality lifestyles' and identifies three patterns of integration: amplification, complementary, and emergence. A technical framework for content design, platform infrastructure, and device interfaces is proposed based on analysis of commercial platforms.", "result": "The analysis demonstrates how users combine physical and virtual activities, providing insights into user engagement in cross-reality environments.", "conclusion": "The proposed framework can guide the development of applications that leverage cross-reality experiences, highlighting the importance of integrated design in metaverse technologies.", "key_contributions": ["Introduction of the concept of 'cross-reality lifestyles'.", "Identification of three patterns of integration for physical and virtual activities.", "Development of a technical framework for creating cross-reality applications."], "limitations": "", "future_work": "Further exploration of user engagement metrics and long-term impacts of cross-reality lifestyles on society is needed.", "keywords": ["cross-reality lifestyles", "metaverse", "virtual reality", "physical activities", "user experience"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2504.21012", "pdf": "https://arxiv.org/pdf/2504.21012.pdf", "abs": "https://arxiv.org/abs/2504.21012", "title": "Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models", "authors": ["Makoto Sato"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "What underlies intuitive human thinking? One approach to this question is to\ncompare the cognitive dynamics of humans and large language models (LLMs).\nHowever, such a comparison requires a method to quantitatively analyze AI\ncognitive behavior under controlled conditions. While anecdotal observations\nsuggest that certain prompts can dramatically change LLM behavior, these\nobservations have remained largely qualitative. Here, we propose a two-part\nframework to investigate this phenomenon: a Transition-Inducing Prompt (TIP)\nthat triggers a rapid shift in LLM responsiveness, and a Transition Quantifying\nPrompt (TQP) that evaluates this change using a separate LLM. Through\ncontrolled experiments, we examined how LLMs react to prompts embedding two\nsemantically distant concepts (e.g., mathematical aperiodicity and traditional\ncrafts)--either fused together or presented separately--by changing their\nlinguistic quality and affective tone. Whereas humans tend to experience\nheightened engagement when such concepts are meaningfully blended producing a\nnovel concept--a form of conceptual fusion--current LLMs showed no significant\ndifference in responsiveness between semantically fused and non-fused prompts.\nThis suggests that LLMs may not yet replicate the conceptual integration\nprocesses seen in human intuition. Our method enables fine-grained,\nreproducible measurement of cognitive responsiveness, and may help illuminate\nkey differences in how intuition and conceptual leaps emerge in artificial\nversus human minds.", "AI": {"tldr": "This paper proposes a method to quantitatively analyze cognitive dynamics of humans and LLMs by comparing their responses to prompts that fuse or separate semantically distant concepts.", "motivation": "To understand the underlying cognitive dynamics of intuitive human thinking compared to large language models (LLMs).", "method": "A two-part framework consisting of Transition-Inducing Prompts (TIP) to trigger changes in LLM responsiveness, and Transition Quantifying Prompts (TQP) to evaluate these changes using a separate LLM in controlled experiments.", "result": "Current LLMs showed no significant difference in responsiveness to semantically fused versus non-fused prompts, indicating a gap in replicating human conceptual integration processes.", "conclusion": "The method allows for reproducible measurement of cognitive responsiveness, highlighting differences in intuition and conceptual leaps between humans and LLMs.", "key_contributions": ["Introduction of TIP and TQP for measuring LLM responsiveness", "Findings suggest LLMs lack the ability to integrate concepts as humans do", "Provides insights into cognitive differences between human and AI thinking"], "limitations": "The study may not capture the full range of human cognitive processes due to the controlled experimental design.", "future_work": "Further exploration of LLMs' capabilities in conceptual integration and human-like intuition.", "keywords": ["cognitive dynamics", "human intuition", "large language models", "conceptual fusion", "AI responsiveness"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2504.21360", "pdf": "https://arxiv.org/pdf/2504.21360.pdf", "abs": "https://arxiv.org/abs/2504.21360", "title": "ImaginateAR: AI-Assisted In-Situ Authoring in Augmented Reality", "authors": ["Jaewook Lee", "Filippo Aleotti", "Diego Mazala", "Guillermo Garcia-Hernando", "Sara Vicente", "Oliver James Johnston", "Isabel Kraus-Liang", "Jakub Powierza", "Donghoon Shin", "Jon E. Froehlich", "Gabriel Brostow", "Jessica Van Brummelen"], "categories": ["cs.HC"], "comment": null, "summary": "While augmented reality (AR) enables new ways to play, tell stories, and\nexplore ideas rooted in the physical world, authoring personalized AR content\nremains difficult for non-experts, often requiring professional tools and time.\nPrior systems have explored AI-driven XR design but typically rely on\nmanually-defined environments and fixed asset libraries, limiting creative\nflexibility and real-world relevance. We introduce ImaginateAR, a mobile\nAI-assisted AR authoring system that aims to let anyone build anything,\nanywhere -- simply by speaking their imagination. ImaginateAR is powered by\ncustom pipelines for offline scene understanding, fast 3D asset generation, and\nLLM-driven speech interaction. Users might say \"a dragon enjoying a campfire\"\n(P7) and iteratively refine the scene using both AI and manual tools. Our\ntechnical evaluation shows that ImaginateAR produces more accurate outdoor\nscene graphs and generates 3D meshes faster than prior methods. A three-part\nuser study (N=20) revealed preferred roles for AI in authoring, what and how\nusers create in free-form use, and design implications for future AR authoring\ntools.", "AI": {"tldr": "ImaginateAR is an AI-assisted AR authoring system that allows users to create personalized AR content simply through voice commands, enhancing creative flexibility.", "motivation": "To address the difficulty non-experts face in authoring personalized AR content, which traditionally requires specialized knowledge and tools.", "method": "ImaginateAR employs custom pipelines for offline scene understanding and fast 3D asset generation, combined with LLM-driven speech interaction, enabling users to create scenes by describing them verbally.", "result": "ImaginateAR produces more accurate outdoor scene graphs and generates 3D meshes faster than previous methods, demonstrating its enhanced capabilities for AR content creation.", "conclusion": "The findings suggest preferred roles for AI in creativity and provide insights for future AR authoring tools based on user interactions and preferences.", "key_contributions": ["Introduction of an AI-driven AR authoring tool that emphasizes voice interaction and user creativity.", "Technical improvements over prior methods in scene understanding and asset generation.", "User study reveals insights on user preferences and design implications for future AR tools."], "limitations": "The study was limited to a small sample size (N=20) and focused on outdoor scenes, which may not generalize to all AR environments.", "future_work": "Exploration of how AI can support more diverse AR authoring tasks and investigation of user interactions in various contexts.", "keywords": ["augmented reality", "AI-assisted authoring", "3D asset generation", "human-computer interaction", "user study"], "importance_score": 8, "read_time_minutes": 5}}
{"id": "2504.21013", "pdf": "https://arxiv.org/pdf/2504.21013.pdf", "abs": "https://arxiv.org/abs/2504.21013", "title": "Analyzing Feedback Mechanisms in AI-Generated MCQs: Insights into Readability, Lexical Properties, and Levels of Challenge", "authors": ["Antoun Yaacoub", "Zainab Assaghir", "Lionel Prevost", "Jérôme Da-Rugna"], "categories": ["cs.CL", "cs.AI"], "comment": "This paper will be presented in the 9th Int. Conf. on Computer,\n  Software and Modeling (ICCSM 2025), Roma, Italy, 2025, July 3-5", "summary": "Artificial Intelligence (AI)-generated feedback in educational settings has\ngarnered considerable attention due to its potential to enhance learning\noutcomes. However, a comprehensive understanding of the linguistic\ncharacteristics of AI-generated feedback, including readability, lexical\nrichness, and adaptability across varying challenge levels, remains limited.\nThis study delves into the linguistic and structural attributes of feedback\ngenerated by Google's Gemini 1.5-flash text model for computer science\nmultiple-choice questions (MCQs). A dataset of over 1,200 MCQs was analyzed,\nconsidering three difficulty levels (easy, medium, hard) and three feedback\ntones (supportive, neutral, challenging). Key linguistic metrics, such as\nlength, readability scores (Flesch-Kincaid Grade Level), vocabulary richness,\nand lexical density, were computed and examined. A fine-tuned RoBERTa-based\nmulti-task learning (MTL) model was trained to predict these linguistic\nproperties, achieving a Mean Absolute Error (MAE) of 2.0 for readability and\n0.03 for vocabulary richness. The findings reveal significant interaction\neffects between feedback tone and question difficulty, demonstrating the\ndynamic adaptation of AI-generated feedback within diverse educational\ncontexts. These insights contribute to the development of more personalized and\neffective AI-driven feedback mechanisms, highlighting the potential for\nimproved learning outcomes while underscoring the importance of ethical\nconsiderations in their design and deployment.", "AI": {"tldr": "Study analyzes the linguistic characteristics of AI-generated feedback for computer science MCQs using Google's Gemini model, revealing its adaptability and potential for personalized learning.", "motivation": "To understand the linguistic characteristics of AI-generated feedback in educational settings and its impact on learning outcomes.", "method": "Analyzed a dataset of over 1,200 computer science multiple-choice questions (MCQs) across three difficulty levels and tones, employing a fine-tuned RoBERTa-based model to predict linguistic properties.", "result": "Achieved a Mean Absolute Error of 2.0 for readability and 0.03 for vocabulary richness, with significant interaction effects between feedback tone and question difficulty.", "conclusion": "AI-generated feedback can dynamically adapt to various educational contexts, improving learning outcomes while necessitating ethical considerations in design and deployment.", "key_contributions": ["Comprehensive analysis of linguistic characteristics of AI-generated feedback.", "Development of a RoBERTa-based model for predicting feedback attributes.", "Insights into the interaction between feedback tone and question difficulty."], "limitations": "Focus on a specific AI model and educational context may limit generalizability.", "future_work": "Further exploration of AI feedback mechanisms across different subjects and educational levels.", "keywords": ["AI-generated feedback", "linguistic characteristics", "educational technology"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2504.21397", "pdf": "https://arxiv.org/pdf/2504.21397.pdf", "abs": "https://arxiv.org/abs/2504.21397", "title": "Coping with Uncertainty in UX Design Practice: Practitioner Strategies and Judgment", "authors": ["Prakash Shukla", "Phuong Bui", "Paul Parsons"], "categories": ["cs.HC"], "comment": "11 pages, In Creativity and Cognition (C&C '25), June 23--25, 2025,\n  Virtual, United Kingdom", "summary": "The complexity of UX design practice extends beyond ill-structured design\nproblems to include uncertainties shaped by shifting stakeholder priorities,\nteam dynamics, limited resources, and implementation constraints. While prior\nresearch in related fields has addressed uncertainty in design more broadly,\nthe specific character of uncertainty in UX practice remains underexplored.\nThis study examines how UX practitioners experience and respond to uncertainty\nin real-world projects, drawing on a multi-week diary study and follow-up\ninterviews with ten designers. We identify a range of practitioner\nstrategies-including adaptive framing, negotiation, and judgment-that allow\ndesigners to move forward amid ambiguity. Our findings highlight the central\nrole of design judgment in navigating uncertainty, including emergent forms\nsuch as temporal and sacrificial judgment, and extend prior understandings by\nshowing how UX practitioners engage uncertainty as a persistent, situated\nfeature of practice.", "AI": {"tldr": "This study investigates how UX practitioners navigate uncertainty in design through a diary study and interviews, identifying strategies such as adaptive framing and negotiation.", "motivation": "To explore the specific character of uncertainty in UX design practice, which has been underexplored compared to related fields.", "method": "Multi-week diary study and follow-up interviews with ten UX designers.", "result": "The study identifies various strategies used by designers, including adaptive framing and negotiation, to handle uncertainty in their projects.", "conclusion": "UX practitioners engage with uncertainty as a persistent and situated feature of their practice, highlighting the importance of design judgment.", "key_contributions": ["Identifies specific strategies employed by UX practitioners to deal with uncertainty", "Introduces concepts of temporal and sacrificial judgment in design", "Sheds light on the situated nature of uncertainty in UX design practice"], "limitations": "", "future_work": "Further research could explore the implications of these findings for design education and practice in different contexts.", "keywords": ["UX design", "uncertainty", "design judgment", "adaptive strategies", "stakeholder dynamics"], "importance_score": 6, "read_time_minutes": 11}}
{"id": "2504.21016", "pdf": "https://arxiv.org/pdf/2504.21016.pdf", "abs": "https://arxiv.org/abs/2504.21016", "title": "Nested Named-Entity Recognition on Vietnamese COVID-19: Dataset and Experiments", "authors": ["Ngoc C. Lê", "Hai-Chung Nguyen-Phung", "Thu-Huong Pham Thi", "Hue Vu", "Phuong-Thao Nguyen Thi", "Thu-Thuy Tran", "Hong-Nhung Le Thi", "Thuy-Duong Nguyen-Thi", "Thanh-Huy Nguyen"], "categories": ["cs.CL", "cs.LG"], "comment": "8 pages. AI4SG-21 The 3rd Workshop on Artificial Intelligence for\n  Social Good at IJCAI 2021", "summary": "The COVID-19 pandemic caused great losses worldwide, efforts are taken place\nto prevent but many countries have failed. In Vietnam, the traceability,\nlocalization, and quarantine of people who contact with patients contribute to\neffective disease prevention. However, this is done by hand, and take a lot of\nwork. In this research, we describe a named-entity recognition (NER) study that\nassists in the prevention of COVID-19 pandemic in Vietnam. We also present our\nmanually annotated COVID-19 dataset with nested named entity recognition task\nfor Vietnamese which be defined new entity types using for our system.", "AI": {"tldr": "The paper discusses a named-entity recognition (NER) study aimed at improving COVID-19 prevention efforts in Vietnam by automating the process of tracing and localizing individuals in contact with confirmed cases.", "motivation": "To enhance the effectiveness of COVID-19 prevention efforts in Vietnam through automated traceability and localization of individuals in contact with infected patients, which are currently done manually.", "method": "The study involves the creation of a manually annotated COVID-19 dataset for Vietnamese, which includes a nested named entity recognition task to define new entity types for the system.", "result": "The study provides insights into challenges faced during the manual tracing process and demonstrates the applicability of NER in automating tasks to aid disease prevention.", "conclusion": "Automating the traceability and localization process can significantly reduce the workload and improve efficiency in managing COVID-19 prevention efforts in Vietnam.", "key_contributions": ["Development of a new dataset for NER specific to COVID-19 in Vietnamese language.", "Introduction of new entity types for improved task definition in NER applications.", "Demonstration of NER's potential in enhancing disease prevention strategies."], "limitations": "The study is focused on a specific geographical area (Vietnam) and may need adaptation for other regions; challenges in dataset annotation and system training may impact generalizability.", "future_work": "Future research could explore the scalability of the NER system to other languages and regions, as well as the integration of additional AI techniques to enhance prediction accuracy.", "keywords": ["COVID-19", "Vietnam", "named-entity recognition", "public health", "AI for social good"], "importance_score": 5, "read_time_minutes": 10}}
{"id": "2504.21477", "pdf": "https://arxiv.org/pdf/2504.21477.pdf", "abs": "https://arxiv.org/abs/2504.21477", "title": "A Comprehensive Survey of Electrical Stimulation Haptic Feedback in Human-Computer Interaction", "authors": ["Simin Yang", "Xian Wang", "Yang Li", "Lik-Hang Lee", "Tristan Camille", "Pan Hui"], "categories": ["cs.HC"], "comment": "23 pages, 7 figures", "summary": "Haptic perception and feedback play a pivotal role in interactive\nexperiences, forming an essential component of human-computer interaction\n(HCI). In recent years, the field of haptic interaction has witnessed\nsignificant advancements, particularly in the area of electrical haptic\nfeedback, driving innovation across various domains. To gain a comprehensive\nunderstanding of the current state of research and the latest developments in\nelectrical haptic interaction, this study systematically reviews the literature\nin this area. Our investigation covers key aspects including haptic devices,\nhaptic perception mechanisms, the comparison and integration of electrical\nhaptic feedback with other feedback modalities, and their diverse applications.\nSpecifically, we conduct a systematic analysis of 110 research papers to\nexplore the forefront of electrical haptic feedback, providing insights into\nits latest trends, challenges, and future directions.", "AI": {"tldr": "This paper reviews advancements in electrical haptic feedback within HCI, analyzing 110 research papers to explore trends, challenges, and applications.", "motivation": "To provide a comprehensive understanding of the current state of research in electrical haptic interaction and its applications in HCI.", "method": "A systematic literature review of 110 research papers focusing on haptic devices, perception mechanisms, and feedback modalities.", "result": "The study highlights significant trends and challenges in electrical haptic feedback and identifies the integration of haptic modalities as an emerging area of exploration.", "conclusion": "The findings emphasize the critical role of electrical haptic feedback in enhancing interactive experiences and suggest directions for future research.", "key_contributions": ["Systematic analysis of 110 research papers", "Insights into current trends and challenges in electrical haptic feedback", "Identification of integration opportunities with other feedback modalities"], "limitations": "", "future_work": "Future directions include exploring the integration of electrical haptic feedback with other sensory modalities and addressing existing challenges in the field.", "keywords": ["Haptic Feedback", "Human-Computer Interaction", "Electrical Haptics", "Systematic Review", "Feedback Modalities"], "importance_score": 8, "read_time_minutes": 20}}
{"id": "2504.21017", "pdf": "https://arxiv.org/pdf/2504.21017.pdf", "abs": "https://arxiv.org/abs/2504.21017", "title": "ViQA-COVID: COVID-19 Machine Reading Comprehension Dataset for Vietnamese", "authors": ["Hai-Chung Nguyen-Phung", "Ngoc C. Lê", "Van-Chien Nguyen", "Hang Thi Nguyen", "Thuy Phuong Thi Nguyen"], "categories": ["cs.CL", "cs.LG"], "comment": "8 pages. Technical report", "summary": "After two years of appearance, COVID-19 has negatively affected people and\nnormal life around the world. As in May 2022, there are more than 522 million\ncases and six million deaths worldwide (including nearly ten million cases and\nover forty-three thousand deaths in Vietnam). Economy and society are both\nseverely affected. The variant of COVID-19, Omicron, has broken disease\nprevention measures of countries and rapidly increased number of infections.\nResources overloading in treatment and epidemics prevention is happening all\nover the world. It can be seen that, application of artificial intelligence\n(AI) to support people at this time is extremely necessary. There have been\nmany studies applying AI to prevent COVID-19 which are extremely useful, and\nstudies on machine reading comprehension (MRC) are also in it. Realizing that,\nwe created the first MRC dataset about COVID-19 for Vietnamese: ViQA-COVID and\ncan be used to build models and systems, contributing to disease prevention.\nBesides, ViQA-COVID is also the first multi-span extraction MRC dataset for\nVietnamese, we hope that it can contribute to promoting MRC studies in\nVietnamese and multilingual.", "AI": {"tldr": "The paper introduces ViQA-COVID, the first machine reading comprehension (MRC) dataset focused on COVID-19 for the Vietnamese language, aiming to aid disease prevention through AI.", "motivation": "The COVID-19 pandemic has caused widespread disruption and increased the need for AI applications to support health measures.", "method": "The authors developed the ViQA-COVID dataset tailored for Vietnamese to facilitate machine reading comprehension in the context of COVID-19.", "result": "ViQA-COVID provides vital resources for building models and systems that can enhance understanding and response to COVID-19 related queries in Vietnamese.", "conclusion": "The dataset is expected to contribute significantly to machine reading comprehension research in Vietnamese, promoting multilingual AI applications.", "key_contributions": ["Introduction of the ViQA-COVID dataset for Vietnamese", "First multi-span extraction MRC dataset for Vietnamese", "Contributes to better AI applications in health informatics during pandemics."], "limitations": "", "future_work": "Encouraging further research on MRC with Vietnamese and expanding the dataset for broader applications.", "keywords": ["COVID-19", "machine reading comprehension", "Vietnamese", "artificial intelligence", "dataset"], "importance_score": 8, "read_time_minutes": 8}}
{"id": "2504.21563", "pdf": "https://arxiv.org/pdf/2504.21563.pdf", "abs": "https://arxiv.org/abs/2504.21563", "title": "A User-Centered Teleoperation GUI for Automated Vehicles: Identifying and Evaluating Information Requirements for Remote Driving and Assistance", "authors": ["Maria-Magdalena Wolf", "Henrik Schmidt", "Michael Christl", "Jana Fank", "Frank Diermeyer"], "categories": ["cs.HC"], "comment": null, "summary": "Teleoperation emerged as a promising fallback for situations beyond the\ncapabilities of automated vehicles. Nevertheless, teleoperation still faces\nchallenges, such as reduced situational awareness. Since situational awareness\nis primarily built through the remote operator's visual perception, the\nGraphical User Interface (GUI) design is critical. In addition to video feeds,\nsupplemental informational elements are crucial - not only for the\npredominantly studied Remote Driving but also for the arising desk-based Remote\nAssistance concepts. This work develops a GUI for different teleoperation\nconcepts by identifying key informational elements during the teleoperation\nprocess through expert interviews (N = 9). Following this, a static and dynamic\nGUI prototype is developed and evaluated in a click-dummy study (N = 36).\nThereby, the dynamic GUI adapts the number of displayed elements according to\nthe teleoperation phase. Results show that both GUIs achieve good System\nUsability Scale (SUS) ratings, with the dynamic GUI significantly outperforming\nthe static version in both usability and task completion time. The User\nExperience Questionnaire (UEQ) score shows potential for improvement. To\nenhance the user experience, the GUI should be evaluated in a follow-up study\nthat includes interaction with a real vehicle.", "AI": {"tldr": "This paper discusses the development and evaluation of a GUI for teleoperation, emphasizing situational awareness through visual perception and informational elements. A dynamic GUI prototype outperforms a static version in usability and task completion time.", "motivation": "Teleoperation serves as a fallback for automated vehicles but faces challenges related to situational awareness, necessitating effective GUI design to enhance operator perception.", "method": "The study involved expert interviews (N = 9) to identify key informational elements for teleoperation, followed by the development of a static and dynamic GUI prototype. A click-dummy study was conducted with participants (N = 36) to evaluate both GUI versions.", "result": "The dynamic GUI significantly outperformed the static version in terms of usability and task completion time, achieving good System Usability Scale ratings. However, the User Experience Questionnaire score indicated room for improvement.", "conclusion": "The study highlights the importance of GUI design in teleoperation and suggests future evaluation of the GUI with real vehicle interaction to enhance user experience further.", "key_contributions": ["Identification of key informational elements for teleoperation GUIs through expert interviews.", "Development of both static and dynamic GUI prototypes for teleoperation.", "Evaluation showing superior performance of dynamic GUIs in usability tests."], "limitations": "The study does not evaluate the GUI in a real vehicle context, limiting the understanding of its practical applicability.", "future_work": "Future research should focus on evaluating the GUI in conjunction with actual vehicle teleoperation.", "keywords": ["Teleoperation", "Graphical User Interface", "Situational Awareness", "User Experience", "Usability"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2504.21018", "pdf": "https://arxiv.org/pdf/2504.21018.pdf", "abs": "https://arxiv.org/abs/2504.21018", "title": "HYPEROFA: Expanding LLM Vocabulary to New Languages via Hypernetwork-Based Embedding Initialization", "authors": ["Enes Özeren", "Yihong Liu", "Hinrich Schütze"], "categories": ["cs.CL", "cs.LG"], "comment": "18 pages, 3 figures, 15 tables", "summary": "Many pre-trained language models (PLMs) exhibit suboptimal performance on\nmid- and low-resource languages, largely due to limited exposure to these\nlanguages during pre-training. A common strategy to address this is to\nintroduce new tokens specific to the target languages, initialize their\nembeddings, and apply continual pre-training on target-language data. Among\nsuch methods, OFA (Liu et al., 2024a) proposes a similarity-based subword\nembedding initialization heuristic that is both effective and efficient.\nHowever, OFA restricts target-language token embeddings to be convex\ncombinations of a fixed number of source-language embeddings, which may limit\nexpressiveness. To overcome this limitation, we propose HYPEROFA, a\nhypernetwork-based approach for more adaptive token embedding initialization.\nThe hypernetwork is trained to map from an external multilingual word vector\nspace to the PLMs token embedding space using source-language tokens. Once\ntrained, it can generate flexible embeddings for target-language tokens,\nserving as a good starting point for continual pretraining. Experiments\ndemonstrate that HYPEROFA consistently outperforms random initialization\nbaseline and matches or exceeds the performance of OFA in both continual\npre-training convergence and downstream task performance. We make the code\npublicly available.", "AI": {"tldr": "HYPEROFA enhances token embedding initialization for mid- and low-resource languages by utilizing a hypernetwork, improving performance over traditional methods.", "motivation": "Address suboptimal performance of pre-trained language models on mid- and low-resource languages due to limited exposure during pre-training.", "method": "HYPEROFA uses a hypernetwork to map from a multilingual word vector space to the token embedding space, allowing for flexible token embeddings for target languages.", "result": "HYPEROFA outperforms random initialization and matches or exceeds the performance of the state-of-the-art approach, OFA, in both continual pre-training and downstream tasks.", "conclusion": "The hypernetwork-based initialization provides a more expressive and adaptive solution for embedding target-language tokens, enhancing performance.", "key_contributions": ["Introduction of HYPEROFA for adaptive token embedding initialization.", "Comparison with OFA showing superior performance in specific contexts.", "Public availability of code for broader use in the community."], "limitations": "The method's performance may still vary based on the specific characteristics of the languages involved.", "future_work": "Exploring further enhancements and applications of hypernetwork-based approaches in diverse linguistic contexts.", "keywords": ["pre-trained language models", "hypernetwork", "natural language processing", "multi-language", "continual pre-training"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2504.21702", "pdf": "https://arxiv.org/pdf/2504.21702.pdf", "abs": "https://arxiv.org/abs/2504.21702", "title": "A Conversational Approach to Well-being Awareness Creation and Behavioural Intention", "authors": ["Antonia Azzini", "Ilaria Baroni", "Irene Celino"], "categories": ["cs.HC"], "comment": null, "summary": "The promotion of a healthy lifestyle is one of the main drivers of an\nindividual's overall physical and psycho-emotional well-being. Digital\ntechnologies are more and more adopted as ''facilitators'' for this goal, to\nraise awareness and solicit healthy lifestyle habits.\n  This study aims to experiment the effects of the adoption of a digital\nconversational tool to influence awareness creation and behavioural change in\nthe context of a well-being lifestyle. Our aim is to collect evidence of the\naspects that must be taken into account when designing and implementing such\ntools in well-being promotion campaigns.\n  To this end, we created a conversational application for promoting well-being\nand healthy lifestyles, which presents relevant information and asks specific\nquestions to its intended users within an interaction happening through a chat\ninterface; the conversational tool presents itself as a well-being counsellor\nnamed Allegra and follows a coaching approach to structure the interaction with\nthe user. In our user study, participants were asked to first interact with\nAllegra in one of three experimental conditions, corresponding to different\nconversational styles; then, they answered a questionnaire about their\nexperience. The questionnaire items were related to intrinsic motivation\nfactors as well as awareness creation and behavioural change. The collected\ndata allowed us to assess the hypotheses of our model that put in connection\nthose variables.\n  Our results confirm the positive effect of intrinsic motivation factors on\nboth awareness creation and behavioural intention in the context of well-being\nand healthy lifestyle; on the other hand, we did not record any statistically\nsignificant effect of different language and communication styles on the\noutcomes.", "AI": {"tldr": "This study examines the efficacy of a digital conversational tool, Allegra, in promoting healthy lifestyles through effective communication and user interaction.", "motivation": "To explore how digital tools can influence awareness and behavioral change towards a healthier lifestyle.", "method": "Participants interacted with a conversational application named Allegra, designed to simulate a well-being counselor and structured interactions based on three different conversational styles. Afterwards, they completed a questionnaire regarding their motivation and behavioral change.", "result": "The study found that intrinsic motivation positively influences awareness creation and behavioral intention for a healthy lifestyle, but different communication styles did not have a significant effect.", "conclusion": "Overall, intrinsic motivation is a key factor in promoting well-being through digital tools, while the choice of conversational style has limited impact on user outcomes.", "key_contributions": ["Development of a digital conversational tool for well-being promotion", "Identification of intrinsic motivation as a critical factor in behavioral change", "Evaluation of conversational styles and their impact on user engagement"], "limitations": "The study did not find statistically significant results for different conversational styles, suggesting complexity in user interactions that may require further investigation.", "future_work": "Future research should explore other elements of conversational design that could enhance user engagement and effectiveness of digital well-being tools.", "keywords": ["digital tools", "conversational agents", "well-being", "behavioral change", "intrinsic motivation"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2504.21019", "pdf": "https://arxiv.org/pdf/2504.21019.pdf", "abs": "https://arxiv.org/abs/2504.21019", "title": "Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations", "authors": ["Yinghan Zhou", "Juan Wen", "Wanli Peng", "Yiming Xue", "Ziwei Zhang", "Zhengxian Wu"], "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by NAACL 2025 main conference", "summary": "The growing popularity of large language models has raised concerns regarding\nthe potential to misuse AI-generated text (AIGT). It becomes increasingly\ncritical to establish an excellent AIGT detection method with high\ngeneralization and robustness. However, existing methods either focus on model\ngeneralization or concentrate on robustness. The unified mechanism, to\nsimultaneously address the challenges of generalization and robustness, is less\nexplored. In this paper, we argue that robustness can be view as a specific\nform of domain shift, and empirically reveal an intrinsic mechanism for model\ngeneralization of AIGT detection task. Then, we proposed a novel AIGT detection\nmethod (DP-Net) via dynamic perturbations introduced by a reinforcement\nlearning with elaborated reward and action. Experimentally, extensive results\nshow that the proposed DP-Net significantly outperforms some state-of-the-art\nAIGT detection methods for generalization capacity in three cross-domain\nscenarios. Meanwhile, the DP-Net achieves best robustness under two text\nadversarial attacks. The code is publicly available at\nhttps://github.com/CAU-ISS-Lab/AIGT-Detection-Evade-Detection/tree/main/DP-Net.", "AI": {"tldr": "This paper presents DP-Net, a novel method for detecting AI-generated text, emphasizing its generalization and robustness against adversarial attacks.", "motivation": "The need for improved detection methods for AI-generated text (AIGT) due to concerns about misuse and the limitations of current detection techniques.", "method": "The proposed method, DP-Net, utilizes dynamic perturbations facilitated by reinforcement learning to enhance both generalization and robustness in AIGT detection.", "result": "DP-Net demonstrated superior performance in generalization across three cross-domain scenarios and exhibited enhanced robustness against two types of text adversarial attacks compared to existing methods.", "conclusion": "The findings support that DP-Net is an effective solution for addressing the dual challenges of generalization and robustness in AIGT detection tasks, thereby contributing valuable techniques in the field.", "key_contributions": ["Introduction of a unified mechanism for AIGT detection addressing both generalization and robustness.", "Development of DP-Net, which utilizes reinforcement learning for dynamic perturbations.", "Empirical validation showing DP-Net's superior performance against state-of-the-art methods."], "limitations": "The paper may not address the implications of using DP-Net in real-world applications extensively.", "future_work": "Future research could explore additional scenarios and further enhancements to the robustness of the method.", "keywords": ["AI-generated text", "detection", "robustness", "generalization", "reinforcement learning"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2504.21731", "pdf": "https://arxiv.org/pdf/2504.21731.pdf", "abs": "https://arxiv.org/abs/2504.21731", "title": "Adaptive 3D UI Placement in Mixed Reality Using Deep Reinforcement Learning", "authors": ["Feiyu Lu", "Mengyu Chen", "Hsiang Hsu", "Pranav Deshpande", "Cheng Yao Wang", "Blair MacIntyre"], "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": "In Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems (CHI EA '24)", "summary": "Mixed Reality (MR) could assist users' tasks by continuously integrating\nvirtual content with their view of the physical environment. However, where and\nhow to place these content to best support the users has been a challenging\nproblem due to the dynamic nature of MR experiences. In contrast to prior work\nthat investigates optimization-based methods, we are exploring how\nreinforcement learning (RL) could assist with continuous 3D content placement\nthat is aware of users' poses and their surrounding environments. Through an\ninitial exploration and preliminary evaluation, our results demonstrate the\npotential of RL to position content that maximizes the reward for users on the\ngo. We further identify future directions for research that could harness the\npower of RL for personalized and optimized UI and content placement in MR.", "AI": {"tldr": "This paper explores the use of reinforcement learning for optimizing 3D content placement in Mixed Reality (MR) environments to enhance user experience.", "motivation": "To address the challenge of effective 3D content placement in dynamic Mixed Reality experiences that optimally supports users' tasks.", "method": "The paper investigates the use of reinforcement learning to continuously place virtual content based on users' poses and surrounding environments.", "result": "Preliminary results show that reinforcement learning can effectively optimize content placement to maximize user rewards while on the move.", "conclusion": "Reinforcement learning offers promising avenues for personalizing and optimizing user interfaces and content placement in MR applications.", "key_contributions": ["Exploration of reinforcement learning for continuous 3D content placement in MR.", "Preliminary evaluation demonstrating RL's effectiveness in optimizing user rewards.", "Identification of future research directions for personalized MR experiences."], "limitations": "The study is preliminary and requires further validation with more extensive user studies.", "future_work": "Future research directions include harnessing RL for improved personalized and optimized UI and content placement in MR.", "keywords": ["mixed reality", "reinforcement learning", "user experience", "3D content placement", "human-computer interaction"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2504.21020", "pdf": "https://arxiv.org/pdf/2504.21020.pdf", "abs": "https://arxiv.org/abs/2504.21020", "title": "Context-Enhanced Contrastive Search for Improved LLM Text Generation", "authors": ["Jaydip Sen", "Rohit Pandey", "Hetvi Waghela"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This is the pre-review version of our paper, which has been accepted\n  for publication in the IEEE 6th International Conference on Emerging\n  Technologies (INCET). The conference will be organized at Belgaum, India,\n  from May 24 to 26, 2025. This is not the final camera-ready paper, which will\n  be available on IEEE Xplore. The paper is 9 pages long, and it contains 2\n  Figures and 4 Tables", "summary": "Recently, Large Language Models (LLMs) have demonstrated remarkable\nadvancements in Natural Language Processing (NLP). However, generating\nhigh-quality text that balances coherence, diversity, and relevance remains\nchallenging. Traditional decoding methods, such as bean search and top-k\nsampling, often struggle with either repetitive or incoherent outputs,\nparticularly in tasks that require long-form text generation. To address these\nlimitations, the paper proposes a novel enhancement of the well-known\nContrastive Search algorithm, Context-Enhanced Contrastive Search (CECS) with\ncontextual calibration. The proposed scheme introduces several novelties\nincluding dynamic contextual importance weighting, multi-level Contrastive\nSearch, and adaptive temperature control, to optimize the balance between\nfluency, creativity, and precision. The performance of CECS is evaluated using\nseveral standard metrics such as BLEU, ROUGE, and semantic similarity.\nExperimental results demonstrate significant improvements in both coherence and\nrelevance of the generated texts by CECS outperforming the existing Contrastive\nSearch techniques. The proposed algorithm has several potential applications in\nthe real world including legal document drafting, customer service chatbots,\nand content marketing.", "AI": {"tldr": "The paper introduces Context-Enhanced Contrastive Search (CECS), an enhancement of the Contrastive Search algorithm that improves text generation quality by balancing coherence, diversity, and relevance.", "motivation": "To address the challenges in generating high-quality long-form text using traditional decoding methods that often produce incoherent or repetitive outputs.", "method": "The proposed CECS introduces dynamic contextual importance weighting, multi-level Contrastive Search, and adaptive temperature control to optimize text generation.", "result": "CECS outperformed existing Contrastive Search techniques, showing significant improvements in coherence and relevance as measured by BLEU, ROUGE, and semantic similarity.", "conclusion": "CECS demonstrates potential for practical applications in areas like legal document drafting and customer service chatbots due to its enhanced text generation capabilities.", "key_contributions": ["Introduction of dynamic contextual importance weighting", "Development of multi-level Contrastive Search", "Implementation of adaptive temperature control"], "limitations": "", "future_work": "Further exploration of CECS applications in various domains and enhancement of the algorithm for broader use cases.", "keywords": ["Large Language Models", "Natural Language Processing", "Contrastive Search"], "importance_score": 9, "read_time_minutes": 30}}
{"id": "2504.21022", "pdf": "https://arxiv.org/pdf/2504.21022.pdf", "abs": "https://arxiv.org/abs/2504.21022", "title": "ConformalNL2LTL: Translating Natural Language Instructions into Temporal Logic Formulas with Conformal Correctness Guarantees", "authors": ["Jun Wang", "David Smith Sundarsingh", "Jyotirmoy V. Deshmukh", "Yiannis Kantaros"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Linear Temporal Logic (LTL) has become a prevalent specification language for\nrobotic tasks. To mitigate the significant manual effort and expertise required\nto define LTL-encoded tasks, several methods have been proposed for translating\nNatural Language (NL) instructions into LTL formulas, which, however, lack\ncorrectness guarantees. To address this, we introduce a new NL-to-LTL\ntranslation method, called ConformalNL2LTL, that can achieve user-defined\ntranslation success rates over unseen NL commands. Our method constructs LTL\nformulas iteratively by addressing a sequence of open-vocabulary\nQuestion-Answering (QA) problems with LLMs. To enable uncertainty-aware\ntranslation, we leverage conformal prediction (CP), a distribution-free\nuncertainty quantification tool for black-box models. CP enables our method to\nassess the uncertainty in LLM-generated answers, allowing it to proceed with\ntranslation when sufficiently confident and request help otherwise. We provide\nboth theoretical and empirical results demonstrating that ConformalNL2LTL\nachieves user-specified translation accuracy while minimizing help rates.", "AI": {"tldr": "Introduction of ConformalNL2LTL, a method for translating Natural Language to Linear Temporal Logic that incorporates uncertainty-aware translation.", "motivation": "To reduce the effort in defining LTL-encoded tasks for robotic applications by translating NL instructions accurately and reliably.", "method": "The new method constructs LTL formulas iteratively through a sequence of open-vocabulary Question-Answering problems using LLMs, incorporating conformal prediction for uncertainty quantification.", "result": "ConformalNL2LTL achieves specified user-defined translation accuracy while minimizing the need for external help during the translation process.", "conclusion": "The proposed method offers a systematic approach to mitigate the challenges of manual LTL task definition, ensuring better accuracy and confidence in translation.", "key_contributions": ["Development of ConformalNL2LTL for NL-to-LTL translation.", "Utilization of conformal prediction for uncertainty assessment in LLM outputs.", "Demonstration of the method's effectiveness in achieving user-defined accuracy goals."], "limitations": "The method's performance may vary based on the complexity of NL commands and the underlying LLM model's capabilities.", "future_work": "Exploration of further enhancements in translation accuracy and expanded vocabulary handling in future applications.", "keywords": ["Natural Language Processing", "Linear Temporal Logic", "Robotics", "Conformal Prediction", "LLM"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2504.21023", "pdf": "https://arxiv.org/pdf/2504.21023.pdf", "abs": "https://arxiv.org/abs/2504.21023", "title": "Param$Δ$ for Direct Weight Mixing: Post-Train Large Language Model at Zero Cost", "authors": ["Sheng Cao", "Mingrui Wu", "Karthik Prasad", "Yuandong Tian", "Zechun Liu"], "categories": ["cs.CL", "cs.LG"], "comment": "Published as a conference paper at ICLR 2025", "summary": "The post-training phase of large language models is essential for enhancing\ncapabilities such as instruction-following, reasoning, and alignment with human\npreferences. However, it demands extensive high-quality data and poses risks\nlike overfitting, alongside significant computational costs due to repeated\npost-training and evaluation after each base model update. This paper\nintroduces $Param\\Delta$, a novel method that streamlines post-training by\ntransferring knowledge from an existing post-trained model to a newly updated\nbase model with ZERO additional training. By computing the difference between\npost-trained model weights ($\\Theta_\\text{post}$) and base model weights\n($\\Theta_\\text{base}$), and adding this to the updated base model\n($\\Theta'_\\text{base}$), we define $Param\\Delta$ Model as:\n$\\Theta_{\\text{Param}\\Delta} = \\Theta_\\text{post} - \\Theta_\\text{base} +\n\\Theta'_\\text{base}$. This approach surprisingly equips the new base model with\npost-trained capabilities, achieving performance comparable to direct\npost-training. We did analysis on LLama3, Llama3.1, Qwen, and\nDeepSeek-distilled models. Results indicate $Param\\Delta$ Model effectively\nreplicates traditional post-training. For example, the $Param\\Delta$ Model\nobtained from 70B Llama3-inst, Llama3-base, Llama3.1-base models attains\napproximately 95\\% of Llama3.1-inst model's performance on average.\n$Param\\Delta$ brings a new perspective on how to fully leverage models in the\nopen-weight community, where checkpoints for base and instruct models are\nreadily available and frequently updated, by providing a cost-free framework to\naccelerate the iterative cycle of model development.", "AI": {"tldr": "Introduces $Param\\Delta$, a method that streamlines post-training of language models by transferring knowledge from existing models without additional training, achieving high performance with reduced costs.", "motivation": "To enhance post-training phase efficiency for large language models while tackling issues like overfitting and high computational costs.", "method": "Computes the difference between weights of a post-trained model and a base model, adding this difference to the updated base model weights to create a new model without additional training.", "result": "$Param\\Delta$ Model demonstrates performance comparable to direct post-training methods, achieving approximately 95% performance of a traditional post-trained model using various models including Llama3 and Llama3.1.", "conclusion": "$Param\\Delta$ provides a cost-efficient framework that leverages model updates to accelerate iterative development in the open-weight community.", "key_contributions": ["Introduces a novel framework for post-training in language models without additional training.", "Achieves high performance comparable to traditional post-training methods.", "Offers a cost-effective approach to facilitate the iterative cycle of model development."], "limitations": "", "future_work": "Further exploration of $Param\\Delta$ across diverse model architectures and applications in various domains.", "keywords": ["large language models", "post-training", "model development", "machine learning", "knowledge transfer"], "importance_score": 8, "read_time_minutes": 12}}
{"id": "2504.21024", "pdf": "https://arxiv.org/pdf/2504.21024.pdf", "abs": "https://arxiv.org/abs/2504.21024", "title": "WebEvolver: Enhancing Web Agent Self-Improvement with Coevolving World Model", "authors": ["Tianqing Fang", "Hongming Zhang", "Zhisong Zhang", "Kaixin Ma", "Wenhao Yu", "Haitao Mi", "Dong Yu"], "categories": ["cs.CL"], "comment": "19 pages", "summary": "Agent self-improvement, where the backbone Large Language Model (LLM) of the\nagent are trained on trajectories sampled autonomously based on their own\npolicies, has emerged as a promising approach for enhancing performance. Recent\nadvancements, particularly in web environments, face a critical limitation:\ntheir performance will reach a stagnation point during autonomous learning\ncycles, hindering further improvement. We argue that this stems from limited\nexploration of the web environment and insufficient exploitation of pre-trained\nweb knowledge in LLMs. To improve the performance of self-improvement, we\npropose a novel framework that introduces a co-evolving World Model LLM. This\nworld model predicts the next observation based on the current observation and\naction within the web environment. Leveraging LLMs' pretrained knowledge of\nabundant web content, the World Model serves dual roles: (1) as a virtual web\nserver generating self-instructed training data to continuously refine the\nagent's policy, and (2) as an imagination engine during inference, enabling\nlook-ahead simulation to guide action selection for the agent LLM. Experiments\nin real-world web environments (Mind2Web-Live, WebVoyager, and GAIA-web) show a\n10% performance gain over existing self-evolving agents, demonstrating the\nefficacy and generalizability of our approach, without using any distillation\nfrom more powerful close-sourced models. Our work establishes the necessity of\nintegrating world models into autonomous agent frameworks to unlock sustained\nadaptability.", "AI": {"tldr": "This paper proposes a novel framework for enhancing agent self-improvement through the use of a co-evolving World Model LLM, addressing performance stagnation in autonomous learning environments.", "motivation": "To address the stagnation in performance that occurs during autonomous learning cycles in web environments, stemming from limited exploration and exploitation of pre-trained web knowledge.", "method": "The proposed framework introduces a co-evolving World Model LLM that predicts observations based on current actions and states. It serves as both a virtual web server for generating training data and as a simulation engine for action selection during inference.", "result": "Experiments showed a 10% performance gain in agent learning compared to existing self-evolving agents across real-world environments like Mind2Web-Live, WebVoyager, and GAIA-web.", "conclusion": "The integration of world models into autonomous agent frameworks is essential for sustained adaptability and performance enhancement in complex environments.", "key_contributions": ["Introduction of a co-evolving World Model LLM for agent self-improvement.", "Demonstration of improved adaptability and performance in web environments.", "Validation of the framework through experiments yielding significant performance gains."], "limitations": "The framework's effectiveness may vary with different environments and types of tasks beyond the tested web scenarios.", "future_work": "Further exploration into enhancing the adaptability of world models and expanding their application in diverse autonomous learning settings.", "keywords": ["autonomous agents", "world model", "large language model", "self-improvement", "performance enhancement"], "importance_score": 8, "read_time_minutes": 19}}
{"id": "2504.21025", "pdf": "https://arxiv.org/pdf/2504.21025.pdf", "abs": "https://arxiv.org/abs/2504.21025", "title": "Durghotona GPT: A Web Scraping and Large Language Model Based Framework to Generate Road Accident Dataset Automatically in Bangladesh", "authors": ["MD Thamed Bin Zaman Chowdhury", "Moazzem Hossain", "Md. Ridwanul Islam"], "categories": ["cs.CL"], "comment": "It has been accepted in IEEE 27th International Conference on\n  Computer and Information Technology (ICCIT). Now, we are waiting for it to\n  get published in IEEE Xplore", "summary": "Road accidents pose significant concerns globally. They lead to large\nfinancial losses, injuries, disabilities, and societal challenges. Accurate and\ntimely accident data is essential for predicting and mitigating these events.\nThis paper presents a novel framework named 'Durghotona GPT' that integrates\nweb scraping and Large Language Models (LLMs) to automate the generation of\ncomprehensive accident datasets from prominent national dailies in Bangladesh.\nThe authors collected accident reports from three major newspapers: Prothom\nAlo, Dhaka Tribune, and The Daily Star. The collected news was then processed\nusing the newest available LLMs: GPT-4, GPT-3.5, and Llama-3. The framework\nefficiently extracts relevant information, categorizes reports, and compiles\ndetailed datasets. Thus, this framework overcomes limitations of manual data\ncollection methods such as delays, errors, and communication gaps. The authors'\nevaluation demonstrates that Llama-3, an open-source model, performs comparably\nto GPT-4. It achieved 89% accuracy in the authors' evaluation. Therefore, it\ncan be considered a cost-effective alternative for similar tasks. The results\nsuggest that the framework developed by the authors can drastically enhance the\nquality and availability of accident data. As a result, it can support critical\napplications in traffic safety analysis, urban planning, and public health. The\nauthors also developed an interface for 'Durghotona GPT' for ease of use as\npart of this paper. Future work will focus on expanding data collection methods\nand refining LLMs to further increase dataset accuracy and applicability.", "AI": {"tldr": "A framework named 'Durghotona GPT' automates the generation of accident datasets from Bangladeshi newspapers using LLMs.", "motivation": "To address the global concerns of road accidents by improving the accuracy and availability of accident data.", "method": "Web scraping and processing accident reports from three major newspapers in Bangladesh using LLMs (GPT-4, GPT-3.5, and Llama-3).", "result": "Llama-3 achieved 89% accuracy, demonstrating comparability to GPT-4 and providing a cost-effective alternative for generating accident datasets.", "conclusion": "The framework enhances the quality of accident data, supporting applications in traffic safety, urban planning, and public health.", "key_contributions": ["Introduction of 'Durghotona GPT' for automated accident data collection", "Evaluation of Llama-3 as a cost-effective alternative to GPT-4", "Development of a user interface for the framework"], "limitations": "", "future_work": "Expand data collection methods and refine LLMs to improve dataset accuracy and applicability.", "keywords": ["accident data", "Large Language Models", "web scraping", "Durghotona GPT", "traffic safety"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2504.21026", "pdf": "https://arxiv.org/pdf/2504.21026.pdf", "abs": "https://arxiv.org/abs/2504.21026", "title": "Creating and Evaluating Code-Mixed Nepali-English and Telugu-English Datasets for Abusive Language Detection Using Traditional and Deep Learning Models", "authors": ["Manish Pandey", "Nageshwar Prasad Yadav", "Mokshada Adduru", "Sawan Rai"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "comment": null, "summary": "With the growing presence of multilingual users on social media, detecting\nabusive language in code-mixed text has become increasingly challenging.\nCode-mixed communication, where users seamlessly switch between English and\ntheir native languages, poses difficulties for traditional abuse detection\nmodels, as offensive content may be context-dependent or obscured by linguistic\nblending. While abusive language detection has been extensively explored for\nhigh-resource languages like English and Hindi, low-resource languages such as\nTelugu and Nepali remain underrepresented, leaving gaps in effective\nmoderation. In this study, we introduce a novel, manually annotated dataset of\n2 thousand Telugu-English and 5 Nepali-English code-mixed comments, categorized\nas abusive and non-abusive, collected from various social media platforms. The\ndataset undergoes rigorous preprocessing before being evaluated across multiple\nMachine Learning (ML), Deep Learning (DL), and Large Language Models (LLMs). We\nexperimented with models including Logistic Regression, Random Forest, Support\nVector Machines (SVM), Neural Networks (NN), LSTM, CNN, and LLMs, optimizing\ntheir performance through hyperparameter tuning, and evaluate it using 10-fold\ncross-validation and statistical significance testing (t-test). Our findings\nprovide key insights into the challenges of detecting abusive language in\ncode-mixed settings and offer a comparative analysis of computational\napproaches. This study contributes to advancing NLP for low-resource languages\nby establishing benchmarks for abusive language detection in Telugu-English and\nNepali-English code-mixed text. The dataset and insights can aid in the\ndevelopment of more robust moderation strategies for multilingual social media\nenvironments.", "AI": {"tldr": "The paper presents a dataset and analysis focused on detecting abusive language in code-mixed Telugu-English and Nepali-English texts, addressing the challenges in moderation on social media.", "motivation": "To address the challenges of detecting abusive language in code-mixed texts, especially for underrepresented languages like Telugu and Nepali.", "method": "A novel manually annotated dataset of 2,000 Telugu-English and 5,000 Nepali-English comments was created and tested using various ML and DL models, including hyperparameter optimization and 10-fold cross-validation.", "result": "The study found that traditional abuse detection models face difficulties in parsing code-mixed texts and provided a comparative analysis among multiple detection models.", "conclusion": "The findings underline the need for tailored moderation strategies in multilingual social media and provide benchmarks for further research in NLP for low-resource languages.", "key_contributions": ["Introduction of a dataset for Telugu-English and Nepali-English abusive language detection", "Comparative analysis of various ML and DL models", "Insights into the challenges of code-mixed language processing"], "limitations": "The dataset is limited to only two low-resource languages and may not capture the full range of abusive language usages across all contexts.", "future_work": "Future research could expand the dataset to include more languages and explore additional context and nuances in abusive language detection.", "keywords": ["abusive language detection", "code-mixed text", "low-resource languages", "NLP", "social media"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2504.21800", "pdf": "https://arxiv.org/pdf/2504.21800.pdf", "abs": "https://arxiv.org/abs/2504.21800", "title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues", "authors": ["Suhas BN", "Dominik Mattioli", "Saeed Abdullah", "Rosa I. Arriaga", "Chris W. Wiese", "Andrew M. Sherrill"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "68T50", "I.2.7; H.3.1"], "comment": "11 pages, 5 tables, updated abstract and tables", "summary": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. In our dataset, synthetic dialogues match structural\nfeatures of real-world dialogues (e.g., speaker switch ratio: 0.98 vs. 0.99),\nhowever, synthetic interactions do not adequately reflect key fidelity markers\n(e.g., distress monitoring). We highlight gaps in existing evaluation\nframeworks and advocate for fidelity-aware metrics that go beyond surface\nfluency to uncover clinically significant failures. Our findings clarify where\nsynthetic data can effectively complement real-world datasets -- and where\ncritical limitations remain.", "AI": {"tldr": "This paper examines the effectiveness of synthetic data, specifically Prolonged Exposure (PE) therapeutic conversations for PTSD, as a tool for training and evaluating clinical models, highlighting both its potential benefits and limitations.", "motivation": "To address privacy concerns, limited access to real-world data, and high costs of annotation in healthcare, this research explores synthetic data as a solution for developing clinical models.", "method": "The study systematically compares real and synthetic dialogues using various metrics, including linguistic and structural analyses, focusing on aspects such as turn-taking patterns and treatment fidelity.", "result": "While synthetic dialogues exhibit similar structural features to real dialogues, they fail to capture important fidelity markers, indicating significant limitations in reflecting the nuances of therapeutic interactions.", "conclusion": "Synthetic data can complement real-world datasets in healthcare applications, but critical gaps exist in capturing the dynamics of therapeutic interactions, necessitating the development of fidelity-aware evaluation metrics.", "key_contributions": ["Introduction of PE-specific metrics derived from linguistic analysis and semantic modeling.", "Demonstration of the potential for synthetic data to address data scarcity and privacy concerns in clinical settings.", "Identification of key fidelity markers that synthetic conversations fail to capture, emphasizing the need for improved evaluation frameworks."], "limitations": "Synthetic dialogues do not adequately reflect subtle dynamics of therapeutic interactions, particularly in distress monitoring and other fidelity markers.", "future_work": "Advocacy for fidelity-aware metrics that extend beyond surface fluency to better assess clinical significance and treatment fidelity in synthetic data.", "keywords": ["synthetic data", "healthcare", "Post-Traumatic Stress Disorder", "therapeutic conversations", "evaluation metrics"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2504.21027", "pdf": "https://arxiv.org/pdf/2504.21027.pdf", "abs": "https://arxiv.org/abs/2504.21027", "title": "UrbanPlanBench: A Comprehensive Urban Planning Benchmark for Evaluating Large Language Models", "authors": ["Yu Zheng", "Longyi Liu", "Yuming Lin", "Jie Feng", "Guozhen Zhang", "Depeng Jin", "Yong Li"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The advent of Large Language Models (LLMs) holds promise for revolutionizing\nvarious fields traditionally dominated by human expertise. Urban planning, a\nprofessional discipline that fundamentally shapes our daily surroundings, is\none such field heavily relying on multifaceted domain knowledge and experience\nof human experts. The extent to which LLMs can assist human practitioners in\nurban planning remains largely unexplored. In this paper, we introduce a\ncomprehensive benchmark, UrbanPlanBench, tailored to evaluate the efficacy of\nLLMs in urban planning, which encompasses fundamental principles, professional\nknowledge, and management and regulations, aligning closely with the\nqualifications expected of human planners. Through extensive evaluation, we\nreveal a significant imbalance in the acquisition of planning knowledge among\nLLMs, with even the most proficient models falling short of meeting\nprofessional standards. For instance, we observe that 70% of LLMs achieve\nsubpar performance in understanding planning regulations compared to other\naspects. Besides the benchmark, we present the largest-ever supervised\nfine-tuning (SFT) dataset, UrbanPlanText, comprising over 30,000 instruction\npairs sourced from urban planning exams and textbooks. Our findings demonstrate\nthat fine-tuned models exhibit enhanced performance in memorization tests and\ncomprehension of urban planning knowledge, while there exists significant room\nfor improvement, particularly in tasks requiring domain-specific terminology\nand reasoning. By making our benchmark, dataset, and associated evaluation and\nfine-tuning toolsets publicly available at\nhttps://github.com/tsinghua-fib-lab/PlanBench, we aim to catalyze the\nintegration of LLMs into practical urban planning, fostering a symbiotic\ncollaboration between human expertise and machine intelligence.", "AI": {"tldr": "The paper introduces UrbanPlanBench, a benchmark to assess LLMs in urban planning, revealing shortcomings in their performance, and presents the UrbanPlanText dataset for fine-tuning models to improve their understanding of planning knowledge.", "motivation": "To explore how LLMs can assist urban planners and evaluate their effectiveness in this domain.", "method": "The authors developed UrbanPlanBench to benchmark LLMs' performance in urban planning and created the UrbanPlanText dataset for supervised fine-tuning with instruction pairs from exams and textbooks.", "result": "Extensive evaluation shows a significant imbalance in LLMs' knowledge, with 70% performing poorly on planning regulations; however, fine-tuned models show improved performance in memorization and comprehension tasks.", "conclusion": "The study highlights LLMs' limitations in urban planning while providing resources for improving their integration into the field.", "key_contributions": ["Introduction of UrbanPlanBench benchmark for LLM evaluation in urban planning", "Creation of UrbanPlanText dataset with over 30,000 instruction pairs", "Findings on LLM performance gaps, particularly in planning regulations"], "limitations": "LLMs still struggle with domain-specific terminology and reasoning despite improvements from fine-tuning.", "future_work": "Encouragement for further research to enhance LLM capabilities in urban planning and their practical application.", "keywords": ["Large Language Models", "urban planning", "benchmarks", "fine-tuning", "dataset"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2504.21117", "pdf": "https://arxiv.org/pdf/2504.21117.pdf", "abs": "https://arxiv.org/abs/2504.21117", "title": "Beyond One-Size-Fits-All: Inversion Learning for Highly Effective NLG Evaluation Prompts", "authors": ["Hanhua Hong", "Chenghao Xiao", "Yang Wang", "Yiqi Liu", "Wenge Rong", "Chenghua Lin"], "categories": ["cs.CL"], "comment": "10 pages", "summary": "Evaluating natural language generation (NLG) systems is challenging due to\nthe diversity of valid outputs. While human evaluation is the gold standard, it\nsuffers from inconsistencies, lack of standardisation, and demographic biases,\nlimiting reproducibility. LLM-based evaluation offers a scalable alternative\nbut is highly sensitive to prompt design, where small variations can lead to\nsignificant discrepancies. In this work, we propose an inversion learning\nmethod that learns effective reverse mappings from model outputs back to their\ninput instructions, enabling the automatic generation of highly effective,\nmodel-specific evaluation prompts. Our method requires only a single evaluation\nsample and eliminates the need for time-consuming manual prompt engineering,\nthereby improving both efficiency and robustness. Our work contributes toward a\nnew direction for more robust and efficient LLM-based evaluation.", "AI": {"tldr": "This paper presents a method for improving evaluation of natural language generation systems by automatically generating model-specific evaluation prompts using inversion learning.", "motivation": "Evaluating natural language generation systems is difficult due to diverse valid outputs and limitations in human evaluation, prompting the need for a scalable solution.", "method": "The authors propose an inversion learning method that creates effective reverse mappings from model outputs to input instructions, allowing for automated generation of evaluation prompts from just one sample.", "result": "The method improves efficiency by eliminating manual prompt engineering, leading to more robust evaluations of NLG systems.", "conclusion": "The proposed method enhances both the efficiency and reliability of LLM-based evaluations, opening new directions for this field.", "key_contributions": ["Introduction of inversion learning for prompt generation", "Elimination of manual prompt engineering", "Improved robustness in model evaluation"], "limitations": "The method's effectiveness may vary with different types of models and outputs.", "future_work": "Further exploration of inversion learning in other AI evaluation contexts and potential improvements in evaluation prompt design.", "keywords": ["natural language generation", "evaluation methodology", "inversion learning", "LLM-based evaluation", "prompt engineering"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2403.02145", "pdf": "https://arxiv.org/pdf/2403.02145.pdf", "abs": "https://arxiv.org/abs/2403.02145", "title": "'SSL?! What on earth is that?': Towards Designing Age-Inclusive Secure Smartphone Browsing", "authors": ["Pavithren V. S. Pakianathan", "L. Siddharth", "Sujithra Raviselvam", "Kristin L. Wood", "Hyowon Lee", "Pin Sym Foong", "Jianying Zhou", "Simon Tangi Perrault"], "categories": ["cs.HC", "cs.CY"], "comment": "This version was last submitted to EuroUSEC 2023 - European Symposium\n  on Usable Security. It was later invited for poster submission at the same\n  conference", "summary": "Owing to the increase in 'certified' phishing websites, there is a steady\nincrease in the number of phishing cases and general susceptibility to\nphishing. Trust mechanisms (e.g., HTTPS Lock Indicators, SSL Certificates) that\nhelp differentiate genuine and phishing websites should therefore be evaluated\nfor their effectiveness in preventing vulnerable users from accessing phishing\nwebsites. In this article, we present a study involving 18 adults (male-6;\nfemale-12) and 12 older adults (male-4; female-8) to understand the usability\nof current trust mechanisms and preferred modalities in a conceptualized\nmechanism. In the first part of the study, using Chrome browser on Android, we\nasked the participants to browse a banking website and a government website for\ndigital particulars. We asked them to identify which one of the two was a\nphishing website, rate the usability of both websites and provide qualitative\nfeedback on the trust mechanisms. In the second part, we conceptualized an\nalternative trust mechanism, which allows seeking social, community and\nAI-based support to make website trust-related decisions. Herein, we asked the\nparticipants as to which modality (social, community or AI) they prefer to seek\nsupport from and why it is preferred. Using the current trust mechanisms, none\nof the participants were able to identify the phishing website. As the\nparticipants rated the current mechanisms poorly in terms of usability, they\nexpressed various difficulties that largely did not differ between adults and\nolder adults. In the conceptualized mechanism, we observed a notable difference\nin the preferred modalities, in that, older adults primarily preferred social\nsupport. In addition to these overall findings, specific observations suggest\nthat future trust mechanisms should not only consider age-specific needs but\nalso incorporate substantial improvement in terms of usability.", "AI": {"tldr": "This study evaluates the effectiveness of current trust mechanisms against phishing websites and proposes a new mechanism incorporating social, community, and AI support.", "motivation": "To address the rising rates of phishing attacks facilitated by certified phishing websites, the study investigates the usability of existing trust mechanisms designed to protect users.", "method": "The study involved 30 participants (18 adults and 12 older adults) who were asked to identify a phishing website among genuine sites while browsing with Chrome on Android. Additionally, participants provided feedback on current mechanisms and expressed preferences for support modalities in a conceptualized trust mechanism.", "result": "None of the participants successfully identified the phishing website using current trust mechanisms, which they rated poorly in usability. Older adults showed a preference for social support in trust-related decisions.", "conclusion": "Future trust mechanisms should consider age-specific needs and significantly improve usability to effectively support users in recognizing phishing threats.", "key_contributions": ["Firsthand evaluation of current online trust mechanisms' usability against phishing sites", "Assessment of user preferences for support modalities in a new conceptualized mechanism", "Insights on age-specific differences in support preferences for phishing detection."], "limitations": "Study limited to a small sample size; findings may not generalize across larger populations or different demographics.", "future_work": "Further research is needed to develop and test improved trust mechanisms that incorporate user preferences and address usability across diverse user groups.", "keywords": ["Phishing", "Usability", "Trust mechanisms", "Human-computer interaction", "AI support"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2504.21132", "pdf": "https://arxiv.org/pdf/2504.21132.pdf", "abs": "https://arxiv.org/abs/2504.21132", "title": "LLM Enhancer: Merged Approach using Vector Embedding for Reducing Large Language Model Hallucinations with External Knowledge", "authors": ["Naheed Rayhan", "Md. Ashrafuzzaman"], "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs), such as ChatGPT, have demonstrated the\ncapability to generate human like, natural responses across a range of tasks,\nincluding task oriented dialogue and question answering. However, their\napplication in real world, critical scenarios is often hindered by a tendency\nto produce inaccurate information and a limited ability to leverage external\nknowledge sources. This paper introduces the LLM ENHANCER system, designed to\nintegrate multiple online sources such as Google, Wikipedia, and DuckDuckGo to\nenhance data accuracy. The LLMs employed within this system are open source.\nThe data acquisition process for the LLM ENHANCER system operates in parallel,\nutilizing custom agent tools to manage the flow of information. Vector\nembeddings are used to identify the most pertinent information, which is\nsubsequently supplied to the LLM for user interaction. The LLM ENHANCER system\nmitigates hallucinations in chat based LLMs while preserving response\nnaturalness and accuracy.", "AI": {"tldr": "The LLM ENHANCER system improves the accuracy of responses from LLMs by integrating multiple online information sources.", "motivation": "LLMs like ChatGPT often produce inaccurate information, limiting their application in critical scenarios. The need for a system that enhances their reliability and accuracy is paramount.", "method": "The LLM ENHANCER integrates information from sources like Google, Wikipedia, and DuckDuckGo using parallel data acquisition and custom agent tools. It employs vector embeddings to determine relevant information for LLM user interaction.", "result": "The system effectively reduces hallucinations in chat-based LLMs while maintaining naturalness and accuracy in responses.", "conclusion": "The LLM ENHANCER demonstrates a viable approach to improving the response quality of LLMs in real-world applications by sourcing accurate information.", "key_contributions": ["Integration of multiple online knowledge sources to enhance LLM responses.", "Reduction of hallucinations while ensuring natural dialogue.", "Use of vector embeddings for relevant information retrieval."], "limitations": "The system's performance may vary based on the quality and currency of the integrated online sources.", "future_work": "Future research could explore additional sources of information and enhance the system's adaptability to various domains.", "keywords": ["Large Language Models", "Information accuracy", "User interaction", "Data acquisition", "Natural language processing"], "importance_score": 9, "read_time_minutes": 6}}
{"id": "2405.13924", "pdf": "https://arxiv.org/pdf/2405.13924.pdf", "abs": "https://arxiv.org/abs/2405.13924", "title": "Emotive Speech-to-Text Interfaces in XR: A Narrative Review of Psychophysiological and Accessibility Advances", "authors": ["Sunday David Ubur", "Denis Gracanin"], "categories": ["cs.HC"], "comment": "Updated with overlooked works, and made enhancements", "summary": "This narrative review on emotional expression in Speech-to-Text (STT)\ninterfaces with Extended Reality (XR) aims to identify advancements,\nlimitations, and research gaps in incorporating emotional expression into\ntranscribed text generated by STT systems. Using a rigorous search strategy,\nrelevant articles published between 2020 and 2024 are extracted and categorized\ninto themes such as communication enhancement technologies, innovations in\ncaptioning, visual and affective augmentation, emotion recognition in AR and\nVR, and empathic machines. The findings reveal the evolution of tools and\ntechniques to meet the needs of individuals with hearing impairments,\nshowcasing innovations in live transcription, closed captioning, AR, VR, and\nemotion recognition technologies. Despite improvements in accessibility, the\nabsence of emotional nuance in transcribed text remains a significant\ncommunication challenge. The study underscores the urgency for innovations in\nSTT technology to capture emotional expressions. The research discusses\nintegrating emotional expression into text through strategies like animated\ntext captions, emojilization tools, and models associating emotions with\nanimation properties. Extending these efforts into AR and VR environments opens\nnew possibilities for immersive and emotionally resonant experiences,\nespecially in educational contexts. The study also explores empathic\napplications in healthcare, education, and human-robot interactions,\nhighlighting the potential for personalized and effective interactions. The\nmultidisciplinary nature of the literature underscores the potential for\ncollaborative and interdisciplinary research.", "AI": {"tldr": "This narrative review discusses advancements and challenges in incorporating emotional expression into Speech-to-Text (STT) systems within Extended Reality (XR), particularly for individuals with hearing impairments.", "motivation": "To identify advancements, limitations, and research gaps in integrating emotional expression into STT technology.", "method": "A narrative review analyzing relevant articles from 2020 to 2024, categorized into themes related to emotional expression and communication technologies.", "result": "The study identifies innovations in live transcription, closed captioning, AR, VR, and emotion recognition technologies, while highlighting the absence of emotional nuance in current STT outputs as a significant challenge.", "conclusion": "Innovations are urgently needed to capture emotional expressions in STT technology, particularly for enhancing communication in immersive environments like AR and VR.", "key_contributions": ["Identification of research gaps in emotional expression in STT systems", "Discussion on the integration of emotional nuances through animated text and emojilization", "Insights into empathic applications in healthcare and education"], "limitations": "The existing STT technologies still struggle to incorporate emotional nuances, impacting the effectiveness of communication for users.", "future_work": "Future research should focus on developing STT technologies that can adequately capture emotional nuances and enhance user interaction in XR environments.", "keywords": ["Speech-to-Text", "Emotional Expression", "Extended Reality", "Emotion Recognition", "Human-Computer Interaction"], "importance_score": 8, "read_time_minutes": 20}}
{"id": "2504.21165", "pdf": "https://arxiv.org/pdf/2504.21165.pdf", "abs": "https://arxiv.org/abs/2504.21165", "title": "Detecting Manipulated Contents Using Knowledge-Grounded Inference", "authors": ["Mark Huasong Meng", "Ruizhe Wang", "Meng Xu", "Chuan Yan", "Guangdong Bai"], "categories": ["cs.CL", "cs.SI"], "comment": "16 pages", "summary": "The detection of manipulated content, a prevalent form of fake news, has been\nwidely studied in recent years. While existing solutions have been proven\neffective in fact-checking and analyzing fake news based on historical events,\nthe reliance on either intrinsic knowledge obtained during training or manually\ncurated context hinders them from tackling zero-day manipulated content, which\ncan only be recognized with real-time contextual information. In this work, we\npropose Manicod, a tool designed for detecting zero-day manipulated content.\nManicod first sources contextual information about the input claim from\nmainstream search engines, and subsequently vectorizes the context for the\nlarge language model (LLM) through retrieval-augmented generation (RAG). The\nLLM-based inference can produce a \"truthful\" or \"manipulated\" decision and\noffer a textual explanation for the decision. To validate the effectiveness of\nManicod, we also propose a dataset comprising 4270 pieces of manipulated fake\nnews derived from 2500 recent real-world news headlines. Manicod achieves an\noverall F1 score of 0.856 on this dataset and outperforms existing methods by\nup to 1.9x in F1 score on their benchmarks on fact-checking and claim\nverification.", "AI": {"tldr": "Manicod is a tool designed for detecting zero-day manipulated content using real-time contextual information sourced from search engines and processed by LLMs through RAG, achieving a high F1 score.", "motivation": "The need to effectively detect zero-day manipulated content in fake news due to limitations of existing solutions relying on historical data or curated context.", "method": "Manicod sources contextual information about claims from mainstream search engines and vectorizes it for LLM inference via retrieval-augmented generation.", "result": "Manicod achieved an F1 score of 0.856 on its dataset comprising 4270 manipulated fake news pieces, outperforming existing methods by up to 1.9x in F1 score.", "conclusion": "The effectiveness of Manicod demonstrates the importance of real-time contextual information for accurately detecting manipulated content in news.", "key_contributions": ["Introduction of Manicod for real-time fake news detection", "Development of a dataset with 4270 manipulated fake news pieces", "Outperforming existing methods in fact-checking metrics."], "limitations": "", "future_work": "Exploration of further enhancements in real-time detection methodologies and application to various news domains.", "keywords": ["fake news detection", "zero-day manipulation", "retrieval-augmented generation", "large language models", "fact-checking"], "importance_score": 9, "read_time_minutes": 16}}
{"id": "2412.03118", "pdf": "https://arxiv.org/pdf/2412.03118.pdf", "abs": "https://arxiv.org/abs/2412.03118", "title": "ObjectFinder: An Open-Vocabulary Assistive System for Interactive Object Search by Blind People", "authors": ["Ruiping Liu", "Jiaming Zhang", "Angela Schön", "Karin Müller", "Junwei Zheng", "Kailun Yang", "Anhong Guo", "Kathrin Gerling", "Rainer Stiefelhagen"], "categories": ["cs.HC", "cs.CV"], "comment": null, "summary": "Searching for objects in unfamiliar scenarios is a challenging task for blind\npeople. It involves specifying the target object, detecting it, and then\ngathering detailed information according to the user's intent. However,\nexisting description- and detection-based assistive technologies do not\nsufficiently support the multifaceted nature of interactive object search\ntasks. We present ObjectFinder, an open-vocabulary wearable assistive system\nfor interactive object search by blind people. ObjectFinder allows users to\nquery target objects using flexible wording. Once the target object is\ndetected, it provides egocentric localization information in real-time,\nincluding distance and direction. Users can then initiate different branches to\ngather detailed information based on their intent towards the target object,\nsuch as navigating to it or perceiving its surroundings. ObjectFinder is\npowered by a seamless combination of open-vocabulary models, namely an\nopen-vocabulary object detector and a multimodal large language model. The\nObjectFinder design concept and its development were carried out in\ncollaboration with a blind co-designer. To evaluate ObjectFinder, we conducted\nan exploratory user study with eight blind participants. We compared\nObjectFinder to BeMyAI and Google Lookout, popular description- and\ndetection-based assistive applications. Our findings indicate that most\nparticipants felt more independent with ObjectFinder and preferred it for\nobject search, as it enhanced scene context gathering and navigation, and\nallowed for active target identification. Finally, we discuss the implications\nfor future assistive systems to support interactive object search.", "AI": {"tldr": "ObjectFinder is an open-vocabulary wearable system designed to aid blind individuals in searching for objects interactively, providing real-time localization and intent-based information gathering.", "motivation": "Blind individuals face significant challenges in searching for objects in unfamiliar environments, necessitating advanced assistive technologies.", "method": "ObjectFinder combines open-vocabulary object detection with a multimodal large language model to facilitate flexible user queries and real-time localization of target objects.", "result": "In user studies, ObjectFinder notably increased independence and preference among blind participants compared to existing assistive applications, enhancing their ability to gather context and navigate.", "conclusion": "The study highlights the potential for improving assistive technologies through user-centered design and open-vocabulary systems to support interactive object search.", "key_contributions": ["Development of an open-vocabulary assistive system for object search", "Real-time egocentric localization for enhanced user navigation", "User-centered design approach involving blind co-designers"], "limitations": "The user study involved only eight participants, which may limit the generalizability of the findings.", "future_work": "Further research should explore the scalability of ObjectFinder and its application in various environments or scenarios.", "keywords": ["assistive technology", "object search", "blind users", "open-vocabulary models", "human-computer interaction"], "importance_score": 8, "read_time_minutes": 12}}
{"id": "2504.21191", "pdf": "https://arxiv.org/pdf/2504.21191.pdf", "abs": "https://arxiv.org/abs/2504.21191", "title": "Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare", "authors": ["Lovedeep Gondara", "Jonathan Simkin", "Graham Sayle", "Shebnum Devji", "Gregory Arbour", "Raymond Ng"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "This study aims to guide language model selection by investigating: 1) the\nnecessity of finetuning versus zero-shot usage, 2) the benefits of\ndomain-adjacent versus generic pretrained models, 3) the value of further\ndomain-specific pretraining, and 4) the continued relevance of Small Language\nModels (SLMs) compared to Large Language Models (LLMs) for specific tasks.\nUsing electronic pathology reports from the British Columbia Cancer Registry\n(BCCR), three classification scenarios with varying difficulty and data size\nare evaluated. Models include various SLMs and an LLM. SLMs are evaluated both\nzero-shot and finetuned; the LLM is evaluated zero-shot only. Finetuning\nsignificantly improved SLM performance across all scenarios compared to their\nzero-shot results. The zero-shot LLM outperformed zero-shot SLMs but was\nconsistently outperformed by finetuned SLMs. Domain-adjacent SLMs generally\nperformed better than the generic SLM after finetuning, especially on harder\ntasks. Further domain-specific pretraining yielded modest gains on easier tasks\nbut significant improvements on the complex, data-scarce task. The results\nhighlight the critical role of finetuning for SLMs in specialized domains,\nenabling them to surpass zero-shot LLM performance on targeted classification\ntasks. Pretraining on domain-adjacent or domain-specific data provides further\nadvantages, particularly for complex problems or limited finetuning data. While\nLLMs offer strong zero-shot capabilities, their performance on these specific\ntasks did not match that of appropriately finetuned SLMs. In the era of LLMs,\nSLMs remain relevant and effective, offering a potentially superior\nperformance-resource trade-off compared to LLMs.", "AI": {"tldr": "The study evaluates the performance of Small Language Models (SLMs) and Large Language Models (LLMs) in the context of electronic pathology report classification, focusing on the impact of finetuning and domain-specific pretraining.", "motivation": "To guide language model selection for specific tasks in medical domain applications, particularly regarding finetuning versus zero-shot usage and the impact of model size and domain specificity.", "method": "Evaluated various SLMs and one LLM using electronic pathology reports from the British Columbia Cancer Registry (BCCR) under differing conditions of finetuning and zero-shot performance across three classification scenarios.", "result": "Finetuning improved SLM performance across all scenarios; zero-shot LLM outperformed zero-shot SLMs but was outperformed by finetuned SLMs, with domain-adjacent SLMs performing better than generic ones.", "conclusion": "SLMs are shown to be more effective when finetuned for specialized tasks, significantly outperforming zero-shot LLMs, indicating their continued relevance and efficiency in specific applications.", "key_contributions": ["Detailed evaluation of SLM vs LLM performance in medical classification tasks.", "Insights on the benefits of finetuning and domain-specific pretraining.", "Demonstration of the ongoing relevance of SLMs in the age of LLMs."], "limitations": "Focus on a specific domain (pathology reports) may limit generalizability; evaluation based on a single dataset.", "future_work": "Further exploration of SLM performance across diverse healthcare applications and additional datasets.", "keywords": ["Language Models", "Finetuning", "Domain-Specific Pretraining", "Small Language Models", "Large Language Models"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2504.21202", "pdf": "https://arxiv.org/pdf/2504.21202.pdf", "abs": "https://arxiv.org/abs/2504.21202", "title": "Automatic Legal Writing Evaluation of LLMs", "authors": ["Ramon Pires", "Roseval Malaquias Junior", "Rodrigo Nogueira"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite the recent advances in Large Language Models, benchmarks for\nevaluating legal writing remain scarce due to the inherent complexity of\nassessing open-ended responses in this domain. One of the key challenges in\nevaluating language models on domain-specific tasks is finding test datasets\nthat are public, frequently updated, and contain comprehensive evaluation\nguidelines. The Brazilian Bar Examination meets these requirements. We\nintroduce oab-bench, a benchmark comprising 105 questions across seven areas of\nlaw from recent editions of the exam. The benchmark includes comprehensive\nevaluation guidelines and reference materials used by human examiners to ensure\nconsistent grading. We evaluate the performance of four LLMs on oab-bench,\nfinding that Claude-3.5 Sonnet achieves the best results with an average score\nof 7.93 out of 10, passing all 21 exams. We also investigated whether LLMs can\nserve as reliable automated judges for evaluating legal writing. Our\nexperiments show that frontier models like OpenAI's o1 achieve a strong\ncorrelation with human scores when evaluating approved exams, suggesting their\npotential as reliable automated evaluators despite the inherently subjective\nnature of legal writing assessment. The source code and the benchmark --\ncontaining questions, evaluation guidelines, model-generated responses, and\ntheir respective automated evaluations -- are publicly available.", "AI": {"tldr": "Introducing oab-bench, a benchmark for evaluating legal writing with LLMs, comprising 105 questions from the Brazilian Bar Examination, showing potential for automated assessment.", "motivation": "To address the scarcity of benchmarks for evaluating legal writing and to enable better assessment of LLMs in domain-specific tasks.", "method": "Creation of the oab-bench with 105 questions and comprehensive evaluation guidelines; evaluation of four LLMs on this benchmark.", "result": "Claude-3.5 Sonnet achieved the best average score of 7.93 out of 10, correlating well with human evaluations on legal writing.", "conclusion": "LLMs, particularly advanced models, show promise as reliable automated judges in the evaluation of legal writing despite its subjective nature.", "key_contributions": ["Development of oab-bench, a comprehensive benchmark for legal writing assessment.", "Demonstration of LLMs' potential as automated evaluators in legal contexts.", "Provision of publicly available resources including questions and evaluations."], "limitations": "The complexity and subjectivity inherent in legal writing assessment may limit the applicability of the evaluations.", "future_work": "Further exploration of LLMs' capabilities in other legal contexts and continuous updates to the benchmark dataset.", "keywords": ["Large Language Models", "Legal writing", "Benchmark", "Automated evaluation", "Brazilian Bar Examination"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2504.21214", "pdf": "https://arxiv.org/pdf/2504.21214.pdf", "abs": "https://arxiv.org/abs/2504.21214", "title": "Pretraining Large Brain Language Model for Active BCI: Silent Speech", "authors": ["Jinzhao Zhou", "Zehong Cao", "Yiqun Duan", "Connor Barkley", "Daniel Leong", "Xiaowei Jiang", "Quoc-Toan Nguyen", "Ziyi Zhao", "Thomas Do", "Yu-Cheng Chang", "Sheng-Fu Liang", "Chin-teng Lin"], "categories": ["cs.CL", "cs.AI", "eess.AS"], "comment": null, "summary": "This paper explores silent speech decoding in active brain-computer interface\n(BCI) systems, which offer more natural and flexible communication than\ntraditional BCI applications. We collected a new silent speech dataset of over\n120 hours of electroencephalogram (EEG) recordings from 12 subjects, capturing\n24 commonly used English words for language model pretraining and decoding.\nFollowing the recent success of pretraining large models with self-supervised\nparadigms to enhance EEG classification performance, we propose Large Brain\nLanguage Model (LBLM) pretrained to decode silent speech for active BCI. To\npretrain LBLM, we propose Future Spectro-Temporal Prediction (FSTP) pretraining\nparadigm to learn effective representations from unlabeled EEG data. Unlike\nexisting EEG pretraining methods that mainly follow a masked-reconstruction\nparadigm, our proposed FSTP method employs autoregressive modeling in temporal\nand frequency domains to capture both temporal and spectral dependencies from\nEEG signals. After pretraining, we finetune our LBLM on downstream tasks,\nincluding word-level and semantic-level classification. Extensive experiments\ndemonstrate significant performance gains of the LBLM over fully-supervised and\npretrained baseline models. For instance, in the difficult cross-session\nsetting, our model achieves 47.0\\% accuracy on semantic-level classification\nand 39.6\\% in word-level classification, outperforming baseline methods by\n5.4\\% and 7.3\\%, respectively. Our research advances silent speech decoding in\nactive BCI systems, offering an innovative solution for EEG language model\npretraining and a new dataset for fundamental research.", "AI": {"tldr": "Explores silent speech decoding in active brain-computer interfaces (BCI) using a new dataset and a Large Brain Language Model (LBLM) trained with a novel pretraining method.", "motivation": "To enhance communication through more natural BCI systems compared to traditional methods by improving silent speech decoding capabilities.", "method": "A Large Brain Language Model (LBLM) is pretrained using a Future Spectro-Temporal Prediction (FSTP) paradigm on a new dataset of EEG recordings, capturing both temporal and spectral dependencies.", "result": "LBLM outperforms fully-supervised and pre-trained baseline models, achieving 47.0% accuracy in semantic-level classification and 39.6% in word-level classification, with significant performance gains.", "conclusion": "The proposed LBLM and the new dataset advance the field of silent speech decoding and provide foundational research resources for future studies.", "key_contributions": ["Introduction of the Large Brain Language Model (LBLM) for silent speech decoding.", "Development of a new silent speech dataset from EEG recordings offering over 120 hours of data.", "Proposing the Future Spectro-Temporal Prediction (FSTP) pretraining paradigm for effective representation learning."], "limitations": "", "future_work": "Further exploration of BCI systems using the pretrained LBLM and improvements in silent speech decoding techniques.", "keywords": ["silent speech decoding", "brain-computer interface", "large language model"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2504.21233", "pdf": "https://arxiv.org/pdf/2504.21233.pdf", "abs": "https://arxiv.org/abs/2504.21233", "title": "Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math", "authors": ["Haoran Xu", "Baolin Peng", "Hany Awadalla", "Dongdong Chen", "Yen-Chun Chen", "Mei Gao", "Young Jin Kim", "Yunsheng Li", "Liliang Ren", "Yelong Shen", "Shuohang Wang", "Weijian Xu", "Jianfeng Gao", "Weizhu Chen"], "categories": ["cs.CL"], "comment": null, "summary": "Chain-of-Thought (CoT) significantly enhances formal reasoning capabilities\nin Large Language Models (LLMs) by training them to explicitly generate\nintermediate reasoning steps. While LLMs readily benefit from such techniques,\nimproving reasoning in Small Language Models (SLMs) remains challenging due to\ntheir limited model capacity. Recent work by Deepseek-R1 demonstrates that\ndistillation from LLM-generated synthetic data can substantially improve the\nreasoning ability of SLM. However, the detailed modeling recipe is not\ndisclosed. In this work, we present a systematic training recipe for SLMs that\nconsists of four steps: (1) large-scale mid-training on diverse distilled\nlong-CoT data, (2) supervised fine-tuning on high-quality long-CoT data, (3)\nRollout DPO leveraging a carefully curated preference dataset, and (4)\nReinforcement Learning (RL) with Verifiable Reward. We apply our method on\nPhi-4-Mini, a compact 3.8B-parameter model. The resulting Phi-4-Mini-Reasoning\nmodel exceeds, on math reasoning tasks, much larger reasoning models, e.g.,\noutperforming DeepSeek-R1-Distill-Qwen-7B by 3.2 points and\nDeepSeek-R1-Distill-Llama-8B by 7.7 points on Math-500. Our results validate\nthat a carefully designed training recipe, with large-scale high-quality CoT\ndata, is effective to unlock strong reasoning capabilities even in\nresource-constrained small models.", "AI": {"tldr": "A systematic training recipe for Small Language Models (SLMs) is proposed to enhance reasoning capabilities using Chain-of-Thought (CoT) data, leading to superior performance on math tasks compared to larger models.", "motivation": "To improve reasoning in Small Language Models (SLMs) which face challenges due to limited model capacity, while leveraging the benefits seen in Large Language Models (LLMs) through Chain-of-Thought (CoT) techniques.", "method": "The methodology consists of four steps: 1. Mid-training on distilled long-CoT data, 2. Supervised fine-tuning on high-quality long-CoT data, 3. Rollout DPO with a curated preference dataset, 4. Reinforcement Learning with Verifiable Reward.", "result": "The Phi-4-Mini-Reasoning model outperforms larger models on math reasoning tasks, exceeding DeepSeek-R1-Distill-Qwen-7B by 3.2 points and DeepSeek-R1-Distill-Llama-8B by 7.7 points on Math-500.", "conclusion": "A well-designed training recipe that utilizes high-quality CoT data can unlock strong reasoning capabilities in small models, demonstrating effective distillation from LLMs.", "key_contributions": ["Systematic training recipe for SLMs to enhance reasoning capabilities.", "Demonstrated performance of Phi-4-Mini-Reasoning model surpassing larger models on math tasks.", "Introduction of Rollout DPO and Reinforcement Learning approaches in the training process."], "limitations": "The detailed modeling recipe of previous works was not fully disclosed, which may limit reproducibility.", "future_work": "Further exploration of the effectiveness of the training recipe on other reasoning tasks and model types.", "keywords": ["Chain-of-Thought", "Small Language Models", "reasoning", "distillation", "reinforcement learning"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2504.21239", "pdf": "https://arxiv.org/pdf/2504.21239.pdf", "abs": "https://arxiv.org/abs/2504.21239", "title": "Memorization and Knowledge Injection in Gated LLMs", "authors": ["Xu Pan", "Ely Hahami", "Zechen Zhang", "Haim Sompolinsky"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) currently struggle to sequentially add new\nmemories and integrate new knowledge. These limitations contrast with the human\nability to continuously learn from new experiences and acquire knowledge\nthroughout life. Most existing approaches add memories either through large\ncontext windows or external memory buffers (e.g., Retrieval-Augmented\nGeneration), and studies on knowledge injection rarely test scenarios\nresembling everyday life events. In this work, we introduce a continual\nlearning framework, Memory Embedded in Gated LLMs (MEGa), which injects event\nmemories directly into the weights of LLMs. Each memory is stored in a\ndedicated set of gated low-rank weights. During inference, a gating mechanism\nactivates relevant memory weights by matching query embeddings to stored memory\nembeddings. This enables the model to both recall entire memories and answer\nrelated questions. On two datasets - fictional characters and Wikipedia events\n- MEGa outperforms baseline approaches in mitigating catastrophic forgetting.\nOur model draws inspiration from the complementary memory system of the human\nbrain.", "AI": {"tldr": "Introducing MEGa, a continual learning framework for LLMs that integrates memories into model weights to enhance knowledge retention and recall.", "motivation": "Current LLMs face challenges in sequentially adding memories and effectively integrating new knowledge, in contrast to human learning capabilities.", "method": "The study presents MEGa, a framework that embeds event memories into LLM weights, using a gating mechanism to activate relevant weights during inference based on query embeddings.", "result": "MEGa outperforms existing methods in two datasets, demonstrating improved performance in avoiding catastrophic forgetting while allowing recall of entire memories and answering related queries.", "conclusion": "The findings suggest that embedding memories in gated weights can enhance LLMs' ability to learn continuously and respond accurately to new information.", "key_contributions": ["Introduction of a new framework for continual learning in LLMs.", "Demonstrated effectiveness of the MEGa model in retaining memories over traditional memory injection methods.", "Innovative use of gated low-rank weights for memory storage and retrieval."], "limitations": "Further testing in more diverse everyday scenarios and real-world applications is needed to validate the framework's effectiveness.", "future_work": "Exploration of additional memory types and broader datasets for improved generalization and applicability.", "keywords": ["Large Language Models", "Continual Learning", "Memory Injection", "Gated Mechanism"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2504.21252", "pdf": "https://arxiv.org/pdf/2504.21252.pdf", "abs": "https://arxiv.org/abs/2504.21252", "title": "Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA", "authors": ["Xuanzhao Dong", "Wenhui Zhu", "Hao Wang", "Xiwen Chen", "Peijie Qiu", "Rui Yin", "Yi Su", "Yalin Wang"], "categories": ["cs.CL"], "comment": null, "summary": "Medical question answering (QA) is a reasoning-intensive task that remains\nchallenging for large language models (LLMs) due to hallucinations and outdated\ndomain knowledge. Retrieval-Augmented Generation (RAG) provides a promising\npost-training solution by leveraging external knowledge. However, existing\nmedical RAG systems suffer from two key limitations: (1) a lack of modeling for\nhuman-like reasoning behaviors during information retrieval, and (2) reliance\non suboptimal medical corpora, which often results in the retrieval of\nirrelevant or noisy snippets. To overcome these challenges, we propose\nDiscuss-RAG, a plug-and-play module designed to enhance the medical QA RAG\nsystem through collaborative agent-based reasoning. Our method introduces a\nsummarizer agent that orchestrates a team of medical experts to emulate\nmulti-turn brainstorming, thereby improving the relevance of retrieved content.\nAdditionally, a decision-making agent evaluates the retrieved snippets before\ntheir final integration. Experimental results on four benchmark medical QA\ndatasets show that Discuss-RAG consistently outperforms MedRAG, especially\nsignificantly improving answer accuracy by up to 16.67% on BioASQ and 12.20% on\nPubMedQA. The code is available at: https://github.com/LLM-VLM-GSL/Discuss-RAG.", "AI": {"tldr": "Discuss-RAG is a proposed module to enhance medical question answering (QA) systems by modeling human-like reasoning and improving content relevance through collaborative agent-based reasoning.", "motivation": "Medical question answering remains challenging for large language models, primarily due to hallucinations and outdated knowledge, necessitating improvements in retrieval processes.", "method": "Discuss-RAG introduces a summarizer agent and a decision-making agent to enhance the traditional RAG system by emulating collaborative brainstorming and evaluating retrieved snippets.", "result": "Discuss-RAG outperforms existing systems like MedRAG, with significant accuracy improvements of up to 16.67% on BioASQ and 12.20% on PubMedQA across various benchmark datasets.", "conclusion": "The experimental results demonstrate that Discuss-RAG effectively enhances the performance of medical QA systems, addressing key limitations of existing methods.", "key_contributions": ["Introduction of a summarizer agent to enhance relevance in medical QA.", "Development of a decision-making agent for evaluating retrieved data snippets.", "Demonstrated significant accuracy improvements on benchmark medical QA datasets."], "limitations": "The study focuses on medical QA and may not directly generalize to other domains or applications of RAG systems.", "future_work": "Further exploration of agent-based reasoning in other medical applications and enhancing the information retrieval process.", "keywords": ["medical question answering", "retrieval-augmented generation", "human-like reasoning", "AI in healthcare", "multi-turn brainstorming"], "importance_score": 9, "read_time_minutes": 8}}
{"id": "2504.21299", "pdf": "https://arxiv.org/pdf/2504.21299.pdf", "abs": "https://arxiv.org/abs/2504.21299", "title": "BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language Models", "authors": ["Zhiting Fan", "Ruizhe Chen", "Zuozhu Liu"], "categories": ["cs.CL"], "comment": null, "summary": "Identifying bias in LLM-generated content is a crucial prerequisite for\nensuring fairness in LLMs. Existing methods, such as fairness classifiers and\nLLM-based judges, face limitations related to difficulties in understanding\nunderlying intentions and the lack of criteria for fairness judgment. In this\npaper, we introduce BiasGuard, a novel bias detection tool that explicitly\nanalyzes inputs and reasons through fairness specifications to provide accurate\njudgments. BiasGuard is implemented through a two-stage approach: the first\nstage initializes the model to explicitly reason based on fairness\nspecifications, while the second stage leverages reinforcement learning to\nenhance its reasoning and judgment capabilities. Our experiments, conducted\nacross five datasets, demonstrate that BiasGuard outperforms existing tools,\nimproving accuracy and reducing over-fairness misjudgments. We also highlight\nthe importance of reasoning-enhanced decision-making and provide evidence for\nthe effectiveness of our two-stage optimization pipeline.", "AI": {"tldr": "BiasGuard is a new tool for detecting bias in LLM-generated content that uses a two-stage approach to provide accurate fairness judgments.", "motivation": "To ensure fairness in LLMs by addressing limitations of existing bias detection methods that struggle with understanding intentions and fairness criteria.", "method": "BiasGuard utilizes a two-stage approach: the first stage initializes the model to reason based on fairness specifications, and the second stage employs reinforcement learning to enhance reasoning and judgment capabilities.", "result": "Experiments across five datasets show BiasGuard outperforms existing tools in accuracy and reduces over-fairness misjudgments.", "conclusion": "BiasGuard demonstrates the importance of reasoning-enhanced decision-making in bias detection and shows the effectiveness of its two-stage optimization process.", "key_contributions": ["Introduction of BiasGuard for bias detection in LLMs.", "Two-stage reasoning approach to enhance judgment accuracy.", "Demonstration of improved performance over existing bias detection tools."], "limitations": "", "future_work": "Further refinement of BiasGuard and exploration of additional datasets for validation.", "keywords": ["bias detection", "LLM fairness", "reinforcement learning", "decision-making", "BiasGuard"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2504.21303", "pdf": "https://arxiv.org/pdf/2504.21303.pdf", "abs": "https://arxiv.org/abs/2504.21303", "title": "Confidence in Large Language Model Evaluation: A Bayesian Approach to Limited-Sample Challenges", "authors": ["Xiao Xiao", "Yu Su", "Sijing Zhang", "Zhang Chen", "Yadong Chen", "Tian Liu"], "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) exhibit probabilistic output characteristics,\nyet conventional evaluation frameworks rely on deterministic scalar metrics.\nThis study introduces a Bayesian approach for LLM capability assessment that\nintegrates prior knowledge through probabilistic inference, addressing\nlimitations under limited-sample regimes. By treating model capabilities as\nlatent variables and leveraging a curated query set to induce discriminative\nresponses, we formalize model ranking as a Bayesian hypothesis testing problem\nover mutually exclusive capability intervals. Experimental evaluations with\nGPT-series models demonstrate that the proposed method achieves superior\ndiscrimination compared to conventional evaluation methods. Results indicate\nthat even with reduced sample sizes, the approach maintains statistical\nrobustness while providing actionable insights, such as probabilistic\nstatements about a model's likelihood of surpassing specific baselines. This\nwork advances LLM evaluation methodologies by bridging Bayesian inference with\npractical constraints in real-world deployment scenarios.", "AI": {"tldr": "This study proposes a Bayesian approach for evaluating large language models (LLMs) that incorporates prior knowledge and improves assessment under limited sample conditions.", "motivation": "Conventional evaluation frameworks for LLMs rely on deterministic metrics, which do not adequately capture the probabilistic nature of their outputs.", "method": "A Bayesian hypothesis testing framework is proposed, treating model capabilities as latent variables and utilizing a curated query set for discriminative response evaluation.", "result": "The proposed Bayesian method demonstrates superior discrimination compared to traditional methods, maintaining statistical robustness even with small sample sizes while providing probabilistic insights about model performance.", "conclusion": "This work enhances LLM evaluation methodologies by integrating Bayesian inference, facilitating better assessments in real-world applications.", "key_contributions": ["Introduced a Bayesian approach for LLM evaluation", "Formalized model ranking as a hypothesis testing problem", "Demonstrated improved discrimination with fewer samples"], "limitations": "The study may require further validation across different LLM architectures beyond GPT-series models.", "future_work": "Future research could explore the application of this Bayesian framework on more diverse model architectures and real-world tasks.", "keywords": ["Bayesian inference", "large language models", "evaluation frameworks", "probabilistic output", "capability assessment"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2504.21330", "pdf": "https://arxiv.org/pdf/2504.21330.pdf", "abs": "https://arxiv.org/abs/2504.21330", "title": "Does the Prompt-based Large Language Model Recognize Students' Demographics and Introduce Bias in Essay Scoring?", "authors": ["Kaixun Yang", "Mladen Raković", "Dragan Gašević", "Guanliang Chen"], "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are widely used in Automated Essay Scoring (AES)\ndue to their ability to capture semantic meaning. Traditional fine-tuning\napproaches required technical expertise, limiting accessibility for educators\nwith limited technical backgrounds. However, prompt-based tools like ChatGPT\nhave made AES more accessible, enabling educators to obtain machine-generated\nscores using natural-language prompts (i.e., the prompt-based paradigm).\nDespite advancements, prior studies have shown bias in fine-tuned LLMs,\nparticularly against disadvantaged groups. It remains unclear whether such\nbiases persist or are amplified in the prompt-based paradigm with cutting-edge\ntools. Since such biases are believed to stem from the demographic information\nembedded in pre-trained models (i.e., the ability of LLMs' text embeddings to\npredict demographic attributes), this study explores the relationship between\nthe model's predictive power of students' demographic attributes based on their\nwritten works and its predictive bias in the scoring task in the prompt-based\nparadigm. Using a publicly available dataset of over 25,000 students'\nargumentative essays, we designed prompts to elicit demographic inferences\n(i.e., gender, first-language background) from GPT-4o and assessed fairness in\nautomated scoring. Then we conducted multivariate regression analysis to\nexplore the impact of the model's ability to predict demographics on its\nscoring outcomes. Our findings revealed that (i) prompt-based LLMs can somewhat\ninfer students' demographics, particularly their first-language backgrounds,\nfrom their essays; (ii) scoring biases are more pronounced when the LLM\ncorrectly predicts students' first-language background than when it does not;\nand (iii) scoring error for non-native English speakers increases when the LLM\ncorrectly identifies them as non-native.", "AI": {"tldr": "This study investigates bias in Automated Essay Scoring (AES) using prompt-based tools like ChatGPT, examining how demographic predictions may influence scoring fairness.", "motivation": "To evaluate the presence of bias in Automated Essay Scoring systems using large language models and the implications of these biases in educational contexts.", "method": "The study utilized a dataset of over 25,000 students' essays, designed prompts to elicit demographic inferences, and performed multivariate regression analysis to explore the relationship between demographic predictions and scoring biases.", "result": "The findings indicate that prompt-based LLMs can infer demographics from essays, with scoring biases heightened for essays from non-native English speakers when their language background is correctly identified.", "conclusion": "The research highlights significant biases in AES for non-native speakers and underscores the need for addressing these biases in prompt-based LLM applications in education.", "key_contributions": ["Exploration of biases in AES using prompt-based paradigms", "Analysis of demographic inference from student essays", "Identification of unfair scoring patterns for non-native speakers"], "limitations": "", "future_work": "Further research is needed to explore mitigation strategies for bias in AES systems and the impact on diverse student populations.", "keywords": ["Automated Essay Scoring", "Large Language Models", "Bias in Education", "Demographic Inference", "Prompt-Based Tools"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2504.21372", "pdf": "https://arxiv.org/pdf/2504.21372.pdf", "abs": "https://arxiv.org/abs/2504.21372", "title": "Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction", "authors": ["Máté Gedeon"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Speech Event Extraction (SpeechEE) is a challenging task that lies at the\nintersection of Automatic Speech Recognition (ASR) and Natural Language\nProcessing (NLP), requiring the identification of structured event information\nfrom spoken language. In this work, we present a modular, pipeline-based\nSpeechEE framework that integrates high-performance ASR with semantic\nsearch-enhanced prompting of Large Language Models (LLMs). Our system first\nclassifies speech segments likely to contain events using a hybrid filtering\nmechanism including rule-based, BERT-based, and LLM-based models. It then\nemploys few-shot LLM prompting, dynamically enriched via semantic similarity\nretrieval, to identify event triggers and extract corresponding arguments. We\nevaluate the pipeline using multiple LLMs (Llama3-8B, GPT-4o-mini, and o1-mini)\nhighlighting significant performance gains with o1-mini, which achieves 63.3%\nF1 on trigger classification and 27.8% F1 on argument classification,\noutperforming prior benchmarks. Our results demonstrate that pipeline\napproaches, when empowered by retrieval-augmented LLMs, can rival or exceed\nend-to-end systems while maintaining interpretability and modularity. This work\nprovides practical insights into LLM-driven event extraction and opens pathways\nfor future hybrid models combining textual and acoustic features.", "AI": {"tldr": "The paper presents a modular pipeline for Speech Event Extraction that integrates Automatic Speech Recognition and Natural Language Processing using Large Language Models, showing significant performance improvements over traditional benchmarks.", "motivation": "The need for effective extraction of structured event information from spoken language in a manner that combines ASR and NLP techniques.", "method": "A hybrid filtering mechanism is employed for classifying speech segments, utilizing rule-based, BERT-based, and LLM-based models, followed by few-shot prompting of LLMs enriched via semantic retrieval for event trigger and argument extraction.", "result": "The system achieves 63.3% F1 on trigger classification and 27.8% F1 on argument classification, outperforming previous benchmarks.", "conclusion": "Pipeline approaches using retrieval-augmented LLMs can surpass end-to-end systems, offering better interpretability and modularity for event extraction tasks.", "key_contributions": ["Proposed a modular, pipeline-based SpeechEE framework integrating ASR and NLP with LLMs.", "Demonstrated significant performance improvements using the o1-mini model in event classification tasks.", "Provided insights into hybrid models combining textual and acoustic features."], "limitations": "", "future_work": "Exploration of further hybrid models that integrate both textual and acoustic features for enhancing event extraction tasks.", "keywords": ["Speech Event Extraction", "Automatic Speech Recognition", "Natural Language Processing", "Large Language Models", "Semantic Search"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2504.21421", "pdf": "https://arxiv.org/pdf/2504.21421.pdf", "abs": "https://arxiv.org/abs/2504.21421", "title": "The Distribution of Dependency Distance and Hierarchical Distance in Contemporary Written Japanese and Its Influencing Factors", "authors": ["Linxuan Wang", "Shuiyuan Yu"], "categories": ["cs.CL"], "comment": "This paper has been accepted by the 13th International Quantitative\n  Linguistics Conference QUALICO 2025", "summary": "To explore the relationship between dependency distance (DD) and hierarchical\ndistance (HD) in Japanese, we compared the probability distributions of DD and\nHD with and without sentence length fixed, and analyzed the changes in mean\ndependency distance (MDD) and mean hierarchical distance (MHD) as sentence\nlength increases, along with their correlation coefficient based on the\nBalanced Corpus of Contemporary Written Japanese. It was found that the valency\nof the predicates is the underlying factor behind the trade-off relation\nbetween MDD and MHD in Japanese. Native speakers of Japanese regulate the\nlinear complexity and hierarchical complexity through the valency of the\npredicates, and the relative sizes of MDD and MHD depend on whether the\nthreshold of valency has been reached. Apart from the cognitive load, the\nvalency of the predicates also affects the probability distributions of DD and\nHD. The effect of the valency of the predicates on the distribution of HD is\ngreater than on that of DD, which leads to differences in their probability\ndistributions and causes the mean of MDD to be lower than that of MHD.", "AI": {"tldr": "This paper examines the interaction between dependency distance and hierarchical distance in Japanese sentences, highlighting the role of predicate valency in regulating complexity and distribution patterns.", "motivation": "Understanding how dependency and hierarchical distances are regulated in the Japanese language can shed light on cognitive processing mechanisms in linguistics.", "method": "The study compares probability distributions of dependency distance (DD) and hierarchical distance (HD) while controlling for sentence length, analyzing mean dependency distance (MDD) and mean hierarchical distance (MHD) using the Balanced Corpus of Contemporary Written Japanese.", "result": "The research found that the valency of predicates significantly influences the relationship between MDD and MHD, with higher valency thresholds correlating to different complexity levels in sentence structure.", "conclusion": "Cognitive load and predicate valency play crucial roles in shaping the dependency and hierarchical distances in Japanese, with implications for understanding linguistic complexity.", "key_contributions": ["Identified the trade-off relationship between MDD and MHD in Japanese based on predicate valency.", "Quantified the impact of sentence length on dependency and hierarchical distances.", "Provided evidence that valency affects the probability distributions of DD and HD differently."], "limitations": "The study is limited to the Japanese language and may not generalize to other languages or linguistic structures.", "future_work": "Future research could explore similar relationships in other languages or delve deeper into cognitive processing associated with different types of predicates.", "keywords": ["dependency distance", "hierarchical distance", "predicate valency", "Japanese linguistics", "cognitive processing"], "importance_score": 3, "read_time_minutes": 10}}
{"id": "2504.21463", "pdf": "https://arxiv.org/pdf/2504.21463.pdf", "abs": "https://arxiv.org/abs/2504.21463", "title": "RWKV-X: A Linear Complexity Hybrid Language Model", "authors": ["Haowen Hou", "Zhiyi Huang", "Kaifeng Tan", "Rongchang Lu", "Fei Richard Yu"], "categories": ["cs.CL"], "comment": "12 pages", "summary": "In this paper, we introduce \\textbf{RWKV-X}, a novel hybrid architecture that\ncombines the efficiency of RWKV for short-range modeling with a sparse\nattention mechanism designed to capture long-range context. Unlike previous\nhybrid approaches that rely on full attention layers and retain quadratic\ncomplexity, RWKV-X achieves linear-time complexity in training and\nconstant-time complexity in inference decoding. We demonstrate that RWKV-X,\nwhen continually pretrained on 64K-token sequences, achieves near-perfect\naccuracy on the 64K passkey retrieval benchmark. It consistently outperforms\nprior RWKV-7 models on long-context benchmarks, while maintaining strong\nperformance on short-context tasks. These results highlight RWKV-X as a\nscalable and efficient backbone for general-purpose language modeling, capable\nof decoding sequences up to 1 million tokens with stable speed and memory\nusage. To facilitate further research and analysis, we have made the\ncheckpoints and the associated code publicly accessible at:\nhttps://github.com/howard-hou/RWKV-X.", "AI": {"tldr": "RWKV-X is a new hybrid architecture that efficiently combines short-range modeling with sparse attention for long-range context, achieving linear-time complexity for training and constant-time for inference, and outperforms earlier models in language tasks.", "motivation": "The need for a scalable and efficient architecture for language modeling that can handle both short and long context without the complexity issues of full attention mechanisms.", "method": "RWKV-X integrates the RWKV architecture with a sparse attention mechanism, allowing it to handle long-range dependencies while maintaining linear complexity in training and constant complexity in decoding.", "result": "RWKV-X demonstrates near-perfect accuracy on a 64K passkey retrieval benchmark and outperforms previous RWKV-7 models in long-context benchmarks, while still excelling in short-context tasks.", "conclusion": "RWKV-X is a promising architecture for general-purpose language modeling, capable of efficiently handling sequences up to 1 million tokens, with consistent speed and memory usage.", "key_contributions": ["Introduces a hybrid architecture combining RWKV with sparse attention for better handling of long-range context.", "Achieves linear-time complexity for training and constant-time complexity for inference, unlike prior full attention models.", "Provides open access to code and checkpoints for further research."], "limitations": "", "future_work": "Further exploration of scalability and performance improvements, as well as applications in diverse language modeling tasks.", "keywords": ["RWKV-X", "sparse attention", "language modeling", "efficiency", "long-context"], "importance_score": 6, "read_time_minutes": 12}}
{"id": "2504.21474", "pdf": "https://arxiv.org/pdf/2504.21474.pdf", "abs": "https://arxiv.org/abs/2504.21474", "title": "Homa at SemEval-2025 Task 5: Aligning Librarian Records with OntoAligner for Subject Tagging", "authors": ["Hadi Bayrami Asl Tekanlou", "Jafar Razmara", "Mahsa Sanaei", "Mostafa Rahgouy", "Hamed Babaei Giglou"], "categories": ["cs.CL", "cs.AI"], "comment": "7 pages, 4 figures, accepted to the LLMs4Subjects shared task at\n  SemEval2025", "summary": "This paper presents our system, Homa, for SemEval-2025 Task 5: Subject\nTagging, which focuses on automatically assigning subject labels to technical\nrecords from TIBKAT using the Gemeinsame Normdatei (GND) taxonomy. We leverage\nOntoAligner, a modular ontology alignment toolkit, to address this task by\nintegrating retrieval-augmented generation (RAG) techniques. Our approach\nformulates the subject tagging problem as an alignment task, where records are\nmatched to GND categories based on semantic similarity. We evaluate\nOntoAligner's adaptability for subject indexing and analyze its effectiveness\nin handling multilingual records. Experimental results demonstrate the\nstrengths and limitations of this method, highlighting the potential of\nalignment techniques for improving subject tagging in digital libraries.", "AI": {"tldr": "Homa is a system for subject tagging that uses ontology alignment and retrieval-augmented generation techniques to match technical records with the GND taxonomy for improved subject indexing.", "motivation": "The paper addresses the need for effective subject tagging of technical records to enhance information retrieval in digital libraries.", "method": "The authors employ OntoAligner for ontology alignment, framing the subject tagging as a semantic similarity alignment task between records and GND categories.", "result": "Experimental results show the method's effectiveness in subject indexing and its adaptability with multilingual records, reflecting both strengths and limitations.", "conclusion": "Alignment techniques hold potential for enhancing subject tagging systems in digital libraries, leveraging ontology and semantic similarity.", "key_contributions": ["Introduction of Homa system for subject tagging", "Application of retrieval-augmented generation techniques", "Evaluation of OntoAligner's effectiveness in multilingual contexts."], "limitations": "The paper discusses limitations in the system's adaptability and effectiveness with diverse record types.", "future_work": "Future research may focus on improving alignment techniques and expanding the applicability of the system to additional contexts.", "keywords": ["subject tagging", "ontology alignment", "retrieval-augmented generation", "multilingual records", "digital libraries"], "importance_score": 5, "read_time_minutes": 10}}
{"id": "2504.21475", "pdf": "https://arxiv.org/pdf/2504.21475.pdf", "abs": "https://arxiv.org/abs/2504.21475", "title": "Advancing Arabic Reverse Dictionary Systems: A Transformer-Based Approach with Dataset Construction Guidelines", "authors": ["Serry Sibaee", "Samar Ahmed", "Abdullah Al Harbi", "Omer Nacar", "Adel Ammar", "Yasser Habashi", "Wadii Boulila"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "This study addresses the critical gap in Arabic natural language processing\nby developing an effective Arabic Reverse Dictionary (RD) system that enables\nusers to find words based on their descriptions or meanings. We present a novel\ntransformer-based approach with a semi-encoder neural network architecture\nfeaturing geometrically decreasing layers that achieves state-of-the-art\nresults for Arabic RD tasks. Our methodology incorporates a comprehensive\ndataset construction process and establishes formal quality standards for\nArabic lexicographic definitions. Experiments with various pre-trained models\ndemonstrate that Arabic-specific models significantly outperform general\nmultilingual embeddings, with ARBERTv2 achieving the best ranking score\n(0.0644). Additionally, we provide a formal abstraction of the reverse\ndictionary task that enhances theoretical understanding and develop a modular,\nextensible Python library (RDTL) with configurable training pipelines. Our\nanalysis of dataset quality reveals important insights for improving Arabic\ndefinition construction, leading to eight specific standards for building\nhigh-quality reverse dictionary resources. This work contributes significantly\nto Arabic computational linguistics and provides valuable tools for language\nlearning, academic writing, and professional communication in Arabic.", "AI": {"tldr": "This study presents an Arabic Reverse Dictionary system using a novel transformer-based approach to improve Arabic natural language processing.", "motivation": "To address the critical gap in Arabic natural language processing and facilitate word retrieval based on meanings or descriptions.", "method": "A novel transformer-based approach with a semi-encoder neural network architecture and a comprehensive dataset construction process for Arabic RD tasks.", "result": "Experiments show that Arabic-specific models outperform general multilingual embeddings, with ARBERTv2 achieving the best ranking score.", "conclusion": "The work contributes significantly to Arabic computational linguistics, providing valuable tools for language learning and professional communication.", "key_contributions": ["Development of an Arabic Reverse Dictionary system using a transformer-based model.", "Establishment of formal quality standards for Arabic lexicographic definitions.", "Creation of a modular Python library (RDTL) for configurable training pipelines."], "limitations": "", "future_work": "Future research might explore enhancements in dataset quality and more applications of the reverse dictionary approach in other languages.", "keywords": ["Arabic natural language processing", "reverse dictionary", "transformer model"], "importance_score": 5, "read_time_minutes": 10}}
{"id": "2504.21540", "pdf": "https://arxiv.org/pdf/2504.21540.pdf", "abs": "https://arxiv.org/abs/2504.21540", "title": "Improving Informally Romanized Language Identification", "authors": ["Adrian Benton", "Alexander Gutkin", "Christo Kirov", "Brian Roark"], "categories": ["cs.CL"], "comment": "16 pages, 14 tables, 4 figures", "summary": "The Latin script is often used to informally write languages with non-Latin\nnative scripts. In many cases (e.g., most languages in India), there is no\nconventional spelling of words in the Latin script, hence there will be high\nspelling variability in written text. Such romanization renders languages that\nare normally easily distinguished based on script highly confusable, such as\nHindi and Urdu. In this work, we increase language identification (LID)\naccuracy for romanized text by improving the methods used to synthesize\ntraining sets. We find that training on synthetic samples which incorporate\nnatural spelling variation yields higher LID system accuracy than including\navailable naturally occurring examples in the training set, or even training\nhigher capacity models. We demonstrate new state-of-the-art LID performance on\nromanized text from 20 Indic languages in the Bhasha-Abhijnaanam evaluation set\n(Madhani et al., 2023a), improving test F1 from the reported 74.7% (using a\npretrained neural model) to 85.4% using a linear classifier trained solely on\nsynthetic data and 88.2% when also training on available harvested text.", "AI": {"tldr": "This paper discusses improving language identification accuracy for romanized text of Indic languages by synthesizing training sets that incorporate natural spelling variations.", "motivation": "The paper addresses the challenges of language identification for languages that are informally written in Latin script, highlighting the high variability in spelling that confuses language detection systems.", "method": "The authors synthesize training sets that include natural spelling variation and compare the performance of language identification systems trained on these synthetic samples against those trained on naturally occurring examples and higher capacity models.", "result": "The study achieves state-of-the-art language identification performance for 20 Indic languages, improving the F1 score from 74.7% to 85.4% using a linear classifier on synthetic data, and up to 88.2% when including harvested text.", "conclusion": "The findings suggest that incorporating synthetic samples with natural spelling variations significantly enhances language identification accuracy for romanized versions of Indic languages.", "key_contributions": ["Introduction of synthetic training sets that consider natural spelling variation for LID.", "Demonstration of state-of-the-art performance for LID in romanized Indic languages.", "Potential framework for improving LID in multi-script languages."], "limitations": "", "future_work": "Future research could explore further integrations of different types of data for LID and test the methods on other language pairs beyond Indic languages.", "keywords": ["Language Identification", "Romanization", "Indic Languages", "Natural Language Processing", "Machine Learning"], "importance_score": 6, "read_time_minutes": 16}}
{"id": "2504.21547", "pdf": "https://arxiv.org/pdf/2504.21547.pdf", "abs": "https://arxiv.org/abs/2504.21547", "title": "TartuNLP at SemEval-2025 Task 5: Subject Tagging as Two-Stage Information Retrieval", "authors": ["Aleksei Dorkin", "Kairit Sirts"], "categories": ["cs.CL"], "comment": "To appear in the Proceedings of the 19th International Workshop on\n  Semantic Evaluation (SemEval-2025)", "summary": "We present our submission to the Task 5 of SemEval-2025 that aims to aid\nlibrarians in assigning subject tags to the library records by producing a list\nof likely relevant tags for a given document. We frame the task as an\ninformation retrieval problem, where the document content is used to retrieve\nsubject tags from a large subject taxonomy. We leverage two types of encoder\nmodels to build a two-stage information retrieval system -- a bi-encoder for\ncoarse-grained candidate extraction at the first stage, and a cross-encoder for\nfine-grained re-ranking at the second stage. This approach proved effective,\ndemonstrating significant improvements in recall compared to single-stage\nmethods and showing competitive results according to qualitative evaluation.", "AI": {"tldr": "A two-stage information retrieval system is proposed for assigning subject tags to library records, utilizing bi-encoders for candidate extraction and cross-encoders for re-ranking.", "motivation": "The project aims to enhance the tagging process for librarians by efficiently generating relevant subject tags for documents using an information retrieval framework.", "method": "The system employs a two-stage approach: firstly, a bi-encoder model retrieves a broad set of candidate tags, and secondly, a cross-encoder refines the selection through fine-grained re-ranking.", "result": "The two-stage method leads to significant improvements in recall over traditional single-stage methods, and it yields competitive results in qualitative assessments.", "conclusion": "The proposed information retrieval system effectively aids librarians in tagging documents, suggesting an advancement in library science practices.", "key_contributions": ["Introduction of a two-stage retrieval system for tagging library records", "Demonstration of improved recall and qualitative results compared to existing methods", "Application of bi-encoder and cross-encoder models in library tag assignment"], "limitations": "", "future_work": "Exploration of further improvements in tag relevance and retrieval efficiency, including potential integration with existing library systems.", "keywords": ["information retrieval", "subject tagging", "bi-encoder", "cross-encoder", "librarians"], "importance_score": 4, "read_time_minutes": 5}}
{"id": "2504.21553", "pdf": "https://arxiv.org/pdf/2504.21553.pdf", "abs": "https://arxiv.org/abs/2504.21553", "title": "Precision Where It Matters: A Novel Spike Aware Mixed-Precision Quantization Strategy for LLaMA-based Language Models", "authors": ["Lucas Maisonnave", "Cyril Moineau", "Olivier Bichler", "Fabrice Rastello"], "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious natural language processing tasks. However, their size presents\nsignificant challenges for deployment and inference. This paper investigates\nthe quantization of LLMs, focusing on the LLaMA architecture and its\nderivatives. We challenge existing assumptions about activation outliers in\nLLMs and propose a novel mixed-precision quantization approach tailored for\nLLaMA-like models. Our method leverages the observation that activation spikes\nin LLaMA architectures are predominantly concentrated in specific projection\nlayers. By applying higher precision (FP16 or FP8) to these layers while\nquantizing the rest of the model to lower bit-widths, we achieve superior\nperformance compared to existing quantization techniques. Experimental results\non LLaMA2, LLaMA3, and Mistral models demonstrate significant improvements in\nperplexity and zero-shot accuracy, particularly for 8-bit per-tensor\nquantization. Our approach outperforms general-purpose methods designed to\nhandle outliers across all architecture types, highlighting the benefits of\narchitecture-specific quantization strategies. This research contributes to the\nongoing efforts to make LLMs more efficient and deployable, potentially\nenabling their use in resource-constrained environments. Our findings emphasize\nthe importance of considering model-specific characteristics in developing\neffective quantization pipelines for state-of-the-art language models by\nidentifying and targeting a small number of projections that concentrate\nactivation spikes.", "AI": {"tldr": "This paper presents a novel mixed-precision quantization approach for LLaMA-like LLMs, improving efficiency and performance in resource-constrained environments.", "motivation": "The size of large language models (LLMs) poses significant challenges for their deployment and inference.", "method": "The authors propose a mixed-precision quantization approach that applies higher precision to specific projection layers while quantizing the rest of the model to lower bit-widths.", "result": "Experimental results show significant improvements in perplexity and zero-shot accuracy for LLaMA2, LLaMA3, and Mistral models using 8-bit per-tensor quantization compared to existing methods.", "conclusion": "Architecture-specific quantization strategies can enhance the efficiency and performance of LLMs, making them better suited for deployment in resource-constrained environments.", "key_contributions": ["Novel mixed-precision quantization approach tailored for LLaMA architectures", "Identification of activation spikes concentrated in specific projection layers", "Demonstrated improvements in performance metrics for LLaMA-like models"], "limitations": "", "future_work": "Further exploration of quantization techniques tailored to other model architectures and their deployment under various constraints.", "keywords": ["Large Language Models", "Quantization", "LLaMA architecture", "Mixed-precision", "Natural Language Processing"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2504.21589", "pdf": "https://arxiv.org/pdf/2504.21589.pdf", "abs": "https://arxiv.org/abs/2504.21589", "title": "DNB-AI-Project at SemEval-2025 Task 5: An LLM-Ensemble Approach for Automated Subject Indexing", "authors": ["Lisa Kluge", "Maximilian Kähler"], "categories": ["cs.CL", "cs.AI", "cs.DL", "I.2.7"], "comment": "11 pages, 4 figures, submitted to SemEval-2025 workshop Task 5:\n  LLMs4Subjects", "summary": "This paper presents our system developed for the SemEval-2025 Task 5:\nLLMs4Subjects: LLM-based Automated Subject Tagging for a National Technical\nLibrary's Open-Access Catalog. Our system relies on prompting a selection of\nLLMs with varying examples of intellectually annotated records and asking the\nLLMs to similarly suggest keywords for new records. This few-shot prompting\ntechnique is combined with a series of post-processing steps that map the\ngenerated keywords to the target vocabulary, aggregate the resulting subject\nterms to an ensemble vote and, finally, rank them as to their relevance to the\nrecord. Our system is fourth in the quantitative ranking in the all-subjects\ntrack, but achieves the best result in the qualitative ranking conducted by\nsubject indexing experts.", "AI": {"tldr": "Development of a system for automated subject tagging using LLMs for a technical library's catalog.", "motivation": "To enhance keyword generation for open-access catalogs using LLMs, improving subject tagging accuracy.", "method": "Utilizing few-shot prompting with LLMs and implementing post-processing steps for keyword mapping, aggregation, and ranking.", "result": "Achieved fourth place in quantitative evaluation and best results in qualitative evaluation by subject indexing experts.", "conclusion": "The system demonstrates the effectiveness of LLMs for keyword suggestion in library contexts.", "key_contributions": ["Implementation of few-shot prompting with LLMs for keyword generation.", "Post-processing techniques for keyword mapping and aggregation.", "Quantitative and qualitative evaluation results highlighting system performance."], "limitations": "Limited testing on diverse datasets beyond the technical library context.", "future_work": "Expanding the system's application to more varied datasets and improving LLM training techniques.", "keywords": ["LLMs", "subject tagging", "keyword generation", "open-access catalog", "SemEval-2025"], "importance_score": 9, "read_time_minutes": 11}}
{"id": "2504.21604", "pdf": "https://arxiv.org/pdf/2504.21604.pdf", "abs": "https://arxiv.org/abs/2504.21604", "title": "Robust Misinformation Detection by Visiting Potential Commonsense Conflict", "authors": ["Bing Wang", "Ximing Li", "Changchun Li", "Bingrui Zhao", "Bo Fu", "Renchu Guan", "Shengsheng Wang"], "categories": ["cs.CL", "cs.CY"], "comment": "11 pages, 2 figures. Accepted by IJCAI 2025. Code:\n  https://github.com/wangbing1416/MD-PCC", "summary": "The development of Internet technology has led to an increased prevalence of\nmisinformation, causing severe negative effects across diverse domains. To\nmitigate this challenge, Misinformation Detection (MD), aiming to detect online\nmisinformation automatically, emerges as a rapidly growing research topic in\nthe community. In this paper, we propose a novel plug-and-play augmentation\nmethod for the MD task, namely Misinformation Detection with Potential\nCommonsense Conflict (MD-PCC). We take inspiration from the prior studies\nindicating that fake articles are more likely to involve commonsense conflict.\nAccordingly, we construct commonsense expressions for articles, serving to\nexpress potential commonsense conflicts inferred by the difference between\nextracted commonsense triplet and golden ones inferred by the well-established\ncommonsense reasoning tool COMET. These expressions are then specified for each\narticle as augmentation. Any specific MD methods can be then trained on those\ncommonsense-augmented articles. Besides, we also collect a novel\ncommonsense-oriented dataset named CoMis, whose all fake articles are caused by\ncommonsense conflict. We integrate MD-PCC with various existing MD backbones\nand compare them across both 4 public benchmark datasets and CoMis. Empirical\nresults demonstrate that MD-PCC can consistently outperform the existing MD\nbaselines.", "AI": {"tldr": "Proposes a novel method for misinformation detection by leveraging commonsense conflicts in texts.", "motivation": "To address the growing challenge of online misinformation which has significant negative impacts.", "method": "Introduces the MD-PCC method that constructs commonsense expressions for articles to detect potential conflicts; develops a commonsense-oriented dataset named CoMis.", "result": "Empirical results show that MD-PCC consistently outperforms existing misinformation detection baselines across multiple benchmark datasets.", "conclusion": "MD-PCC provides a promising approach to enhance misinformation detection using commonsense reasoning.", "key_contributions": ["Introduction of a novel augmentation method for misinformation detection (MD-PCC)", "Creation of a new commonsense-oriented dataset (CoMis) focusing on commonsense conflicts", "Integration and performance testing of MD-PCC with existing misinformation detection frameworks"], "limitations": "The applicability may depend on the quality of commonsense knowledge available and the diversity of the dataset.", "future_work": "Exploration of further commonsense reasoning techniques to improve detection capabilities and expansion of the dataset for broader application.", "keywords": ["Misinformation Detection", "Commonsense Reasoning", "Machine Learning", "Natural Language Processing", "Dataset CoMis"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2504.21605", "pdf": "https://arxiv.org/pdf/2504.21605.pdf", "abs": "https://arxiv.org/abs/2504.21605", "title": "RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations", "authors": ["Jonas Gwozdz", "Andreas Both"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) increasingly serve as knowledge interfaces, yet\nsystematically assessing their reliability with conflicting information remains\ndifficult. We propose an RDF-based framework to assess multilingual LLM\nquality, focusing on knowledge conflicts. Our approach captures model responses\nacross four distinct context conditions (complete, incomplete, conflicting, and\nno-context information) in German and English. This structured representation\nenables the comprehensive analysis of knowledge leakage-where models favor\ntraining data over provided context-error detection, and multilingual\nconsistency. We demonstrate the framework through a fire safety domain\nexperiment, revealing critical patterns in context prioritization and\nlanguage-specific performance, and demonstrating that our vocabulary was\nsufficient to express every assessment facet encountered in the 28-question\nstudy.", "AI": {"tldr": "This paper presents an RDF-based framework for assessing the reliability of multilingual LLMs, particularly in handling conflicting information.", "motivation": "There is a need for systematic assessment of LLM reliability when they face conflicting information, as current methods are inadequate.", "method": "The framework analyzes model responses in four context scenarios: complete, incomplete, conflicting, and no-context, specifically for German and English.", "result": "The experiment in the fire safety domain revealed significant insights into how context prioritization varies and the performance disparities between languages.", "conclusion": "The proposed framework successfully identifies knowledge conflicts and encourages future assessments in various domains using LLMs.", "key_contributions": ["Introduction of an RDF-based framework for assessing multilingual LLM reliability", "Identification of context prioritization patterns in LLM responses", "Demonstration of language-specific performance variations in LLMs"], "limitations": "The study is limited to the fire safety domain and may not generalize to other contexts without further validation.", "future_work": "Future research should extend the framework to diverse domains and further explore language-specific performance and context handling.", "keywords": ["Large Language Models", "Assessment Framework", "Multilingual LLM Quality"], "importance_score": 8, "read_time_minutes": 7}}
{"id": "2504.21625", "pdf": "https://arxiv.org/pdf/2504.21625.pdf", "abs": "https://arxiv.org/abs/2504.21625", "title": "Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn Instruction-Following Ability", "authors": ["Jiaming Wang"], "categories": ["cs.CL"], "comment": null, "summary": "The ability to follow instructions accurately is fundamental for Large\nLanguage Models (LLMs) to serve as reliable agents in real-world applications.\nWhile existing instruction-following benchmarks are either single-turn or\nintroduce new requirements in each turn without allowing self-correction,\nMeeseeks simulates realistic human-LLM interactions through an iterative\nfeedback process. This design enables models to self-correct based on specific\nrequirement failures, better reflecting real-world user-end usage patterns. The\nbenchmark implements a comprehensive evaluation system with 38 capability tags\norganized across three dimensions: Intent Recognition, Granular Content\nValidation, and Output Structure Validation. Through rigorous evaluation across\nLLMs, Meeseeks provides valuable insights into LLMs' instruction-following\ncapabilities in practical applications.", "AI": {"tldr": "Meeseeks is a benchmark for evaluating LLMs' instruction-following abilities through iterative feedback and self-correction, reflecting practical user interactions.", "motivation": "The reliance on accurate instruction-following in real-world applications of LLMs demands a benchmark that closely simulates human-LLM interactions.", "method": "Meeseeks features an iterative feedback process that allows LLMs to self-correct based on specific failures, with a structured evaluation of 38 capability tags across three dimensions.", "result": "Evaluation across LLMs using Meeseeks highlights significant insights into their instruction-following capabilities and discrepancies in performance based on user-like interactions.", "conclusion": "Meeseeks offers a new approach for benchmarking LLMs, demonstrating that iterative feedback mechanisms can enhance the reliability of instruction-following in practical applications.", "key_contributions": ["Introduces an iterative feedback mechanism for LLM evaluation.", "Organizes capabilities into three evaluative dimensions.", "Provides a comprehensive set of 38 capability tags for instruction-following assessment."], "limitations": "", "future_work": "Exploration of further capabilities and potential improvements in LLM self-correction during instruction-following tasks.", "keywords": ["Large Language Models", "instruction-following", "benchmark"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2504.21635", "pdf": "https://arxiv.org/pdf/2504.21635.pdf", "abs": "https://arxiv.org/abs/2504.21635", "title": "Sadeed: Advancing Arabic Diacritization Through Small Language Model", "authors": ["Zeina Aldallal", "Sara Chrouf", "Khalil Hennara", "Mohamed Motaism Hamed", "Muhammad Hreden", "Safwan AlModhayan"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Arabic text diacritization remains a persistent challenge in natural language\nprocessing due to the language's morphological richness. In this paper, we\nintroduce Sadeed, a novel approach based on a fine-tuned decoder-only language\nmodel adapted from Kuwain 1.5B Hennara et al. [2025], a compact model\noriginally trained on diverse Arabic corpora. Sadeed is fine-tuned on carefully\ncurated, high-quality diacritized datasets, constructed through a rigorous\ndata-cleaning and normalization pipeline. Despite utilizing modest\ncomputational resources, Sadeed achieves competitive results compared to\nproprietary large language models and outperforms traditional models trained on\nsimilar domains. Additionally, we highlight key limitations in current\nbenchmarking practices for Arabic diacritization. To address these issues, we\nintroduce SadeedDiac-25, a new benchmark designed to enable fairer and more\ncomprehensive evaluation across diverse text genres and complexity levels.\nTogether, Sadeed and SadeedDiac-25 provide a robust foundation for advancing\nArabic NLP applications, including machine translation, text-to-speech, and\nlanguage learning tools.", "AI": {"tldr": "Sadeed is a fine-tuned language model for Arabic text diacritization that achieves competitive results with modest resources and introduces a new benchmark for evaluation.", "motivation": "To tackle the challenges of Arabic text diacritization, which is complicated by the language's morphological richness.", "method": "Sadeed is based on a fine-tuned decoder-only language model adapted from Kuwain 1.5B, trained on high-quality diacritized datasets through a rigorous data-cleaning pipeline.", "result": "Sadeed achieves results competitive with proprietary models and outperforms traditional methods; introduces SadeedDiac-25 as a new benchmark for fair evaluation.", "conclusion": "Sadeed and SadeedDiac-25 collectively advance Arabic NLP applications, aiding fields like machine translation and language learning.", "key_contributions": ["Introduction of Sadeed, a novel model for Arabic text diacritization.", "Development of SadeedDiac-25 benchmark for better evaluation metrics.", "Rigorous data-cleaning approach for dataset curation."], "limitations": "Highlights existing limitations in current benchmarking practices for Arabic diacritization.", "future_work": "Improving evaluation metrics and exploring further applications of Sadeed in various Arabic NLP tasks.", "keywords": ["Arabic NLP", "diacritization", "language model", "benchmark", "machine translation"], "importance_score": 6, "read_time_minutes": 15}}
{"id": "2504.21677", "pdf": "https://arxiv.org/pdf/2504.21677.pdf", "abs": "https://arxiv.org/abs/2504.21677", "title": "20min-XD: A Comparable Corpus of Swiss News Articles", "authors": ["Michelle Wastl", "Jannis Vamvas", "Selena Calleri", "Rico Sennrich"], "categories": ["cs.CL"], "comment": "10 pages; accepted at SwissText 2025", "summary": "We present 20min-XD (20 Minuten cross-lingual document-level), a\nFrench-German, document-level comparable corpus of news articles, sourced from\nthe Swiss online news outlet 20 Minuten/20 minutes. Our dataset comprises\naround 15,000 article pairs spanning 2015 to 2024, automatically aligned based\non semantic similarity. We detail the data collection process and alignment\nmethodology. Furthermore, we provide a qualitative and quantitative analysis of\nthe corpus. The resulting dataset exhibits a broad spectrum of cross-lingual\nsimilarity, ranging from near-translations to loosely related articles, making\nit valuable for various NLP applications and broad linguistically motivated\nstudies. We publicly release the dataset in document- and sentence-aligned\nversions and code for the described experiments.", "AI": {"tldr": "20min-XD is a French-German, document-level comparable corpus of news articles comprising around 15,000 article pairs. It aims to support various NLP applications.", "motivation": "To provide a resource for NLP applications and linguistically motivated studies through a cross-lingual dataset.", "method": "Articles were sourced from the Swiss online news outlet 20 Minuten/20 minutes and automatically aligned based on semantic similarity.", "result": "The dataset shows a wide range of cross-lingual similarities, making it suitable for various applications in NLP.", "conclusion": "The released dataset will support research in cross-lingual NLP and similar studies.", "key_contributions": ["Creation of a large French-German document-level comparable corpus", ".", "Release of both document- and sentence-aligned versions with accompanying code."], "limitations": "", "future_work": "Further exploration of the dataset's applications in different NLP tasks and studies.", "keywords": ["cross-lingual", "NLP", "comparable corpus", "semantic similarity", "news articles"], "importance_score": 4, "read_time_minutes": 10}}
{"id": "2504.21681", "pdf": "https://arxiv.org/pdf/2504.21681.pdf", "abs": "https://arxiv.org/abs/2504.21681", "title": "Investigating the Effect of Parallel Data in the Cross-Lingual Transfer for Vision-Language Encoders", "authors": ["Andrei-Alexandru Manea", "Jindřich Libovický"], "categories": ["cs.CL"], "comment": null, "summary": "Most pre-trained Vision-Language (VL) models and training data for the\ndownstream tasks are only available in English. Therefore, multilingual VL\ntasks are solved using cross-lingual transfer: fine-tune a multilingual\npre-trained model or transfer the text encoder using parallel data. We study\nthe alternative approach: transferring an already trained encoder using\nparallel data. We investigate the effect of parallel data: domain and the\nnumber of languages, which were out of focus in previous work. Our results show\nthat even machine-translated task data are the best on average, caption-like\nauthentic parallel data outperformed it in some languages. Further, we show\nthat most languages benefit from multilingual training.", "AI": {"tldr": "The paper investigates the effectiveness of transferring a pre-trained Vision-Language encoder using parallel data across multiple languages, emphasizing the impact of the size and domain of the parallel data used.", "motivation": "To address the limited availability of pre-trained Vision-Language models and datasets in languages other than English, and to explore alternative approaches to multilingual tasks.", "method": "The study evaluates the performance of multilingual Vision-Language models by transferring a trained encoder using various types of parallel data, including machine-translated and authentic caption-like data.", "result": "The results indicate that while machine-translated task data perform well on average, authentic parallel data tends to outperform it in certain languages, showing that most languages indeed benefit from multilingual training.", "conclusion": "The findings suggest that the choice of parallel data is crucial for optimizing multilingual Vision-Language tasks, and that various languages can achieve improvements through dedicated multilingual training efforts.", "key_contributions": ["Introduces an alternative approach for multilingual VL tasks by transferring an already trained encoder.", "Analyzes the effect of parallel data's domain and the number of languages on model performance.", "Demonstrates the effectiveness of authentic parallel data over machine-translated data in specific contexts."], "limitations": "The study may be limited by the specific languages and domains analyzed, which may not generalize to all scenarios.", "future_work": "Future research could investigate additional language pairs and larger datasets to further validate the findings and optimize parallel data selection.", "keywords": ["Vision-Language models", "multilingual tasks", "parallel data"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2504.21685", "pdf": "https://arxiv.org/pdf/2504.21685.pdf", "abs": "https://arxiv.org/abs/2504.21685", "title": "Enhancing Health Mention Classification Performance: A Study on Advancements in Parameter Efficient Tuning", "authors": ["Reem Abdel-Salam", "Mary Adewunmi"], "categories": ["cs.CL", "cs.AI"], "comment": "10 pages", "summary": "Health Mention Classification (HMC) plays a critical role in leveraging\nsocial media posts for real-time tracking and public health monitoring.\nNevertheless, the process of HMC presents significant challenges due to its\nintricate nature, primarily stemming from the contextual aspects of health\nmentions, such as figurative language and descriptive terminology, rather than\nexplicitly reflecting a personal ailment. To address this problem, we argue\nthat clearer mentions can be achieved through conventional fine-tuning with\nenhanced parameters of biomedical natural language methods (NLP). In this\nstudy, we explore different techniques such as the utilisation of\npart-of-speech (POS) tagger information, improving on PEFT techniques, and\ndifferent combinations thereof. Extensive experiments are conducted on three\nwidely used datasets: RHDM, PHM, and Illness. The results incorporated POS\ntagger information, and leveraging PEFT techniques significantly improves\nperformance in terms of F1-score compared to state-of-the-art methods across\nall three datasets by utilising smaller models and efficient training.\nFurthermore, the findings highlight the effectiveness of incorporating POS\ntagger information and leveraging PEFT techniques for HMC. In conclusion, the\nproposed methodology presents a potentially effective approach to accurately\nclassifying health mentions in social media posts while optimising the model\nsize and training efficiency.", "AI": {"tldr": "This paper discusses the challenges of Health Mention Classification in social media and proposes a methodology that improves classification accuracy using POS tagger information and PEFT techniques.", "motivation": "To leverage social media posts for real-time public health monitoring by improving Health Mention Classification (HMC).", "method": "The study employs conventional fine-tuning with enhanced parameters of biomedical natural language methods, utilizing part-of-speech tagger information and improving PEFT techniques.", "result": "Using the proposed method, significant improvements in F1-score were observed across three datasets (RHDM, PHM, and Illness), outperforming state-of-the-art methods.", "conclusion": "The proposed methodology effectively classifies health mentions in social media with optimized model size and training efficiency.", "key_contributions": ["Improved HMC through the use of POS tagger information.", "Enhanced performance with PEFT techniques.", "Successful experimentation on multiple datasets."], "limitations": "", "future_work": "", "keywords": ["Health Mention Classification", "natural language processing", "public health monitoring"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2504.21742", "pdf": "https://arxiv.org/pdf/2504.21742.pdf", "abs": "https://arxiv.org/abs/2504.21742", "title": "Investigating Literary Motifs in Ancient and Medieval Novels with Large Language Models", "authors": ["Emelie Hallenberg"], "categories": ["cs.CL"], "comment": null, "summary": "The Greek fictional narratives often termed love novels or romances, ranging\nfrom the first century CE to the middle of the 15th century, have long been\nconsidered as similar in many ways, not least in the use of particular literary\nmotifs. By applying the use of fine-tuned large language models, this study\naims to investigate which motifs exactly that the texts in this corpus have in\ncommon, and in which ways they differ from each other. The results show that\nwhile some motifs persist throughout the corpus, others fluctuate in frequency,\nindicating certain trends or external influences. Conclusively, the method\nproves to adequately extract literary motifs according to a set definition,\nproviding data for both quantitative and qualitative analyses.", "AI": {"tldr": "This study investigates the common and differing literary motifs in Greek love novels from the first century CE to the 15th century using fine-tuned large language models.", "motivation": "To explore the similarities and differences in literary motifs in Greek romantic narratives across centuries.", "method": "The study employs fine-tuned large language models to analyze a corpus of Greek fictional love novels for motif identification.", "result": "The analysis reveals persistent and fluctuating motifs, indicating trends and external influences over time.", "conclusion": "The method effectively extracts a defined set of literary motifs, facilitating both quantitative and qualitative analysis.", "key_contributions": ["Application of large language models in literary analysis", "Identification of common and differing motifs across time periods", "Quantitative data supporting qualitative insights in literary studies."], "limitations": "", "future_work": "Further exploration of external influences on motif trends and expansion of the analysis to other literary genres or periods.", "keywords": ["literary motifs", "Greek love novels", "large language models"], "importance_score": 2, "read_time_minutes": 10}}
{"id": "2504.21747", "pdf": "https://arxiv.org/pdf/2504.21747.pdf", "abs": "https://arxiv.org/abs/2504.21747", "title": "Improving Retrieval-Augmented Neural Machine Translation with Monolingual Data", "authors": ["Maxime Bouthors", "Josep Crego", "François Yvon"], "categories": ["cs.CL", "I.2.7"], "comment": "13 pages", "summary": "Conventional retrieval-augmented neural machine translation (RANMT) systems\nleverage bilingual corpora, e.g., translation memories (TMs). Yet, in many\nsettings, in-domain monolingual target-side corpora are often available. This\nwork explores ways to take advantage of such resources by retrieving relevant\nsegments directly in the target language, based on a source-side query. For\nthis, we design improved cross-lingual retrieval systems, trained with both\nsentence level and word-level matching objectives. In our experiments with two\nRANMT architectures, we first demonstrate the benefits of such cross-lingual\nobjectives in a controlled setting, obtaining translation performances that\nsurpass standard TM-based models. We then showcase our method on a real-world\nset-up, where the target monolingual resources far exceed the amount of\nparallel data and observe large improvements of our new techniques, which\noutperform both the baseline setting, and general-purpose cross-lingual\nretrievers.", "AI": {"tldr": "This paper improves retrieval-augmented neural machine translation (RANMT) by utilizing in-domain monolingual target-side corpora for translation, outperforming traditional translation memories.", "motivation": "To leverage the abundance of in-domain monolingual target-side corpora for improving translation quality in RANMT systems, as conventional methods rely heavily on bilingual corpora.", "method": "The authors designed advanced cross-lingual retrieval systems with both sentence-level and word-level matching objectives to retrieve relevant segments in the target language based on source-side queries.", "result": "Experiments demonstrated that the proposed cross-lingual retrieval objectives significantly enhance translation performance over traditional translation memory-based models, particularly in scenarios where monolingual resources are abundant.", "conclusion": "The new techniques developed allow for better utilization of target-side monolingual corpora, leading to performance improvements in real-world settings compared to baseline and general-purpose cross-lingual retrievers.", "key_contributions": ["Introduction of cross-lingual retrieval systems for RANMT", "Implementation of sentence-level and word-level matching objectives", "Demonstrated performance improvements using monolingual target-side corpora"], "limitations": "The paper does not address the potential drawbacks of using monolingual resources, such as the quality and relevance of the retrieved segments in practical applications.", "future_work": "Future research could explore further optimization of retrieval systems and their integration into various translation tasks.", "keywords": ["neural machine translation", "retrieval-augmented", "cross-lingual", "monolingual corpora", "translation performance"], "importance_score": 6, "read_time_minutes": 13}}
{"id": "2504.21773", "pdf": "https://arxiv.org/pdf/2504.21773.pdf", "abs": "https://arxiv.org/abs/2504.21773", "title": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness", "authors": ["Junsheng Huang", "Zhitao He", "Sandeep Polisetty", "Qingyun Wang", "May Fung"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "With the widespread application of large language models (LLMs), the issue of\ngenerating non-existing facts, known as hallucination, has garnered increasing\nattention. Previous research in enhancing LLM confidence estimation mainly\nfocuses on the single problem setting. However, LLM awareness of its internal\nparameterized knowledge boundary under the more challenging multi-problem\nsetting, which requires answering multiple problems accurately simultaneously,\nremains underexplored. To bridge this gap, we introduce a novel method,\nMultiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates\nthe learning of answer prediction and confidence estimation during fine-tuning\non instruction data. Extensive experiments demonstrate that our method\noutperforms baselines by up to 25% in average precision.", "AI": {"tldr": "The paper introduces MAC-Tuning, a novel approach for improving confidence estimation in LLMs during multi-problem settings, addressing hallucination issues.", "motivation": "With the rise of LLMs, hallucinations (generating false information) have become a significant concern that this research aims to mitigate, particularly in multi-problem environments.", "method": "The proposed method, MAC-Tuning, involves separating the processes of answer prediction and confidence estimation during the fine-tuning phase on instruction data.", "result": "Experimental results reveal that MAC-Tuning improves average precision by up to 25% compared to existing methods.", "conclusion": "The findings suggest that the separation of learning processes enhances the predictive capabilities and reliability of LLMs.", "key_contributions": ["Introduction of MAC-Tuning method for simultaneous multi-problem answer prediction and confidence estimation.", "Improvement of average precision in LLM outputs by up to 25%.", "Focus on addressing the challenge of hallucination in generated responses."], "limitations": "", "future_work": "Future research could explore further refinements of MAC-Tuning and its application to different LLM architectures.", "keywords": ["large language models", "confidence estimation", "multi-problem setting", "answer prediction", "hallucination"], "importance_score": 9, "read_time_minutes": 5}}
{"id": "2504.21776", "pdf": "https://arxiv.org/pdf/2504.21776.pdf", "abs": "https://arxiv.org/abs/2504.21776", "title": "WebThinker: Empowering Large Reasoning Models with Deep Research Capability", "authors": ["Xiaoxi Li", "Jiajie Jin", "Guanting Dong", "Hongjin Qian", "Yutao Zhu", "Yongkang Wu", "Ji-Rong Wen", "Zhicheng Dou"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate\nimpressive long-horizon reasoning capabilities. However, their reliance on\nstatic internal knowledge limits their performance on complex,\nknowledge-intensive tasks and hinders their ability to produce comprehensive\nresearch reports requiring synthesis of diverse web information. To address\nthis, we propose \\textbf{WebThinker}, a deep research agent that empowers LRMs\nto autonomously search the web, navigate web pages, and draft research reports\nduring the reasoning process. WebThinker integrates a \\textbf{Deep Web\nExplorer} module, enabling LRMs to dynamically search, navigate, and extract\ninformation from the web when encountering knowledge gaps. It also employs an\n\\textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to\nseamlessly interleave reasoning, information gathering, and report writing in\nreal time. To further enhance research tool utilization, we introduce an\n\\textbf{RL-based training strategy} via iterative online Direct Preference\nOptimization (DPO). Extensive experiments on complex reasoning benchmarks\n(GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive)\ndemonstrate that WebThinker significantly outperforms existing methods and\nstrong proprietary systems. Our approach enhances LRM reliability and\napplicability in complex scenarios, paving the way for more capable and\nversatile deep research systems. The code is available at\nhttps://github.com/RUC-NLPIR/WebThinker.", "AI": {"tldr": "WebThinker is a deep research agent that enhances large reasoning models by enabling them to autonomously search the web and draft research reports, overcoming limitations of static internal knowledge.", "motivation": "To improve the performance of large reasoning models on complex, knowledge-intensive tasks that require dynamic information synthesis from the web.", "method": "WebThinker integrates a Deep Web Explorer for real-time web searching and navigating, combined with an Autonomous Think-Search-and-Draft strategy and an RL-based training strategy via iterative online Direct Preference Optimization.", "result": "WebThinker demonstrates significant performance improvements on various reasoning benchmarks and scientific report generation tasks, outperforming existing methods and proprietary systems.", "conclusion": "The WebThinker framework presents a significant advancement in the reliability and applicability of large reasoning models for complex scenarios, leading to enhanced capabilities in deep research systems.", "key_contributions": ["Development of a deep research agent that autonomously navigates web resources.", "Integration of real-time reasoning, information gathering, and report drafting.", "Introduction of a reinforcement learning-based training strategy for improved performance."], "limitations": "", "future_work": "Further enhancement of LRM capabilities and exploration of additional applications in research and beyond.", "keywords": ["Large reasoning models", "Deep research agent", "Web navigation"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2504.21800", "pdf": "https://arxiv.org/pdf/2504.21800.pdf", "abs": "https://arxiv.org/abs/2504.21800", "title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues", "authors": ["Suhas BN", "Dominik Mattioli", "Saeed Abdullah", "Rosa I. Arriaga", "Chris W. Wiese", "Andrew M. Sherrill"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "68T50", "I.2.7; H.3.1"], "comment": "11 pages, 5 tables, updated abstract and tables", "summary": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. In our dataset, synthetic dialogues match structural\nfeatures of real-world dialogues (e.g., speaker switch ratio: 0.98 vs. 0.99),\nhowever, synthetic interactions do not adequately reflect key fidelity markers\n(e.g., distress monitoring). We highlight gaps in existing evaluation\nframeworks and advocate for fidelity-aware metrics that go beyond surface\nfluency to uncover clinically significant failures. Our findings clarify where\nsynthetic data can effectively complement real-world datasets -- and where\ncritical limitations remain.", "AI": {"tldr": "This paper explores the use of synthetic data for training models in PTSD therapy by comparing real and synthetic therapeutic conversations.", "motivation": "The adoption of synthetic data in healthcare is necessary due to privacy concerns, limited access to real data, and high annotation costs.", "method": "The authors systematically compare real and synthetic dialogues using various metrics including linguistic, structural, and protocol-specific ones such as turn-taking patterns and treatment fidelity. They introduce PE-specific metrics derived from linguistic analysis and semantic modeling.", "result": "Findings indicate that while synthetic dialogues match certain structural features of real dialogues, they fail to capture critical fidelity markers like distress monitoring, highlighting gaps in existing evaluation frameworks.", "conclusion": "Synthetic data shows potential in mitigating data scarcity but struggles with capturing the dynamics of therapeutic interactions; the authors propose fidelity-aware metrics for better assessment.", "key_contributions": ["Introduction of a novel framework for assessing clinical fidelity in synthetic dialogues.", "Systematic comparison of real vs synthetic therapeutic conversations using comprehensive metrics.", "Highlighting the limitations of synthetic data in capturing subtle therapeutic dynamics."], "limitations": "Synthetic dialogues do not adequately reflect key fidelity markers, limiting their effectiveness as a stand-alone data source.", "future_work": "Further development of fidelity-aware metrics and investigation into mitigating the identified limitations of synthetic data in therapeutic contexts.", "keywords": ["Synthetic data", "Post-Traumatic Stress Disorder", "Therapeutic conversations", "Fidelity metrics", "Healthcare AI"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2504.21801", "pdf": "https://arxiv.org/pdf/2504.21801.pdf", "abs": "https://arxiv.org/abs/2504.21801", "title": "DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition", "authors": ["Z. Z. Ren", "Zhihong Shao", "Junxiao Song", "Huajian Xin", "Haocheng Wang", "Wanjia Zhao", "Liyue Zhang", "Zhe Fu", "Qihao Zhu", "Dejian Yang", "Z. F. Wu", "Zhibin Gou", "Shirong Ma", "Hongxuan Tang", "Yuxuan Liu", "Wenjun Gao", "Daya Guo", "Chong Ruan"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.", "AI": {"tldr": "DeepSeek-Prover-V2 is an advanced LLM for formal theorem proving, achieving notable performance on various benchmarks by integrating informal and formal reasoning.", "motivation": "To advance the capabilities of large language models in formal theorem proving by seamlessly integrating informal and formal mathematical reasoning.", "method": "The model uses a cold-start training procedure where DeepSeek-V3 decomposes complex problems into subgoals, synthesizing proofs through a step-by-step reasoning process, followed by reinforcement learning.", "result": "Achieved a state-of-the-art performance with an 88.9% pass ratio on the MiniF2F-test and successfully tackled problems from PutnamBench and AIME competitions, including a newly introduced benchmark called ProverBench.", "conclusion": "DeepSeek-Prover-V2 significantly narrows the gap between informal and formal mathematical reasoning in LLMs, showcasing its utility in theorem proving.", "key_contributions": ["Introduction of DeepSeek-Prover-V2 for formal theorem proving in Lean 4.", "Creation of the ProverBench evaluation benchmark with 325 formalized problems.", "Demonstrated a significant improvement in solving capabilities over existing models."], "limitations": "", "future_work": "Further exploration of the capabilities of LLMs in formal reasoning and potential extensions of the model for enhanced problem-solving.", "keywords": ["large language model", "theorem proving", "formal reasoning", "machine learning", "AI"], "importance_score": 6, "read_time_minutes": 15}}
{"id": "2504.21851", "pdf": "https://arxiv.org/pdf/2504.21851.pdf", "abs": "https://arxiv.org/abs/2504.21851", "title": "TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments", "authors": ["Sichang Tu", "Abigail Powers", "Stephen Doogan", "Jinho D. Choi"], "categories": ["cs.CL", "cs.AI"], "comment": "5 figures, 4 tables", "summary": "Objectives: While Large Language Models (LLMs) have been widely used to\nassist clinicians and support patients, no existing work has explored dialogue\nsystems for standard diagnostic interviews and assessments. This study aims to\nbridge the gap in mental healthcare accessibility by developing an LLM-powered\ndialogue system that replicates clinician behavior. Materials and Methods: We\nintroduce TRUST, a framework of cooperative LLM modules capable of conducting\nformal diagnostic interviews and assessments for Post-Traumatic Stress Disorder\n(PTSD). To guide the generation of appropriate clinical responses, we propose a\nDialogue Acts schema specifically designed for clinical interviews.\nAdditionally, we develop a patient simulation approach based on real-life\ninterview transcripts to replace time-consuming and costly manual testing by\nclinicians. Results: A comprehensive set of evaluation metrics is designed to\nassess the dialogue system from both the agent and patient simulation\nperspectives. Expert evaluations by conversation and clinical specialists show\nthat TRUST performs comparably to real-life clinical interviews. Discussion:\nOur system performs at the level of average clinicians, with room for future\nenhancements in communication styles and response appropriateness. Conclusions:\nOur TRUST framework shows its potential to facilitate mental healthcare\navailability.", "AI": {"tldr": "This paper presents TRUST, an LLM-powered dialogue system designed for conducting formal diagnostic interviews for PTSD, aiming to enhance mental healthcare accessibility.", "motivation": "The study addresses the lack of existing dialogue systems for standard diagnostic interviews in mental healthcare, which affects accessibility.", "method": "The authors develop the TRUST framework, which consists of cooperative LLM modules and a Dialogue Acts schema tailored for clinical interviews, using a patient simulation approach based on real-life transcripts.", "result": "Evaluation metrics indicate that TRUST performs comparably to real-life clinical interviews, as confirmed by expert evaluations.", "conclusion": "TRUST demonstrates the potential to improve mental healthcare accessibility, although there is room for enhancements in communication styles.", "key_contributions": ["Introduction of the TRUST framework for mental health diagnostic interviews.", "Development of a Dialogue Acts schema for guiding clinical responses.", "Implementation of a patient simulation approach to streamline testing."], "limitations": "The system is currently at the level of average clinicians and may require further improvements in response appropriateness and communication styles.", "future_work": "Future research may focus on enhancing communication styles and exploring other diagnostic use cases.", "keywords": ["Large Language Models", "dialogue systems", "mental healthcare", "PTSD", "clinical interviews"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2310.18964", "pdf": "https://arxiv.org/pdf/2310.18964.pdf", "abs": "https://arxiv.org/abs/2310.18964", "title": "LLMs and Finetuning: Benchmarking cross-domain performance for hate speech detection", "authors": ["Ahmad Nasir", "Aadish Sharma", "Kokil Jaidka", "Saifuddin Ahmed"], "categories": ["cs.CL"], "comment": "18 pages, 3 figures, 5 tables", "summary": "In the evolving landscape of online communication, hate speech detection\nremains a formidable challenge, further compounded by the diversity of digital\nplatforms. This study investigates the effectiveness and adaptability of\npre-trained and fine-tuned Large Language Models (LLMs) in identifying hate\nspeech, to address two central questions: (1) To what extent does the model\nperformance depend on the fine-tuning and training parameters?, (2) To what\nextent do models generalize to cross-domain hate speech detection? and (3) What\nare the specific features of the datasets or models that influence the\ngeneralization potential? The experiment shows that LLMs offer a huge advantage\nover the state-of-the-art even without pretraining. Ordinary least squares\nanalyses suggest that the advantage of training with fine-grained hate speech\nlabels is washed away with the increase in dataset size. While our research\ndemonstrates the potential of large language models (LLMs) for hate speech\ndetection, several limitations remain, particularly regarding the validity and\nthe reproducibility of the results. We conclude with an exhaustive discussion\nof the challenges we faced in our experimentation and offer recommended best\npractices for future scholars designing benchmarking experiments of this kind.", "AI": {"tldr": "This study explores how pre-trained and fine-tuned LLMs can effectively detect hate speech across diverse digital platforms, revealing the impact of training parameters and dataset features on model performance.", "motivation": "To address the challenge of hate speech detection in online communication and assess the effectiveness of LLMs in this context.", "method": "The study employs ordinary least squares analyses to evaluate the performance of pre-trained and fine-tuned LLMs in hate speech detection and examines their adaptability across different domains.", "result": "The findings indicate that LLMs outperform state-of-the-art methods, even without pretraining. However, the advantage of using fine-grained hate speech labels diminishes as dataset sizes increase.", "conclusion": "While LLMs show significant potential for hate speech detection, limitations in the validity and reproducibility of results persist; the paper discusses these challenges and proposes best practices for future research.", "key_contributions": ["Demonstrates the effectiveness of LLMs for hate speech detection.", "Identifies the diminished returns of fine-grained labels with larger dataset sizes.", "Provides recommendations for benchmarking experiments in hate speech detection."], "limitations": "Concerns regarding the validity and reproducibility of experimental results remain.", "future_work": "Future research should focus on overcoming the identified challenges and developing more robust benchmarking methodologies.", "keywords": ["Hate Speech Detection", "Large Language Models", "Machine Learning"], "importance_score": 7, "read_time_minutes": 18}}
{"id": "2402.13517", "pdf": "https://arxiv.org/pdf/2402.13517.pdf", "abs": "https://arxiv.org/abs/2402.13517", "title": "Round Trip Translation Defence against Large Language Model Jailbreaking Attacks", "authors": ["Canaan Yung", "Hadi Mohaghegh Dolatabadi", "Sarah Erfani", "Christopher Leckie"], "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, 6 figures", "summary": "Large language models (LLMs) are susceptible to social-engineered attacks\nthat are human-interpretable but require a high level of comprehension for LLMs\nto counteract. Existing defensive measures can only mitigate less than half of\nthese attacks at most. To address this issue, we propose the Round Trip\nTranslation (RTT) method, the first algorithm specifically designed to defend\nagainst social-engineered attacks on LLMs. RTT paraphrases the adversarial\nprompt and generalizes the idea conveyed, making it easier for LLMs to detect\ninduced harmful behavior. This method is versatile, lightweight, and\ntransferrable to different LLMs. Our defense successfully mitigated over 70% of\nPrompt Automatic Iterative Refinement (PAIR) attacks, which is currently the\nmost effective defense to the best of our knowledge. We are also the first to\nattempt mitigating the MathsAttack and reduced its attack success rate by\nalmost 40%. Our code is publicly available at\nhttps://github.com/Cancanxxx/Round_Trip_Translation_Defence\n  This version of the article has been accepted for publication, after peer\nreview (when applicable) but is not the Version of Record and does not reflect\npost-acceptance improvements, or any corrections. The Version of Record is\navailable online at: https://doi.org/10.48550/arXiv.2402.13517 Use of this\nAccepted Version is subject to the publisher's Accepted Manuscript terms of use\nhttps://www.springernature.com/gp/open-research/policies/accepted-manuscript-terms", "AI": {"tldr": "Proposes Round Trip Translation (RTT) to defend LLMs against social-engineered attacks, achieving over 70% mitigation of specific attack types.", "motivation": "Existing defensive measures for LLMs against social-engineered attacks are inadequate, necessitating a robust solution.", "method": "The RTT algorithm paraphrases adversarial prompts to help LLMs better identify harmful behaviors.", "result": "RTT mitigated over 70% of Prompt Automatic Iterative Refinement (PAIR) attacks and reduced MathsAttack success rates by nearly 40%.", "conclusion": "RTT is a versatile and effective method for defending LLMs against tailored social-engineered threats, with public code available for further development.", "key_contributions": ["First algorithm specifically designed to defend against social-engineered attacks on LLMs.", "Mitigated over 70% of PAIR attacks.", "Reduced MathsAttack success rate by almost 40%."], "limitations": "", "future_work": "Exploration of additional attack types and enhancement of defense methods across various LLM architectures.", "keywords": ["Large Language Models", "Social-engineered attacks", "Round Trip Translation", "Defense mechanisms", "Machine Learning"], "importance_score": 9, "read_time_minutes": 6}}
{"id": "2404.19442", "pdf": "https://arxiv.org/pdf/2404.19442.pdf", "abs": "https://arxiv.org/abs/2404.19442", "title": "Does Generative AI speak Nigerian-Pidgin?: Issues about Representativeness and Bias for Multilingualism in LLMs", "authors": ["David Ifeoluwa Adelani", "A. Seza Doğruöz", "Iyanuoluwa Shode", "Anuoluwapo Aremu"], "categories": ["cs.CL"], "comment": "Accepted to NAACL 2025 (findings), please cite ACL anthology\n  reference on https://aclanthology.org/2025.findings-naacl.85/", "summary": "Nigeria is a multilingual country with 500+ languages. Naija is a Nigerian\nPidgin spoken by approximately 120M speakers and it is a mixed language (e.g.,\nEnglish, Portuguese, Yoruba, Hausa and Igbo). Although it has mainly been a\nspoken language until recently, there are some online platforms (e.g.,\nWikipedia), publishing in written Naija as well. West African Pidgin English\n(WAPE) is also spoken in Nigeria and it is used by BBC to broadcast news on the\ninternet to a wider audience not only in Nigeria but also in other West African\ncountries (e.g., Cameroon and Ghana). Through statistical analyses and Machine\nTranslation experiments, our paper shows that these two pidgin varieties do not\nrepresent each other (i.e., there are linguistic differences in word order and\nvocabulary) and Generative AI operates only based on WAPE. In other words,\nNaija is underrepresented in Generative AI, and it is hard to teach LLMs with\nfew examples. In addition to the statistical analyses, we also provide\nhistorical information on both pidgins as well as insights from the interviews\nconducted with volunteer Wikipedia contributors in Naija.", "AI": {"tldr": "This paper analyzes the linguistic characteristics of Naija and West African Pidgin English (WAPE) and highlights the underrepresentation of Naija in Generative AI applications, revealing significant linguistic differences between the two pidgins.", "motivation": "To explore the linguistic differences between Naija and WAPE, and to investigate the implications of these differences for Generative AI applications and Machine Translation.", "method": "Statistical analyses and Machine Translation experiments are conducted to compare Naija and WAPE, alongside interviews with volunteer Wikipedia contributors in Naija.", "result": "The analysis reveals that Naija and WAPE do not represent each other linguistically, with distinct vocabulary and word order, and that Generative AI primarily operates with WAPE, neglecting Naija.", "conclusion": "Generative AI's dependence on WAPE and the linguistic uniqueness of Naija suggest challenges in teaching LLMs due to its underrepresentation in training data.", "key_contributions": ["Identifies linguistic differences between Naija and WAPE.", "Demonstrates the underrepresentation of Naija in Generative AI applications.", "Provides historical context and insights from interviews with contributors."], "limitations": "The study may not cover all linguistic aspects of Naija and its representation in AI due to the complexity of pidgin languages.", "future_work": "Further research is needed to enhance the representation of Naija in AI systems and to better integrate multilingual aspects into Generative AI.", "keywords": ["Naija", "West African Pidgin English", "Generative AI", "Machine Translation", "linguistic diversity"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2405.15471", "pdf": "https://arxiv.org/pdf/2405.15471.pdf", "abs": "https://arxiv.org/abs/2405.15471", "title": "Emergence of a High-Dimensional Abstraction Phase in Language Transformers", "authors": ["Emily Cheng", "Diego Doimo", "Corentin Kervadec", "Iuri Macocco", "Jade Yu", "Alessandro Laio", "Marco Baroni"], "categories": ["cs.CL"], "comment": "Published as conference paper at ICLR 2025", "summary": "A language model (LM) is a mapping from a linguistic context to an output\ntoken. However, much remains to be known about this mapping, including how its\ngeometric properties relate to its function. We take a high-level geometric\napproach to its analysis, observing, across five pre-trained transformer-based\nLMs and three input datasets, a distinct phase characterized by high intrinsic\ndimensionality. During this phase, representations (1) correspond to the first\nfull linguistic abstraction of the input; (2) are the first to viably transfer\nto downstream tasks; (3) predict each other across different LMs. Moreover, we\nfind that an earlier onset of the phase strongly predicts better language\nmodelling performance. In short, our results suggest that a central\nhigh-dimensionality phase underlies core linguistic processing in many common\nLM architectures.", "AI": {"tldr": "The study analyzes the geometric properties of language models (LMs) and identifies a high-dimensionality phase that corresponds to core linguistic processing.", "motivation": "To understand the geometric mapping of linguistic contexts in language models and its implications for their function.", "method": "Analyzed five pre-trained transformer-based LMs across three input datasets to investigate their geometric characteristics.", "result": "Discovered a distinct high-dimensionality phase related to linguistic abstraction and downstream task prediction, which also correlates with language modeling performance.", "conclusion": "A central high-dimensionality phase is critical for linguistic processing in various LM architectures, indicating implications for model design.", "key_contributions": ["Identification of a high-dimensionality phase in LMs", "Relationship between high-dimensionality and language modeling performance", "Insights into how representations transfer to downstream tasks"], "limitations": "The analysis is limited to a specific set of LMs and datasets, and further exploration is needed across more architectures and contexts.", "future_work": "To investigate the high-dimensionality phase in other language models and its implications for broader linguistic processing.", "keywords": ["language models", "geometric properties", "high-dimensionality", "linguistic processing", "transformer-based LMs"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2410.07825", "pdf": "https://arxiv.org/pdf/2410.07825.pdf", "abs": "https://arxiv.org/abs/2410.07825", "title": "Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models", "authors": ["Zhipeng Chen", "Kun Zhou", "Liang Song", "Wayne Xin Zhao", "Bingning Wang", "Weipeng Chen", "Ji-Rong Wen"], "categories": ["cs.CL"], "comment": "17 Pages. Working in progress", "summary": "Multi-lingual ability transfer has become increasingly important for the\nbroad application of large language models (LLMs). Existing work highly relies\non training with the multi-lingual ability-related data, which may be not\navailable for low-resource languages. To solve it, we propose a Multi-lingual\nAbility Extraction and Transfer approach, named as MAET. Our key idea is to\ndecompose and extract language-agnostic ability-related weights from LLMs, and\ntransfer them across different languages by simple addition and subtraction\noperations without training. Specially, our MAET consists of the extraction and\ntransfer stages. In the extraction stage, we firstly locate key neurons that\nare highly related to specific abilities, and then employ them to extract the\ntransferable ability-specific weights. In the transfer stage, we further select\nthe ability-related parameter tensors, and design the merging strategy based on\nthe linguistic and ability specific weights, to build the multi-lingual\nability-enhanced LLM. To demonstrate the effectiveness of our proposed\napproach, we conduct extensive experiments on mathematical and scientific tasks\nin both high-resource lingual and low-resource lingual scenarios. Experiment\nresults have shown that MAET can effectively and efficiently extract and\ntransfer the advanced abilities, and outperform training-based baseline\nmethods. Our code and data are available at https://github.com/RUCAIBox/MAET.", "AI": {"tldr": "The paper presents a method for transferring multi-lingual abilities from large language models (LLMs) without needing additional training on low-resource languages.", "motivation": "The increasing need for multilingual capability in LLMs, especially for low-resource languages, where training data may be scarce.", "method": "The Multi-lingual Ability Extraction and Transfer (MAET) approach extracts language-agnostic ability-related weights from LLMs through two stages: extraction and transfer, utilizing neuron selection and weight manipulation.", "result": "Extensive experiments demonstrate that MAET effectively extracts and transfers language abilities, outperforming traditional training-based methods.", "conclusion": "MAET offers a novel approach for enhancing multilingual capabilities in LLMs with improved efficiency and effectiveness, particularly for low-resource languages.", "key_contributions": ["Introduction of the MAET framework for multilingual ability transfer", "Effective extraction of ability-related weights from LLMs", "Demonstrated performance improvements in mathematical and scientific tasks over baseline methods."], "limitations": "The method may require further validation across a broader range of languages and tasks to establish generalizability.", "future_work": "Exploration of additional task-specific enhancements and broader language applicability.", "keywords": ["Multi-lingual Ability Transfer", "Large Language Models", "Language-Agnostic Weights", "Neural Network", "Low-Resource Languages"], "importance_score": 8, "read_time_minutes": 17}}
{"id": "2410.16658", "pdf": "https://arxiv.org/pdf/2410.16658.pdf", "abs": "https://arxiv.org/abs/2410.16658", "title": "Adsorb-Agent: Autonomous Identification of Stable Adsorption Configurations via Large Language Model Agent", "authors": ["Janghoon Ock", "Tirtha Vinchurkar", "Yayati Jadhav", "Amir Barati Farimani"], "categories": ["cs.CL", "cond-mat.mtrl-sci"], "comment": null, "summary": "Adsorption energy is a key reactivity descriptor in catalysis, enabling\nefficient screening for optimal catalysts. However, determining adsorption\nenergy typically requires evaluating numerous adsorbate-catalyst\nconfigurations. Current algorithmic approaches rely on exhaustive enumeration\nof adsorption sites and configurations, which makes the process computationally\nintensive and does not inherently guarantee the identification of the global\nminimum energy. In this work, we introduce Adsorb-Agent, a Large Language Model\n(LLM) agent designed to efficiently identify system-specific stable adsorption\nconfigurations corresponding to the global minimum adsorption energy.\nAdsorb-Agent leverages its built-in knowledge and emergent reasoning\ncapabilities to strategically explore adsorption configurations likely to hold\nadsorption energy. By reducing the reliance on exhaustive sampling, it\nsignificantly decreases the number of initial configurations required while\nimproving the accuracy of adsorption energy predictions. We evaluate\nAdsorb-Agent's performance across twenty representative systems encompassing a\nrange of complexities. The Adsorb-Agent successfully identifies comparable\nadsorption energies for 83.7% of the systems and achieves lower energies,\ncloser to the actual global minimum, for 35% of the systems, while requiring\nsignificantly fewer initial configurations than conventional methods. Its\ncapability is particularly evident in complex systems, where it identifies\nlower adsorption energies for 46.7% of systems involving intermetallic surfaces\nand 66.7% of systems with large adsorbate molecules. These results demonstrate\nthe potential of Adsorb-Agent to accelerate catalyst discovery by reducing\ncomputational costs and improving the reliability of adsorption energy\npredictions.", "AI": {"tldr": "Adsorb-Agent, an LLM agent, enhances the identification of stable adsorption configurations for optimal catalyst discovery by reducing computational costs and improving adsorption energy predictions.", "motivation": "Determining adsorption energy is crucial in catalysis for screening optimal catalysts, but current methods are computationally intensive and may not identify global minima.", "method": "The paper introduces Adsorb-Agent, an LLM that strategically explores configurations to find stable adsorption states while requiring fewer initial configurations than traditional methods.", "result": "Adsorb-Agent identifies comparable adsorption energies for 83.7% of tested systems and achieves lower energies closer to the global minimum in 35% of cases, particularly excelling in complex systems.", "conclusion": "Adsorb-Agent can significantly accelerate catalyst discovery by improving the accuracy of adsorption energy predictions while decreasing computational demands.", "key_contributions": ["Introduction of Adsorb-Agent as an LLM for adsorption energy prediction", "Demonstrated efficiency in identifying stable configurations", "Improved accuracy in comparing adsorption energies across complex systems"], "limitations": "", "future_work": "Further improvements on Adsorb-Agent's exploration strategies and applications to more complex catalytic systems.", "keywords": ["Adsorption energy", "Catalysis", "Large Language Model", "Machine Learning", "Computational efficiency"], "importance_score": 5, "read_time_minutes": 10}}
{"id": "2501.00571", "pdf": "https://arxiv.org/pdf/2501.00571.pdf", "abs": "https://arxiv.org/abs/2501.00571", "title": "KnowRA: Knowledge Retrieval Augmented Method for Document-level Relation Extraction with Comprehensive Reasoning Abilities", "authors": ["Chengcheng Mai", "Yuxiang Wang", "Ziyu Gong", "Hanxiang Wang", "Yihua Huang"], "categories": ["cs.CL"], "comment": "This work has been accepted by IJCAI 2025", "summary": "Document-level relation extraction (Doc-RE) aims to extract relations between\nentities across multiple sentences. Therefore, Doc-RE requires more\ncomprehensive reasoning abilities like humans, involving complex cross-sentence\ninteractions between entities, contexts, and external general knowledge,\ncompared to the sentence-level RE. However, most existing Doc-RE methods focus\non optimizing single reasoning ability, but lack the ability to utilize\nexternal knowledge for comprehensive reasoning on long documents. To solve\nthese problems, a knowledge retrieval augmented method, named KnowRA, was\nproposed with comprehensive reasoning to autonomously determine whether to\naccept external knowledge to assist DocRE. Firstly, we constructed a document\ngraph for semantic encoding and integrated the co-reference resolution model to\naugment the co-reference reasoning ability. Then, we expanded the document\ngraph into a document knowledge graph by retrieving the external knowledge base\nfor common-sense reasoning and a novel knowledge filtration method was\npresented to filter out irrelevant knowledge. Finally, we proposed the axis\nattention mechanism to build direct and indirect associations with intermediary\nentities for achieving cross-sentence logical reasoning. Extensive experiments\nconducted on two datasets verified the effectiveness of our method compared to\nthe state-of-the-art baselines. Our code is available at\nhttps://anonymous.4open.science/r/KnowRA.", "AI": {"tldr": "This paper introduces KnowRA, a method for document-level relation extraction (Doc-RE) that enhances reasoning capabilities by incorporating external knowledge and a novel axis attention mechanism.", "motivation": "Existing Doc-RE methods focus on single reasoning abilities and neglect the utilization of external knowledge for complex reasoning in long documents.", "method": "KnowRA uses a document graph for semantic encoding, integrates a co-reference resolution model, expands the graph into a document knowledge graph with external knowledge retrieval, and employs an axis attention mechanism for cross-sentence reasoning.", "result": "Extensive experiments on two datasets show that KnowRA outperforms state-of-the-art baselines in document-level relation extraction tasks.", "conclusion": "KnowRA successfully enhances document-level relation extraction capabilities by effectively integrating external knowledge and improving reasoning mechanisms.", "key_contributions": ["Introduction of the KnowRA method for Doc-RE", "Development of a document knowledge graph incorporating external knowledge", "Implementation of an axis attention mechanism for reasoning across sentences."], "limitations": "The effectiveness of the method may vary depending on the quality and relevance of the external knowledge retrieved.", "future_work": "Further exploration of optimizing knowledge retrieval and reasoning paradigms for even more complex relation extraction tasks.", "keywords": ["relation extraction", "document-level", "knowledge retrieval", "axis attention", "machine learning"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2502.11258", "pdf": "https://arxiv.org/pdf/2502.11258.pdf", "abs": "https://arxiv.org/abs/2502.11258", "title": "Leveraging Conditional Mutual Information to Improve Large Language Model Fine-Tuning For Classification", "authors": ["Thanushon Sivakaran", "En-Hui Yang"], "categories": ["cs.CL"], "comment": "6 pages, 2 figures, Published to IEEE ISIT 2025", "summary": "Although large language models (LLMs) have demonstrated remarkable\ncapabilities in recent years, the potential of information theory (IT) to\nenhance LLM development remains underexplored. This paper introduces the\ninformation theoretic principle of Conditional Mutual Information (CMI) to LLM\nfine-tuning for classification tasks, exploring its promise in two main ways:\nminimizing CMI to improve a model's standalone performance and maximizing CMI\nto enhance knowledge distillation (KD) for more capable student models. To\napply CMI in LLM fine-tuning, we adapt the recently proposed CMI-constrained\ndeep learning framework, which was initially developed for image\nclassification, with some modification. By minimizing CMI during LLM\nfine-tuning, we achieve superior performance gains on 6 of 8 GLUE\nclassification tasks compared to BERT. Additionally, maximizing CMI during the\nKD process results in significant performance improvements in 6 of 8 GLUE\nclassification tasks compared to DistilBERT. These findings demonstrate CMI's\nadaptability for optimizing both standalone LLMs and student models, showcasing\nits potential as a robust framework for advancing LLM fine-tuning. Our work\nbridges the gap between information theory and LLM development, offering new\ninsights for building high-performing language models.", "AI": {"tldr": "This paper explores using Conditional Mutual Information (CMI) to enhance fine-tuning of large language models (LLMs) for classification tasks, demonstrating improved performance through both minimizing and maximizing CMI.", "motivation": "To investigate the underexplored potential of information theory, specifically Conditional Mutual Information (CMI), in enhancing the performance of large language models (LLMs).", "method": "The paper adapts a CMI-constrained deep learning framework for applying CMI in LLM fine-tuning, focusing on minimizing CMI for model performance and maximizing CMI for knowledge distillation.", "result": "Minimizing CMI during LLM fine-tuning leads to superior performance on 6 out of 8 GLUE classification tasks compared to BERT, while maximizing CMI during knowledge distillation significantly improves performance on 6 out of 8 GLUE tasks compared to DistilBERT.", "conclusion": "The findings highlight the adaptability of CMI for optimizing both standalone LLMs and student models, positioning it as a valuable framework for advancing LLM fine-tuning.", "key_contributions": ["Introduction of Conditional Mutual Information for LLM fine-tuning", "Adaptation of a CMI-constrained framework for LLM tasks", "Demonstration of superior GLUE task performance using CMI methods"], "limitations": "", "future_work": "Exploring further applications of information theory principles in LLM development and investigating additional metrics for model performance optimization.", "keywords": ["Large Language Models", "Conditional Mutual Information", "Fine-tuning", "Knowledge Distillation", "GLUE Benchmark"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2503.04785", "pdf": "https://arxiv.org/pdf/2503.04785.pdf", "abs": "https://arxiv.org/abs/2503.04785", "title": "Mapping Trustworthiness in Large Language Models: A Bibliometric Analysis Bridging Theory to Practice", "authors": ["José Siqueira de Cerqueira", "Kai-Kristian Kemell", "Muhammad Waseem", "Rebekah Rousi", "Nannan Xi", "Juho Hamari", "Pekka Abrahamsson"], "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "The rapid proliferation of Large Language Models (LLMs) has raised pressing\nconcerns regarding their trustworthiness, spanning issues of reliability,\ntransparency, fairness, and ethical alignment. Despite the increasing adoption\nof LLMs across various domains, there remains a lack of consensus on how to\noperationalize trustworthiness in practice. This study bridges the gap between\ntheoretical discussions and implementation by conducting a bibliometric mapping\nanalysis of 2,006 publications from 2019 to 2025. Through co-authorship\nnetworks, keyword co-occurrence analysis, and thematic evolution tracking, we\nidentify key research trends, influential authors, and prevailing definitions\nof LLM trustworthiness. Additionally, a systematic review of 68 core papers is\nconducted to examine conceptualizations of trust and their practical\nimplications. Our findings reveal that trustworthiness in LLMs is often framed\nthrough existing organizational trust frameworks, emphasizing dimensions such\nas ability, benevolence, and integrity. However, a significant gap exists in\ntranslating these principles into concrete development strategies. To address\nthis, we propose a structured mapping of 20 trust-enhancing techniques across\nthe LLM lifecycle, including retrieval-augmented generation (RAG),\nexplainability techniques, and post-training audits. By synthesizing\nbibliometric insights with practical strategies, this study contributes towards\nfostering more transparent, accountable, and ethically aligned LLMs, ensuring\ntheir responsible deployment in real-world applications.", "AI": {"tldr": "This study analyzes the trustworthiness of Large Language Models (LLMs) through a bibliometric mapping of 2,006 publications, revealing key trends and proposing a structured mapping of trust-enhancing techniques for responsible LLM deployment.", "motivation": "To address concerns regarding the trustworthiness of LLMs and the lack of consensus on how to implement it in practice.", "method": "Conducting a bibliometric mapping analysis of publications, including co-authorship networks, keyword co-occurrence analysis, and thematic evolution tracking, alongside a systematic review of 68 core papers.", "result": "Identified key research trends, influential authors, and existing organizational trust frameworks related to LLMs, proposing 20 trust-enhancing techniques throughout the LLM lifecycle.", "conclusion": "The study highlights the importance of translating trust principles into development strategies to improve LLM transparency and accountability in real-world applications.", "key_contributions": ["Bibliometric mapping analysis of LLM trustworthiness literature", "Identification of key trends and influential authors", "Proposal of 20 trust-enhancing techniques for practical implementation"], "limitations": "The study reveals a gap in translating theoretical trust principles into actionable strategies for LLM development.", "future_work": "Further research is needed to operationalize the proposed trust-enhancing techniques effectively in various LLM applications.", "keywords": ["Large Language Models", "Trustworthiness", "Bibliometric Analysis", "Trust-enhancing Techniques", "Ethical AI"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2503.14258", "pdf": "https://arxiv.org/pdf/2503.14258.pdf", "abs": "https://arxiv.org/abs/2503.14258", "title": "JuDGE: Benchmarking Judgment Document Generation for Chinese Legal System", "authors": ["Weihang Su", "Baoqing Yue", "Qingyao Ai", "Yiran Hu", "Jiaqi Li", "Changyue Wang", "Kaiyuan Zhang", "Yueyue Wu", "Yiqun Liu"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "This paper introduces JuDGE (Judgment Document Generation Evaluation), a\nnovel benchmark for evaluating the performance of judgment document generation\nin the Chinese legal system. We define the task as generating a complete legal\njudgment document from the given factual description of the case. To facilitate\nthis benchmark, we construct a comprehensive dataset consisting of factual\ndescriptions from real legal cases, paired with their corresponding full\njudgment documents, which serve as the ground truth for evaluating the quality\nof generated documents. This dataset is further augmented by two external legal\ncorpora that provide additional legal knowledge for the task: one comprising\nstatutes and regulations, and the other consisting of a large collection of\npast judgment documents. In collaboration with legal professionals, we\nestablish a comprehensive automated evaluation framework to assess the quality\nof generated judgment documents across various dimensions. We evaluate various\nbaseline approaches, including few-shot in-context learning, fine-tuning, and a\nmulti-source retrieval-augmented generation (RAG) approach, using both general\nand legal-domain LLMs. The experimental results demonstrate that, while RAG\napproaches can effectively improve performance in this task, there is still\nsubstantial room for further improvement. All the codes and datasets are\navailable at: https://github.com/oneal2000/JuDGE.", "AI": {"tldr": "JuDGE is a benchmark for evaluating judgment document generation in the Chinese legal system.", "motivation": "To evaluate the performance of judgment document generation from factual case descriptions in the legal domain.", "method": "A comprehensive dataset of factual descriptions and corresponding judgment documents was created, alongside an automated evaluation framework. Various baseline approaches, including in-context learning and RAG, were evaluated using general and legal-domain LLMs.", "result": "RAG approaches showed improved performance in generating legal judgment documents, but significant room for improvement remains.", "conclusion": "While the benchmark and evaluation methods are established, further research is needed to enhance the quality of generated documents.", "key_contributions": ["Creation of the JuDGE benchmark dataset for legal judgment generation", "Development of an automated evaluation framework", "Assessment of baseline approaches in generating legal documents"], "limitations": "The study is limited to the Chinese legal system and may not generalize to other jurisdictions.", "future_work": "Further improvements in model accuracy and generalization to other legal systems are needed.", "keywords": ["Judgment Document Generation", "Legal NLP", "Evaluation Benchmark"], "importance_score": 4, "read_time_minutes": 10}}
{"id": "2503.21934", "pdf": "https://arxiv.org/pdf/2503.21934.pdf", "abs": "https://arxiv.org/abs/2503.21934", "title": "Proof or Bluff? Evaluating LLMs on 2025 USA Math Olympiad", "authors": ["Ivo Petrov", "Jasper Dekoninck", "Lyuben Baltadzhiev", "Maria Drencheva", "Kristian Minchev", "Mislav Balunović", "Nikola Jovanović", "Martin Vechev"], "categories": ["cs.CL"], "comment": null, "summary": "Recent math benchmarks for large language models (LLMs) such as MathArena\nindicate that state-of-the-art reasoning models achieve impressive performance\non mathematical competitions like AIME, with the leading model, Gemini-2.5-Pro,\nachieving scores comparable to top human competitors. However, these benchmarks\nevaluate models solely based on final numerical answers, neglecting rigorous\nreasoning and proof generation which are essential for real-world mathematical\ntasks. To address this, we introduce the first comprehensive evaluation of\nfull-solution reasoning for challenging mathematical problems. Using expert\nhuman annotators, we evaluated several state-of-the-art reasoning models on the\nsix problems from the 2025 USAMO within hours of their release. Our results\nreveal that all tested models struggled significantly: only Gemini-2.5-Pro\nachieves a non-trivial score of 25%, while all other models achieve less than\n5%. Through detailed analysis of reasoning traces, we identify the most common\nfailure modes and find several unwanted artifacts arising from the optimization\nstrategies employed during model training. Overall, our results suggest that\ncurrent LLMs are inadequate for rigorous mathematical reasoning tasks,\nhighlighting the need for substantial improvements in reasoning and proof\ngeneration capabilities.", "AI": {"tldr": "Evaluation of LLMs on rigorous mathematical reasoning reveals significant inadequacies in current models.", "motivation": "To comprehensively evaluate full-solution reasoning capabilities of LLMs on challenging mathematical problems beyond just final numerical answers.", "method": "Expert human annotators evaluated several state-of-the-art reasoning models on six problems from the 2025 USAMO shortly after their release.", "result": "Only Gemini-2.5-Pro achieved a non-trivial score of 25%, while all other models scored less than 5%.", "conclusion": "Current LLMs are inadequate for rigorous mathematical reasoning tasks, indicating the need for improvements in reasoning and proof generation.", "key_contributions": ["First comprehensive evaluation of LLMs on full-solution mathematical reasoning", "Identification of common failure modes in LLM performance", "Discussion of optimization artifacts in model training"], "limitations": "Study limited to six specific USAMO problems and may not generalize to all mathematical reasoning tasks.", "future_work": "Future research should focus on enhancing reasoning and proof generation capabilities of LLMs for better performance in mathematical tasks.", "keywords": ["Large Language Models", "Mathematical Reasoning", "USAMO", "Failure Modes", "Proof Generation"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2504.10342", "pdf": "https://arxiv.org/pdf/2504.10342.pdf", "abs": "https://arxiv.org/abs/2504.10342", "title": "VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain Knowledge", "authors": ["Yueqi Song", "Tianyue Ou", "Yibo Kong", "Zecheng Li", "Graham Neubig", "Xiang Yue"], "categories": ["cs.CL"], "comment": "56 pages, 43 figures", "summary": "Current multimodal benchmarks often conflate reasoning with domain-specific\nknowledge, making it difficult to isolate and evaluate general reasoning\nabilities in non-expert settings. To address this, we introduce VisualPuzzles,\na benchmark that targets visual reasoning while deliberately minimizing\nreliance on specialized knowledge. VisualPuzzles consists of diverse questions\nspanning five categories: algorithmic, analogical, deductive, inductive, and\nspatial reasoning. One major source of our questions is manually translated\nlogical reasoning questions from the Chinese Civil Service Examination.\nExperiments show that VisualPuzzles requires significantly less intensive\ndomain-specific knowledge and more complex reasoning compared to benchmarks\nlike MMMU, enabling us to better evaluate genuine multimodal reasoning.\nEvaluations show that state-of-the-art multimodal large language models\nconsistently lag behind human performance on VisualPuzzles, and that strong\nperformance on knowledge-intensive benchmarks does not necessarily translate to\nsuccess on reasoning-focused, knowledge-light tasks. Additionally, reasoning\nenhancements such as scaling up inference compute (with \"thinking\" modes) yield\ninconsistent gains across models and task types, and we observe no clear\ncorrelation between model size and performance. We also found that models\nexhibit different reasoning and answering patterns on VisualPuzzles compared to\nbenchmarks with heavier emphasis on knowledge. VisualPuzzles offers a clearer\nlens through which to evaluate reasoning capabilities beyond factual recall and\ndomain knowledge.", "AI": {"tldr": "Introducing VisualPuzzles, a benchmark for evaluating visual reasoning that minimizes reliance on domain-specific knowledge.", "motivation": "Current benchmarks mix reasoning with specialized knowledge, obscuring genuine reasoning evaluation in non-expert contexts.", "method": "VisualPuzzles includes diverse questions across categories like algorithmic and analogical reasoning, largely sourced from logical reasoning questions of the Chinese Civil Service Examination.", "result": "Experiments reveal that VisualPuzzles demands less domain knowledge and fosters complex reasoning, showing SOTA models underperform compared to humans.", "conclusion": "VisualPuzzles is an effective tool to evaluate reasoning beyond mere factual recall, highlighting distinctive reasoning patterns of models compared to knowledge-heavy benchmarks.", "key_contributions": ["Introduction of VisualPuzzles for visual reasoning evaluation", "Demonstration of SOTA models lagging behind human performance", "Insights on model reasoning patterns relative to knowledge-intensive benchmarks"], "limitations": "The dependency on specific question sources and potential biases in question design.", "future_work": "Exploring further enhancements in reasoning capabilities and cross-benchmark comparisons.", "keywords": ["Visual reasoning", "Benchmarking", "Machine learning", "Multimodal", "Reasoning capabilities"], "importance_score": 7, "read_time_minutes": 20}}
{"id": "2504.12311", "pdf": "https://arxiv.org/pdf/2504.12311.pdf", "abs": "https://arxiv.org/abs/2504.12311", "title": "Learning Optimal Prompt Ensemble for Multi-source Visual Prompt Transfer", "authors": ["Enming Zhang", "Liwen Cao", "Yanru Wu", "Zijie Zhao", "Guan Wang", "Yang Li"], "categories": ["cs.CL"], "comment": null, "summary": "Prompt tuning has emerged as a lightweight adaptation strategy for adapting\nfoundation models to downstream tasks, particularly in resource-constrained\nsystems. As pre-trained prompts have become valuable intellectual assets,\ncombining multiple source prompts offers a promising approach to enhance\ngeneralization to new tasks by leveraging complementary knowledge from diverse\nsources. However, naive aggregation of these prompts often leads to\nrepresentation collapse due to mutual interference, undermining their\ncollective potential. To address these challenges, we propose HGPrompt, an\nadaptive framework for multi-source prompt transfer that learns optimal\nensemble weights by jointly optimizing dual objectives: transferability and\nstability. Specifically, we first introduce an information-theoretic metric to\nevaluate the transferability of prompt-induced features on the target task,\ncapturing the intrinsic alignment between the feature representations.\nAdditionally, we propose a novel Gradient Alignment Regularization to mitigate\ngradient conflicts among prompts, enabling stable and coherent knowledge\ntransfer from multiple sources while suppressing interference. Extensive\nexperiments on the large-scale VTAB benchmark demonstrate that HGPrompt\nachieves state-of-the-art performance, validating its effectiveness in\nmulti-source prompt transfer.", "AI": {"tldr": "HGPrompt is a framework for multi-source prompt transfer that optimizes transferability and stability to enhance generalization while mitigating representation collapse.", "motivation": "The motivation behind this research is to improve the adaptation of foundation models to downstream tasks by combining multiple source prompts without losing performance due to mutual interference.", "method": "The authors propose HGPrompt, which uses an information-theoretic metric for evaluating transferability and a novel Gradient Alignment Regularization to balance the gradient conflicts among prompts during knowledge transfer.", "result": "HGPrompt achieves state-of-the-art performance on the VTAB benchmark, successfully demonstrating its effectiveness in multi-source prompt transfer.", "conclusion": "The framework effectively enhances the generalization capabilities of foundation models by optimizing prompt aggregation while minimizing representation collapse.", "key_contributions": ["Introduction of HGPrompt framework for multi-source prompt transfer.", "Development of an information-theoretic metric for assessing prompt transferability.", "Implementation of Gradient Alignment Regularization to reduce interference among prompts."], "limitations": "", "future_work": "Future research could explore further optimizations in prompt tuning and extending the framework to additional downstream tasks.", "keywords": ["prompt tuning", "multi-source prompt transfer", "information-theoretic metric", "gradient alignment", "foundation models"], "importance_score": 8, "read_time_minutes": 5}}
