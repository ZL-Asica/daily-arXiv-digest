{"id": "2509.02732", "pdf": "https://arxiv.org/pdf/2509.02732.pdf", "abs": "https://arxiv.org/abs/2509.02732", "title": "STRive: An association rule-based system for the exploration of spatiotemporal categorical data", "authors": ["Mauro Diaz", "Luis Sante", "Joel Perca", "João Victor da Silva", "Nivan Ferreira", "Jorge Poco"], "categories": ["cs.HC"], "comment": null, "summary": "Effectively analyzing spatiotemporal data plays a central role in\nunderstanding real-world phenomena and informing decision-making. Capturing the\ninteraction between spatial and temporal dimensions also helps explain the\nunderlying structure of the data. However, most datasets do not reveal\nattribute relationships, requiring additional algorithms to extract meaningful\npatterns. Existing visualization tools often focus either on attribute\nrelationships or spatiotemporal analysis, but rarely support both\nsimultaneously. In this paper, we present STRive (SpatioTemporal Rule\nInteractive Visual Explorer), a visual analytics system that enables users to\nuncover and explore spatial and temporal patterns in data. At the core of\nSTRive lies Association Rule Mining (ARM), which we apply to spatiotemporal\ndatasets to generate interpretable and actionable insights. We combine ARM with\nmultiple interactive mechanisms to analyze the extracted relationships.\nAssociation rules serve as interpretable guidance mechanisms for visual\nanalytics by highlighting the meaningful aspects of the data that users should\ninvestigate. Our methodology includes three key steps: rule generation, rule\nclustering, and interactive visualization. STRive offers two modes of analysis.\nThe first operates at the rule cluster level and includes four coordinated\nviews, each showing a different facet of a cluster, including its temporal and\nspatial behavior. The second mode mirrors the first but focuses on individual\nrules within a selected cluster. We evaluate the effectiveness of STRive\nthrough two case studies involving real-world datasets -- fatal vehicle\naccidents and urban crime. Results demonstrate the system's ability to support\nthe discovery and analysis of interpretable patterns in complex spatiotemporal\ncontexts.", "AI": {"tldr": "STRive is a visual analytics system that helps users explore spatial and temporal patterns in spatiotemporal datasets using Association Rule Mining, offering two modes of analysis for interpreting complex data insights.", "motivation": "Effective analysis of spatiotemporal data is essential for understanding real-world phenomena and making informed decisions, yet existing tools often fail to combine spatial and temporal analysis.", "method": "The methodology involves three steps: generating association rules from spatiotemporal datasets, clustering these rules, and providing interactive visualizations to explore the relationships.", "result": "The evaluation through case studies on fatal vehicle accidents and urban crime demonstrates STRive's capability in discovering and analyzing interpretable patterns from complex datasets.", "conclusion": "STRive enables users to uncover actionable insights by employing a dual-mode visualization of rule clusters and individual rules, demonstrating its effectiveness in spatiotemporal analysis.", "key_contributions": ["Introduction of STRive for spatiotemporal data analysis", "Combines Association Rule Mining with interactive visualization", "Evaluation through real-world datasets to showcase effectiveness"], "limitations": "", "keywords": ["spatiotemporal analysis", "visual analytics", "association rule mining"], "importance_score": 5, "read_time_minutes": 8}}
{"id": "2509.02878", "pdf": "https://arxiv.org/pdf/2509.02878.pdf", "abs": "https://arxiv.org/abs/2509.02878", "title": "Designing a Lightweight GenAI Interface for Visual Data Analysis", "authors": ["Ratanond Koonchanok", "Alex Kale", "Khairi Reda"], "categories": ["cs.HC"], "comment": null, "summary": "Recent advances in Generative AI have transformed how users interact with\ndata analysis through natural language interfaces. However, many systems rely\ntoo heavily on LLMs, creating risks of hallucination, opaque reasoning, and\nreduced user control. We present a hybrid visual analysis system that\nintegrates GenAI in a constrained, high-level role to support statistical\nmodeling while preserving transparency and user agency. GenAI translates\nnatural language intent into formal statistical formulations, while interactive\nvisualizations surface model behavior, residual patterns, and hypothesis\ncomparisons to guide iterative exploration. Model fitting, diagnostics, and\nhypothesis testing are delegated entirely to a structured R-based backend,\nensuring correctness, interpretability, and reproducibility. By combining\nGenAI-assisted intent translation with visualization-driven reasoning, our\napproach broadens access to modeling tools without compromising rigor. We\npresent an example use case of the tool and discuss challenges and\nopportunities for future research.", "AI": {"tldr": "This paper presents a hybrid visual analysis system that integrates Generative AI (GenAI) to assist in statistical modeling while maintaining transparency and user control.", "motivation": "To address the limitations of existing systems that overly rely on LLMs, causing issues like hallucination and opaque reasoning.", "method": "The system uses GenAI for translating natural language intents into statistical formulations, while employing interactive visualizations to reveal model behavior and support exploratory analysis.", "result": "The system enables users to fit models, perform diagnostics, and test hypotheses within a structured R-based backend, thereby ensuring correctness and interpretability of results.", "conclusion": "The integration of GenAI in a controlled way enhances accessibility to statistical tools while upholding research rigor, with discussions on the implications for future developments.", "key_contributions": ["Hybrid approach combining GenAI with visual analysis", "Ensures correctness and interpretability through a structured R-based backend", "Broadens access to modeling tools without sacrificing rigor."], "limitations": "", "keywords": ["Generative AI", "visual analysis", "statistical modeling"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2509.02910", "pdf": "https://arxiv.org/pdf/2509.02910.pdf", "abs": "https://arxiv.org/abs/2509.02910", "title": "The Basic B*** Effect: The Use of LLM-based Agents Reduces the Distinctiveness and Diversity of People's Choices", "authors": ["Sandra C. Matz", "C. Blaine Horton", "Sofie Goethals"], "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) increasingly act on people's behalf: they write\nemails, buy groceries, and book restaurants. While the outsourcing of human\ndecision-making to AI can be both efficient and effective, it raises a\nfundamental question: how does delegating identity-defining choices to AI\nreshape who people become? We study the impact of agentic LLMs on two\nidentity-relevant outcomes: interpersonal distinctiveness - how unique a\nperson's choices are relative to others - and intrapersonal diversity - the\nbreadth of a single person's choices over time. Using real choices drawn from\nsocial-media behavior of 1,000 U.S. users (110,000 choices in total), we\ncompare a generic and personalized agent to a human baseline. Both agents shift\npeople's choices toward more popular options, reducing the distinctiveness of\ntheir behaviors and preferences. While the use of personalized agents tempers\nthis homogenization (compared to the generic AI), it also more strongly\ncompresses the diversity of people's preference portfolios by narrowing what\nthey explore across topics and psychological affinities. Understanding how AI\nagents might flatten human experience, and how using generic versus\npersonalized agents involves distinctiveness-diversity trade-offs, is critical\nfor designing systems that augment rather than constrain human agency, and for\nsafeguarding diversity in thought, taste, and expression.", "AI": {"tldr": "Study on how LLMs impact personal choices and identity, revealing trade-offs between distinctiveness and diversity in user behavior.", "motivation": "To understand the effects of large language models on identity-defining choices made by individuals.", "method": "Analyzed 110,000 social media choices from 1,000 U.S. users, comparing choices made with a generic agent, a personalized agent, and a human baseline.", "result": "Both LLM agents lead to less distinct choices, with personalized agents reducing distinctiveness more than generic agents but compressing the breadth of individual preferences.", "conclusion": "The design of AI systems must consider the impact on human agency and the trade-offs between distinctiveness and diversity in user choices.", "key_contributions": ["Introduced the concept of distinctiveness-diversity trade-offs in agentic LLM use.", "Provided empirical evidence on how LLMs affect interpersonal distinctiveness and intrapersonal diversity.", "Highlighted the need for careful design of AI systems to safeguard diversity in human experience."], "limitations": "Study focused on social media choices; more research needed across diverse contexts and decision-making scenarios.", "keywords": ["large language models", "identity", "human agency", "distinctiveness", "diversity"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2509.02933", "pdf": "https://arxiv.org/pdf/2509.02933.pdf", "abs": "https://arxiv.org/abs/2509.02933", "title": "Demonstrating Visual Information Manipulation Attacks in Augmented Reality: A Hands-On Miniature City-Based Setup", "authors": ["Yanming Xiu", "Maria Gorlatova"], "categories": ["cs.HC"], "comment": "The paper has been accepted to 2025 MobiHoc 1st Workshop on Enhancing\n  Security, Privacy, and Trust in Extended Reality (XR) Systems", "summary": "Augmented reality (AR) enhances user interaction with the real world but also\npresents vulnerabilities, particularly through Visual Information Manipulation\n(VIM) attacks. These attacks alter important real-world visual cues, leading to\nuser confusion and misdirected actions. In this demo, we present a hands-on\nexperience using a miniature city setup, where users interact with manipulated\nAR content via the Meta Quest 3. The demo highlights the impact of VIM attacks\non user decision-making and underscores the need for effective security\nmeasures in AR systems. Future work includes a user study and cross-platform\ntesting.", "AI": {"tldr": "This paper discusses the impact of Visual Information Manipulation attacks on augmented reality interactions, using a hands-on demo to illustrate its effects.", "motivation": "The paper addresses the security vulnerabilities in augmented reality systems caused by Visual Information Manipulation (VIM) attacks, which can confuse users and lead to poor decision-making.", "method": "A hands-on demo using a miniature city setup and the Meta Quest 3 allows users to interact with manipulated AR content to observe the effects of VIM attacks.", "result": "The demo illustrates significant user confusion and misdirected actions as a result of VIM attacks on augmented reality content.", "conclusion": "The study underscores the necessity for effective security measures in AR systems to protect users from vulnerabilities introduced by VIM attacks.", "key_contributions": ["Hands-on demonstration of VIM attacks in a controlled environment.", "Identification of user confusion as a consequence of manipulated AR content.", "Proposal for future user studies and cross-platform testing to validate findings."], "limitations": "", "keywords": ["Augmented Reality", "Visual Information Manipulation", "User Interaction", "Security", "User Study"], "importance_score": 7, "read_time_minutes": 5}}
{"id": "2509.02785", "pdf": "https://arxiv.org/pdf/2509.02785.pdf", "abs": "https://arxiv.org/abs/2509.02785", "title": "DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off", "authors": ["Jusheng Zhang", "Yijia Fan", "Kaitong Cai", "Zimeng Huang", "Xiaofei Sun", "Jian Wang", "Chengpei Tang", "Keze Wang"], "categories": ["cs.CL", "cs.AI"], "comment": "Accepted 2025 EMNLP (MainConference)", "summary": "This paper introduces DrDiff, a novel framework for long-text generation that\novercomes the efficiency-quality trade-off through three core technologies.\nFirst, we design a dynamic expert scheduling mechanism that intelligently\nallocates computational resources during the diffusion process based on text\ncomplexity, enabling more efficient handling of text generation tasks of\nvarying difficulty. Second, we introduce a Hierarchical Sparse Attention (HSA)\nmechanism that adaptively adjusts attention patterns according to a variety of\ninput lengths, reducing computational complexity from O($n^2$) to O($n$) while\nmaintaining model performance. Finally, we propose a soft absorption guidance\noptimization strategy that combines with DPM-solver++ to reduce diffusion\nsteps, significantly improving generation speed. Comprehensive experiments on\nvarious long-text generation benchmarks demonstrate the superiority of our\nDrDiff over the existing SOTA methods.", "AI": {"tldr": "DrDiff is a novel framework for efficient long-text generation that improves efficiency and quality through expert scheduling, hierarchical sparse attention, and absorption guidance optimization.", "motivation": "The paper addresses the efficiency-quality trade-off in long-text generation tasks, aiming to enhance the performance of text generation models.", "method": "The method includes a dynamic expert scheduling mechanism, a Hierarchical Sparse Attention (HSA) mechanism, and a soft absorption guidance optimization strategy.", "result": "DrDiff demonstrates superior performance on long-text generation benchmarks compared to existing state-of-the-art methods.", "conclusion": "The proposed DrDiff framework significantly improves generation speed and maintains high model performance, providing a viable solution for efficient long-text generation.", "key_contributions": ["Dynamic expert scheduling for text complexity-based resource allocation", "Hierarchical Sparse Attention mechanism for reducing computational complexity", "Soft absorption guidance optimization to speed up generation"], "limitations": "", "keywords": ["long-text generation", "dynamic scheduling", "sparse attention", "absorption guidance", "ML"], "importance_score": 8, "read_time_minutes": 5}}
{"id": "2509.03164", "pdf": "https://arxiv.org/pdf/2509.03164.pdf", "abs": "https://arxiv.org/abs/2509.03164", "title": "OPRA-Vis: Visual Analytics System to Assist Organization-Public Relationship Assessment with Large Language Models", "authors": ["Sangbong Yoo", "Seongbum Seo", "Chanyoung Yoon", "Hyelim Lee", "Jeong-Nam Kim", "Chansoo Kim", "Yun Jang", "Takanori Fujiwara"], "categories": ["cs.HC"], "comment": null, "summary": "Analysis of public opinions collected from digital media helps organizations\nmaintain positive relationships with the public. Such public relations (PR)\nanalysis often involves assessing opinions, for example, measuring how strongly\npeople trust an organization. Pre-trained Large Language Models (LLMs) hold\ngreat promise for supporting Organization-Public Relationship Assessment (OPRA)\nbecause they can map unstructured public text to OPRA dimensions and articulate\nrationales through prompting. However, adapting LLMs for PR analysis typically\nrequires fine-tuning on large labeled datasets, which is both labor-intensive\nand knowledge-intensive, making it difficult for PR researchers to apply these\nmodels. In this paper, we present OPRA-Vis, a visual analytics system that\nleverages LLMs for OPRA without requiring extensive labeled data. Our framework\nemploys Chain-of-Thought prompting to guide LLMs in analyzing public opinion\ndata by incorporating PR expertise directly into the reasoning process.\nFurthermore, OPRA-Vis provides visualizations that reveal the clues and\nreasoning paths used by LLMs, enabling users to explore, critique, and refine\nmodel decisions. We demonstrate the effectiveness of OPRA-Vis through two\nreal-world use cases and evaluate it quantitatively, through comparisons with\nalternative LLMs and prompting strategies, and qualitatively, through\nassessments of usability, effectiveness, and expert feedback.", "AI": {"tldr": "OPRA-Vis is a visual analytics system that utilizes Large Language Models for public relations analysis without the need for large labeled datasets, enabling effective analysis of public opinions and providing insightful visualizations.", "motivation": "Organizations need to understand public opinions to maintain positive relationships, but adapting LLMs requires extensive labeled datasets which are hard to obtain in PR contexts.", "method": "The OPRA-Vis framework employs Chain-of-Thought prompting to utilize LLMs for analyzing public opinion data while directly incorporating PR expertise into the reasoning process.", "result": "The effectiveness of OPRA-Vis was demonstrated with two real-world use cases, showing its usability, effectiveness, and positive expert feedback, as well as performance comparisons with alternative LLMs.", "conclusion": "OPRA-Vis facilitates more accessible and effective public relations analysis by minimizing the dependency on large labeled datasets while still leveraging the power of LLMs.", "key_contributions": ["Introduction of OPRA-Vis as a visual analytics system for PR analysis using LLMs.", "Utilization of Chain-of-Thought prompting to integrate PR expertise into LLM reasoning.", "Visualizations that allow users to explore and critique LLM decisions."], "limitations": "", "keywords": ["Organization-Public Relationship Assessment", "Large Language Models", "Public Relations Analysis"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2509.02830", "pdf": "https://arxiv.org/pdf/2509.02830.pdf", "abs": "https://arxiv.org/abs/2509.02830", "title": "SSVD: Structured SVD for Parameter-Efficient Fine-Tuning and Benchmarking under Domain Shift in ASR", "authors": ["Pu Wang", "Shinji Watanabe", "Hugo Van hamme"], "categories": ["cs.CL", "eess.AS"], "comment": "Accepted by IEEE ASRU 2025", "summary": "Parameter-efficient fine-tuning (PEFT) has emerged as a scalable solution for\nadapting large foundation models. While low-rank adaptation (LoRA) is widely\nused in speech applications, its state-of-the-art variants, e.g., VeRA, DoRA,\nPiSSA, and SVFT, are developed mainly for language and vision tasks, with\nlimited validation in speech. This work presents the first comprehensive\nintegration and benchmarking of these PEFT methods within ESPnet. We further\nintroduce structured SVD-guided (SSVD) fine-tuning, which selectively rotates\ninput-associated right singular vectors while keeping output-associated vectors\nfixed to preserve semantic mappings. This design enables robust domain\nadaptation with minimal trainable parameters and improved efficiency. We\nevaluate all methods on domain-shifted speech recognition tasks, including\nchild speech and dialectal variation, across model scales from 0.1B to 2B. All\nimplementations are released in ESPnet to support reproducibility and future\nwork.", "AI": {"tldr": "This paper benchmarks various parameter-efficient fine-tuning methods for speech recognition, including a new structured SVD-guided approach to improve domain adaptation efficiency.", "motivation": "To integrate and benchmark parameter-efficient fine-tuning methods for better performance in speech recognition tasks.", "method": "The paper introduces structured SVD-guided (SSVD) fine-tuning, which selectively adjusts specific singular vectors during training to enhance efficiency and domain adaptation.", "result": "The methods were evaluated on tasks involving child speech and dialectal variations, demonstrating improved performance and efficiency across different model sizes.", "conclusion": "The proposed SSVD fine-tuning method provides a robust approach for domain adaptation in speech recognition while maintaining low parameter counts.", "key_contributions": ["First comprehensive benchmarking of PEFT methods in speech recognition", "Introduction of structured SVD-guided fine-tuning for efficient domain adaptation", "Evaluation of multiple PEFT methods across various model scales."], "limitations": "The focus is predominantly on speech applications, potentially limiting applicability to other areas like language or vision.", "keywords": ["Parameter-efficient fine-tuning", "speech recognition", "domain adaptation"], "importance_score": 5, "read_time_minutes": 10}}
{"id": "2509.03181", "pdf": "https://arxiv.org/pdf/2509.03181.pdf", "abs": "https://arxiv.org/abs/2509.03181", "title": "Beyond Words: Interjection Classification for Improved Human-Computer Interaction", "authors": ["Yaniv Goren", "Yuval Cohen", "Alexander Apartsin", "Yehudit Aperstein"], "categories": ["cs.HC", "cs.LG"], "comment": "9 pages", "summary": "In the realm of human-computer interaction, fostering a natural dialogue\nbetween humans and machines is paramount. A key, often overlooked, component of\nthis dialogue is the use of interjections such as \"mmm\" and \"hmm\". Despite\ntheir frequent use to express agreement, hesitation, or requests for\ninformation, these interjections are typically dismissed as \"non-words\" by\nAutomatic Speech Recognition (ASR) engines. Addressing this gap, we introduce a\nnovel task dedicated to interjection classification, a pioneer in the field to\nour knowledge. This task is challenging due to the short duration of\ninterjection signals and significant inter- and intra-speaker variability. In\nthis work, we present and publish a dataset of interjection signals collected\nspecifically for interjection classification. We employ this dataset to train\nand evaluate a baseline deep learning model. To enhance performance, we augment\nthe training dataset using techniques such as tempo and pitch transformation,\nwhich significantly improve classification accuracy, making models more robust.\nThe interjection dataset, a Python library for the augmentation pipeline,\nbaseline model, and evaluation scripts, are available to the research\ncommunity.", "AI": {"tldr": "This paper introduces a novel task in human-computer interaction focused on classifying interjections like \"mmm\" and \"hmm,\" addressing their dismissal in ASR systems by presenting a dedicated dataset and baseline deep learning model.", "motivation": "To improve the natural dialogue in human-computer interactions by recognizing the importance of interjections, which are usually ignored by ASR engines.", "method": "A dataset of interjection signals was collected and annotated for interjection classification. A baseline deep learning model was trained and evaluated using this dataset, with performance enhancements through tempo and pitch transformation techniques for data augmentation.", "result": "The baseline model achieved improved classification accuracy thanks to the data augmentation strategies, indicating the potential of these techniques for creating more robust models.", "conclusion": "The work highlights the significance of interjections in conversation and provides valuable resources, including an interjection dataset, a Python library for augmentation, and evaluation scripts, to facilitate further research in this area.", "key_contributions": ["Introduction of a novel interjection classification task in ASR systems", "Publication of a dedicated interjection dataset for research use", "Development of a baseline deep learning model with performance enhancement techniques"], "limitations": "", "keywords": ["Human-Computer Interaction", "Interjection Classification", "Automatic Speech Recognition", "Deep Learning", "Data Augmentation"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2509.02834", "pdf": "https://arxiv.org/pdf/2509.02834.pdf", "abs": "https://arxiv.org/abs/2509.02834", "title": "Clustering Discourses: Racial Biases in Short Stories about Women Generated by Large Language Models", "authors": ["Gustavo Bonil", "João Gondim", "Marina dos Santos", "Simone Hashiguti", "Helena Maia", "Nadia Silva", "Helio Pedrini", "Sandra Avila"], "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 3 figures. Accepted at STIL @ BRACIS 2025", "summary": "This study investigates how large language models, in particular LLaMA\n3.2-3B, construct narratives about Black and white women in short stories\ngenerated in Portuguese. From 2100 texts, we applied computational methods to\ngroup semantically similar stories, allowing a selection for qualitative\nanalysis. Three main discursive representations emerge: social overcoming,\nancestral mythification and subjective self-realization. The analysis uncovers\nhow grammatically coherent, seemingly neutral texts materialize a crystallized,\ncolonially structured framing of the female body, reinforcing historical\ninequalities. The study proposes an integrated approach, that combines machine\nlearning techniques with qualitative, manual discourse analysis.", "AI": {"tldr": "This study explores narrative constructions involving Black and white women in Portuguese short stories generated by LLaMA 3.2-3B, revealing social and historical inequalities.", "motivation": "To investigate how large language models construct narratives that reflect historical inequalities, especially regarding gender and race, in automatically generated texts.", "method": "Analyzed 2100 texts generated using LLaMA 3.2-3B, applying computational methods to group semantically similar stories for qualitative analysis.", "result": "The analysis identified three main discursive representations: social overcoming, ancestral mythification, and subjective self-realization, highlighting how these texts reinforce historical inequalities.", "conclusion": "The study suggests integrating machine learning techniques with qualitative discourse analysis to better understand how narratives in AI-generated texts reflect social issues.", "key_contributions": ["Introduces a framework for analyzing AI-generated narratives with a focus on gender and race.", "Identifies key discursive representations in AI-generated stories about women.", "Proposes a novel integrated methodology combining qualitative and computational analysis."], "limitations": "Focuses specifically on narratives generated in Portuguese, which may limit generalizability to other languages or contexts.", "keywords": ["Large language models", "Discourse analysis", "Narrative construction", "Social inequalities", "Machine learning"], "importance_score": 6, "read_time_minutes": 12}}
{"id": "2509.03199", "pdf": "https://arxiv.org/pdf/2509.03199.pdf", "abs": "https://arxiv.org/abs/2509.03199", "title": "Finding My Way: Influence of Different Audio Augmented Reality Navigation Cues on User Experience and Subjective Usefulness", "authors": ["Sina Hinzmann", "Francesco Vona", "Juliane Henning", "Mohamed Amer", "Omar Abdellatif", "Tanja Kojic", "Jan-Niklas Voigt-Antons"], "categories": ["cs.HC"], "comment": null, "summary": "As augmented reality (AR) becomes increasingly prevalent in mobile and\ncontext-aware applications, the role of auditory cues in guiding users through\nphysical environments is becoming critical. This study investigates the\neffectiveness and user experience of various categories of audio cues,\nincluding fully non-verbal sounds and speech-derived Spearcons, during outdoor\nnavigation tasks using the Meta Quest 3 headset. Twenty participants navigated\nfive outdoor routes using audio-only cue types: Artificial Sounds, Nature\nSounds, Spearcons, Musical Instruments, and Auditory Icons. Subjective\nevaluations were collected to assess the perceived effectiveness and user\nexperience of each sound type. Results revealed significant differences in\nperceived novelty and stimulation across sound types. Artificial Sounds and\nMusical Instruments were rated higher than Spearcons in novelty, while\nArtificial Sounds were also rated higher than Spearcons in stimulation. Overall\npreference was evenly split between Nature Sounds and Artificial Sounds. These\nfindings suggest that incorporating aspects of novelty and user engagement in\nauditory feedback design may enhance the effectiveness of AR navigation\nsystems.", "AI": {"tldr": "The study explores how different types of auditory cues affect user experience during AR navigation tasks.", "motivation": "To understand the role of auditory cues in enhancing navigation experiences in augmented reality (AR) applications.", "method": "Twenty participants used a Meta Quest 3 headset to navigate five outdoor routes with various audio cues, including Artificial Sounds, Nature Sounds, Spearcons, Musical Instruments, and Auditory Icons. Subjective evaluations were collected to assess perceived effectiveness and user experience of each sound type.", "result": "Significant differences were found in perceived novelty and stimulation among sound types. Artificial Sounds and Musical Instruments were rated higher for novelty, while Artificial Sounds outperformed Spearcons in stimulation. Overall preference was split between Nature Sounds and Artificial Sounds.", "conclusion": "Incorporating novelty and user engagement into auditory feedback design can enhance the effectiveness of AR navigation systems.", "key_contributions": ["Examines the impact of audio cue types on user navigation in AR environments.", "Highlights the importance of novelty and stimulation in auditory feedback design.", "Provides empirical insights for designing effective AR navigation systems."], "limitations": "Limited sample size and specific context (outdoor navigation), may not generalize to all AR applications.", "keywords": ["Augmented Reality", "Auditory Cues", "User Experience", "Navigation", "AR Systems"], "importance_score": 7, "read_time_minutes": 5}}
{"id": "2509.02855", "pdf": "https://arxiv.org/pdf/2509.02855.pdf", "abs": "https://arxiv.org/abs/2509.02855", "title": "IDEAlign: Comparing Large Language Models to Human Experts in Open-ended Interpretive Annotations", "authors": ["Hyunji Nam", "Lucia Langlois", "James Malamut", "Mei Tan", "Dorottya Demszky"], "categories": ["cs.CL", "cs.CY"], "comment": "10 pages, 9 pages for appendix", "summary": "Large language models (LLMs) are increasingly applied to open-ended,\ninterpretive annotation tasks, such as thematic analysis by researchers or\ngenerating feedback on student work by teachers. These tasks involve free-text\nannotations requiring expert-level judgments grounded in specific objectives\n(e.g., research questions or instructional goals). Evaluating whether\nLLM-generated annotations align with those generated by expert humans is\nchallenging to do at scale, and currently, no validated, scalable measure of\nsimilarity in ideas exists. In this paper, we (i) introduce the scalable\nevaluation of interpretive annotation by LLMs as a critical and understudied\ntask, (ii) propose IDEAlgin, an intuitive benchmarking paradigm for capturing\nexpert similarity ratings via a \"pick-the-odd-one-out\" triplet judgment task,\nand (iii) evaluate various similarity metrics, including vector-based ones\n(topic models, embeddings) and LLM-as-a-judge via IDEAlgin, against these human\nbenchmarks. Applying this approach to two real-world educational datasets\n(interpretive analysis and feedback generation), we find that vector-based\nmetrics largely fail to capture the nuanced dimensions of similarity meaningful\nto experts. Prompting LLMs via IDEAlgin significantly improves alignment with\nexpert judgments (9-30% increase) compared to traditional lexical and\nvector-based metrics. These results establish IDEAlgin as a promising paradigm\nfor evaluating LLMs against open-ended expert annotations at scale, informing\nresponsible deployment of LLMs in education and beyond.", "AI": {"tldr": "The paper introduces IDEAlgin, a benchmarking paradigm for evaluating the similarity of LLM-generated annotations to expert human annotations in interpretive tasks.", "motivation": "There is a lack of validated measures for assessing the alignment of LLM-generated annotations with expert judgments, which is crucial for their effective deployment in tasks like educational feedback and thematic analysis.", "method": "IDEAlgin uses a 'pick-the-odd-one-out' triplet judgment task to capture expert similarity ratings and compares various similarity metrics including vector-based ones and LLM-as-a-judge against human benchmarks.", "result": "The study reveals that traditional vector-based metrics are inadequate in capturing expert nuance, whereas IDEAlgin significantly boosts alignment with expert responses (9-30% improvement).", "conclusion": "IDEAlgin is positioned as a vital tool for scaling the evaluation of LLMs in interpretive annotation tasks, promoting responsible utilization in educational contexts and beyond.", "key_contributions": ["Introduction of IDEAlgin for evaluating interpretive annotation by LLMs", "Demonstration of significant improvements in expert alignment using IDEAlgin", "Critique of existing vector-based metrics in measuring nuanced similarity"], "limitations": "", "keywords": ["Large language models", "interpretive annotation", "evaluation metrics", "education", "expert judgments"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2509.03232", "pdf": "https://arxiv.org/pdf/2509.03232.pdf", "abs": "https://arxiv.org/abs/2509.03232", "title": "Card Sorting with Fewer Cards and the Same Mental Models? A Re-examination of an Established Practice", "authors": ["Eduard Kuric", "Peter Demcak", "Matus Krajcovic"], "categories": ["cs.HC", "H.5"], "comment": null, "summary": "To keep card sorting with a lot of cards concise, a common strategy for\ngauging mental models involves presenting participants with fewer randomly\nselected cards instead of the full set. This is a decades-old practice, but its\neffects lacked systematic examination. To assess how randomized subsets affect\ndata, we conducted an experiment with 160 participants. We compared results\nbetween full and randomized 60\\% card sets, then analyzed sample size\nrequirements and the impacts of individual personality and cognitive factors.\nOur results demonstrate that randomized subsets can yield comparable similarity\nmatrices to standard card sorting, but thematic patterns in categories can\ndiffer. Increased data variability also warrants larger sample sizes (25-35 for\n60% card subset). Results indicate that personality traits and cognitive\nreflection interact with card sorting. Our research suggests evidence-based\npractices for conducting card sorting while exposing the influence of study\ndesign and individual differences on measurement of mental models.", "AI": {"tldr": "This paper investigates the impact of using randomized subsets in card sorting on mental models, comparing these to full card sets.", "motivation": "To systematically examine the effects of using fewer randomly selected cards in card sorting on data outcomes, given its common use in gauging mental models.", "method": "An experiment with 160 participants compared full card sets to randomized 60% card subsets, analyzing sample size requirements and the effects of individual cognitive factors.", "result": "Randomized subsets yield comparable similarity matrices, but thematic patterns differ, indicating increased data variability necessitates larger sample sizes (25-35).", "conclusion": "The study highlights the importance of considering individual differences and study design when interpreting card sorting results, providing evidence-based practices.", "key_contributions": ["Demonstrated that randomized subsets can provide similar data outcomes as full sets in card sorting.", "Identified the need for larger sample sizes when using random subsets due to increased data variability.", "Showed the interaction of personality traits and cognitive reflection with card sorting outcomes."], "limitations": "Limited to specific personality traits measured; results may vary with different participant demographics.", "keywords": ["card sorting", "mental models", "randomized subsets", "sample size", "personality traits"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2509.02864", "pdf": "https://arxiv.org/pdf/2509.02864.pdf", "abs": "https://arxiv.org/abs/2509.02864", "title": "A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation", "authors": ["Kesen Wang", "Daulet Toibazar", "Pedro J. Moreno"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present an end-to-end, self-evolving adversarial workflow for long-context\nQuestion-Answer (QA) Generation in Arabic. By orchestrating multiple\nspecialized LVLMs: a question generator, an evaluator, and a swarm of answer\ngenerators, our system iteratively refines its own performance without any\nhuman intervention. Starting from raw, multi-page Arabic documents across\ndiverse domains, the question generator produces fine-grained, context-aware\nqueries to be tackled by the answer generator swarm, and the evaluator assesses\nand feeds back quality metrics. This closed-loop cycle enables continuous\nlearning: low-confidence outputs trigger automated re-generation and model\nupdates, progressively enhancing question difficulty and relevance. Moreover,\nwe set the quality metrics as a tunable hyperparameter, enabling question\ngeneration at controllable and customizable difficulty levels. We release\nAraLongBench, a large-scale Arabic benchmark of single- and multi-page\nchallenges spanning hundreds of pages, and demonstrate that our self-evolving\nworkflow substantially outperform static pipelines, markedly boosting the\nlong-context comprehension capabilities of leading Arabic Large Vision Language\nModels (LVLMs). Lastly, we also meticulously architect a fully automated\nagentic workflow for long-context Arabic document collection.", "AI": {"tldr": "An automated, self-evolving workflow for long-context QA generation in Arabic using LVLMs to improve performance without human intervention.", "motivation": "To enhance question-answering capabilities on long-context Arabic documents by creating an automated workflow that refines itself dynamically.", "method": "The system utilizes multiple LVLMs including a question generator, answer generators, and an evaluator, working in a feedback loop to continuously learn and improve output quality.", "result": "The proposed workflow significantly outperforms static pipelines and boosts comprehension in long-context scenarios for Arabic LVLMs.", "conclusion": "The release of AraLongBench offers a benchmark for Arabic QA tasks and demonstrates the efficacy of a fully automated, agentic workflow.", "key_contributions": ["Introduction of a self-evolving adversarial workflow for QA in Arabic", "Release of AraLongBench, a benchmark for Arabic question-answering", "Demonstration of significant performance improvements over existing static methods"], "limitations": "", "keywords": ["Arabic", "Question-Answer Generation", "Large Vision Language Models", "Self-evolving Workflow", "Benchmark"], "importance_score": 5, "read_time_minutes": 10}}
{"id": "2509.03271", "pdf": "https://arxiv.org/pdf/2509.03271.pdf", "abs": "https://arxiv.org/abs/2509.03271", "title": "Beyond Quantification: Navigating Uncertainty in Professional AI Systems", "authors": ["Sylvie Delacroix", "Diana Robinson", "Umang Bhatt", "Jacopo Domenicucci", "Jessica Montgomery", "Gael Varoquaux", "Carl Henrik Ek", "Vincent Fortuin", "Yulan He", "Tom Diethe", "Neill Campbell", "Mennatallah El-Assady", "Soren Hauberg", "Ivana Dusparic", "Neil Lawrence"], "categories": ["cs.HC"], "comment": null, "summary": "The growing integration of large language models across professional domains\ntransforms how experts make critical decisions in healthcare, education, and\nlaw. While significant research effort focuses on getting these systems to\ncommunicate their outputs with probabilistic measures of reliability, many\nconsequential forms of uncertainty in professional contexts resist such\nquantification. A physician pondering the appropriateness of documenting\npossible domestic abuse, a teacher assessing cultural sensitivity, or a\nmathematician distinguishing procedural from conceptual understanding face\nforms of uncertainty that cannot be reduced to percentages. This paper argues\nfor moving beyond simple quantification toward richer expressions of\nuncertainty essential for beneficial AI integration. We propose participatory\nrefinement processes through which professional communities collectively shape\nhow different forms of uncertainty are communicated. Our approach acknowledges\nthat uncertainty expression is a form of professional sense-making that\nrequires collective development rather than algorithmic optimization.", "AI": {"tldr": "The paper discusses how large language models (LLMs) impact decision-making in various professional fields and argues for richer expressions of uncertainty rather than simple quantification.", "motivation": "The integration of large language models in fields like healthcare and education necessitates a better understanding of how to communicate uncertainty in decisions, as traditional quantification methods fall short.", "method": "The paper advocates for participatory refinement processes where professional communities collaboratively define and shape the expression of uncertainty in their respective domains.", "result": "It highlights the inadequacy of probabilistic measures for capturing complex uncertainties faced by professionals, suggesting alternative approaches that foster collaborative sense-making.", "conclusion": "The authors conclude that effectively communicating different forms of uncertainty requires collective input from professionals rather than relying solely on algorithmic solutions.", "key_contributions": ["Proposed participatory refinement processes for uncertainty communication.", "Emphasized the need for richer expressions of uncertainty in decision-making.", "Critiqued the limitations of current probabilistic measures in professional contexts."], "limitations": "The paper does not provide empirical data to support the proposed methods.", "keywords": ["large language models", "uncertainty", "participatory design", "healthcare", "education"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2509.02908", "pdf": "https://arxiv.org/pdf/2509.02908.pdf", "abs": "https://arxiv.org/abs/2509.02908", "title": "Advancing Minority Stress Detection with Transformers: Insights from the Social Media Datasets", "authors": ["Santosh Chapagain", "Cory J Cascalheira", "Shah Muhammad Hamdi", "Soukaina Filali Boubrahimi", "Jillian R. Scheer"], "categories": ["cs.CL"], "comment": "Accepted in Social Network Analysis and Mining Journal (SNAM)", "summary": "Individuals from sexual and gender minority groups experience\ndisproportionately high rates of poor health outcomes and mental disorders\ncompared to their heterosexual and cisgender counterparts, largely as a\nconsequence of minority stress as described by Meyer's (2003) model. This study\npresents the first comprehensive evaluation of transformer-based architectures\nfor detecting minority stress in online discourse. We benchmark multiple\ntransformer models including ELECTRA, BERT, RoBERTa, and BART against\ntraditional machine learning baselines and graph-augmented variants. We further\nassess zero-shot and few-shot learning paradigms to assess their applicability\non underrepresented datasets. Experiments are conducted on the two largest\npublicly available Reddit corpora for minority stress detection, comprising\n12,645 and 5,789 posts, and are repeated over five random seeds to ensure\nrobustness. Our results demonstrate that integrating graph structure\nconsistently improves detection performance across transformer-only models and\nthat supervised fine-tuning with relational context outperforms zero and\nfew-shot approaches. Theoretical analysis reveals that modeling social\nconnectivity and conversational context via graph augmentation sharpens the\nmodels' ability to identify key linguistic markers such as identity\nconcealment, internalized stigma, and calls for support, suggesting that\ngraph-enhanced transformers offer the most reliable foundation for digital\nhealth interventions and public health policy.", "AI": {"tldr": "Evaluation of transformer-based architectures for detecting minority stress in online discourse, showing that graph-augmented models improve performance.", "motivation": "To address the health disparities faced by sexual and gender minority groups and evaluate the effectiveness of machine learning models in detecting minority stress in online discourse.", "method": "Benchmarking multiple transformer models (ELECTRA, BERT, RoBERTa, BART) against traditional machine learning and graph-augmented models, testing zero-shot and few-shot learning on Reddit corpora.", "result": "Graph-augmented transformers consistently outperform traditional models in detecting minority stress, especially with supervised fine-tuning that integrates relational context.", "conclusion": "Graph-enhanced transformers provide a reliable foundation for interventions in digital health and public health policy by effectively identifying linguistic markers of minority stress.", "key_contributions": ["First comprehensive evaluation of transformer architectures for minority stress detection", "Demonstrated improvement in detection performance with graph-augmented models", "Highlighted importance of incorporating social connectivity and conversational context."], "limitations": "Study limited to online discourse within specific Reddit corpora; generalizability to other contexts may vary.", "keywords": ["minority stress", "transformer models", "graph augmentation", "machine learning", "public health"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2509.03392", "pdf": "https://arxiv.org/pdf/2509.03392.pdf", "abs": "https://arxiv.org/abs/2509.03392", "title": "More AI Assistance Reduces Cognitive Engagement: Examining the AI Assistance Dilemma in AI-Supported Note-Taking", "authors": ["Xinyue Chen", "Kunlin Ruan", "Kexin Phyllis Ju", "Nathan Yap", "Xu Wang"], "categories": ["cs.HC"], "comment": "Accepted by CSCW2025", "summary": "As AI tools become increasingly embedded in cognitively demanding tasks such\nas note-taking, questions remain about whether they enhance or undermine\ncognitive engagement. This paper examines the \"AI Assistance Dilemma\" in\nnote-taking, investigating how varying levels of AI support affect user\nengagement and comprehension. In a within-subject experiment, we asked\nparticipants (N=30) to take notes during lecture videos under three conditions:\nAutomated AI (high assistance with structured notes), Intermediate AI (moderate\nassistance with real-time summary, and Minimal AI (low assistance with\ntranscript). Results reveal that Intermediate AI yields the highest post-test\nscores and Automated AI the lowest. Participants, however, preferred the\nautomated setup due to its perceived ease of use and lower cognitive effort,\nsuggesting a discrepancy between preferred convenience and cognitive benefits.\nOur study provides insights into designing AI assistance that preserves\ncognitive engagement, offering implications for designing moderate AI support\nin cognitive tasks.", "AI": {"tldr": "The paper investigates the impact of different levels of AI assistance in note-taking on user engagement and comprehension, finding that Intermediate AI support produced the best cognitive results despite users preferring more automated solutions.", "motivation": "To explore how varying AI support levels influence cognitive engagement and learning outcomes during note-taking. The research addresses the implications of using AI tools in cognitively demanding tasks.", "method": "Conducted a within-subject experiment with 30 participants taking notes under three AI assistance conditions: Automated AI, Intermediate AI, and Minimal AI.", "result": "Intermediate AI resulted in the highest post-test scores, while Automated AI led to the lowest comprehension scores. Preferences leaned towards Automated AI despite its lower cognitive benefits.", "conclusion": "The findings suggest a need for careful design of AI assistance to enhance cognitive engagement, advocating for moderate AI support in tasks requiring cognitive effort.", "key_contributions": ["Investigates the 'AI Assistance Dilemma' in note-taking.", "Demonstrates the trade-off between user preference for convenience and cognitive benefits of AI tools.", "Offers design implications for AI support in cognitive tasks."], "limitations": "Limited sample size (N=30), focused solely on note-taking during lecture videos, potentially undermining external validity.", "keywords": ["AI Assistance", "Cognitive Engagement", "Note-Taking", "Human-Computer Interaction", "Learning Outcomes"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2509.02915", "pdf": "https://arxiv.org/pdf/2509.02915.pdf", "abs": "https://arxiv.org/abs/2509.02915", "title": "English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM", "authors": ["Taekyung Ahn", "Hosung Nam"], "categories": ["cs.CL"], "comment": null, "summary": "This study demonstrates that a Multimodal Large Language Model (MLLM) adapted\nvia Low-Rank Adaptation (LoRA) can perform both Automatic Pronunciation\nAssessment (APA) and Mispronunciation Detection and Diagnosis (MDD)\nsimultaneously. Leveraging Microsoft's Phi-4-multimodal-instruct, our\nfine-tuning method eliminates the need for complex architectural changes or\nseparate training procedures conventionally required for these distinct tasks.\nFine-tuned on the Speechocean762 dataset, the pronunciation evaluation scores\npredicted by the model exhibited a strong Pearson Correlation Coefficient (PCC\n> 0.7) with human-assigned scores, while achieving low Word Error Rate (WER)\nand Phoneme Error Rate (PER) (both < 0.15). Notably, fine-tuning only the LoRA\nlayers was sufficient to achieve performance levels comparable to those\nachieved by fine-tuning all audio layers. This research highlights that an\nintegrated pronunciation assessment system can be established by adapting large\nmultimodal models without full fine-tuning, utilizing a significantly simpler\ntraining methodology compared to previous joint models designed for\nsimultaneous APA and MDD. This efficient LoRA-based approach paves the way for\nmore accessible, integrated, and effective Computer-Assisted Pronunciation\nTraining (CAPT) technologies for English L2 learners.", "AI": {"tldr": "A study on adapting a Multimodal Large Language Model (MLLM) using Low-Rank Adaptation (LoRA) for simultaneous Automatic Pronunciation Assessment (APA) and Mispronunciation Detection and Diagnosis (MDD).", "motivation": "To create a more efficient and integrated system for pronunciation assessment without complex training processes.", "method": "The model was fine-tuned using LoRA on the Speechocean762 dataset to simultaneously perform APA and MDD, achieving strong correlation with human scores.", "result": "The fine-tuned model exhibited a Pearson Correlation Coefficient (PCC > 0.7) with human scores and low Word and Phoneme Error Rates (both < 0.15).", "conclusion": "This research demonstrates that LoRA can effectively enable integrated pronunciation assessment without full model fine-tuning, making technology more accessible for English L2 learners.", "key_contributions": ["Introduced a simplified method for integrating APA and MDD tasks using LoRA with a MLLM.", "Achieved strong performance metrics indicating effective pronunciation assessment for L2 learners.", "Demonstrated the potential for accessible CAPT technologies through efficient fine-tuning."], "limitations": "", "keywords": ["Multimodal Large Language Model", "Low-Rank Adaptation", "Automatic Pronunciation Assessment", "Mispronunciation Detection", "Computer-Assisted Pronunciation Training"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2509.03430", "pdf": "https://arxiv.org/pdf/2509.03430.pdf", "abs": "https://arxiv.org/abs/2509.03430", "title": "EclipseTouch: Touch Segmentation on Ad Hoc Surfaces using Worn Infrared Shadow Casting", "authors": ["Vimal Mollyn", "Nathan DeVrio", "Chris Harrison"], "categories": ["cs.HC", "cs.CV", "cs.GR", "cs.RO"], "comment": "Accepted to UIST 2025", "summary": "The ability to detect touch events on uninstrumented, everyday surfaces has\nbeen a long-standing goal for mixed reality systems. Prior work has shown that\nvirtual interfaces bound to physical surfaces offer performance and ergonomic\nbenefits over tapping at interfaces floating in the air. A wide variety of\napproaches have been previously developed, to which we contribute a new\nheadset-integrated technique called \\systemname. We use a combination of a\ncomputer-triggered camera and one or more infrared emitters to create\nstructured shadows, from which we can accurately estimate hover distance (mean\nerror of 6.9~mm) and touch contact (98.0\\% accuracy). We discuss how our\ntechnique works across a range of conditions, including surface material,\ninteraction orientation, and environmental lighting.", "AI": {"tldr": "A new headset-integrated technique for detecting touch events on uninstrumented surfaces using structured shadows.", "motivation": "To improve the interaction experience in mixed reality systems by detecting touch events on everyday surfaces, enhancing performance and ergonomics.", "method": "The proposed technique employs a computer-triggered camera and infrared emitters to create structured shadows for estimating hover distance and touch contact.", "result": "Achieved a mean error of 6.9 mm in hover distance estimation and 98.0% accuracy in touch contact detection.", "conclusion": "The technique is versatile, performing well under various conditions including different surface materials and lighting environments.", "key_contributions": ["Introduction of a headset-integrated method for touch detection on uninstrumented surfaces", "Demonstrated high accuracy and low error in hover distance estimation", "Validated effectiveness across varied materials and environmental conditions."], "limitations": "", "keywords": ["mixed reality", "human-computer interaction", "touch detection", "infrared sensing", "structured shadows"], "importance_score": 7, "read_time_minutes": 5}}
{"id": "2509.02926", "pdf": "https://arxiv.org/pdf/2509.02926.pdf", "abs": "https://arxiv.org/abs/2509.02926", "title": "Decoding the Rule Book: Extracting Hidden Moderation Criteria from Reddit Communities", "authors": ["Youngwoo Kim", "Himanshu Beniwal", "Steven L. Johnson", "Thomas Hartvigsen"], "categories": ["cs.CL"], "comment": "Accepted to EMNLP 2025 Main", "summary": "Effective content moderation systems require explicit classification\ncriteria, yet online communities like subreddits often operate with diverse,\nimplicit standards. This work introduces a novel approach to identify and\nextract these implicit criteria from historical moderation data using an\ninterpretable architecture. We represent moderation criteria as score tables of\nlexical expressions associated with content removal, enabling systematic\ncomparison across different communities. Our experiments demonstrate that these\nextracted lexical patterns effectively replicate the performance of neural\nmoderation models while providing transparent insights into decision-making\nprocesses. The resulting criteria matrix reveals significant variations in how\nseemingly shared norms are actually enforced, uncovering previously\nundocumented moderation patterns including community-specific tolerances for\nlanguage, features for topical restrictions, and underlying subcategories of\nthe toxic speech classification.", "AI": {"tldr": "This paper introduces a method for extracting implicit moderation criteria from historical moderation data in online communities, providing insights into community-specific standards.", "motivation": "Effective content moderation requires explicit classification criteria, but communities like subreddits often have diverse, implicit standards.", "method": "The authors developed an interpretable architecture that identifies and extracts moderation criteria from historical moderation data, represented as score tables of lexical expressions.", "result": "The extracted lexical patterns replicate the performance of neural moderation models while offering transparent insights into the decision-making process, revealing community-specific moderation patterns.", "conclusion": "This approach uncovers significant variations in moderation norms across communities and identifies previously undocumented patterns.", "key_contributions": ["Novel method for extracting implicit moderation criteria", "Transparent insights into decision-making processes in moderation", "Identification of community-specific moderation patterns"], "limitations": "The study focuses on historical data; current moderation practices may vary.", "keywords": ["content moderation", "implicit criteria", "online communities", "moderation patterns", "neural models"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2509.03451", "pdf": "https://arxiv.org/pdf/2509.03451.pdf", "abs": "https://arxiv.org/abs/2509.03451", "title": "SmartPoser: Arm Pose Estimation with a Smartphone and Smartwatch Using UWB and IMU Data", "authors": ["Nathan DeVrio", "Vimal Mollyn", "Chris Harrison"], "categories": ["cs.HC", "cs.CV", "cs.GR", "cs.RO"], "comment": "The first two listed authors contributed equally. Published at UIST\n  2023", "summary": "The ability to track a user's arm pose could be valuable in a wide range of\napplications, including fitness, rehabilitation, augmented reality input, life\nlogging, and context-aware assistants. Unfortunately, this capability is not\nreadily available to consumers. Systems either require cameras, which carry\nprivacy issues, or utilize multiple worn IMUs or markers. In this work, we\ndescribe how an off-the-shelf smartphone and smartwatch can work together to\naccurately estimate arm pose. Moving beyond prior work, we take advantage of\nmore recent ultra-wideband (UWB) functionality on these devices to capture\nabsolute distance between the two devices. This measurement is the perfect\ncomplement to inertial data, which is relative and suffers from drift. We\nquantify the performance of our software-only approach using off-the-shelf\ndevices, showing it can estimate the wrist and elbow joints with a \\hl{median\npositional error of 11.0~cm}, without the user having to provide training data.", "AI": {"tldr": "The paper presents a method for tracking arm pose using a smartphone and smartwatch, leveraging ultra-wideband technology for accuracy.", "motivation": "Tracking arm pose is crucial for various applications but existing methods have privacy concerns or require multiple devices.", "method": "The approach uses smartphones and smartwatches together, utilizing ultra-wideband functionality to measure absolute distance and complement inertial data.", "result": "The system estimates the wrist and elbow joints with a median positional error of 11.0 cm, and does so without needing user-provided training data.", "conclusion": "This method provides a practical and privacy-conscious solution for arm pose tracking using commonly available consumer devices.", "key_contributions": ["Utilization of ultra-wideband technology for arm pose estimation", "Combining smartphone and smartwatch for accurate tracking", "No need for user training data"], "limitations": "", "keywords": ["arm pose tracking", "ultra-wideband", "smartphone", "smartwatch", "user privacy"], "importance_score": 8, "read_time_minutes": 6}}
{"id": "2509.02949", "pdf": "https://arxiv.org/pdf/2509.02949.pdf", "abs": "https://arxiv.org/abs/2509.02949", "title": "ProMQA-Assembly: Multimodal Procedural QA Dataset on Assembly", "authors": ["Kimihiro Hasegawa", "Wiradee Imrattanatrai", "Masaki Asada", "Susan Holm", "Yuran Wang", "Vincent Zhou", "Ken Fukuda", "Teruko Mitamura"], "categories": ["cs.CL", "cs.CV"], "comment": "29 pages. Code and data: https://github.com/kimihiroh/promqa-assembly", "summary": "Assistants on assembly tasks have a large potential to benefit humans from\neveryday tasks to industrial settings. However, no testbeds support\napplication-oriented system evaluation in a practical setting, especially in\nassembly. To foster the development, we propose a new multimodal QA dataset on\nassembly activities. Our dataset, ProMQA-Assembly, consists of 391 QA pairs\nthat require the multimodal understanding of human-activity recordings and\ntheir instruction manuals in an online-style manner. In the development, we\nadopt a semi-automated QA annotation approach, where LLMs generate candidates\nand humans verify them, as a cost-effective method, and further improve it by\nintegrating fine-grained action labels to diversify question types.\nFurthermore, we create instruction task graphs for the target tasks of\nassembling toy vehicles. These newly created task graphs are used in our\nbenchmarking experiment, as well as to facilitate the human verification\nprocess in the QA annotation. Utilizing our dataset, we benchmark models,\nincluding competitive proprietary multimodal models. Our results suggest great\nroom for improvement for the current models. We believe our new evaluation\ndataset can contribute to the further development of procedural-activity\nassistants.", "AI": {"tldr": "The paper presents ProMQA-Assembly, a multimodal QA dataset for evaluating assembly tasks involving human activity and instruction manuals.", "motivation": "There is a lack of practical testbeds for evaluating assistants in assembly tasks across various settings.", "method": "The dataset consists of 391 QA pairs created through a semi-automated QA annotation process, where LLMs generate candidates and humans verify them, combined with fine-grained action labels to improve diversity in question types.", "result": "Benchmarking experiments with existing models indicate significant potential for improvement in multimodal understanding for assembly tasks.", "conclusion": "The ProMQA-Assembly dataset is expected to enhance the development of procedural-activity assistants.", "key_contributions": ["Introduction of a new multimodal QA dataset for assembly tasks.", "Semi-automated QA annotation approach leveraging LLMs.", "Development of instruction task graphs to aid in benchmarking and annotation."], "limitations": "Results indicate current models underperform, suggesting limitations in existing multimodal understanding capabilities.", "keywords": ["multimodal QA", "assembly tasks", "human-activity recordings", "instruction manuals", "dataset"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2509.02999", "pdf": "https://arxiv.org/pdf/2509.02999.pdf", "abs": "https://arxiv.org/abs/2509.02999", "title": "DiaCBT: A Long-Periodic Dialogue Corpus Guided by Cognitive Conceptualization Diagram for CBT-based Psychological Counseling", "authors": ["Yougen Zhou", "Ningning Zhou", "Qin Chen", "Jie Zhou", "Aimin Zhou", "Liang He"], "categories": ["cs.CL"], "comment": null, "summary": "Psychotherapy reaches only a small fraction of individuals suffering from\nmental disorders due to social stigma and the limited availability of\ntherapists. Large language models (LLMs), when equipped with professional\npsychotherapeutic skills, offer a promising solution to expand access to mental\nhealth services. However, the lack of psychological conversation datasets\npresents significant challenges in developing effective psychotherapy-guided\nconversational agents. In this paper, we construct a long-periodic dialogue\ncorpus for counseling based on cognitive behavioral therapy (CBT). Our curated\ndataset includes multiple sessions for each counseling and incorporates\ncognitive conceptualization diagrams (CCDs) to guide client simulation across\ndiverse scenarios. To evaluate the utility of our dataset, we train an in-depth\ncounseling model and present a comprehensive evaluation framework to benchmark\nit against established psychological criteria for CBT-based counseling. Results\ndemonstrate that DiaCBT effectively enhances LLMs' ability to emulate\npsychologists with CBT expertise, underscoring its potential for training more\nprofessional counseling agents.", "AI": {"tldr": "This study introduces DiaCBT, a dialogue corpus for counseling based on CBT, aimed at enhancing LLMs for mental health applications.", "motivation": "To address the limited access to psychotherapy due to social stigma and therapist availability, leveraging LLMs equipped with psychotherapeutic skills is proposed as a solution.", "method": "A long-periodic dialogue corpus is constructed for counseling, integrating multiple sessions and cognitive conceptualization diagrams to facilitate client simulation.", "result": "The training of an in-depth counseling model using the DiaCBT dataset shows significant improvement in LLMs' capability to simulate psychologists skilled in CBT.", "conclusion": "DiaCBT demonstrates the potential to improve the training of conversational agents for professional counseling by employing established psychological criteria for evaluation.", "key_contributions": ["Introduction of a long-periodic dialogue corpus for therapy based on CBT", "Integration of cognitive conceptualization diagrams in client simulations", "Development of a benchmark evaluation framework for counseling models"], "limitations": "", "keywords": ["mental health", "large language models", "Cognitive Behavioral Therapy", "conversational agents", "dataset"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2509.03010", "pdf": "https://arxiv.org/pdf/2509.03010.pdf", "abs": "https://arxiv.org/abs/2509.03010", "title": "Mitigating Data Imbalance in Automated Speaking Assessment", "authors": ["Fong-Chun Tsai", "Kuan-Tang Huang", "Bi-Cheng Yan", "Tien-Hong Lo", "Berlin Chen"], "categories": ["cs.CL", "cs.LG", "eess.AS"], "comment": "Submitted to APSIPA 2025", "summary": "Automated Speaking Assessment (ASA) plays a crucial role in evaluating\nsecond-language (L2) learners proficiency. However, ASA models often suffer\nfrom class imbalance, leading to biased predictions. To address this, we\nintroduce a novel objective for training ASA models, dubbed the Balancing Logit\nVariation (BLV) loss, which perturbs model predictions to improve feature\nrepresentation for minority classes without modifying the dataset. Evaluations\non the ICNALE benchmark dataset show that integrating the BLV loss into a\ncelebrated text-based (BERT) model significantly enhances classification\naccuracy and fairness, making automated speech evaluation more robust for\ndiverse learners.", "AI": {"tldr": "This paper introduces a Balancing Logit Variation (BLV) loss to improve Automated Speaking Assessment (ASA) models by addressing class imbalance without changing the dataset.", "motivation": "To enhance the fairness and accuracy of ASA models for L2 learners by addressing bias in predictions due to class imbalance.", "method": "The paper proposes a novel training objective, the BLV loss, which perturbs model predictions to improve feature representation for minority classes in ASA models.", "result": "Using the BLV loss with a BERT model on the ICNALE benchmark dataset, the accuracy and fairness of automated speech evaluation were significantly improved.", "conclusion": "The BLV loss makes ASA models more robust and equitable for diverse learners by effectively addressing class imbalance without modifying existing datasets.", "key_contributions": ["Introduction of the Balancing Logit Variation (BLV) loss for ASA models", "Demonstrated significant improvements in model accuracy and fairness", "Novel approach to handling class imbalance without altering the dataset"], "limitations": "", "keywords": ["Automated Speaking Assessment", "class imbalance", "BERT", "machine learning", "language assessment"], "importance_score": 6, "read_time_minutes": 5}}
{"id": "2509.03020", "pdf": "https://arxiv.org/pdf/2509.03020.pdf", "abs": "https://arxiv.org/abs/2509.03020", "title": "Training LLMs to be Better Text Embedders through Bidirectional Reconstruction", "authors": ["Chang Su", "Dengliang Shi", "Siyuan Huang", "Jintao Du", "Changhua Meng", "Yu Cheng", "Weiqiang Wang", "Zhouhan Lin"], "categories": ["cs.CL", "cs.IR"], "comment": "accepted by EMNLP 2025 Main Conference", "summary": "Large language models (LLMs) have increasingly been explored as powerful text\nembedders. Existing LLM-based text embedding approaches often leverage the\nembedding of the final token, typically a reserved special token such as [EOS].\nHowever, these tokens have not been intentionally trained to capture the\nsemantics of the whole context, limiting their capacity as text embeddings,\nespecially for retrieval and re-ranking tasks. We propose to add a new training\nstage before contrastive learning to enrich the semantics of the final token\nembedding. This stage employs bidirectional generative reconstruction tasks,\nnamely EBQ2D (Embedding-Based Query-to-Document) and EBD2Q (Embedding-Based\nDocument-to-Query), which interleave to anchor the [EOS] embedding and\nreconstruct either side of Query-Document pairs. Experimental results\ndemonstrate that our additional training stage significantly improves LLM\nperformance on the Massive Text Embedding Benchmark (MTEB), achieving new\nstate-of-the-art results across different LLM base models and scales.", "AI": {"tldr": "This paper proposes a new training stage for large language models to enhance text embeddings by utilizing generative reconstruction tasks before contrastive learning, leading to improved performance on embedding benchmarks.", "motivation": "Existing LLM-based embeddings often rely on the final token, which limits their semantic capture for retrieval tasks. The motivation is to enhance this process to improve document and query handling.", "method": "The authors introduce bidirectional generative reconstruction tasks (EBQ2D and EBD2Q) that enrich the final token embedding by reconstructing aspects of Query-Document pairs.", "result": "The proposed method achieved state-of-the-art results on the Massive Text Embedding Benchmark (MTEB) across various LLM models and scales, showcasing significant performance improvements.", "conclusion": "The added training stage enhances the semantic richness of LLM embeddings, providing a more robust foundation for retrieval tasks.", "key_contributions": ["Introduction of new training stage for LLMs to improve text embeddings.", "Implementation of EBQ2D and EBD2Q tasks for embedding enrichment.", "Demonstration of state-of-the-art results on the MTEB."], "limitations": "", "keywords": ["large language models", "text embeddings", "generative reconstruction", "contrastive learning", "information retrieval"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2509.03057", "pdf": "https://arxiv.org/pdf/2509.03057.pdf", "abs": "https://arxiv.org/abs/2509.03057", "title": "Structure-Learnable Adapter Fine-Tuning for Parameter-Efficient Large Language Models", "authors": ["Ming Gong", "Yingnan Deng", "Nia Qi", "Yujun Zou", "Zhihao Xue", "Yun Zi"], "categories": ["cs.CL"], "comment": null, "summary": "This paper addresses the issues of parameter redundancy, rigid structure, and\nlimited task adaptability in the fine-tuning of large language models. It\nproposes an adapter-based fine-tuning method built on a structure-learnable\nmechanism. By introducing differentiable gating functions and structural\nsparsity control variables, the method enables automatic optimization of\nadapter insertion points, activation paths, and module combinations. This\nallows the model to adjust its structure flexibly in multi-task settings to\nmatch different task characteristics. With the backbone parameters kept frozen,\nthe method uses a structure search mechanism to guide the dynamic construction\nof task-specific efficient substructures during training. This significantly\nimproves parameter utilization and representational capacity. In addition, the\npaper designs a set of sensitivity analysis experiments to systematically\nevaluate the effects of sparsity weight, noise injection ratio, and data\nperturbation on model performance. These experiments verify the stability and\nrobustness of the proposed method across various multi-task natural language\nunderstanding tasks. The experimental results show that the proposed method\noutperforms mainstream parameter-efficient tuning techniques on multiple tasks.\nIt achieves a better balance among accuracy, compression rate, and robustness\nto noise and perturbation.", "AI": {"tldr": "This paper proposes an adapter-based fine-tuning method for large language models to improve flexibility and performance in multi-task settings.", "motivation": "To address issues of parameter redundancy, rigid structure, and limited task adaptability in fine-tuning large language models.", "method": "An adapter-based fine-tuning method is proposed, utilizing a structure-learnable mechanism with differentiable gating functions and structural sparsity control variables to optimize adapter insertion points and module combinations.", "result": "The method demonstrates improved parameter utilization and representational capacity, outperforming mainstream parameter-efficient tuning techniques on various multi-task natural language understanding tasks.", "conclusion": "The proposed method shows enhanced stability and robustness across different tasks while maintaining a good balance between accuracy and compression rate.", "key_contributions": ["Adapter-based fine-tuning method", "Differentiable gating functions and sparsity control", "Dynamic construction of task-specific efficient substructures"], "limitations": "", "keywords": ["fine-tuning", "large language models", "multi-task learning", "adapter-based", "sparsity"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2509.03060", "pdf": "https://arxiv.org/pdf/2509.03060.pdf", "abs": "https://arxiv.org/abs/2509.03060", "title": "A Long Short-Term Memory (LSTM) Model for Business Sentiment Analysis Based on Recurrent Neural Network", "authors": ["Md. Jahidul Islam Razin", "Md. Abdul Karim", "M. F. Mridha", "S M Rafiuddin", "Tahira Alam"], "categories": ["cs.CL"], "comment": "11 pages, 9 figures, 3 tables, published in Sustainable Communication\n  Networks and Application: Proceedings of ICSCN 2020 (2021). Paper presents an\n  LSTM-based business sentiment analysis model with 91.33% accuracy, compares\n  against KNN, SVM, and Naive Bayes, and discusses methodology, dataset,\n  training/testing, results, and implementation tools", "summary": "Business sentiment analysis (BSA) is one of the significant and popular\ntopics of natural language processing. It is one kind of sentiment analysis\ntechniques for business purposes. Different categories of sentiment analysis\ntechniques like lexicon-based techniques and different types of machine\nlearning algorithms are applied for sentiment analysis on different languages\nlike English, Hindi, Spanish, etc. In this paper, long short-term memory (LSTM)\nis applied for business sentiment analysis, where a recurrent neural network is\nused. An LSTM model is used in a modified approach to prevent the vanishing\ngradient problem rather than applying the conventional recurrent neural network\n(RNN). To apply the modified RNN model, product review dataset is used. In this\nexperiment, 70\\% of the data is trained for the LSTM and the rest 30\\% of the\ndata is used for testing. The result of this modified RNN model is compared\nwith other conventional RNN models, and a comparison is made among the results.\nIt is noted that the proposed model performs better than the other conventional\nRNN models. Here, the proposed model, i.e., the modified RNN model approach has\nachieved around 91.33\\% of accuracy. By applying this model, any business\ncompany or e-commerce business site can identify the feedback from their\ncustomers about different types of products that customers like or dislike.\nBased on the customer reviews, a business company or e-commerce platform can\nevaluate its marketing strategy.", "AI": {"tldr": "The paper presents a modified LSTM model for business sentiment analysis, achieving 91.33% accuracy and outperforming conventional RNN models.", "motivation": "To improve business sentiment analysis by applying a modified LSTM model that addresses the vanishing gradient problem common in traditional RNNs.", "method": "The paper implements a modified long short-term memory (LSTM) model on a product review dataset, using 70% of the data for training and 30% for testing.", "result": "The modified LSTM model achieved an accuracy of 91.33%, outperforming traditional RNN models such as KNN, SVM, and Naive Bayes in sentiment analysis tasks.", "conclusion": "The proposed modified RNN model can effectively evaluate customer feedback, enabling businesses to enhance their marketing strategies based on sentiment analysis.", "key_contributions": ["Introduction of a modified LSTM approach for business sentiment analysis", "Demonstration of improved accuracy over conventional RNN models", "Application of the model to product reviews for business insights"], "limitations": "", "keywords": ["Sentiment Analysis", "LSTM", "Business Intelligence", "Machine Learning", "E-commerce"], "importance_score": 7, "read_time_minutes": 11}}
{"id": "2402.07911", "pdf": "https://arxiv.org/pdf/2402.07911.pdf", "abs": "https://arxiv.org/abs/2402.07911", "title": "From Metrics to Meaning: Time to Rethink Evaluation in Human-AI Collaborative Design", "authors": ["Sean P. Walton", "Ben J. Evans", "Alma A. M. Rahat", "James Stovold", "Jakub Vincalek"], "categories": ["cs.HC", "cs.AI", "cs.CE", "cs.NE", "I.2.0; J.6; G.1.6"], "comment": "31 pages, under review", "summary": "As AI systems increasingly shape decision making in creative design contexts,\nunderstanding how humans engage with these tools has become a critical\nchallenge for interactive intelligent systems research. This paper contributes\na challenge to rethink how to evaluate human--AI collaborative systems,\nadvocating for a more nuanced and multidimensional approach. Findings from one\nof the largest field studies to date (n = 808) of a human--AI co-creative\nsystem, The Genetic Car Designer, complemented by a controlled lab study (n =\n12) are presented. The system is based on an interactive evolutionary algorithm\nwhere participants were tasked with designing a simple two dimensional\nrepresentation of a car. Participants were exposed to galleries of design\nsuggestions generated by an intelligent system, MAP--Elites, and a random\ncontrol. Results indicate that exposure to galleries generated by MAP--Elites\nsignificantly enhanced both cognitive and behavioural engagement, leading to\nhigher-quality design outcomes. Crucially for the wider community, the analysis\nreveals that conventional evaluation methods, which often focus on solely\nbehavioural and design quality metrics, fail to capture the full spectrum of\nuser engagement. By considering the human--AI design process as a changing\nemotional, behavioural and cognitive state of the designer, we propose\nevaluating human--AI systems holistically and considering intelligent systems\nas a core part of the user experience -- not simply a back end tool.", "AI": {"tldr": "The paper challenges conventional evaluation methods for human-AI collaborative systems, advocating for a multidimensional approach by analyzing a large field study of a co-creative design tool.", "motivation": "To enhance understanding of human engagement with AI systems in creative design and to propose improved evaluation methods for human-AI collaborations.", "method": "A field study with 808 participants and a controlled lab study with 12 participants, examining the effects of an interactive evolutionary algorithm on design quality and user engagement.", "result": "Exposure to design suggestions from the MAP-Elites algorithm significantly improved cognitive and behavioral engagement, resulting in higher-quality design outcomes compared to a random control.", "conclusion": "Conventional evaluation methods inadequately capture user engagement in human-AI systems; a holistic approach considering emotional, behavioral, and cognitive aspects is needed.", "key_contributions": ["Introduction of a holistic evaluation approach for human-AI collaborative systems.", "Findings from a large field study demonstrating the impact of AI on design outcomes.", "Highlighting the importance of user engagement metrics beyond traditional design quality."], "limitations": "The study is limited to specific design contexts and may not generalize across all human-AI interactions.", "keywords": ["Human-AI collaboration", "Interactive intelligent systems", "User engagement"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2509.03116", "pdf": "https://arxiv.org/pdf/2509.03116.pdf", "abs": "https://arxiv.org/abs/2509.03116", "title": "Measuring Scalar Constructs in Social Science with LLMs", "authors": ["Hauke Licht", "Rupak Sarkar", "Patrick Y. Wu", "Pranav Goel", "Niklas Stoehr", "Elliott Ash", "Alexander Miserlis Hoyle"], "categories": ["cs.CL"], "comment": "Accepted to EMNLP 2025 (Main)", "summary": "Many constructs that characterize language, like its complexity or\nemotionality, have a naturally continuous semantic structure; a public speech\nis not just \"simple\" or \"complex,\" but exists on a continuum between extremes.\nAlthough large language models (LLMs) are an attractive tool for measuring\nscalar constructs, their idiosyncratic treatment of numerical outputs raises\nquestions of how to best apply them. We address these questions with a\ncomprehensive evaluation of LLM-based approaches to scalar construct\nmeasurement in social science. Using multiple datasets sourced from the\npolitical science literature, we evaluate four approaches: unweighted direct\npointwise scoring, aggregation of pairwise comparisons,\ntoken-probability-weighted pointwise scoring, and finetuning. Our study yields\nactionable findings for applied researchers. First, LLMs prompted to generate\npointwise scores directly from texts produce discontinuous distributions with\nbunching at arbitrary numbers. The quality of the measurements improves with\npairwise comparisons made by LLMs, but it improves even more by taking\npointwise scores and weighting them by token probability. Finally, finetuning\nsmaller models with as few as 1,000 training pairs can match or exceed the\nperformance of prompted LLMs.", "AI": {"tldr": "This paper evaluates LLM-based approaches for measuring scalar constructs in social science, finding that token probability-weighted pointwise scoring significantly improves measurement quality.", "motivation": "To address the challenges of using large language models for measuring scalar constructs like complexity and emotionality in public speech.", "method": "The study evaluates four LLM-based approaches: unweighted direct pointwise scoring, aggregation of pairwise comparisons, token-probability-weighted pointwise scoring, and finetuning.", "result": "Pairwise comparisons improve measurement quality, but token probability-weighted scores provide even better results. Finetuning smaller models with a limited dataset can equal or exceed prompted LLMs performance.", "conclusion": "LLMs can effectively measure scalar constructs in social science, particularly when utilizing token probability weighting and appropriate finetuning.", "key_contributions": ["Evaluation of LLM approaches for scalar construct measurement", "Identification of token probability weighting as a key improvement", "Demonstration that finetuning smaller models can match LLM performance"], "limitations": "", "keywords": ["Large Language Models", "Scalar Constructs", "Social Science", "Measurement Techniques", "Finetuning"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2409.15550", "pdf": "https://arxiv.org/pdf/2409.15550.pdf", "abs": "https://arxiv.org/abs/2409.15550", "title": "Talk, Listen, Connect: How Humans and AI Evaluate Empathy in Responses to Emotionally Charged Narratives", "authors": ["Mahnaz Roshanaei", "Rezvaneh Rezapour", "Magy Seif El-Nasr"], "categories": ["cs.HC", "F.2.2; I.2.7"], "comment": "21 pages, 4 figures, 6 tables. Title updated from \"Talk, Listen,\n  Connect: Navigating Empathy in Human-AI Interactions\" to \"Talk, Listen,\n  Connect: How Humans and AI Evaluate Empathy in Responses to Emotionally\n  Charged Narratives\" in this version. This is version 2 (v2) of the paper. All\n  previous citations of arXiv:2409.15550 with the old title still refer to the\n  same paper", "summary": "Social interactions promote well-being, yet barriers like geographic\ndistance, time limitations, and mental health conditions can limit face-to-face\ninteractions. Emotionally responsive AI systems, such as chatbots, offer new\nopportunities for social and emotional support, but raise critical questions\nabout how empathy is perceived and experienced in human-AI interactions. This\nstudy examines how empathy is evaluated in AI-generated versus human responses.\nUsing personal narratives, we explored how persona attributes (e.g., gender,\nempathic traits, shared experiences) and story qualities affect empathy\nratings. We compared responses from standard and fine-tuned AI models with\nhuman judgments. Results show that while humans are highly sensitive to\nemotional vividness and shared experience, AI-responses are less influenced by\nthese cues, often lack nuance in empathic expression. These findings highlight\nchallenges in designing emotionally intelligent systems that respond\nmeaningfully across diverse users and contexts, and informs the design of\nethically aware tools to support social connection and well-being.", "AI": {"tldr": "This study investigates how empathy is perceived in responses from AI versus humans, revealing differences in emotional expression and sensitivity to context.", "motivation": "To explore the role of emotionally responsive AI systems in supporting social and emotional well-being, particularly in situations where human interaction is limited.", "method": "The study utilized personal narratives to compare empathy evaluations between AI-generated responses and human responses, focusing on persona attributes and narrative qualities.", "result": "Results indicate that humans are more sensitive to emotional nuances and shared experiences in narratives, while AI responses often lack this subtlety in empathy expression.", "conclusion": "The findings emphasize the need for carefully designed emotionally intelligent AI systems that can meaningfully engage with users, promoting social connection.", "key_contributions": ["Examining empathy perception in AI vs human interactions", "Identifying the impact of persona attributes on empathy ratings", "Informing design principles for ethically aware AI tools for social support"], "limitations": "AI responses often miss nuanced emotional expressions and deeper context-driven empathy, potentially leading to user dissatisfaction.", "keywords": ["empathy", "human-AI interaction", "emotionally responsive AI", "social support", "AI design ethics"], "importance_score": 8, "read_time_minutes": 30}}
{"id": "2509.03122", "pdf": "https://arxiv.org/pdf/2509.03122.pdf", "abs": "https://arxiv.org/abs/2509.03122", "title": "From Evaluation to Defense: Constructing Persistent Edit-Based Fingerprints for Large Language Models", "authors": ["Yue Li", "Xin Yi", "Dongsheng Shi", "Yongyi Cui", "Gerard de Melo", "Xiaoling Wang", "Linlin Wang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "preprint", "summary": "The intellectual property (IP) protection of Large Language Models (LLMs) is\nincreasingly critical. Injecting specialized fingerprints into LLMs through\ninstruction tuning is a common IP protection technique. However, this may\nsignificantly degrade model performance, requires substantial computational\nresources, and exhibits poor persistence under model modifications. We argue\nthat knowledge editing offers a lightweight alternative that is more suitable\nfor fingerprint injection. Accordingly, we apply knowledge editing to\nfingerprint injection for the first time and demonstrate its strong capability.\nDespite using scrambled text as fingerprints to prevent them from being\noverwritten during fine-tuning, degradation still occurs under large-scale\nfine-tuning. To address this, we propose Fingerprint Subspace-aware Fine-Tuning\n(FSFT), which reduces fingerprint degradation by constraining the update of the\nfingerprint subspace. The performance of FSFT exceeds fine-tuning by 10% even\nin the worst-case scenario. Additionally, we observe that the\nfingerprint-injected models struggle to distinguish between fingerprints and\nsimilar texts due to the high similarity of their features. This finding\nunderscores the urgent need for more robust and fine-grained fingerprinting\ninjection methods for LLMs.", "AI": {"tldr": "This paper introduces a novel approach to intellectual property protection for LLMs using knowledge editing and proposes Fingerprint Subspace-aware Fine-Tuning (FSFT) to enhance fingerprint persistence.", "motivation": "There is a need for effective IP protection mechanisms for Large Language Models without significantly degrading their performance.", "method": "The paper applies knowledge editing to fingerprint injection and proposes a new method called Fingerprint Subspace-aware Fine-Tuning (FSFT) to enhance the robustness of the fingerprinting process.", "result": "FSFT reduces fingerprint degradation by constraining updates and demonstrates a performance improvement of 10% compared to traditional fine-tuning methods, even in challenging scenarios.", "conclusion": "The study highlights the necessity for advanced fingerprinting techniques for LLMs, addressing performance degradation issues that occur with current methods.", "key_contributions": ["Introduction of knowledge editing for fingerprint injection in LLMs", "Proposal of Fingerprint Subspace-aware Fine-Tuning (FSFT)", "Demonstration of FSFT's effectiveness in reducing degradation and improving performance."], "limitations": "Fingerprint degradation still occurs under large-scale fine-tuning even with the proposed method.", "keywords": ["Large Language Models", "intellectual property", "knowledge editing", "fine-tuning", "fingerprinting"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2509.03143", "pdf": "https://arxiv.org/pdf/2509.03143.pdf", "abs": "https://arxiv.org/abs/2509.03143", "title": "An experimental and computational study of an Estonian single-person word naming", "authors": ["Kaidi Lõo", "Arvi Tavast", "Maria Heitmeier", "Harald Baayen"], "categories": ["cs.CL"], "comment": null, "summary": "This study investigates lexical processing in Estonian. A large-scale\nsingle-subject experiment is reported that combines the word naming task with\neye-tracking. Five response variables (first fixation duration, total fixation\nduration, number of fixations, word naming latency, and spoken word duration)\nare analyzed with the generalized additive model. Of central interest is the\nquestion of whether measures for lexical processing generated by a\ncomputational model of the mental lexicon (the Discriminative Lexicon Model,\nDLM) are predictive for these response variables, and how they compare to\nclassical predictors such as word frequency, neighborhood size, and\ninflectional paradigm size. Computational models were implemented both with\nlinear and deep mappings. Central findings are, first, that DLM-based measures\nare powerful predictors for lexical processing, second, that DLM-measures using\ndeep learning are not necessarily more precise predictors of lexical processing\nthan DLM-measures using linear mappings, third, that classical predictors tend\nto provide somewhat more precise fits compared to DLM-based predictors (except\nfor total fixation duration, where the two provide equivalent goodness of fit),\nand fourth, that in the naming task lexical variables are not predictive for\nfirst fixation duration and the total number of fixations. As the DLM works\nwith mappings from form to meaning, the predictivity of DLM-based measures for\ntotal fixation duration, naming latencies, and spoken word duration indicates\nthat meaning is heavily involved in the present word naming task.", "AI": {"tldr": "This study analyzes lexical processing in Estonian through a large-scale experiment combining word naming tasks and eye-tracking, focusing on predictors of response variables.", "motivation": "To investigate the predictiveness of the Discriminative Lexicon Model (DLM) in lexical processing compared to classical predictors like word frequency and neighborhood size.", "method": "A single-subject experiment with word naming tasks and eye-tracking, analyzing five response variables using a generalized additive model.", "result": "DLM-based measures are powerful predictors for certain lexical processing tasks, but classical predictors offer better precision overall, except in specific cases of total fixation duration.", "conclusion": "Meaning plays a significant role in word naming tasks, as indicated by the effectiveness of DLM-based measures for various response variables.", "key_contributions": ["Demonstration of the predictive power of DLM-based measures for lexical processing in Estonian.", "Comparison of DLM measures with classical predictors.", "Insights into the role of meaning in lexical processing tasks."], "limitations": "", "keywords": ["lexical processing", "Discriminative Lexicon Model", "eye-tracking", "word naming task", "deep learning"], "importance_score": 4, "read_time_minutes": 15}}
{"id": "2509.03148", "pdf": "https://arxiv.org/pdf/2509.03148.pdf", "abs": "https://arxiv.org/abs/2509.03148", "title": "Expanding the WMT24++ Benchmark with Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader", "authors": ["Jannis Vamvas", "Ignacio Pérez Prat", "Not Battesta Soliva", "Sandra Baltermia-Guetg", "Andrina Beeli", "Simona Beeli", "Madlaina Capeder", "Laura Decurtins", "Gian Peder Gregori", "Flavia Hobi", "Gabriela Holderegger", "Arina Lazzarini", "Viviana Lazzarini", "Walter Rosselli", "Bettina Vital", "Anna Rutkiewicz", "Rico Sennrich"], "categories": ["cs.CL"], "comment": "Submitted to WMT25 (Open Language Data Initiative Shared Task)", "summary": "The Romansh language, spoken in Switzerland, has limited resources for\nmachine translation evaluation. In this paper, we present a benchmark for six\nvarieties of Romansh: Rumantsch Grischun, a supra-regional variety, and five\nregional varieties: Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader. Our\nreference translations were created by human translators based on the WMT24++\nbenchmark, which ensures parallelism with more than 55 other languages. An\nautomatic evaluation of existing MT systems and LLMs shows that translation out\nof Romansh into German is handled relatively well for all the varieties, but\ntranslation into Romansh is still challenging.", "AI": {"tldr": "This paper presents a benchmark for evaluating machine translation of the Romansh language and its varieties.", "motivation": "To address the lack of resources for machine translation evaluation in the Romansh language, which is spoken in Switzerland.", "method": "The paper develops a benchmark for six varieties of Romansh using human-generated reference translations, based on the WMT24++ benchmark for parallelism with over 55 languages.", "result": "The evaluation shows that translation from Romansh to German is relatively effective across varieties, while translating into Romansh remains challenging.", "conclusion": "More development is needed to improve machine translation systems for Romansh, particularly for translations into the language.", "key_contributions": ["Established a benchmark for machine translation evaluation for six varieties of Romansh.", "Provided insight into the translation effectiveness from Romansh to German and the challenges of translation into Romansh.", "Created human reference translations based on a recognized benchmark."], "limitations": "The study only focuses on translation between Romansh and German, potentially overlooking other language pairs.", "keywords": ["Romansh", "machine translation", "benchmark", "language evaluation", "WMT"], "importance_score": 3, "read_time_minutes": 15}}
{"id": "2509.03161", "pdf": "https://arxiv.org/pdf/2509.03161.pdf", "abs": "https://arxiv.org/abs/2509.03161", "title": "Domain Adaptation of LLMs for Process Data", "authors": ["Rafael Seidi Oyamada", "Jari Peeperkorn", "Jochen De Weerdt", "Johannes De Smedt"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In recent years, Large Language Models (LLMs) have emerged as a prominent\narea of interest across various research domains, including Process Mining\n(PM). Current applications in PM have predominantly centered on prompt\nengineering strategies or the transformation of event logs into narrative-style\ndatasets, thereby exploiting the semantic capabilities of LLMs to address\ndiverse tasks. In contrast, this study investigates the direct adaptation of\npretrained LLMs to process data without natural language reformulation,\nmotivated by the fact that these models excel in generating sequences of\ntokens, similar to the objective in PM. More specifically, we focus on\nparameter-efficient fine-tuning techniques to mitigate the computational\noverhead typically associated with such models. Our experimental setup focuses\non Predictive Process Monitoring (PPM), and considers both single- and\nmulti-task predictions. The results demonstrate a potential improvement in\npredictive performance over state-of-the-art recurrent neural network (RNN)\napproaches and recent narrative-style-based solutions, particularly in the\nmulti-task setting. Additionally, our fine-tuned models exhibit faster\nconvergence and require significantly less hyperparameter optimization.", "AI": {"tldr": "This study explores the direct application of pretrained Large Language Models to process mining data, using parameter-efficient fine-tuning to enhance predictive performance in Predictive Process Monitoring tasks.", "motivation": "To leverage the capabilities of Large Language Models in Process Mining without natural language reformulation and to improve predictive monitoring performance.", "method": "The study employs parameter-efficient fine-tuning techniques on pretrained LLMs to adapt them for Predictive Process Monitoring, focusing on both single- and multi-task predictions.", "result": "The results show improved predictive performance compared to state-of-the-art RNN approaches and narrative-style solutions, especially in a multi-task setting, along with faster convergence and reduced need for hyperparameter optimization.", "conclusion": "Direct adaptation of LLMs to process data can enhance predictive capabilities in process mining while minimizing computational costs associated with fine-tuning.", "key_contributions": ["Direct adaptation of LLMs to process mining without natural language reformulation", "Parameter-efficient fine-tuning techniques that lower computational overhead", "Improved predictive performance over traditional models and methods in multi-task settings"], "limitations": "", "keywords": ["Large Language Models", "Process Mining", "Predictive Process Monitoring", "Parameter-efficient fine-tuning", "Machine Learning"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2509.03162", "pdf": "https://arxiv.org/pdf/2509.03162.pdf", "abs": "https://arxiv.org/abs/2509.03162", "title": "SinhalaMMLU: A Comprehensive Benchmark for Evaluating Multitask Language Understanding in Sinhala", "authors": ["Ashmari Pramodya", "Nirasha Nelki", "Heshan Shalinda", "Chamila Liyanage", "Yusuke Sakai", "Randil Pushpananda", "Ruvan Weerasinghe", "Hidetaka Kamigaito", "Taro Watanabe"], "categories": ["cs.CL"], "comment": "19 pages, 11 figures", "summary": "Large Language Models (LLMs) demonstrate impressive general knowledge and\nreasoning abilities, yet their evaluation has predominantly focused on global\nor anglocentric subjects, often neglecting low-resource languages and\nculturally specific content. While recent multilingual benchmarks attempt to\nbridge this gap, many rely on automatic translation, which can introduce errors\nand misrepresent the original cultural context. To address this, we introduce\nSinhalaMMLU, the first multiple-choice question answering benchmark designed\nspecifically for Sinhala, a low-resource language. The dataset includes over\n7,000 questions spanning secondary to collegiate education levels, aligned with\nthe Sri Lankan national curriculum, and covers six domains and 30 subjects,\nencompassing both general academic topics and culturally grounded knowledge. We\nevaluate 26 LLMs on SinhalaMMLU and observe that, while Claude 3.5 sonnet and\nGPT-4o achieve the highest average accuracies at 67% and 62% respectively,\noverall model performance remains limited. In particular, models struggle in\nculturally rich domains such as the Humanities, revealing substantial room for\nimprovement in adapting LLMs to low-resource and culturally specific contexts.", "AI": {"tldr": "Introduction of SinhalaMMLU, the first benchmark for evaluating LLMs on Sinhala with a focus on academic and culturally specific knowledge.", "motivation": "To address the lack of multilingual evaluations for low-resource languages and the shortcomings in understanding culturally specific content in large language models.", "method": "Development of SinhalaMMLU, a multiple-choice question answering dataset for Sinhala with 7,000 questions across various educational levels and subjects, aligned with the national curriculum.", "result": "26 LLMs were evaluated on SinhalaMMLU, with Claude 3.5 sonnet and GPT-4o achieving the highest accuracies but overall performance remaining limited, particularly in humanities subjects.", "conclusion": "Models exhibit insufficient understanding of culturally rich domains, indicating the need for improvements in adapting LLMs for low-resource and culturally specific languages.", "key_contributions": ["Creation of the first Sinhala language benchmark for LLM evaluation", "In-depth evaluation of existing LLMs on culturally and academically relevant questions", "Highlighting the performance limitations of LLMs in low-resource language contexts"], "limitations": "", "keywords": ["Large Language Models", "SinhalaMMLU", "low-resource languages", "cultural knowledge", "evaluation benchmarks"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2509.03256", "pdf": "https://arxiv.org/pdf/2509.03256.pdf", "abs": "https://arxiv.org/abs/2509.03256", "title": "Comparison of End-to-end Speech Assessment Models for the NOCASA 2025 Challenge", "authors": ["Aleksei Žavoronkov", "Tanel Alumäe"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Published at IEEE MLSP 2025", "summary": "This paper presents an analysis of three end-to-end models developed for the\nNOCASA 2025 Challenge, aimed at automatic word-level pronunciation assessment\nfor children learning Norwegian as a second language. Our models include an\nencoder-decoder Siamese architecture (E2E-R), a prefix-tuned direct\nclassification model leveraging pretrained wav2vec2.0 representations, and a\nnovel model integrating alignment-free goodness-of-pronunciation (GOP) features\ncomputed via CTC. We introduce a weighted ordinal cross-entropy loss tailored\nfor optimizing metrics such as unweighted average recall and mean absolute\nerror. Among the explored methods, our GOP-CTC-based model achieved the highest\nperformance, substantially surpassing challenge baselines and attaining top\nleaderboard scores.", "AI": {"tldr": "This paper analyzes three end-to-end models for automatic word-level pronunciation assessment for children learning Norwegian, achieving high performance with a novel model that integrates GOP features.", "motivation": "The objective is to enhance automatic pronunciation assessment tools for children learning Norwegian as a second language.", "method": "Three models were developed: an encoder-decoder Siamese architecture, a prefix-tuned direct classification model using wav2vec2.0, and a novel model with alignment-free GOP features via CTC, optimized using a tailored loss function.", "result": "The GOP-CTC-based model demonstrated the highest performance, exceeding challenge baselines and achieving top leaderboard scores.", "conclusion": "The introduction of a weighted ordinal cross-entropy loss improved the model's effectiveness in pronunciation assessment.", "key_contributions": ["Development of three unique models for pronunciation assessment", "Integration of alignment-free GOP features via CTC", "Introduction of a specific weighted ordinal cross-entropy loss function"], "limitations": "", "keywords": ["pronunciation assessment", "Siamese architecture", "goodness-of-pronunciation"], "importance_score": 4, "read_time_minutes": 15}}
{"id": "2509.03300", "pdf": "https://arxiv.org/pdf/2509.03300.pdf", "abs": "https://arxiv.org/abs/2509.03300", "title": "LatPhon: Lightweight Multilingual G2P for Romance Languages and English", "authors": ["Luis Felipe Chary", "Miguel Arjona Ramirez"], "categories": ["cs.CL"], "comment": null, "summary": "Grapheme-to-phoneme (G2P) conversion is a key front-end for text-to-speech\n(TTS), automatic speech recognition (ASR), speech-to-speech translation (S2ST)\nand alignment systems, especially across multiple Latin-script languages.We\npresent LatPhon, a 7.5 M - parameter Transformer jointly trained on six such\nlanguages--English, Spanish, French, Italian, Portuguese, and Romanian. On the\npublic ipa-dict corpus, it attains a mean phoneme error rate (PER) of 3.5%,\noutperforming the byte-level ByT5 baseline (5.4%) and approaching\nlanguage-specific WFSTs (3.2%) while occupying 30 MB of memory, which makes\non-device deployment feasible when needed. These results indicate that compact\nmultilingual G2P can serve as a universal front-end for Latin-language speech\npipelines.", "AI": {"tldr": "LatPhon is a compact multilingual Grapheme-to-Phoneme model achieving competitive performance in TTS and ASR systems.", "motivation": "To enhance performance in text-to-speech and speech recognition systems across multiple Latin-script languages while maintaining a manageable model size for on-device deployment.", "method": "LatPhon is a 7.5 M-parameter Transformer model trained jointly on English, Spanish, French, Italian, Portuguese, and Romanian languages, leveraging a public corpus for evaluation.", "result": "LatPhon achieves a mean phoneme error rate (PER) of 3.5%, outperforming the byte-level ByT5 baseline (5.4%) and nearing the language-specific WFSTs (3.2%).", "conclusion": "The results suggest that LatPhon can serve as an efficient and effective front-end for multilingual speech systems.", "key_contributions": ["Introduction of a multilingual G2P model that is efficient and compact.", "Joint training across six major languages to improve multilingual G2P accuracy.", "Demonstration of on-device deployment feasibility for practical applications."], "limitations": "", "keywords": ["Grapheme-to-Phoneme", "Text-to-Speech", "Automatic Speech Recognition", "Multilingual", "Transformer"], "importance_score": 6, "read_time_minutes": 5}}
{"id": "2509.03312", "pdf": "https://arxiv.org/pdf/2509.03312.pdf", "abs": "https://arxiv.org/abs/2509.03312", "title": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "authors": ["Guibin Zhang", "Junhao Wang", "Junjie Chen", "Wangchunshu Zhou", "Kun Wang", "Shuicheng Yan"], "categories": ["cs.CL", "cs.MA"], "comment": null, "summary": "Large Language Model (LLM)-based agentic systems, often comprising multiple\nmodels, complex tool invocations, and orchestration protocols, substantially\noutperform monolithic agents. Yet this very sophistication amplifies their\nfragility, making them more prone to system failure. Pinpointing the specific\nagent or step responsible for an error within long execution traces defines the\ntask of agentic system failure attribution. Current state-of-the-art reasoning\nLLMs, however, remain strikingly inadequate for this challenge, with accuracy\ngenerally below 10%. To address this gap, we propose AgenTracer, the first\nautomated framework for annotating failed multi-agent trajectories via\ncounterfactual replay and programmed fault injection, producing the curated\ndataset TracerTraj. Leveraging this resource, we develop AgenTracer-8B, a\nlightweight failure tracer trained with multi-granular reinforcement learning,\ncapable of efficiently diagnosing errors in verbose multi-agent interactions.\nOn the Who&When benchmark, AgenTracer-8B outperforms giant proprietary LLMs\nlike Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18%, setting a new standard\nin LLM agentic failure attribution. More importantly, AgenTracer-8B delivers\nactionable feedback to off-the-shelf multi-agent systems like MetaGPT and MaAS\nwith 4.8-14.2% performance gains, empowering self-correcting and self-evolving\nagentic AI.", "AI": {"tldr": "AgenTracer automates failure attribution in multi-agent systems, improving error diagnosis and performance of LLM-based agents.", "motivation": "To address the fragility of large language model-based agentic systems during execution and improve failure attribution accuracy, which is currently below 10%.", "method": "The paper introduces an automated framework called AgenTracer for annotating failed multi-agent trajectories, using counterfactual replay and programmed fault injection to create the TracerTraj dataset. AgenTracer-8B is trained with multi-granular reinforcement learning for error diagnosis.", "result": "AgenTracer-8B outperforms proprietary LLMs like Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18% on the Who&When benchmark, and offers performance improvements of 4.8-14.2% for multi-agent systems.", "conclusion": "AgenTracer-8B sets a new standard for LLM agentic failure attribution and provides actionable feedback for enhancing multi-agent system performance.", "key_contributions": ["Introduction of the AgenTracer framework for failure attribution in multi-agent systems.", "Development of the TracerTraj dataset for training failure diagnosis models.", "Creation of AgenTracer-8B, a lightweight failure tracer that surpasses existing proprietary LLMs."], "limitations": "", "keywords": ["agentic systems", "failure attribution", "large language models", "reinforcement learning", "multi-agent interactions"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2509.03405", "pdf": "https://arxiv.org/pdf/2509.03405.pdf", "abs": "https://arxiv.org/abs/2509.03405", "title": "LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations", "authors": ["Daniela Gottesman", "Alon Gilae-Dotan", "Ido Cohen", "Yoav Gur-Arieh", "Marius Mosbach", "Ori Yoran", "Mor Geva"], "categories": ["cs.CL"], "comment": "Submitted to TACL, August 2025", "summary": "Language models (LMs) increasingly drive real-world applications that require\nworld knowledge. However, the internal processes through which models turn data\ninto representations of knowledge and beliefs about the world, are poorly\nunderstood. Insights into these processes could pave the way for developing LMs\nwith knowledge representations that are more consistent, robust, and complete.\nTo facilitate studying these questions, we present LMEnt, a suite for analyzing\nknowledge acquisition in LMs during pretraining. LMEnt introduces: (1) a\nknowledge-rich pretraining corpus, fully annotated with entity mentions, based\non Wikipedia, (2) an entity-based retrieval method over pretraining data that\noutperforms previous approaches by as much as 80.4%, and (3) 12 pretrained\nmodels with up to 1B parameters and 4K intermediate checkpoints, with\ncomparable performance to popular open-sourced models on knowledge benchmarks.\nTogether, these resources provide a controlled environment for analyzing\nconnections between entity mentions in pretraining and downstream performance,\nand the effects of causal interventions in pretraining data. We show the\nutility of LMEnt by studying knowledge acquisition across checkpoints, finding\nthat fact frequency is key, but does not fully explain learning trends. We\nrelease LMEnt to support studies of knowledge in LMs, including knowledge\nrepresentations, plasticity, editing, attribution, and learning dynamics.", "AI": {"tldr": "LMEnt is a tool for analyzing knowledge acquisition in language models during pretraining, introducing a knowledge-rich corpus, an improved retrieval method, and multiple pretrained models.", "motivation": "To understand how language models acquire and represent knowledge from data, which could improve their consistency and robustness.", "method": "LMEnt provides a fully annotated pretraining corpus, an entity-based retrieval method, and includes 12 pretrained models to study knowledge acquisition and influence on performance.", "result": "The entity-based retrieval method outperformed previous approaches by 80.4%, and the pretrained models show comparable performance to open-sourced models on knowledge benchmarks.", "conclusion": "LMEnt supports research on knowledge in language models including aspects such as representations, plasticity, and learning dynamics.", "key_contributions": ["Knowledge-rich pretraining corpus annotated with entity mentions", "Novel entity-based retrieval method", "Release of multiple pretrained models for knowledge analysis"], "limitations": "", "keywords": ["Language Models", "Knowledge Acquisition", "Pretraining", "Entity Retrieval", "Machine Learning"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2509.03407", "pdf": "https://arxiv.org/pdf/2509.03407.pdf", "abs": "https://arxiv.org/abs/2509.03407", "title": "Learning Mechanism Underlying NLP Pre-Training and Fine-Tuning", "authors": ["Yarden Tzach", "Ronit D. Gross", "Ella Koresh", "Shalom Rosner", "Or Shpringer", "Tal Halevi", "Ido Kanter"], "categories": ["cs.CL"], "comment": "46 pages, 18 figures, 10 tables", "summary": "Natural language processing (NLP) enables the understanding and generation of\nmeaningful human language, typically using a pre-trained complex architecture\non a large dataset to learn the language and next fine-tune its weights to\nimplement a specific task. Twofold goals are examined; to understand the\nmechanism underlying successful pre-training and to determine the interplay\nbetween the pre-training accuracy and the fine-tuning of classification tasks.\nThe following main results were obtained; the accuracy per token (APT)\nincreased with its appearance frequency in the dataset, and its average over\nall tokens served as an order parameter to quantify pre-training success, which\nincreased along the transformer blocks. Pre-training broke the symmetry among\ntokens and grouped them into finite, small, strong match token clusters, as\ninferred from the presented token confusion matrix. This feature was sharpened\nalong the transformer blocks toward the output layer, enhancing its performance\nconsiderably compared with that of the embedding layer. Consequently,\nhigher-order language structures were generated by pre-training, even though\nthe learning cost function was directed solely at identifying a single token.\nThese pre-training findings were reflected by the improved fine-tuning accuracy\nalong the transformer blocks. Additionally, the output label prediction\nconfidence was found to be independent of the average input APT, as the input\nmeaning was preserved since the tokens are replaced primarily by strong match\ntokens. Finally, although pre-training is commonly absent in image\nclassification tasks, its underlying mechanism is similar to that used in\nfine-tuning NLP classification tasks, hinting at its universality. The results\nwere based on the BERT-6 architecture pre-trained on the Wikipedia dataset and\nfine-tuned on the FewRel and DBpedia classification tasks.", "AI": {"tldr": "This paper explores the mechanisms of successful pre-training in NLP, highlighting the relationship between pre-training accuracy and fine-tuning performance across classification tasks using the BERT-6 architecture.", "motivation": "To understand the mechanisms driving effective pre-training in natural language processing and its relationship with fine-tuning performance on classification tasks.", "method": "The study utilized the BERT-6 architecture, pre-training it on the Wikipedia dataset and fine-tuning it on FewRel and DBpedia classification tasks to observe accuracy trends.", "result": "The accuracy per token increased with its frequency, leading to enhanced performance as noted in the confusion matrix and its effect along transformer blocks, resulting in improved fine-tuning accuracy.", "conclusion": "Pre-training mechanisms in NLP show similarities to techniques used in image classification, indicating a universal pattern across different machine learning tasks.", "key_contributions": ["Proposed a novel metric (accuracy per token) for pre-training success.", "Demonstrated the grouping of tokens into strong match clusters during pre-training.", "Showed that mechanisms of pre-training in NLP can apply to image classification.", "Identified independence of prediction confidence from average input accuracy."], "limitations": "Focus mainly on the BERT-6 architecture limits generalizability; insights might vary for other models.", "keywords": ["natural language processing", "pre-training", "fine-tuning", "BERT-6", "classification"], "importance_score": 8, "read_time_minutes": 45}}
{"id": "2509.03419", "pdf": "https://arxiv.org/pdf/2509.03419.pdf", "abs": "https://arxiv.org/abs/2509.03419", "title": "Curse of Knowledge: When Complex Evaluation Context Benefits yet Biases LLM Judges", "authors": ["Weiyuan Li", "Xintao Wang", "Siyu Yuan", "Rui Xu", "Jiangjie Chen", "Qingqing Dong", "Yanghua Xiao", "Deqing Yang"], "categories": ["cs.CL"], "comment": "8 pages, 4 figures, conference", "summary": "As large language models (LLMs) grow more capable, they face increasingly\ndiverse and complex tasks, making reliable evaluation challenging. The paradigm\nof LLMs as judges has emerged as a scalable solution, yet prior work primarily\nfocuses on simple settings. Their reliability in complex tasks--where\nmulti-faceted rubrics, unstructured reference answers, and nuanced criteria are\ncritical--remains understudied. In this paper, we constructed ComplexEval, a\nchallenge benchmark designed to systematically expose and quantify Auxiliary\nInformation Induced Biases. We systematically investigated and validated 6\npreviously unexplored biases across 12 basic and 3 advanced scenarios. Key\nfindings reveal: (1) all evaluated models exhibit significant susceptibility to\nthese biases, with bias magnitude scaling with task complexity; (2) notably,\nLarge Reasoning Models (LRMs) show paradoxical vulnerability. Our in-depth\nanalysis offers crucial insights for improving the accuracy and verifiability\nof evaluation signals, paving the way for more general and robust evaluation\nmodels.", "AI": {"tldr": "This paper investigates biases in large language models (LLMs) during complex evaluations, presenting a benchmark called ComplexEval.", "motivation": "To address the challenge of reliably evaluating LLMs on diverse and complex tasks, where existing evaluations have proven inadequate.", "method": "Developed ComplexEval benchmark to expose and quantify Auxiliary Information Induced Biases across various scenarios.", "result": "Identified 6 previously unknown biases affecting LLM evaluations, with significant susceptibility linked to task complexity.", "conclusion": "The findings provide insights to improve LLM evaluation accuracy and reliability, highlighting the need for better evaluation models.", "key_contributions": ["Introduction of ComplexEval benchmark for evaluating LLMs", "Identification of 6 novel biases", "Analysis of LLM susceptibility to biases related to task complexity"], "limitations": "Focuses primarily on biases and does not propose solutions for all identified issues.", "keywords": ["large language models", "evaluation", "bias", "complex tasks", "benchmark"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2509.03467", "pdf": "https://arxiv.org/pdf/2509.03467.pdf", "abs": "https://arxiv.org/abs/2509.03467", "title": "Continuous Saudi Sign Language Recognition: A Vision Transformer Approach", "authors": ["Soukeina Elhassen", "Lama Al Khuzayem", "Areej Alhothali", "Ohoud Alzamzami", "Nahed Alowaidi"], "categories": ["cs.CL", "cs.AI"], "comment": "23 pages, 13 figures, 5 tables", "summary": "Sign language (SL) is an essential communication form for hearing-impaired\nand deaf people, enabling engagement within the broader society. Despite its\nsignificance, limited public awareness of SL often leads to inequitable access\nto educational and professional opportunities, thereby contributing to social\nexclusion, particularly in Saudi Arabia, where over 84,000 individuals depend\non Saudi Sign Language (SSL) as their primary form of communication. Although\ncertain technological approaches have helped to improve communication for\nindividuals with hearing impairments, there continues to be an urgent\nrequirement for more precise and dependable translation techniques, especially\nfor Arabic sign language variants like SSL. Most state-of-the-art solutions\nhave primarily focused on non-Arabic sign languages, resulting in a\nconsiderable absence of resources dedicated to Arabic sign language,\nspecifically SSL. The complexity of the Arabic language and the prevalence of\nisolated sign language datasets that concentrate on individual words instead of\ncontinuous speech contribute to this issue. To address this gap, our research\nrepresents an important step in developing SSL resources. To address this, we\nintroduce the first continuous Saudi Sign Language dataset called KAU-CSSL,\nfocusing on complete sentences to facilitate further research and enable\nsophisticated recognition systems for SSL recognition and translation.\nAdditionally, we propose a transformer-based model, utilizing a pretrained\nResNet-18 for spatial feature extraction and a Transformer Encoder with\nBidirectional LSTM for temporal dependencies, achieving 99.02\\% accuracy at\nsigner dependent mode and 77.71\\% accuracy at signer independent mode. This\ndevelopment leads the way to not only improving communication tools for the SSL\ncommunity but also making a substantial contribution to the wider field of sign\nlanguage.", "AI": {"tldr": "This paper presents the KAU-CSSL dataset, the first continuous Saudi Sign Language dataset, along with a novel transformer-based model for accurate SSL recognition and translation.", "motivation": "The research addresses the urgent need for precise and reliable translation techniques for Saudi Sign Language, which has been overlooked in favor of non-Arabic sign languages.", "method": "A transformer-based model is proposed, utilizing a pretrained ResNet-18 for spatial feature extraction and a Transformer Encoder with Bidirectional LSTM for temporal dependencies.", "result": "The model achieves an accuracy of 99.02% in signer dependent mode and 77.71% in signer independent mode, demonstrating its effectiveness.", "conclusion": "The KAU-CSSL dataset and the proposed model significantly advance the capabilities of communication tools for the hearing-impaired community and contribute to the field of sign language technology.", "key_contributions": ["Introduction of the KAU-CSSL dataset focusing on continuous SSL.", "Development of a transformer-based model for SSL recognition.", "High accuracy rates in both signer dependent and independent settings."], "limitations": "", "keywords": ["Saudi Sign Language", "SL recognition", "transformer model", "dataset", "communication technology"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2509.03479", "pdf": "https://arxiv.org/pdf/2509.03479.pdf", "abs": "https://arxiv.org/abs/2509.03479", "title": "Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games", "authors": ["Haonan Wang", "Mingjia Zhao", "Junfeng Sun", "Wei Liu"], "categories": ["cs.CL"], "comment": "6 papges", "summary": "As AI technology advances, research in playing text-based games with agents\nhas becomeprogressively popular. In this paper, a novel approach to agent\ndesign and agent learning ispresented with the context of reinforcement\nlearning. A model of deep learning is first applied toprocess game text and\nbuild a world model. Next, the agent is learned through a policy gradient-based\ndeep reinforcement learning method to facilitate conversion from state value to\noptimal policy.The enhanced agent works better in several text-based game\nexperiments and significantlysurpasses previous agents on game completion ratio\nand win rate. Our study introduces novelunderstanding and empirical ground for\nusing reinforcement learning for text games and sets thestage for developing\nand optimizing reinforcement learning agents for more general domains\nandproblems.", "AI": {"tldr": "This paper presents a novel agent design and learning approach for text-based games using deep reinforcement learning, introducing a new model for state value conversion to optimal policy that improves game performance.", "motivation": "To advance research in agent performance in text-based games using reinforcement learning techniques.", "method": "A model of deep learning processes the game text to build a world model, followed by a policy gradient-based deep reinforcement learning method for agent training.", "result": "The enhanced agent significantly outperforms previous agents in game completion ratio and win rate in text-based game experiments.", "conclusion": "This research provides empirical evidence and a new understanding of applying reinforcement learning techniques to text-based games, fostering future development in broader applications.", "key_contributions": ["Introduction of a deep learning model for world state processing in text games", "Development of an optimized policy gradient training method for agents", "Demonstration of significant improvements in game metrics compared to previous agents"], "limitations": "", "keywords": ["reinforcement learning", "text-based games", "agent design", "deep learning", "policy gradient"], "importance_score": 5, "read_time_minutes": 6}}
{"id": "2406.13748", "pdf": "https://arxiv.org/pdf/2406.13748.pdf", "abs": "https://arxiv.org/abs/2406.13748", "title": "Learn and Unlearn: Addressing Misinformation in Multilingual LLMs", "authors": ["Taiming Lu", "Philipp Koehn"], "categories": ["cs.CL", "cs.LG"], "comment": "EMNLP 2025 Main Conference", "summary": "This paper investigates the propagation of harmful information in\nmultilingual large language models (LLMs) and evaluates the efficacy of various\nunlearning methods. We demonstrate that fake information, regardless of the\nlanguage it is in, once introduced into these models through training data, can\nspread across different languages, compromising the integrity and reliability\nof the generated content. Our findings reveal that standard unlearning\ntechniques, which typically focus on English data, are insufficient in\nmitigating the spread of harmful content in multilingual contexts and could\ninadvertently reinforce harmful content across languages. We show that only by\naddressing harmful responses in both English and the original language of the\nharmful data can we effectively eliminate generations for all languages. This\nunderscores the critical need for comprehensive unlearning strategies that\nconsider the multilingual nature of modern LLMs to enhance their safety and\nreliability across diverse linguistic landscapes.", "AI": {"tldr": "This paper examines harmful information propagation in multilingual large language models (LLMs) and the effectiveness of unlearning methods.", "motivation": "To address the spread of harmful content across languages in multilingual LLMs and the shortcomings of existing unlearning methodologies.", "method": "Analysis of the propagation of fake information in multilingual contexts and evaluation of various unlearning techniques.", "result": "Findings indicate that traditional unlearning methods fail to mitigate the spread of harmful content across languages and may reinforce it instead.", "conclusion": "Comprehensive unlearning strategies are essential to enhance the safety and reliability of multilingual LLMs by addressing harmful responses in both English and original languages.", "key_contributions": ["Investigates the multilingual spread of harmful information in LLMs.", "Evaluates the efficacy of various unlearning methods in a multilingual context.", "Proposes a necessity for comprehensive unlearning strategies for multilingual LLMs."], "limitations": "Focused primarily on the evaluation of existing unlearning techniques without proposing new algorithms.", "keywords": ["multilingual LLMs", "harmful content", "unlearning techniques"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2406.15486", "pdf": "https://arxiv.org/pdf/2406.15486.pdf", "abs": "https://arxiv.org/abs/2406.15486", "title": "SampleAttention: Near-Lossless Acceleration of Long Context LLM Inference with Adaptive Structured Sparse Attention", "authors": ["Qianchao Zhu", "Jiangfei Duan", "Chang Chen", "Siran Liu", "Guanyu Feng", "Xin Lv", "Xiao Chuanfu", "Dahua Lin", "Chao Yang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) now support extremely long context windows, but\nthe quadratic complexity of vanilla attention results in significantly long\nTime-to-First-Token (TTFT) latency. Existing approaches to address this\ncomplexity require additional pretraining or finetuning, and often sacrifice\nmodel accuracy. In this paper, we first provide both theoretical and empirical\nfoundations for near-lossless sparse attention. We find dynamically capturing\nhead-specific sparse patterns at runtime with low overhead is crucial. To\naddress this, we propose SampleAttention, an adaptive structured and\nnear-lossless sparse attention. Leveraging observed significant sparse\npatterns, SampleAttention attends to a fixed percentage of adjacent tokens to\ncapture local window patterns, and employs a two-stage query-guided key-value\nfiltering approach, which adaptively select a minimum set of key-values with\nlow overhead, to capture column stripe patterns. Comprehensive evaluations show\nthat SampleAttention can seamlessly replace vanilla attention in off-the-shelf\nLLMs with nearly no accuracy loss, and reduces TTFT by up to $2.42\\times$\ncompared with FlashAttention.", "AI": {"tldr": "This paper introduces SampleAttention, a method that significantly reduces Time-to-First-Token (TTFT) latency in large language models (LLMs) by implementing adaptive sparse attention without sacrificing model accuracy.", "motivation": "To address the long TTFT latency caused by the quadratic complexity of vanilla attention in LLMs, while maintaining model accuracy and avoiding the need for additional pretraining or finetuning.", "method": "The paper proposes SampleAttention, which captures head-specific sparse patterns at runtime with decreased overhead. It leverages local window patterns by attending to a fixed percentage of adjacent tokens and employs a two-stage query-guided filtering method to select minimal key-values for capturing patterns.", "result": "SampleAttention replaces vanilla attention in LLMs with nearly no accuracy loss and achieves a reduction in TTFT by as much as 2.42 times compared to existing methods like FlashAttention.", "conclusion": "The proposed SampleAttention is an effective solution for reducing TTFT in LLMs by utilizing adaptive sparse attention while maintaining model performance.", "key_contributions": ["Introduced SampleAttention for adaptive and near-lossless sparse attention in LLMs.", "Demonstrated significant reduction in TTFT latency without accuracy loss.", "Provided both theoretical and empirical foundations for the method."], "limitations": "", "keywords": ["large language models", "sparse attention", "Time-to-First-Token"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2406.17642", "pdf": "https://arxiv.org/pdf/2406.17642.pdf", "abs": "https://arxiv.org/abs/2406.17642", "title": "Banishing LLM Hallucinations Requires Rethinking Generalization", "authors": ["Johnny Li", "Saksham Consul", "Eda Zhou", "James Wong", "Naila Farooqui", "Yuxin Ye", "Nithyashree Manohar", "Zhuxiaona Wei", "Tian Wu", "Ben Echols", "Sharon Zhou", "Gregory Diamos"], "categories": ["cs.CL", "cs.AI"], "comment": "I want to revisit some of the experiments in this paper, specifically\n  figure 5", "summary": "Despite their powerful chat, coding, and reasoning abilities, Large Language\nModels (LLMs) frequently hallucinate. Conventional wisdom suggests that\nhallucinations are a consequence of a balance between creativity and\nfactuality, which can be mitigated, but not eliminated, by grounding the LLM in\nexternal knowledge sources. Through extensive systematic experiments, we show\nthat these traditional approaches fail to explain why LLMs hallucinate in\npractice. Specifically, we show that LLMs augmented with a massive Mixture of\nMemory Experts (MoME) can easily memorize large datasets of random numbers. We\ncorroborate these experimental findings with a theoretical construction showing\nthat simple neural networks trained to predict the next token hallucinate when\nthe training loss is above a threshold as it usually does in practice when\ntraining on internet scale data. We interpret our findings by comparing against\ntraditional retrieval methods for mitigating hallucinations. We use our\nfindings to design a first generation model for removing hallucinations --\nLamini-1 -- that stores facts in a massive mixture of millions of memory\nexperts that are retrieved dynamically.", "AI": {"tldr": "The paper investigates hallucinations in Large Language Models (LLMs), demonstrating that conventional mitigating methods are ineffective. It introduces a new model, Lamini-1, designed to minimize hallucinations by using a massive mixture of memory experts to store and retrieve facts dynamically.", "motivation": "To address the phenomenon of hallucinations in Large Language Models (LLMs) and understand their underlying causes.", "method": "Systematic experiments and theoretical analysis were conducted to understand the behavior of LLMs and to design a novel model called Lamini-1 that uses a massive mixture of memory experts for fact retrieval.", "result": "The findings reveal that traditional methods fail to mitigate hallucinations effectively and that LLMs can easily memorize large datasets when augmented with a Mixture of Memory Experts. The new model, Lamini-1, was developed to dynamically retrieve facts and reduce hallucinations significantly.", "conclusion": "The study provides insights into why LLMs hallucinate and emphasizes the need for new approaches, like Lamini-1, for improving LLM reliability.", "key_contributions": ["Demonstration that traditional methods do not explain LLM hallucinations", "Introduction of the Lamini-1 model for dynamic fact retrieval", "Theoretical construction linking training loss to hallucination frequency"], "limitations": "The study is based on the experimental analysis of specific datasets and may not generalize across all use cases.", "keywords": ["Large Language Models", "hallucinations", "Mixture of Memory Experts", "fact retrieval", "Lamini-1"], "importance_score": 8, "read_time_minutes": 12}}
{"id": "2410.16033", "pdf": "https://arxiv.org/pdf/2410.16033.pdf", "abs": "https://arxiv.org/abs/2410.16033", "title": "TreeBoN: Enhancing Inference-Time Alignment with Speculative Tree-Search and Best-of-N Sampling", "authors": ["Jiahao Qiu", "Yifu Lu", "Yifan Zeng", "Jiacheng Guo", "Jiayi Geng", "Chenhao Zhu", "Xinzhe Juan", "Ling Yang", "Huazheng Wang", "Kaixuan Huang", "Yue Wu", "Mengdi Wang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Inference-time alignment enhances the performance of large language models\nwithout requiring additional training or fine-tuning but presents challenges\ndue to balancing computational efficiency with high-quality output. Best-of-N\n(BoN) sampling, as a simple yet powerful approach, generates multiple responses\nand selects the best one, achieving improved performance but with a high\ncomputational cost. We propose TreeBoN, a novel framework that integrates a\nspeculative tree-search strategy into Best-of-N (BoN) Sampling. TreeBoN\nmaintains a set of parent nodes, iteratively branching and pruning low-quality\nresponses, thereby reducing computational overhead while maintaining high\noutput quality. Our approach also leverages token-level rewards from Direct\nPreference Optimization (DPO) to guide tree expansion and prune low-quality\npaths. We evaluate TreeBoN using AlpacaFarm, HH-RLHF, UltraFeedback, GSM8K, and\nTutorEval datasets, demonstrating consistent improvements. Specifically,\nTreeBoN achieves the highest win rate of 65% on TutorEval and around 60% win\nrates across other different datasets, outperforming standard BoN with the same\ncomputational cost and showcasing its scalability and alignment efficacy.", "AI": {"tldr": "TreeBoN is a novel framework enhancing Best-of-N sampling for large language models by incorporating a speculative tree-search strategy, improving response quality while reducing computational costs.", "motivation": "Inference-time alignment is crucial for enhancing large language model performance without additional training, but it often struggles with computational efficiency versus output quality.", "method": "TreeBoN integrates a speculative tree-search strategy into Best-of-N sampling, maintaining parent nodes and pruning low-quality responses, while using token-level rewards from Direct Preference Optimization to guide the process.", "result": "TreeBoN demonstrated consistent improvements across various datasets, achieving the highest win rate of 65% on TutorEval and around 60% on others, while matching the computational costs of standard BoN.", "conclusion": "TreeBoN effectively balances computational overhead and response quality, making it a scalable and efficient solution for large language model inference.", "key_contributions": ["Introduces TreeBoN framework for improved Best-of-N sampling", "Reduces computational cost while maintaining high quality outputs", "Leverages token-level rewards for efficient tree expansion"], "limitations": "", "keywords": ["Best-of-N sampling", "TreeBoN", "large language models", "computational efficiency", "Direct Preference Optimization"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2410.20940", "pdf": "https://arxiv.org/pdf/2410.20940.pdf", "abs": "https://arxiv.org/abs/2410.20940", "title": "Attacking Misinformation Detection Using Adversarial Examples Generated by Language Models", "authors": ["Piotr Przybyła", "Euan McGill", "Horacio Saggion"], "categories": ["cs.CL"], "comment": "Presented at EMNLP 2025", "summary": "Large language models have many beneficial applications, but can they also be\nused to attack content-filtering algorithms in social media platforms? We\ninvestigate the challenge of generating adversarial examples to test the\nrobustness of text classification algorithms detecting low-credibility content,\nincluding propaganda, false claims, rumours and hyperpartisan news. We focus on\nsimulation of content moderation by setting realistic limits on the number of\nqueries an attacker is allowed to attempt. Within our solution (TREPAT),\ninitial rephrasings are generated by large language models with prompts\ninspired by meaning-preserving NLP tasks, such as text simplification and style\ntransfer. Subsequently, these modifications are decomposed into small changes,\napplied through beam search procedure, until the victim classifier changes its\ndecision. We perform (1) quantitative evaluation using various prompts, models\nand query limits, (2) targeted manual assessment of the generated text and (3)\nqualitative linguistic analysis. The results confirm the superiority of our\napproach in the constrained scenario, especially in case of long input text\n(news articles), where exhaustive search is not feasible.", "AI": {"tldr": "This paper explores the use of large language models to generate adversarial examples that can deceive content-filtering algorithms on social media, particularly those detecting low-credibility content.", "motivation": "The study aims to determine if large language models can effectively attack content-filtering algorithms, thereby testing their robustness against various low-credibility content types.", "method": "The proposed method, TREPAT, involves generating initial rephrasings through large language models using prompts based on meaning-preserving NLP tasks. These are then refined through a beam search procedure to induce changes in the victim classifier's decisions.", "result": "The experiments demonstrate that the proposed approach outperforms traditional methods in constrained scenarios, particularly with longer input texts such as news articles.", "conclusion": "The findings highlight the potential threats posed by large language models to content moderation systems, necessitating improvements in the robustness of such algorithms.", "key_contributions": ["Introduction of TREPAT for generating adversarial examples", "Demonstration of the effectiveness of LLMs in deceiving content filtering algorithms", "Comprehensive evaluation across quantitative, qualitative, and linguistic analyses"], "limitations": "The study assumes a controlled environment which may not fully represent real-world scenarios; further research is needed to generalize findings.", "keywords": ["large language models", "content moderation", "adversarial examples", "text classification", "robustness testing"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2501.09997", "pdf": "https://arxiv.org/pdf/2501.09997.pdf", "abs": "https://arxiv.org/abs/2501.09997", "title": "Attention-guided Self-reflection for Zero-shot Hallucination Detection in Large Language Models", "authors": ["Qiang Liu", "Xinlong Chen", "Yue Ding", "Bowen Song", "Weiqiang Wang", "Shu Wu", "Liang Wang"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hallucination has emerged as a significant barrier to the effective\napplication of Large Language Models (LLMs). In this work, we introduce a novel\nAttention-Guided SElf-Reflection (AGSER) approach for zero-shot hallucination\ndetection in LLMs. The AGSER method utilizes attention contributions to\ncategorize the input query into attentive and non-attentive queries. Each query\nis then processed separately through the LLMs, allowing us to compute\nconsistency scores between the generated responses and the original answer. The\ndifference between the two consistency scores serves as a hallucination\nestimator. In addition to its efficacy in detecting hallucinations, AGSER\nnotably reduces computational overhead, requiring only three passes through the\nLLM and utilizing two sets of tokens. We have conducted extensive experiments\nwith four widely-used LLMs across three different hallucination benchmarks,\ndemonstrating that our approach significantly outperforms existing methods in\nzero-shot hallucination detection.", "AI": {"tldr": "Introducing a method for zero-shot hallucination detection in Large Language Models using attention contributions.", "motivation": "To address the significant barrier of hallucination in Large Language Models (LLMs) which impacts their effective application.", "method": "The Attention-Guided SElf-Reflection (AGSER) approach uses attention contributions to categorize queries and compute consistency scores to estimate hallucination.", "result": "The AGSER method significantly outperforms existing zero-shot hallucination detection methods across several benchmarks while reducing computational costs.", "conclusion": "AGSER effectively detects hallucinations in LLMs with fewer computational passes and improved performance.", "key_contributions": ["Introduction of AGSER for zero-shot hallucination detection", "Utilization of attention contributions for categorizing queries", "Demonstrated performance improvements across multiple LLMs and benchmarks."], "limitations": "", "keywords": ["Large Language Models", "hallucination detection", "attention mechanisms", "zero-shot learning"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2502.04387", "pdf": "https://arxiv.org/pdf/2502.04387.pdf", "abs": "https://arxiv.org/abs/2502.04387", "title": "FedP$^2$EFT: Federated Learning to Personalize PEFT for Multilingual LLMs", "authors": ["Royson Lee", "Minyoung Kim", "Fady Rezk", "Rui Li", "Stylianos I. Venieris", "Timothy Hospedales"], "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Federated learning (FL) has enabled the training of multilingual large\nlanguage models (LLMs) on diverse and decentralized multilingual data,\nespecially on low-resource languages. To improve client-specific performance,\npersonalization via the use of parameter-efficient fine-tuning (PEFT) modules\nsuch as LoRA is common. This involves a personalization strategy (PS), such as\nthe design of the PEFT adapter structures (e.g., in which layers to add LoRAs\nand what ranks) and choice of hyperparameters (e.g., learning rates) for\nfine-tuning. Instead of manual PS configuration, we propose FedP$^2$EFT, a\nfederated learning-to-personalize method for multilingual LLMs in cross-device\nFL settings. Unlike most existing PEFT structure selection methods, which are\nprone to overfitting low-data regimes, FedP$^2$EFT collaboratively learns the\noptimal personalized PEFT structure for each client via Bayesian sparse rank\nselection. Evaluations on both simulated and real-world multilingual FL\nbenchmarks demonstrate that FedP$^2$EFT largely outperforms existing\npersonalized fine-tuning methods, while complementing other existing FL\nmethods. Code is available at https://github.com/SamsungLabs/fedp2eft.", "AI": {"tldr": "FedP^2EFT is a method for personalizing multilingual LLMs in federated learning settings, using Bayesian sparse rank selection for optimal structure learning.", "motivation": "The paper addresses the challenge of personalizing multilingual LLMs in low-resource language environments without the need for manual configuration of personalization strategies.", "method": "FedP^2EFT employs a federated learning framework that uses Bayesian sparse rank selection to learn optimal personalized parameter-efficient fine-tuning (PEFT) structures for each client.", "result": "FedP^2EFT demonstrates significant improvements over existing personalized fine-tuning methods in multilingual federated learning benchmarks.", "conclusion": "The evaluations suggest that FedP^2EFT offers a robust solution for optimizing PEFT structures in multilingual federated learning settings, successfully avoiding overfitting to low-data issues.", "key_contributions": ["Introduction of FedP^2EFT for multilingual LLMs in federated learning", "Utilization of Bayesian sparse rank selection for personalized fine-tuning", "Demonstrated superiority over existing personalized fine-tuning approaches."], "limitations": "", "keywords": ["Federated learning", "Multilingual LLMs", "Personalization", "Bayesian sparse rank selection", "Parameter-efficient fine-tuning"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2502.11128", "pdf": "https://arxiv.org/pdf/2502.11128.pdf", "abs": "https://arxiv.org/abs/2502.11128", "title": "FELLE: Autoregressive Speech Synthesis with Token-Wise Coarse-to-Fine Flow Matching", "authors": ["Hui Wang", "Shujie Liu", "Lingwei Meng", "Jinyu Li", "Yifan Yang", "Shiwan Zhao", "Haiyang Sun", "Yanqing Liu", "Haoqin Sun", "Jiaming Zhou", "Yan Lu", "Yong Qin"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted by ACM Multimedia 2025", "summary": "To advance continuous-valued token modeling and temporal-coherence\nenforcement, we propose FELLE, an autoregressive model that integrates language\nmodeling with token-wise flow matching. By leveraging the autoregressive nature\nof language models and the generative efficacy of flow matching, FELLE\neffectively predicts continuous-valued tokens (mel-spectrograms). For each\ncontinuous-valued token, FELLE modifies the general prior distribution in flow\nmatching by incorporating information from the previous step, improving\ncoherence and stability. Furthermore, to enhance synthesis quality, FELLE\nintroduces a coarse-to-fine flow-matching mechanism, generating\ncontinuous-valued tokens hierarchically, conditioned on the language model's\noutput. Experimental results demonstrate the potential of incorporating\nflow-matching techniques in autoregressive mel-spectrogram modeling, leading to\nsignificant improvements in TTS generation quality, as shown in\nhttps://aka.ms/felle.", "AI": {"tldr": "FELLE is an autoregressive model that combines language modeling with token-wise flow matching to improve the generation of continuous-valued tokens, specifically mel-spectrograms, enhancing temporal coherence and synthesis quality in TTS applications.", "motivation": "To improve continuous-valued token modeling and enforce temporal coherence in text-to-speech (TTS) generation.", "method": "FELLE integrates autoregressive language modeling with token-wise flow matching, employing a coarse-to-fine flow-matching mechanism to predict continuous-valued tokens hierarchically based on language model outputs.", "result": "FELLE demonstrates significant improvements in TTS generation quality by incorporating flow-matching techniques, as evidenced by experimental results.", "conclusion": "The research highlights the effectiveness of using flow matching in autoregressive mel-spectrogram modeling, leading to enhanced TTS synthesis quality.", "key_contributions": ["Introduction of FELLE for continuous-valued token modeling", "Combination of autoregressive modeling with flow matching for improved coherence", "Coarse-to-fine flow-matching mechanism for hierarchical token prediction"], "limitations": "", "keywords": ["Token modeling", "Text-to-speech", "Flow matching", "Continuous-valued tokens", "Autoregressive models"], "importance_score": 4, "read_time_minutes": 10}}
{"id": "2502.18179", "pdf": "https://arxiv.org/pdf/2502.18179.pdf", "abs": "https://arxiv.org/abs/2502.18179", "title": "Problem Solved? Information Extraction Design Space for Layout-Rich Documents using LLMs", "authors": ["Gaye Colakoglu", "Gürkan Solmaz", "Jonathan Fürst"], "categories": ["cs.CL", "cs.AI"], "comment": "accepted at EMNLP'25", "summary": "This paper defines and explores the design space for information extraction\n(IE) from layout-rich documents using large language models (LLMs). The three\ncore challenges of layout-aware IE with LLMs are 1) data structuring, 2) model\nengagement, and 3) output refinement. Our study investigates the sub-problems\nand methods within these core challenges, such as input representation,\nchunking, prompting, selection of LLMs, and multimodal models. It examines the\neffect of different design choices through LayIE-LLM, a new, open-source,\nlayout-aware IE test suite, benchmarking against traditional, fine-tuned IE\nmodels. The results on two IE datasets show that LLMs require adjustment of the\nIE pipeline to achieve competitive performance: the optimized configuration\nfound with LayIE-LLM achieves 13.3--37.5 F1 points more than a general-practice\nbaseline configuration using the same LLM. To find a well-working\nconfiguration, we develop a one-factor-at-a-time (OFAT) method that achieves\nnear-optimal results. Our method is only 0.8--1.8 points lower than the best\nfull factorial exploration with a fraction (2.8%) of the required computation.\nOverall, we demonstrate that, if well-configured, general-purpose LLMs match\nthe performance of specialized models, providing a cost-effective,\nfinetuning-free alternative. Our test-suite is available at\nhttps://github.com/gayecolakoglu/LayIE-LLM.", "AI": {"tldr": "This paper explores the design space for information extraction from layout-rich documents using LLMs, identifying core challenges and proposing a new test suite for benchmarking.", "motivation": "To address the challenges of information extraction from layout-rich documents using LLMs.", "method": "The study analyzes methods for input representation, chunking, prompting, model selection, and output refinement, using LayIE-LLM, a new test suite.", "result": "The optimized configuration from LayIE-LLM shows a significant performance improvement, achieving 13.3–37.5 F1 points beyond a baseline.", "conclusion": "Well-configured general-purpose LLMs can match specialized models for layout-aware information extraction, offering a cost-effective approach without the need for fine-tuning.", "key_contributions": ["Development of LayIE-LLM, a layout-aware IE test suite", "Proposed one-factor-at-a-time method for optimized configurations", "Demonstration that LLMs can achieve specialized model performance with proper configuration"], "limitations": "", "keywords": ["information extraction", "layout-aware", "large language models", "benchmarking", "test suite"], "importance_score": 9, "read_time_minutes": 15}}
