{"id": "2508.20263", "pdf": "https://arxiv.org/pdf/2508.20263.pdf", "abs": "https://arxiv.org/abs/2508.20263", "title": "Athena: Intermediate Representations for Iterative Scaffolded App Generation with an LLM", "authors": ["Jazbo Beason", "Ruijia Cheng", "Eldon Schoop", "Jeffrey Nichols"], "categories": ["cs.HC"], "comment": null, "summary": "It is challenging to generate the code for a complete user interface using a\nLarge Language Model (LLM). User interfaces are complex and their\nimplementations often consist of multiple, inter-related files that together\nspecify the contents of each screen, the navigation flows between the screens,\nand the data model used throughout the application. It is challenging to craft\na single prompt for an LLM that contains enough detail to generate a complete\nuser interface, and even then the result is frequently a single large and\ndifficult to understand file that contains all of the generated screens. In\nthis paper, we introduce Athena, a prototype application generation environment\nthat demonstrates how the use of shared intermediate representations, including\nan app storyboard, data model, and GUI skeletons, can help a developer work\nwith an LLM in an iterative fashion to craft a complete user interface. These\nintermediate representations also scaffold the LLM's code generation process,\nproducing organized and structured code in multiple files while limiting\nerrors. We evaluated Athena with a user study that found 75% of participants\npreferred our prototype over a typical chatbot-style baseline for prototyping\napps.", "AI": {"tldr": "Athena is a prototype application generation tool that helps developers create user interfaces using LLMs, employing intermediate representations to structure code generation.", "motivation": "Generating complete user interfaces with LLMs is complex due to the intricacy of UI components and their interconnected files.", "method": "The paper presents Athena, which uses shared intermediate representations like app storyboards, data models, and GUI skeletons to facilitate iterative UI development with LLMs.", "result": "A user study showed that 75% of participants preferred Athena over a traditional chatbot-style approach for app prototyping.", "conclusion": "Athena can enhance the code generation process by producing organized and structured output while reducing errors.", "key_contributions": ["Introduction of shared intermediate representations for UI generation", "Demonstration of iterative development with LLMs", "User study validating Athena's effectiveness over traditional methods"], "limitations": "The study's sample size and scope may limit generalizability.", "keywords": ["Large Language Models", "User Interface Generation", "Prototype Development", "Human-Computer Interaction", "App Storyboard"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2508.20383", "pdf": "https://arxiv.org/pdf/2508.20383.pdf", "abs": "https://arxiv.org/abs/2508.20383", "title": "Identifying Framing Practices in Visualization Design Through Practitioner Reflections", "authors": ["Prakash Shukla", "Paul Parsons"], "categories": ["cs.HC"], "comment": "Accepted for publication in the IEEEVIS Workshop on Visualization for\n  Communication (VisComm 25)", "summary": "Framing -- how designers define and reinterpret problems, shape narratives,\nand guide audience understanding -- is central to design practice. Yet in\nvisualization research, framing has been examined mostly through its rhetorical\nand perceptual effects on audiences, leaving its role in the design process\nunderexplored. This study addresses that gap by analyzing publicly available\npodcasts and book chapters in which over 80 professional visualization\ndesigners reflect on their work. We find that framing is a pervasive, iterative\nactivity, evident in scoping problems, interpreting data, aligning with\nstakeholder goals, and shaping narrative direction. Our analysis identifies the\nconditions that trigger reframing and the strategies practitioners use to\nnavigate uncertainty and guide design. These findings position framing as a\ncore dimension of visualization practice and underscore the need for research\nand education to support the interpretive and strategic judgment that\npractitioners exercise throughout the design process.", "AI": {"tldr": "This study examines the role of framing in the design process of visualization, identifying it as a critical component that influences problem scoping, data interpretation, and narrative development.", "motivation": "To explore the underexamined role of framing in the design process of visualization, beyond its effects on audience perception.", "method": "Analysis of podcasts and book chapters from over 80 professional visualization designers reflecting on their design practices.", "result": "Framing is identified as a pervasive and iterative activity in visualization design, affecting various stages such as problem definition and stakeholder alignment.", "conclusion": "Framing is a core dimension of visualization practice that needs more focus in research and education to enhance practitioners' strategic judgment.", "key_contributions": ["Identifies framing as a critical aspect of the design process in visualization.", "Explores conditions that trigger reframing in design.", "Outlines strategies used by practitioners to manage uncertainty."], "limitations": "", "keywords": ["Framing", "Visualization Design", "Design Process", "Strategic Judgment", "Narrative Development"], "importance_score": 4, "read_time_minutes": 15}}
{"id": "2508.20464", "pdf": "https://arxiv.org/pdf/2508.20464.pdf", "abs": "https://arxiv.org/abs/2508.20464", "title": "Human-Centered Design for Connected Automation: Predicting Pedestrian Crossing Intentions", "authors": ["Sanaz Motamedi", "Viktoria Marcus", "Griffin Pitts"], "categories": ["cs.HC", "cs.ET", "H.5.2; H.1.2; I.6; J.4"], "comment": null, "summary": "Road traffic remains a leading cause of death worldwide, with pedestrians and\nother vulnerable road users accounting for over half of the 1.19 million annual\nfatalities, much of it due to human error. Level-5 automated driving systems\n(ADSs), capable of full self-driving without human oversight, have the\npotential to reduce these incidents. However, their effectiveness depends not\nonly on automation performance but also on their ability to communicate intent\nand coordinate safely with pedestrians in the absence of traditional driver\ncues. Understanding how pedestrians interpret and respond to ADS behavior is\ntherefore critical to the development of connected vehicle systems. This study\nextends the Theory of Planned Behavior (TPB) by incorporating four external\nfactors (i.e. safety, trust, compatibility, and understanding) to model\npedestrian decision-making in road-crossing scenarios involving level-5 ADSs.\nUsing data from an online survey (n = 212), results show that perceived\nbehavioral control, attitude, and social information significantly predict\npedestrians' crossing intentions. External factors, particularly perceived\nsafety and understanding, strongly influence these constructs. Findings provide\nactionable insights for designing external human-machine interfaces (eHMIs) and\ncooperative V2X communication strategies that support safe, transparent\ninteractions between automated vehicles and pedestrians. This work contributes\nto the development of inclusive, human-centered connected mobility systems.", "AI": {"tldr": "This study explores pedestrian decision-making in road-crossing scenarios with level-5 automated driving systems (ADSs), highlighting the impact of external factors on their behavior.", "motivation": "To address the high fatality rates in road traffic due to human error and improve interactions between pedestrians and level-5 ADSs.", "method": "The study extends the Theory of Planned Behavior (TPB) by adding four external factors (safety, trust, compatibility, understanding) and analyzes data from an online survey with 212 participants.", "result": "Data analysis reveals that perceived behavioral control, attitude, and social information predict crossing intentions, with safety and understanding being significant influencers.", "conclusion": "The findings suggest the importance of designing effective human-machine interfaces and communication strategies for safer interactions between automated vehicles and pedestrians.", "key_contributions": ["Extended TPB to include external factors relevant to ADSs", "Identified key predictors of pedestrian crossing intentions", "Provided insights for designing eHMIs and V2X strategies"], "limitations": "", "keywords": ["automated driving systems", "pedestrian behavior", "human-machine interaction", "traffic safety", "Theory of Planned Behavior"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2508.20477", "pdf": "https://arxiv.org/pdf/2508.20477.pdf", "abs": "https://arxiv.org/abs/2508.20477", "title": "What is \"Spatial\" about Spatial Computing?", "authors": ["Yibo Wang", "Yuhan Luo", "Janghee Cho", "Junnan Yu"], "categories": ["cs.HC", "H.5.1; H.5.2; H.2.8"], "comment": null, "summary": "Recent advancements in geographic information systems and mixed reality\ntechnologies have positioned spatial computing as a transformative paradigm in\ncomputational science. However, the field remains conceptually fragmented, with\ndiverse interpretations across disciplines like Human-Computer Interaction,\nGeographic Information Science, and Computer Science, which hinders a\ncomprehensive understanding of spatial computing and poses challenges for its\ncoherent advancement and interdisciplinary integration. In this paper, we trace\nthe origins and historical evolution of spatial computing and examine how\n\"spatial\" is understood, identifying two schools of thought: \"spatial\" as the\ncontextual understanding of space, where spatial data guides interaction in the\nphysical world; and \"spatial\" as a mixed space for interaction, emphasizing the\nseamless integration of physical and digital environments to enable embodied\nengagement. By synthesizing these perspectives, we propose spatial computing as\na computational paradigm that redefines the interplay between environment,\ncomputation, and human experience, offering a holistic lens to enhance its\nconceptual clarity and inspire future technological innovations that support\nmeaningful interactions with and shaping of environments.", "AI": {"tldr": "This paper explores the fragmented field of spatial computing, tracing its historical evolution and proposing a cohesive understanding that enhances identity and technological innovation in the interplay of physical and digital spaces.", "motivation": "To address the conceptual fragmentation in spatial computing and enhance interdisciplinary understanding and advancement.", "method": "The authors trace the historical origins of spatial computing and categorize two perspectives on 'spatial' to unify understanding across disciplines.", "result": "Identified two schools of thought on spatial computing: one focusing on spatial data guiding interaction in the physical world, and the other emphasizing embodied engagement through the integration of physical and digital environments.", "conclusion": "The synthesis of these perspectives establishes spatial computing as a transformative computational paradigm that redefines human interactions with environments.", "key_contributions": ["Identifies and categorizes the conceptual fragmentation in spatial computing.", "Proposes a unified conceptual model for understanding spatial computing across disciplines.", "Highlights implications for future technological innovations in HCI and spatial interactions."], "limitations": "", "keywords": ["spatial computing", "Human-Computer Interaction", "mixed reality", "geographic information systems", "interdisciplinary integration"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2508.20201", "pdf": "https://arxiv.org/pdf/2508.20201.pdf", "abs": "https://arxiv.org/abs/2508.20201", "title": "Social Bias in Multilingual Language Models: A Survey", "authors": ["Lance Calvin Lim Gamboa", "Yue Feng", "Mark Lee"], "categories": ["cs.CL"], "comment": "Accepted into EMNLP 2025 Main Conference", "summary": "Pretrained multilingual models exhibit the same social bias as models\nprocessing English texts. This systematic review analyzes emerging research\nthat extends bias evaluation and mitigation approaches into multilingual and\nnon-English contexts. We examine these studies with respect to linguistic\ndiversity, cultural awareness, and their choice of evaluation metrics and\nmitigation techniques. Our survey illuminates gaps in the field's dominant\nmethodological design choices (e.g., preference for certain languages, scarcity\nof multilingual mitigation experiments) while cataloging common issues\nencountered and solutions implemented in adapting bias benchmarks across\nlanguages and cultures. Drawing from the implications of our findings, we chart\ndirections for future research that can reinforce the multilingual bias\nliterature's inclusivity, cross-cultural appropriateness, and alignment with\nstate-of-the-art NLP advancements.", "AI": {"tldr": "This paper reviews research on bias in multilingual AI models, highlighting methodological gaps and proposing future directions for mitigating bias across languages and cultures.", "motivation": "To address the social biases present in pretrained multilingual models and enhance their evaluation and mitigation in non-English contexts.", "method": "The study systematically reviews existing research on bias evaluation and mitigation in multilingual models, focusing on linguistic diversity and cultural considerations.", "result": "The review identifies gaps in methodological choices, such as language preference and the lack of multilingual mitigation experiments, while also cataloging common issues and solutions in adapting bias benchmarks.", "conclusion": "The paper emphasizes the need for future research to enhance inclusivity and cultural appropriateness in multilingual bias literature and to align with advancements in NLP.", "key_contributions": ["Systematic analysis of bias evaluation in multilingual AI models.", "Identification of methodological gaps in current research.", "Proposals for future research directions to improve cross-cultural bias mitigation."], "limitations": "The review may not encompass all existing literature and focuses more on certain languages.", "keywords": ["multilingual models", "bias evaluation", "human-computer interaction", "NLP advancement"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2508.20522", "pdf": "https://arxiv.org/pdf/2508.20522.pdf", "abs": "https://arxiv.org/abs/2508.20522", "title": "VisiTrail: A Cognitive Visualization Tool for Time-Series Analysis of Eye Tracking Data from Attention Game", "authors": ["Abdul Rehman", "Ilona Heldal", "Jerry Chun-Wei Lin"], "categories": ["cs.HC"], "comment": null, "summary": "Eye Tracking (ET) can help to understand visual attention and cognitive\nprocesses in interactive environments. In attention tasks, distinguishing\nbetween relevant target objects and distractors is crucial for effective\nperformance, yet the underlying gaze patterns that drive successful task\ncompletion remain incompletely understood. Traditional gaze analyses lack\ncomprehensive insights into the temporal dynamics of attention allocation and\nthe relationship between gaze behavior and task performance. When applied to\ncomplex visual search scenarios, current gaze analysis methods face several\nlimitations, including the isolation of measurements, visual stability, search\nefficiency, and the decision-making processes involved in these scenarios. This\npaper proposes an analysis tool that considers time series for eye tracking\ndata from task performance and also gaze measures (fixations, saccades and\nsmooth pursuit); temporal pattern analysis that reveals how attention evolves\nthroughout task performance; object-click sequence tracking that directly links\nvisual attention to user actions; and performance metrics that quantify both\naccuracy and efficiency. This tool provides comprehensive visualization\ntechniques that make complex patterns of stimuli and gaze connections\ninterpretable.", "AI": {"tldr": "This paper presents a new analysis tool for eye tracking data that enhances understanding of visual attention and cognitive processes in interactive environments by integrating temporal pattern analysis and performance metrics.", "motivation": "To address the limited insights from traditional gaze analyses in understanding visual attention dynamics and their impact on task performance in complex visual search scenarios.", "method": "The proposed tool analyzes time series eye tracking data, incorporating gaze measures like fixations and saccades, and provides insights into temporal patterns and object-click sequences linked to user actions and performance metrics.", "result": "The tool reveals how attention evolves during task performance and provides comprehensive visualizations that clarify complex relationships between gaze behavior and user actions.", "conclusion": "This eye tracking analysis tool offers a robust framework for understanding cognitive processes and enhancing performance in interactive visual tasks.", "key_contributions": ["Integration of time series analysis for gaze data", "Visualization techniques that interpret complex gaze-stimuli connections", "Linking gaze behavior directly to user actions with performance metrics"], "limitations": "", "keywords": ["Eye Tracking", "Visual Attention", "Cognitive Processes", "Gaze Analysis", "Interactive Environments"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2508.20217", "pdf": "https://arxiv.org/pdf/2508.20217.pdf", "abs": "https://arxiv.org/abs/2508.20217", "title": "Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models", "authors": ["Mohammad Amini", "Babak Ahmadi", "Xiaomeng Xiong", "Yilin Zhang", "Christopher Qiao"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This study explores automatic generation (AIG) using language models to\ncreate multiple choice questions (MCQs) for morphological assessment, aiming to\nreduce the cost and inconsistency of manual test development. The study used a\ntwo-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)\nwith a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven\nstructured prompting strategies, including zero-shot, few-shot,\nchain-of-thought, role-based, sequential, and combinations. Generated items\nwere assessed using automated metrics and expert scoring across five\ndimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate\nhuman scoring at scale. Results show that structured prompting, especially\nstrategies combining chain-of-thought and sequential design, significantly\nimproved Gemma's outputs. Gemma generally produced more construct-aligned and\ninstructionally appropriate items than GPT-3.5's zero-shot responses, with\nprompt design playing a key role in mid-size model performance. This study\ndemonstrates that structured prompting and efficient fine-tuning can enhance\nmidsized models for AIG under limited data conditions. We highlight the value\nof combining automated metrics, expert judgment, and large-model simulation to\nensure alignment with assessment goals. The proposed workflow offers a\npractical and scalable way to develop and validate language assessment items\nfor K-12.", "AI": {"tldr": "The study investigates the use of language models for generating multiple choice questions to enhance morphological assessments, focusing on structured prompting and model efficiency.", "motivation": "To address the high costs and inconsistencies associated with manual development of assessment tests for morphology.", "method": "The study utilized a two-fold approach comparing a fine-tuned medium model (Gemma) with a larger untuned model (GPT-3.5) and evaluated various structured prompting strategies.", "result": "Structured prompting significantly improved the outputs of the Gemma model, generating more construct-aligned items compared to the untuned GPT-3.5 in zero-shot configurations.", "conclusion": "Efficient fine-tuning and appropriate prompting strategies can enhance the performance of mid-sized language models for automated item generation in educational assessments.", "key_contributions": ["Demonstrated the effectiveness of structured prompting for AIG in assessments.", "Highlighted the benefits of fine-tuning on mid-sized models under limited data conditions.", "Proposed a scalable workflow for generating and validating language assessment items."], "limitations": "The study focuses primarily on K-12 assessments and may not generalize to other educational levels or contexts.", "keywords": ["Automatic Generation", "Language Models", "Multiple Choice Questions", "Morphological Assessment", "Structured Prompting"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2508.20585", "pdf": "https://arxiv.org/pdf/2508.20585.pdf", "abs": "https://arxiv.org/abs/2508.20585", "title": "Persode: Personalized Visual Journaling with Episodic Memory-Aware AI Agent", "authors": ["Seokho Jin", "Manseo Kim", "Sungho Byun", "Hansol Kim", "Jungmin Lee", "Sujeong Baek", "Semi Kim", "Sanghum Park", "Sung Park"], "categories": ["cs.HC"], "comment": null, "summary": "Reflective journaling often lacks personalization and fails to engage\nGeneration Alpha and Z, who prefer visually immersive and fast-paced\ninteractions over traditional text-heavy methods. Visual storytelling enhances\nemotional recall and offers an engaging way to process personal expe- riences.\nDesigned with these digital-native generations in mind, this paper introduces\nPersode, a journaling system that integrates personalized onboarding,\nmemory-aware conversational agents, and automated visual storytelling. Persode\ncaptures user demographics and stylistic preferences through a tailored\nonboarding process, ensuring outputs resonate with individual identities. Using\na Retrieval-Augmented Generation (RAG) framework, it prioritizes emotionally\nsignificant memories to provide meaningful, context-rich interactions.\nAdditionally, Persode dynamically transforms user experiences into visually\nengaging narratives by generating prompts for advanced text-to-image models,\nadapting characters, backgrounds, and styles to user preferences. By addressing\nthe need for personalization, visual engagement, and responsiveness, Persode\nbridges the gap between traditional journaling and the evolving preferences of\nGen Alpha and Z.", "AI": {"tldr": "Persode is a personalized journaling system designed for Generation Alpha and Z, integrating visual storytelling and memory-aware interactions to enhance user engagement.", "motivation": "The traditional journaling methods lack personalization and do not engage the digital-native Generation Alpha and Z effectively, who prefer faster and more visually immersive experiences.", "method": "Persode employs a tailored onboarding process to capture user demographics and stylistic preferences. It uses a Retrieval-Augmented Generation (RAG) framework to prioritize emotionally significant memories and generates visually engaging narratives through text-to-image models.", "result": "Persode successfully enhances emotional recall and engagement by providing personalized, context-rich interactions tailored to individual user preferences.", "conclusion": "By addressing personalization, visual engagement, and responsiveness, Persode effectively meets the evolving preferences of younger generations, bridging the gap between traditional and modern journaling.", "key_contributions": ["Introduction of a personalized onboarding process for journaling", "Utilization of a RAG framework for prioritizing significant memories", "Dynamic generation of visual narratives using text-to-image models"], "limitations": "", "keywords": ["Reflective journaling", "Visual storytelling", "Generation Alpha", "Generation Z", "Retrieval-Augmented Generation"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2508.20223", "pdf": "https://arxiv.org/pdf/2508.20223.pdf", "abs": "https://arxiv.org/abs/2508.20223", "title": "Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach", "authors": ["Andrei Mihai Albu", "Giovanni Pollo", "Alessio Burrello", "Daniele Jahier Pagliari", "Cristian Tesconi", "Alessandra Neri", "Dario Soldi", "Fabio Autieri", "Sara Vinco"], "categories": ["cs.CL"], "comment": null, "summary": "The growing complexity of cyber-physical systems, particularly in automotive\napplications, has increased the demand for efficient modeling and cross-domain\nco-simulation techniques. While SystemC Transaction-Level Modeling (TLM)\nenables effective hardware/software co-design, its limited interoperability\nwith models from other engineering domains poses integration challenges. This\npaper presents a fully open-source methodology for integrating SystemC TLM\nmodels into Functional Mock-up Interface (FMI)-based co-simulation workflows.\nBy encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional\nMock-up Units (FMUs), the proposed approach facilitates seamless, standardized\nintegration across heterogeneous simulation environments. We introduce a\nlightweight open-source toolchain, address key technical challenges such as\ntime synchronization and data exchange, and demonstrate the feasibility and\neffectiveness of the integration through representative case studies.", "AI": {"tldr": "This paper proposes an open-source methodology for integrating SystemC TLM models into FMI-based co-simulation, improving interoperability in automotive cyber-physical systems.", "motivation": "To address integration challenges in modeling complex cyber-physical systems, particularly in automotive applications.", "method": "The paper presents a methodology that encapsulates SystemC TLM components as FMI 3.0 Co Simulation FMUs, facilitating integration in heterogeneous simulation environments.", "result": "The integration approach is shown to be feasible and effective, with demonstrated case studies addressing synchronization and data exchange.", "conclusion": "The proposed toolchain offers a standardized solution for co-simulation across different domains, thereby enhancing the modeling capabilities in automotive and other applications.", "key_contributions": ["Development of a methodology for encapsulating SystemC TLM components as FMI FMUs", "Introduction of an open-source toolchain for enhanced co-simulation", "Solving challenges related to time synchronization and data exchange"], "limitations": "", "keywords": ["Cyber-physical systems", "SystemC", "FMI", "Co-simulation", "Automotive"], "importance_score": 2, "read_time_minutes": 10}}
{"id": "2508.20635", "pdf": "https://arxiv.org/pdf/2508.20635.pdf", "abs": "https://arxiv.org/abs/2508.20635", "title": "Schema-Guided Response Generation using Multi-Frame Dialogue State for Motivational Interviewing Systems", "authors": ["Jie Zeng", "Yukiko I. Nakano"], "categories": ["cs.HC"], "comment": "28pages, 15 figures, 10 tables", "summary": "The primary goal of Motivational Interviewing (MI) is to help clients build\ntheir own motivation for behavioral change. To support this in dialogue\nsystems, it is essential to guide large language models (LLMs) to generate\ncounselor responses aligned with MI principles. By employing a schema-guided\napproach, this study proposes a method for updating multi-frame dialogue states\nand a strategy decision mechanism that dynamically determines the response\nfocus in a manner grounded in MI principles. The proposed method was\nimplemented in a dialogue system and evaluated through a user study. Results\nshowed that the proposed system successfully generated MI-favorable responses\nand effectively encouraged the user's (client's) deliberation by asking\neliciting questions.", "AI": {"tldr": "This study proposes a dialogue system integrating Motivational Interviewing principles to guide LLMs in generating counselor responses that foster behavioral change.", "motivation": "The goal is to enhance client motivation for behavioral change through effective dialogue systems that follow Motivational Interviewing principles.", "method": "A schema-guided approach was developed for updating multi-frame dialogue states, along with a decision mechanism for dynamically determining response focus based on MI principles.", "result": "The implemented dialogue system was evaluated through a user study, demonstrating success in generating MI-favorable responses and encouraging client deliberation through effective questioning.", "conclusion": "The study shows the feasibility of aligning LLM-generated responses with Motivational Interviewing to support clients in behavioral change.", "key_contributions": ["Development of a schema-guided approach for dialogue systems based on MI principles", "Evaluation of a dialogue system through user study", "Successful generation of MI-favorable responses in dialogue interactions"], "limitations": "", "keywords": ["Motivational Interviewing", "Dialogue Systems", "Large Language Models", "Behavioral Change", "User Study"], "importance_score": 8, "read_time_minutes": 28}}
{"id": "2508.20324", "pdf": "https://arxiv.org/pdf/2508.20324.pdf", "abs": "https://arxiv.org/abs/2508.20324", "title": "Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities", "authors": ["Rikuto Kotoge", "Mai Nishimura", "Jiaxin Ma"], "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement Learning has emerged as a post-training approach to elicit\nagentic RAG behaviors such as search and planning from language models.\nHowever, compact language models (e.g., 0.5B parameters) struggle due to poor\nreasoning ability, resulting in sparse rewards and unstable training. To\novercome these difficulties, we propose Distillation-Guided Policy Optimization\n(DGPO), which addresses the challenges through cold-start initialization from\nteacher demonstrations and continuous teacher guidance during policy\noptimization. To systematically evaluate our approach, we introduce Agentic RAG\nCapabilities (ARC), a fine-grained metric analyzing reasoning, search\ncoordination, and response synthesis. Comprehensive experiments demonstrate\nthat DGPO enables compact models to achieve sophisticated agentic search\nbehaviors, even outperforming the larger teacher model in some cases. DGPO\nmakes agentic RAG feasible in computing resource-constrained environments.", "AI": {"tldr": "Proposes Distillation-Guided Policy Optimization (DGPO) to enhance reasoning and search behavior in compact language models by using teacher demonstrations and guidance.", "motivation": "To improve the reasoning ability and performance of compact language models in reinforcement learning tasks, addressing issues of sparse rewards and unstable training.", "method": "Introduces Distillation-Guided Policy Optimization (DGPO) which utilizes cold-start initialization from teacher demonstrations and continuous guidance during policy optimization.", "result": "DGPO allows compact models to exhibit advanced agentic behaviors, sometimes outperforming larger models, demonstrating its effectiveness in resource-constrained environments.", "conclusion": "DGPO makes it feasible for compact language models to perform agentic RAG behaviors effectively, showing promising results in evaluation metrics and experiments.", "key_contributions": ["Introduction of Distillation-Guided Policy Optimization (DGPO) for compact language models.", "Development of Agentic RAG Capabilities (ARC) as a fine-grained evaluation metric.", "Demonstration of compact models achieving advanced behaviors through teacher-guided training."], "limitations": "", "keywords": ["Reinforcement Learning", "Language Models", "Agentic Behaviors"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2508.21036", "pdf": "https://arxiv.org/pdf/2508.21036.pdf", "abs": "https://arxiv.org/abs/2508.21036", "title": "Understanding, Protecting, and Augmenting Human Cognition with Generative AI: A Synthesis of the CHI 2025 Tools for Thought Workshop", "authors": ["Lev Tankelevitch", "Elena L. Glassman", "Jessica He", "Aniket Kittur", "Mina Lee", "Srishti Palani", "Advait Sarkar", "Gonzalo Ramos", "Yvonne Rogers", "Hari Subramonyam"], "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Generative AI (GenAI) radically expands the scope and capability of\nautomation for work, education, and everyday tasks, a transformation posing\nboth risks and opportunities for human cognition. How will human cognition\nchange, and what opportunities are there for GenAI to augment it? Which\ntheories, metrics, and other tools are needed to address these questions? The\nCHI 2025 workshop on Tools for Thought aimed to bridge an emerging science of\nhow the use of GenAI affects human thought, from metacognition to critical\nthinking, memory, and creativity, with an emerging design practice for building\nGenAI tools that both protect and augment human thought. Fifty-six researchers,\ndesigners, and thinkers from across disciplines as well as industry and\nacademia, along with 34 papers and portfolios, seeded a day of discussion,\nideation, and community-building. We synthesize this material here to begin\nmapping the space of research and design opportunities and to catalyze a\nmultidisciplinary community around this pressing area of research.", "AI": {"tldr": "This paper summarizes a CHI 2025 workshop on how generative AI (GenAI) affects human cognition and explores opportunities for design practices that augment human thought.", "motivation": "To explore the implications of generative AI on human cognition and identify tools and practices that can enhance critical thinking, memory, and creativity.", "method": "The workshop brought together 56 researchers and designers to discuss the impact of GenAI on cognitive processes and design tools that can augment human thought.", "result": "The workshop produced 34 papers and portfolios, leading to discussions that mapped research and design opportunities in the domain of GenAI and cognition.", "conclusion": "A synthesis of the workshop material serves to initiate a multidisciplinary community focused on integrating generative AI into cognitive enhancement practices.", "key_contributions": ["Identified key areas where generative AI can augment human cognition.", "Sourced diverse perspectives from academia and industry on GenAI's impact.", "Catalyzed discussions on design practices for developing tools that support cognitive processes."], "limitations": "", "keywords": ["Generative AI", "Human Cognition", "Design Practices", "Metacognition", "Critical Thinking"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2508.20325", "pdf": "https://arxiv.org/pdf/2508.20325.pdf", "abs": "https://arxiv.org/abs/2508.20325", "title": "GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs", "authors": ["Haibo Jin", "Ruoxi Chen", "Peiyan Zhang", "Andy Zhou", "Yang Zhang", "Haohan Wang"], "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "54 pages", "summary": "As Large Language Models become increasingly integral to various domains,\ntheir potential to generate harmful responses has prompted significant societal\nand regulatory concerns. In response, governments have issued ethics guidelines\nto promote the development of trustworthy AI. However, these guidelines are\ntypically high-level demands for developers and testers, leaving a gap in\ntranslating them into actionable testing questions to verify LLM compliance.\n  To address this challenge, we introduce GUARD (\\textbf{G}uideline\n\\textbf{U}pholding Test through \\textbf{A}daptive \\textbf{R}ole-play and\nJailbreak \\textbf{D}iagnostics), a testing method designed to operationalize\nguidelines into specific guideline-violating questions that assess LLM\nadherence. To implement this, GUARD uses automated generation of\nguideline-violating questions based on government-issued guidelines, thereby\ntesting whether responses comply with these guidelines. When responses directly\nviolate guidelines, GUARD reports inconsistencies. Furthermore, for responses\nthat do not directly violate guidelines, GUARD integrates the concept of\n``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that\nprovoke unethical or guideline-violating responses, effectively identifying\npotential scenarios that could bypass built-in safety mechanisms. Our method\nfinally culminates in a compliance report, delineating the extent of adherence\nand highlighting any violations.\n  We have empirically validated the effectiveness of GUARD on seven LLMs,\nincluding Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,\nGPT-4o, and Claude-3.7, by testing compliance under three government-issued\nguidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can\ntransfer jailbreak diagnostics to vision-language models, demonstrating its\nusage in promoting reliable LLM-based applications.", "AI": {"tldr": "This paper introduces GUARD, a testing method designed to ensure compliance of Large Language Models (LLMs) with government-issued ethical guidelines. It aims to operationalize vague guidelines into actionable questions to assess LLM adherence, using automated generation of guideline-violating questions and diagnostics to identify unethical responses.", "motivation": "Governments have issued high-level ethics guidelines for AI, but there is a lack of processes to translate these into specific, actionable test questions to verify compliance, raising concerns about harmful AI responses.", "method": "GUARD operationalizes guidelines into specific, guideline-violating questions and employs jailbreak diagnostics (GUARD-JD) to provoke guideline violations in LLM responses, assessing their compliance.", "result": "GUARD was empirically validated on seven LLMs, demonstrating its effectiveness in testing compliance with government-issued guidelines and identifying potential bypass scenarios for safety mechanisms.", "conclusion": "GUARD produces compliance reports detailing adherence levels and violations, proving applicable not only to LLMs but also potentially transferable to vision-language models.", "key_contributions": ["Introduced GUARD as a structured testing method for LLM compliance with ethical guidelines.", "Developed GUARD-JD for effective diagnostics of guideline-violating responses.", "Empirically validated against multiple LLMs and guidelines, showcasing transferability to other AI models."], "limitations": "", "keywords": ["Large Language Models", "AI Compliance", "Ethics Guidelines", "Jailbreak Diagnostics", "Human-Computer Interaction"], "importance_score": 9, "read_time_minutes": 54}}
{"id": "2508.21061", "pdf": "https://arxiv.org/pdf/2508.21061.pdf", "abs": "https://arxiv.org/abs/2508.21061", "title": "OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models", "authors": ["Adam Coscia", "Shunan Guo", "Eunyee Koh", "Alex Endert"], "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "Accepted to UIST 2025. 18 pages, 9 figures, 2 tables. For a demo\n  video, see https://youtu.be/uobhmxo6EIE", "summary": "As multi-turn dialogues with large language models (LLMs) grow longer and\nmore complex, how can users better evaluate and review progress on their\nconversational goals? We present OnGoal, an LLM chat interface that helps users\nbetter manage goal progress. OnGoal provides real-time feedback on goal\nalignment through LLM-assisted evaluation, explanations for evaluation results\nwith examples, and overviews of goal progression over time, enabling users to\nnavigate complex dialogues more effectively. Through a study with 20\nparticipants on a writing task, we evaluate OnGoal against a baseline chat\ninterface without goal tracking. Using OnGoal, participants spent less time and\neffort to achieve their goals while exploring new prompting strategies to\novercome miscommunication, suggesting tracking and visualizing goals can\nenhance engagement and resilience in LLM dialogues. Our findings inspired\ndesign implications for future LLM chat interfaces that improve goal\ncommunication, reduce cognitive load, enhance interactivity, and enable\nfeedback to improve LLM performance.", "AI": {"tldr": "OnGoal is an LLM chat interface that facilitates better goal management in multi-turn dialogues, improving user engagement and task efficiency.", "motivation": "To enhance user evaluation and management of conversational goals in complex multi-turn dialogues with LLMs.", "method": "A study with 20 participants on a writing task comparing OnGoal with a baseline chat interface without goal tracking.", "result": "Participants using OnGoal achieved their goals more efficiently while discovering new prompting strategies to improve communication during dialogues.", "conclusion": "Tracking and visualizing goals can enhance user engagement, reduce cognitive load, and improve feedback mechanisms in LLM dialogues.", "key_contributions": ["Introduction of OnGoal for goal management in LLM chats", "Demonstrated efficiency improvements in achieving conversational goals", "Provided design implications for future LLM chat interfaces"], "limitations": "", "keywords": ["goal management", "LLM chat interface", "user engagement"], "importance_score": 9, "read_time_minutes": 18}}
{"id": "2508.20351", "pdf": "https://arxiv.org/pdf/2508.20351.pdf", "abs": "https://arxiv.org/abs/2508.20351", "title": "Joint Enhancement of Relational Reasoning for Long-Context LLMs", "authors": ["Zhirui Chen", "Wei Shen", "Jiashui Huang", "Ling Shao"], "categories": ["cs.CL"], "comment": "9 pages, 5 pages Accepted by EMNLP 2025 Findings", "summary": "Despite significant progress, large language models (LLMs) still struggle\nwith long contexts due to memory limitations and their inability to tackle\ncomplex and long-context tasks. Additionally, LLMs often suffer from a lack of\ntransparency and are prone to producing hallucinations. To address these\nchallenges, we propose \\textbf{JERR}, a novel framework designed to enhance\nlong-context comprehension via graph-based reasoning in LLMs. JERR integrates\nthree key components: synopsis extraction, graph construction, and relational\nreasoning. First, synopsis is extracted by chunking text strategically,\nallowing the model to summarize and understand information more efficiently.\nSecond, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring\nlogical consistency and clarity. Finally, we incorporate Monte Carlo Tree\nSearch (MCTS) to help the model navigate complex reasoning paths, ensuring more\naccurate and interpretable outputs. This framework provides a novel solution\nthat enables LLMs to handle extended contexts and complex reasoning tasks with\nimproved reliability and transparency. Experimental results show that JERR\nconsistently outperforms all baselines on the ROUGE and F1 metrics, achieving\nthe highest scores on the LLM-Rater evaluation.", "AI": {"tldr": "The paper presents JERR, a framework to improve long-context comprehension in LLMs through graph-based reasoning.", "motivation": "Large language models (LLMs) face challenges with long contexts and complex tasks due to memory limitations and lack of transparency.", "method": "The JERR framework integrates synopsis extraction, graph construction, and relational reasoning, using chunking for text summarization, building a directed acyclic graph to resolve redundancy, and employing Monte Carlo Tree Search for complex reasoning.", "result": "JERR outperforms all baselines on ROUGE and F1 metrics, achieving the highest scores on the LLM-Rater evaluation.", "conclusion": "JERR provides a robust solution for enhancing LLMs' ability to handle extended contexts and complex reasoning tasks reliably and transparently.", "key_contributions": ["Introduction of the JERR framework for long-context comprehension", "Use of graph-based reasoning for improved logical consistency", "Enhancement of interpretability in LLM outputs through MCTS"], "limitations": "", "keywords": ["Large Language Models", "Graph-Based Reasoning", "Long Contexts"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2508.20373", "pdf": "https://arxiv.org/pdf/2508.20373.pdf", "abs": "https://arxiv.org/abs/2508.20373", "title": "Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems", "authors": ["Yuyao Wang", "Bowen Liu", "Jianheng Tang", "Nuo Chen", "Yuhan Li", "Qifan Zhang", "Jia Li"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Reasoning Large Language Models (RLLMs) have recently achieved remarkable\nprogress on complex reasoning tasks, largely enabled by their long\nchain-of-thought (Long CoT) capabilities. However, developing these Long CoT\nbehaviors relies heavily on post-training with high-quality datasets, which are\ntypically costly and human-curated (e.g., mathematics and code), leaving\nscalable alternatives unexplored. In this work, we introduce NP-hard (NPH)\ngraph problems as a novel synthetic training corpus, as they inherently require\ndeep reasoning, extensive exploration, and reflective strategies, which are\ncore characteristics of Long CoT reasoning. Building on this insight, we\ndevelop a two-stage post-training framework: (i) Long CoT Supervised\nFine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially\nenhances reasoning depth, and (ii) Reinforcement Learning (RL) with a\nfine-grained reward design, which sharpens reasoning efficiency. Our flagship\nmodel, Graph-R1-7B, demonstrates strong generalization across mathematics,\ncoding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both\naccuracy and reasoning efficiency. These results position NPH graph problems as\nan effective and scalable resource for advancing Long CoT reasoning in LLMs,\nopening a new frontier for LLM post-training. Our implementation is available\nat https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted\nin our Hugging Face collection HKUST-DSAIL/Graph-R1.", "AI": {"tldr": "This paper introduces NP-hard graph problems as a synthetic training resource to enhance reasoning capabilities in large language models, proposing a two-stage post-training framework to improve reasoning depth and efficiency.", "motivation": "The need for cost-effective alternatives to high-quality datasets for developing Long CoT behaviors in reasoning large language models.", "method": "A two-stage post-training framework consisting of supervised fine-tuning on rejection-sampled NP-hard graph instances followed by reinforcement learning with a fine-grained reward design.", "result": "The model Graph-R1-7B achieves strong generalization across various domains and outperforms an existing large model on NP-hard graph problems in terms of accuracy and reasoning efficiency.", "conclusion": "NP-hard graph problems provide an effective and scalable resource for enhancing reasoning in language models, enabling further advancements in Long CoT reasoning.", "key_contributions": ["Introduction of NP-hard graph problems as a synthetic training corpus for reasoning", "Development of a two-stage post-training framework combining supervised fine-tuning and reinforcement learning", "Demonstration of improved reasoning efficiency and accuracy in handling NP-hard problems."], "limitations": "", "keywords": ["Large Language Models", "Graph Problems", "Reinforcement Learning", "Supervised Fine-Tuning", "Long Chain-of-Thought"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2508.20385", "pdf": "https://arxiv.org/pdf/2508.20385.pdf", "abs": "https://arxiv.org/abs/2508.20385", "title": "CAPE: Context-Aware Personality Evaluation Framework for Large Language Models", "authors": ["Jivnesh Sandhan", "Fei Cheng", "Tushar Sandhan", "Yugo Murawaki"], "categories": ["cs.CL"], "comment": "Accepted at EMNLP25 (Findings)", "summary": "Psychometric tests, traditionally used to assess humans, are now being\napplied to Large Language Models (LLMs) to evaluate their behavioral traits.\nHowever, existing studies follow a context-free approach, answering each\nquestion in isolation to avoid contextual influence. We term this the Disney\nWorld test, an artificial setting that ignores real-world applications, where\nconversational history shapes responses. To bridge this gap, we propose the\nfirst Context-Aware Personality Evaluation (CAPE) framework for LLMs,\nincorporating prior conversational interactions. To thoroughly analyze the\ninfluence of context, we introduce novel metrics to quantify the consistency of\nLLM responses, a fundamental trait in human behavior.\n  Our exhaustive experiments on 7 LLMs reveal that conversational history\nenhances response consistency via in-context learning but also induces\npersonality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme\ndeviations. While GPT models are robust to question ordering, Gemini-1.5-Flash\nand Llama-8B display significant sensitivity. Moreover, GPT models response\nstem from their intrinsic personality traits as well as prior interactions,\nwhereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.\nFinally, applying our framework to Role Playing Agents (RPAs) shows\ncontext-dependent personality shifts improve response consistency and better\nalign with human judgments. Our code and datasets are publicly available at:\nhttps://github.com/jivnesh/CAPE", "AI": {"tldr": "This paper introduces the Context-Aware Personality Evaluation (CAPE) framework for assessing the personality traits of Large Language Models (LLMs), highlighting the impact of prior conversational context on response consistency and personality shifts.", "motivation": "To address the limitations of traditional psychometric assessments on LLMs by incorporating the contextual history of conversations, leading to a more realistic evaluation of their behavioral traits.", "method": "The paper proposes the CAPE framework, introducing novel metrics to assess the consistency of LLM responses based on prior conversational interactions and conducting experiments on 7 different LLMs.", "result": "Experiments show that conversational history enhances response consistency but can induce personality shifts in models, with some models being more sensitive to context than others.", "conclusion": "The CAPE framework improves the evaluation of LLMs by accounting for context, making their responses better aligned with human judgments, particularly in applications involving Role Playing Agents.", "key_contributions": ["Introduction of the CAPE framework for context-aware personality evaluation of LLMs.", "Development of novel metrics to quantify response consistency of LLMs based on conversational history.", "Demonstration of personality shifts in LLM responses influenced by prior interactions, with practical implications for Role Playing Agents."], "limitations": "The framework is contingent on the quality and relevance of prior conversations, which may not always represent real-world interactions comprehensively.", "keywords": ["Large Language Models", "Personality Evaluation", "Context-Aware", "Response Consistency", "Conversational History"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2508.20395", "pdf": "https://arxiv.org/pdf/2508.20395.pdf", "abs": "https://arxiv.org/abs/2508.20395", "title": "Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction", "authors": ["Xu Guo"], "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "11 pages, 4 figures", "summary": "Recent advancements in large language models (LLMs) often rely on generating\nintermediate reasoning steps to enhance accuracy. However, little work has\nexamined how reasoning utility contributes to the final answer's correctness.\nDue to the stochastic nature of autoregressive generation, generating more\ncontext does not guarantee increased confidence in the answer. If we could\npredict, during generation, whether a reasoning step will be useful, we could\nstop early or prune ineffective steps, avoiding distractions in the final\ndecision.\n  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to\ngenerate reasoning chains, and then employing a separate model (Qwen3-8B) to\nquantify the utility of these chains for final accuracy. Specifically, we\nmeasure the model's uncertainty on the answer span Y at each reasoning step\nusing conditional entropy (expected negative log-likelihood over the\nvocabulary) with context expanding step by step. Our results show a clear\npattern: conditional entropy that decreases over steps is strongly associated\nwith correct answers, whereas flat or increasing entropy often results in wrong\nanswers. We also corroborate that incorrect reasoning paths tend to be longer\nthan correct ones, suggesting that longer reasoning does not necessarily yield\nbetter outcomes. These findings serve as a foundation to inspire future work on\ndesigning efficient reasoning pipelines that detect and avoid unproductive\nreasoning early.", "AI": {"tldr": "This paper investigates the role of intermediate reasoning steps in large language models and their contribution to answer correctness, finding that decreasing conditional entropy during reasoning indicates higher accuracy.", "motivation": "To understand how reasoning utility affects the correctness of answers generated by large language models, particularly in the context of autoregressive generation.", "method": "An oracle study on the MATH dataset was conducted using Qwen2.5-32B and GPT-4o to generate reasoning chains. A separate model (Qwen3-8B) was employed to quantify the utility of these chains based on conditional entropy at each reasoning step.", "result": "The study found that decreasing conditional entropy during reasoning is associated with correct answers, while incorrect paths tend to be longer and have flat or increasing entropy.", "conclusion": "These findings highlight the need for efficient reasoning pipelines that can identify and avoid unproductive reasoning early in the generation process.", "key_contributions": ["Demonstrates the relationship between reasoning utility and answer correctness", "Establishes that decreasing conditional entropy correlates with correct answers", "Provides insights into the efficiency of reasoning pipelines for LLMs"], "limitations": "The study relies on specific models and datasets, which may limit generalizability.", "keywords": ["large language models", "reasoning utility", "conditional entropy", "MATH dataset", "answer correctness"], "importance_score": 9, "read_time_minutes": 11}}
{"id": "2508.20410", "pdf": "https://arxiv.org/pdf/2508.20410.pdf", "abs": "https://arxiv.org/abs/2508.20410", "title": "UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools", "authors": ["Sam Jung", "Agustin Garcinuno", "Spencer Mateega"], "categories": ["cs.CL"], "comment": null, "summary": "AI text-to-app tools promise high quality applications and websites in\nminutes, yet no public benchmark rigorously verifies those claims. We introduce\nUI-Bench, the first large-scale benchmark that evaluates visual excellence\nacross competing AI text-to-app tools through expert pairwise comparison.\nSpanning 10 tools, 30 prompts, 300 generated sites, and \\textit{4000+} expert\njudgments, UI-Bench ranks systems with a TrueSkill-derived model that yields\ncalibrated confidence intervals. UI-Bench establishes a reproducible standard\nfor advancing AI-driven web design. We release (i) the complete prompt set,\n(ii) an open-source evaluation framework, and (iii) a public leaderboard. The\ngenerated sites rated by participants will be released soon. View the UI-Bench\nleaderboard at https://uibench.ai/leaderboard.", "AI": {"tldr": "Introduction of UI-Bench, a benchmark for evaluating AI text-to-app tools for web design.", "motivation": "To rigorously assess the visual excellence of AI text-to-app tools since no public benchmark currently exists.", "method": "Evaluation through expert pairwise comparison, spanning 10 tools, 30 prompts, and 300 generated sites, using a TrueSkill-derived model.", "result": "UI-Bench establishes a ranking of systems with calibrated confidence intervals and offers a public leaderboard.", "conclusion": "UI-Bench provides a reproducible standard for advancing AI-driven web design and promotes transparency in the performance of various tools.", "key_contributions": ["Introduction of the first large-scale benchmark for AI text-to-app tools", "Release of a complete prompt set and an open-source evaluation framework", "Establishment of a public leaderboard to track system performance."], "limitations": "", "keywords": ["AI", "web design", "benchmark", "evaluation", "TrueSkill"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2508.20973", "pdf": "https://arxiv.org/pdf/2508.20973.pdf", "abs": "https://arxiv.org/abs/2508.20973", "title": "ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents", "authors": ["Tianjian Liu", "Fanqi Wan", "Jiajian Guo", "Xiaojun Quan"], "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "21 pages, 6 Figures", "summary": "Proactive dialogue has emerged as a critical and challenging research problem\nin advancing large language models (LLMs). Existing works predominantly focus\non domain-specific or task-oriented scenarios, which leads to fragmented\nevaluations and limits the comprehensive exploration of models' proactive\nconversation abilities. In this work, we propose ProactiveEval, a unified\nframework designed for evaluating proactive dialogue capabilities of LLMs. This\nframework decomposes proactive dialogue into target planning and dialogue\nguidance, establishing evaluation metrics across various domains. Moreover, it\nalso enables the automatic generation of diverse and challenging evaluation\ndata. Based on the proposed framework, we develop 328 evaluation environments\nspanning 6 distinct domains. Through experiments with 22 different types of\nLLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional\nperformance on target planning and dialogue guidance tasks, respectively.\nFinally, we investigate how reasoning capabilities influence proactive\nbehaviors and discuss their implications for future model development.", "AI": {"tldr": "ProactiveEval is a unified framework for evaluating proactive dialogue abilities of large language models (LLMs), focusing on target planning and dialogue guidance across diverse domains.", "motivation": "Existing evaluations of proactive dialogue in LLMs are fragmented and limited to domain-specific tasks, necessitating a more comprehensive approach.", "method": "ProactiveEval decomposes proactive dialogue into target planning and dialogue guidance and establishes metrics for evaluation across six distinct domains, along with generating diverse evaluation data.", "result": "Experiments with 22 types of LLMs revealed that DeepSeek-R1 and Claude-3.7-Sonnet excelled in target planning and dialogue guidance, respectively.", "conclusion": "The study enhances understanding of how reasoning affects proactive dialogue behavior in LLMs and suggests directions for future research and model development.", "key_contributions": ["Introduction of the ProactiveEval framework for evaluating proactive dialogue", "Creation of 328 evaluation environments across 6 domains", "Insights into the role of reasoning capabilities in proactive dialogue"], "limitations": "", "keywords": ["proactive dialogue", "large language models", "evaluation framework", "target planning", "dialogue guidance"], "importance_score": 8, "read_time_minutes": 21}}
{"id": "2508.20416", "pdf": "https://arxiv.org/pdf/2508.20416.pdf", "abs": "https://arxiv.org/abs/2508.20416", "title": "DentalBench: Benchmarking and Advancing LLMs Capability for Bilingual Dentistry Understanding", "authors": ["Hengchuan Zhu", "Yihuan Xu", "Yichen Li", "Zijie Meng", "Zuozhu Liu"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) and medical LLMs (Med-LLMs)\nhave demonstrated strong performance on general medical benchmarks. However,\ntheir capabilities in specialized medical fields, such as dentistry which\nrequire deeper domain-specific knowledge, remain underexplored due to the lack\nof targeted evaluation resources. In this paper, we introduce DentalBench, the\nfirst comprehensive bilingual benchmark designed to evaluate and advance LLMs\nin the dental domain. DentalBench consists of two main components: DentalQA, an\nEnglish-Chinese question-answering (QA) benchmark with 36,597 questions\nspanning 4 tasks and 16 dental subfields; and DentalCorpus, a large-scale,\nhigh-quality corpus with 337.35 million tokens curated for dental domain\nadaptation, supporting both supervised fine-tuning (SFT) and\nretrieval-augmented generation (RAG). We evaluate 14 LLMs, covering\nproprietary, open-source, and medical-specific models, and reveal significant\nperformance gaps across task types and languages. Further experiments with\nQwen-2.5-3B demonstrate that domain adaptation substantially improves model\nperformance, particularly on knowledge-intensive and terminology-focused tasks,\nand highlight the importance of domain-specific benchmarks for developing\ntrustworthy and effective LLMs tailored to healthcare applications.", "AI": {"tldr": "This paper presents DentalBench, a bilingual benchmark for evaluating LLMs in the dental domain, consisting of a QA benchmark and a large corpus for domain adaptation.", "motivation": "To address the gap in evaluating LLMs in specialized medical fields, particularly dentistry, due to limited resources.", "method": "Introduction of DentalBench with two components: DentalQA for question-answering and DentalCorpus for domain-specific adaptations, followed by evaluation of 14 LLMs.", "result": "Significant performance gaps were found across task types and languages, and domain adaptation notably improved model performance on knowledge-intensive tasks.", "conclusion": "Domain-specific benchmarks are essential for developing effective LLMs in healthcare applications, confirming the potential for improved trustworthiness in medical AI.", "key_contributions": ["Introduction of DentalBench, the first bilingual benchmark for the dental field.", "Development of a large-scale dental corpus for model adaptation.", "Evaluation of various LLMs revealing performance gaps and the impact of domain adaptation."], "limitations": "Focused solely on dentistry, with potential applicability limited to generalization without additional domain-specific resources.", "keywords": ["large language models", "medical LLMs", "dental benchmark", "domain adaptation", "question-answering"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2508.20417", "pdf": "https://arxiv.org/pdf/2508.20417.pdf", "abs": "https://arxiv.org/abs/2508.20417", "title": "KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval", "authors": ["Chi Minh Bui", "Ngoc Mai Thieu", "Van Vinh Nguyen", "Json J. Jung", "Khac-Hoai Nam Bui"], "categories": ["cs.CL", "cs.DB"], "comment": "Accepted at Main EMNLP 2025", "summary": "The integration of knowledge graphs (KGs) with large language models (LLMs)\noffers significant potential to improve the retrieval phase of\nretrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR,\na novel framework for Contextual Query Retrieval (CQR) that enhances the\nretrieval phase by enriching the contextual representation of complex input\nqueries using a corpus-centric KG. Unlike existing methods that primarily\naddress corpus-level context loss, KG-CQR focuses on query enrichment through\nstructured relation representations, extracting and completing relevant KG\nsubgraphs to generate semantically rich query contexts. Comprising subgraph\nextraction, completion, and contextual generation modules, KG-CQR operates as a\nmodel-agnostic pipeline, ensuring scalability across LLMs of varying sizes\nwithout additional training. Experimental results on RAGBench and MultiHop-RAG\ndatasets demonstrate KG-CQR's superior performance, achieving a 4-6%\nimprovement in mAP and a 2-3% improvement in Recall@25 over strong baseline\nmodels. Furthermore, evaluations on challenging RAG tasks such as multi-hop\nquestion answering show that, by incorporating KG-CQR, the performance\nconsistently outperforms the existing baseline in terms of retrieval\neffectiveness", "AI": {"tldr": "KG-CQR is a novel framework that enhances query retrieval in retrieval-augmented generation systems by using knowledge graphs to improve query contextualization.", "motivation": "Existing methods focus on corpus-level context loss in RAG systems, but there is a need for better query enrichment to improve retrieval performance.", "method": "KG-CQR employs subgraph extraction, completion, and contextual generation modules to enrich the representation of complex input queries using a knowledge graph, enabling it to work with different LLM sizes without requiring additional training.", "result": "KG-CQR shows superior performance with a 4-6% improvement in mAP and a 2-3% improvement in Recall@25 on RAGBench and MultiHop-RAG datasets compared to strong baselines.", "conclusion": "Incorporating KG-CQR into RAG tasks like multi-hop question answering consistently improves retrieval effectiveness over existing baselines.", "key_contributions": ["Introduction of KG-CQR for enriched query contextualization", "Model-agnostic pipeline for scalability across LLMs", "Demonstrated empirical improvements in retrieval tasks"], "limitations": "", "keywords": ["Knowledge Graphs", "Large Language Models", "Retrieval-Augmented Generation", "Contextual Query Retrieval", "Multi-hop Question Answering"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2508.20420", "pdf": "https://arxiv.org/pdf/2508.20420.pdf", "abs": "https://arxiv.org/abs/2508.20420", "title": "CAMB: A comprehensive industrial LLM benchmark on civil aviation maintenance", "authors": ["Feng Zhang", "Chengjie Pang", "Yuehan Zhang", "Chenyu Luo"], "categories": ["cs.CL"], "comment": null, "summary": "Civil aviation maintenance is a domain characterized by stringent industry\nstandards. Within this field, maintenance procedures and troubleshooting\nrepresent critical, knowledge-intensive tasks that require sophisticated\nreasoning. To address the lack of specialized evaluation tools for large\nlanguage models (LLMs) in this vertical, we propose and develop an\nindustrial-grade benchmark specifically designed for civil aviation\nmaintenance. This benchmark serves a dual purpose: It provides a standardized\ntool to measure LLM capabilities within civil aviation maintenance, identifying\nspecific gaps in domain knowledge and complex reasoning. By pinpointing these\ndeficiencies, the benchmark establishes a foundation for targeted improvement\nefforts (e.g., domain-specific fine-tuning, RAG optimization, or specialized\nprompt engineering), ultimately facilitating progress toward more intelligent\nsolutions within civil aviation maintenance. Our work addresses a significant\ngap in the current LLM evaluation, which primarily focuses on mathematical and\ncoding reasoning tasks. In addition, given that Retrieval-Augmented Generation\n(RAG) systems are currently the dominant solutions in practical applications ,\nwe leverage this benchmark to evaluate existing well-known vector embedding\nmodels and LLMs for civil aviation maintenance scenarios. Through experimental\nexploration and analysis, we demonstrate the effectiveness of our benchmark in\nassessing model performance within this domain, and we open-source this\nevaluation benchmark and code to foster further research and\ndevelopment:https://github.com/CamBenchmark/cambenchmark", "AI": {"tldr": "Proposal of an industrial-grade benchmark for evaluating LLMs in civil aviation maintenance.", "motivation": "To address the lack of specialized evaluation tools for LLMs in civil aviation maintenance, which is critical for knowledge-intensive tasks and reasoning.", "method": "Development of a benchmark specifically for civil aviation maintenance to measure LLM capabilities and identify knowledge gaps.", "result": "Demonstrated effectiveness of the benchmark in assessing model performance and provided an open-source tool to promote further research.", "conclusion": "The benchmark facilitates targeted improvements in LLM performance through specialized fine-tuning and optimization, addressing gaps in existing evaluation.", "key_contributions": ["Development of a specialized benchmark for LLMs in civil aviation maintenance.", "Identification of specific knowledge and reasoning gaps in existing LLMs.", "Open-sourcing the evaluation tool to promote further research."], "limitations": "", "keywords": ["civil aviation", "maintenance", "large language models", "benchmark", "RAG"], "importance_score": 4, "read_time_minutes": 10}}
{"id": "2508.20442", "pdf": "https://arxiv.org/pdf/2508.20442.pdf", "abs": "https://arxiv.org/abs/2508.20442", "title": "Searching the Title of Practical Work of the Informatics Engineering Bachelor Program with the Case Base Reasoning Method", "authors": ["Agung Sukrisna Jaya", "Osvari Arsalan", "Danny Matthew Saputra"], "categories": ["cs.CL"], "comment": null, "summary": "Case Base Reasoning (CBR) is a case solving technique based on experience in\ncases that have occurred before with the highest similarity. CBR is used to\nsearch for practical work titles. TF-IDF is applied to process the\nvectorization of each practical work title word and Cosine Similarity for the\ncalculation of similarity values. This system can search either in the form of\ntitles or keywords. The output of the system is the title of practical work and\nthe match value of each title. Based on the test results using 705 practical\nwork titles, testing was carried out with five titles and carried out in two\nstages. The first stage searches with existing titles and the second stage\nrandomizes the title from the first stage. And the results obtained in the\nsecond stage are the same number of titles found and the highest average match\nscore.", "AI": {"tldr": "This paper discusses a Case Based Reasoning (CBR) system that uses TF-IDF and Cosine Similarity for searching practical work titles based on previous cases.", "motivation": "To improve the efficiency of searching for practical work titles using past experiences with similar cases.", "method": "The paper utilizes TF-IDF for vectorizing each practical work title word and employs Cosine Similarity to calculate similarity values.", "result": "The system is capable of searching for practical work titles and keywords, achieving a consistent match score using 705 practical work titles.", "conclusion": "The two-phase testing showed that the title matching process is effective in returning relevant titles with high average match scores.", "key_contributions": ["Development of a CBR system for title searching", "Application of TF-IDF and Cosine Similarity", "Empirical testing with practical work titles"], "limitations": "", "keywords": ["Case Based Reasoning", "TF-IDF", "Cosine Similarity", "Title Searching", "Practical Work"], "importance_score": 3, "read_time_minutes": 10}}
{"id": "2508.20453", "pdf": "https://arxiv.org/pdf/2508.20453.pdf", "abs": "https://arxiv.org/abs/2508.20453", "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers", "authors": ["Zhenting Wang", "Qi Chang", "Hemani Patel", "Shashank Biju", "Cheng-En Wu", "Quan Liu", "Aolin Ding", "Alireza Rezazadeh", "Ankit Shah", "Yujia Bao", "Eugene Siow"], "categories": ["cs.CL"], "comment": null, "summary": "We introduce MCP-Bench, a benchmark for evaluating large language models\n(LLMs) on realistic, multi-step tasks that demand tool use, cross-tool\ncoordination, precise parameter control, and planning/reasoning for solving\ntasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28\nrepresentative live MCP servers spanning 250 tools across domains such as\nfinance, traveling, scientific computing, and academic search. Unlike prior\nAPI-based benchmarks, each MCP server provides a set of complementary tools\ndesigned to work together, enabling the construction of authentic, multi-step\ntasks with rich input-output coupling. Tasks in MCP-Bench test agents' ability\nto retrieve relevant tools from fuzzy instructions without explicit tool names,\nplan multi-hop execution trajectories for complex objectives, ground responses\nin intermediate tool outputs, and orchestrate cross-domain workflows -\ncapabilities not adequately evaluated by existing benchmarks that rely on\nexplicit tool specifications, shallow few-step workflows, and isolated domain\noperations. We propose a multi-faceted evaluation framework covering tool-level\nschema understanding and usage, trajectory-level planning, and task completion.\nExperiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench. Code\nand data: https://github.com/Accenture/mcp-bench.", "AI": {"tldr": "MCP-Bench is a benchmark for assessing LLMs on complex tasks that require tool use, coordination, and reasoning across domains.", "motivation": "The need for a realistic benchmark to evaluate LLM performances on multi-step tasks involving various tools and planning capabilities.", "method": "Development of MCP-Bench that connects LLMs to multiple MCP servers with a suite of complementary tools to perform complex, multi-step tasks.", "result": "Experiments on 20 advanced LLMs demonstrate ongoing challenges in utilizing the MCP-Bench effectively, highlighting performance issues across various tasks.", "conclusion": "MCP-Bench provides a more authentic assessment of LLM capabilities than previous benchmarks but reveals significant challenges in LLM task execution.", "key_contributions": ["Introduction of a novel benchmark for LLMs addressing multi-step tasks", "Integration of multiple tools across domains for comprehensive task evaluation", "Establishment of a new evaluation framework focusing on planning and tool usage."], "limitations": "MCP-Bench exposes persistent challenges in LLM performance that are not fully addressed through existing benchmarks.", "keywords": ["MCP-Bench", "large language models", "benchmark", "tool use", "task evaluation"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2508.20460", "pdf": "https://arxiv.org/pdf/2508.20460.pdf", "abs": "https://arxiv.org/abs/2508.20460", "title": "Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques", "authors": ["Yucheng Ruan", "Xiang Lan", "Daniel J. Tan", "Hairil Rizal Abdullah", "Mengling Feng"], "categories": ["cs.CL"], "comment": null, "summary": "Background Predicting mortality and resource utilization from electronic\nhealth records (EHRs) is challenging yet crucial for optimizing patient\noutcomes and managing costs in intensive care unit (ICU). Existing approaches\npredominantly focus on structured EHRs, often ignoring the valuable clinical\ninsights in free-text notes. Additionally, the potential of textual information\nwithin structured data is not fully leveraged. This study aimed to introduce\nand assess a deep learning framework using natural language processing\ntechniques that integrates multimodal EHRs to predict mortality and resource\nutilization in critical care settings. Methods Utilizing two real-world EHR\ndatasets, we developed and evaluated our model on three clinical tasks with\nleading existing methods. We also performed an ablation study on three key\ncomponents in our framework: medical prompts, free-texts, and pre-trained\nsentence encoder. Furthermore, we assessed the model's robustness against the\ncorruption in structured EHRs. Results Our experiments on two real-world\ndatasets across three clinical tasks showed that our proposed model improved\nperformance metrics by 1.6\\%/0.8\\% on BACC/AUROC for mortality prediction,\n0.5%/2.2% on RMSE/MAE for LOS prediction, 10.9%/11.0% on RMSE/MAE for surgical\nduration estimation compared to the best existing methods. It consistently\ndemonstrated superior performance compared to other baselines across three\ntasks at different corruption rates. Conclusions The proposed framework is an\neffective and accurate deep learning approach for predicting mortality and\nresource utilization in critical care. The study also highlights the success of\nusing prompt learning with a transformer encoder in analyzing multimodal EHRs.\nImportantly, the model showed strong resilience to data corruption within\nstructured data, especially at high corruption levels.", "AI": {"tldr": "A deep learning framework leveraging NLP techniques for predicting mortality and resource utilization from multimodal EHRs, showing improved performance against traditional methods.", "motivation": "To enhance the prediction of mortality and resource utilization in ICUs by utilizing both structured and free-text clinical data from EHRs.", "method": "Developed and evaluated a deep learning model on two EHR datasets, focusing on three clinical tasks and conducting an ablation study on key components of the model.", "result": "The model improved performance metrics for mortality prediction by 1.6%/0.8% on BACC/AUROC, LOS prediction by 0.5%/2.2% on RMSE/MAE, and surgical duration estimation by 10.9%/11.0% on RMSE/MAE compared to existing best methods.", "conclusion": "The framework is effective and resilient in predicting outcomes from multimodal EHRs, demonstrating the advantages of integrating natural language processing techniques and prompt learning.", "key_contributions": ["Introduced a novel deep learning framework integrating multimodal EHR data.", "Demonstrated improved performance in mortality and resource utilization predictions.", "Highlighted the effectiveness of prompt learning with a transformer encoder on clinical tasks."], "limitations": "", "keywords": ["mortality prediction", "resource utilization", "EHR", "deep learning", "natural language processing"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2508.20468", "pdf": "https://arxiv.org/pdf/2508.20468.pdf", "abs": "https://arxiv.org/abs/2508.20468", "title": "ConspirED: A Dataset for Cognitive Traits of Conspiracy Theories and Large Language Model Safety", "authors": ["Luke Bates", "Max Glockner", "Preslav Nakov", "Iryna Gurevych"], "categories": ["cs.CL"], "comment": null, "summary": "Conspiracy theories erode public trust in science and institutions while\nresisting debunking by evolving and absorbing counter-evidence. As AI-generated\nmisinformation becomes increasingly sophisticated, understanding rhetorical\npatterns in conspiratorial content is important for developing interventions\nsuch as targeted prebunking and assessing AI vulnerabilities. We introduce\nConspirED (CONSPIR Evaluation Dataset), which captures the cognitive traits of\nconspiratorial ideation in multi-sentence excerpts (80--120 words) from online\nconspiracy articles, annotated using the CONSPIR cognitive framework\n(Lewandowsky and Cook, 2020). ConspirED is the first dataset of conspiratorial\ncontent annotated for general cognitive traits. Using ConspirED, we (i) develop\ncomputational models that identify conspiratorial traits and determine dominant\ntraits in text excerpts, and (ii) evaluate large language/reasoning model\n(LLM/LRM) robustness to conspiratorial inputs. We find that both are misaligned\nby conspiratorial content, producing output that mirrors input reasoning\npatterns, even when successfully deflecting comparable fact-checked\nmisinformation.", "AI": {"tldr": "This paper introduces ConspirED, a dataset for analyzing the cognitive traits of conspiracy theories and evaluates LLM performance against conspiratorial content.", "motivation": "Conspiracy theories undermine trust in science, making it crucial to understand their structure and the impact of AI-generated misinformation.", "method": "ConspirED is created by annotating excerpts from conspiracy articles using the CONSPIR cognitive framework to identify traits of conspiratorial ideation and test LLM robustness.", "result": "The computational models identify key conspiratorial traits and reveal that LLMs reflect conspiratorial reasoning patterns in their outputs even when countering misinformation.", "conclusion": "Understanding conspiratorial ideation through ConspirED and evaluating LLMs can help mitigate the spread of AI-generated misinformation.", "key_contributions": ["Introduction of the ConspirED dataset for conspiratorial content", "Development of models to identify conspiratorial traits", "Evaluation of LLM robustness against conspiracy-related inputs"], "limitations": "The study may be limited by the dataset's representativeness of all conspiratorial content and the potential biases in LLM responses.", "keywords": ["conspiracy theories", "cognitive traits", "LLM robustness", "misinformation", "dataset"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2508.20511", "pdf": "https://arxiv.org/pdf/2508.20511.pdf", "abs": "https://arxiv.org/abs/2508.20511", "title": "Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark", "authors": ["Chihiro Taguchi", "Seng Mai", "Keita Kurabe", "Yusuke Sakai", "Georgina Agyei", "Soudabeh Eslami", "David Chiang"], "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 7 tables, 2 figures. Accepted at EMNLP Main 2025. Code and\n  data released at https://github.com/ctaguchi/LSLB", "summary": "Multilingual machine translation (MT) benchmarks play a central role in\nevaluating the capabilities of modern MT systems. Among them, the FLORES+\nbenchmark is widely used, offering English-to-many translation data for over\n200 languages, curated with strict quality control protocols. However, we study\ndata in four languages (Asante Twi, Japanese, Jinghpaw, and South Azerbaijani)\nand uncover critical shortcomings in the benchmark's suitability for truly\nmultilingual evaluation. Human assessments reveal that many translations fall\nbelow the claimed 90% quality standard, and the annotators report that source\nsentences are often too domain-specific and culturally biased toward the\nEnglish-speaking world. We further demonstrate that simple heuristics, such as\ncopying named entities, can yield non-trivial BLEU scores, suggesting\nvulnerabilities in the evaluation protocol. Notably, we show that MT models\ntrained on high-quality, naturalistic data perform poorly on FLORES+ while\nachieving significant gains on our domain-relevant evaluation set. Based on\nthese findings, we advocate for multilingual MT benchmarks that use\ndomain-general and culturally neutral source texts rely less on named entities,\nin order to better reflect real-world translation challenges.", "AI": {"tldr": "This paper critiques the FLORES+ multilingual machine translation benchmark for its inadequacies in evaluation, particularly due to domain-specific and culturally biased source texts.", "motivation": "To address the limitations of FLORES+ in evaluating multilingual machine translation systems across various languages and contexts.", "method": "The authors conducted human assessments on translations in four languages, focusing on quality and cultural bias, and analyzed performance metrics using alternative evaluation sets.", "result": "Human evaluations showed many translations failed to meet the claimed quality standards, and high-quality models struggled with FLORES+, emphasizing the benchmark's flaws.", "conclusion": "The study calls for improved multilingual MT benchmarks that are culturally neutral and less reliant on named entities to better represent real-world translation challenges.", "key_contributions": ["Critique of FLORES+ benchmark evaluation practices", "Demonstration of vulnerable scoring methodologies with heuristics", "Recommendation for culturally neutral evaluation standards"], "limitations": "The study is limited to four specific languages and may not generalize across all multilingual scenarios.", "keywords": ["multilingual machine translation", "evaluation benchmarks", "cultural bias", "FLORES+", "translation quality"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2508.20514", "pdf": "https://arxiv.org/pdf/2508.20514.pdf", "abs": "https://arxiv.org/abs/2508.20514", "title": "SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM", "authors": ["Pengjiang Li", "Zaitian Wang", "Xinhao Zhang", "Ran Zhang", "Lu Jiang", "Pengfei Wang", "Yuanchun Zhou"], "categories": ["cs.CL"], "comment": null, "summary": "Topic discovery in scientific literature provides valuable insights for\nresearchers to identify emerging trends and explore new avenues for\ninvestigation, facilitating easier scientific information retrieval. Many\nmachine learning methods, particularly deep embedding techniques, have been\napplied to discover research topics. However, most existing topic discovery\nmethods rely on word embedding to capture the semantics and lack a\ncomprehensive understanding of scientific publications, struggling with\ncomplex, high-dimensional text relationships. Inspired by the exceptional\ncomprehension of textual information by large language models (LLMs), we\npropose an advanced topic discovery method enhanced by LLMs to improve\nscientific topic identification, namely SciTopic. Specifically, we first build\na textual encoder to capture the content from scientific publications,\nincluding metadata, title, and abstract. Next, we construct a space\noptimization module that integrates entropy-based sampling and triplet tasks\nguided by LLMs, enhancing the focus on thematic relevance and contextual\nintricacies between ambiguous instances. Then, we propose to fine-tune the\ntextual encoder based on the guidance from the LLMs by optimizing the\ncontrastive loss of the triplets, forcing the text encoder to better\ndiscriminate instances of different topics. Finally, extensive experiments\nconducted on three real-world datasets of scientific publications demonstrate\nthat SciTopic outperforms the state-of-the-art (SOTA) scientific topic\ndiscovery methods, enabling researchers to gain deeper and faster insights.", "AI": {"tldr": "The paper proposes a new method for topic discovery in scientific literature using large language models (LLMs) to improve the identification of research topics.", "motivation": "To provide better tools for researchers to identify emerging trends and enhance scientific information retrieval through improved topic discovery methods.", "method": "The proposed method, SciTopic, utilizes a textual encoder to analyze scientific publications, coupled with an entropy-based sampling module and triplet tasks guided by LLMs to optimize thematic relevance.", "result": "Extensive experiments show that SciTopic significantly outperforms existing state-of-the-art methods in scientific topic discovery.", "conclusion": "The integration of LLMs in SciTopic enhances the precision of topic identification in scientific literature, facilitating faster and deeper insights for researchers.", "key_contributions": ["Introduction of SciTopic, an LLM-enhanced topic discovery method", "Novel integration of entropy-based sampling and triplet tasks", "Demonstrated superior performance compared to current state-of-the-art methods"], "limitations": "", "keywords": ["Topic Discovery", "Large Language Models", "Scientific Publications"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2508.20532", "pdf": "https://arxiv.org/pdf/2508.20532.pdf", "abs": "https://arxiv.org/abs/2508.20532", "title": "Overview of BioASQ 2024: The twelfth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering", "authors": ["Anastasios Nentidis", "Georgios Katsimpras", "Anastasia Krithara", "Salvador Lima-Lpez", "Eullia Farr-Maduell", "Martin Krallinger", "Natalia Loukachevitch", "Vera Davydova", "Elena Tutubalina", "Georgios Paliouras"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "25 pages, 16 tables, 1 figure", "summary": "This is an overview of the twelfth edition of the BioASQ challenge in the\ncontext of the Conference and Labs of the Evaluation Forum (CLEF) 2024. BioASQ\nis a series of international challenges promoting advances in large-scale\nbiomedical semantic indexing and question answering. This year, BioASQ\nconsisted of new editions of the two established tasks b and Synergy, and two\nnew tasks: a) MultiCardioNER on the adaptation of clinical entity detection to\nthe cardiology domain in a multilingual setting, and b) BIONNE on nested NER in\nRussian and English. In this edition of BioASQ, 37 competing teams participated\nwith more than 700 distinct submissions in total for the four different shared\ntasks of the challenge. Similarly to previous editions, most of the\nparticipating systems achieved competitive performance, suggesting the\ncontinuous advancement of the state-of-the-art in the field.", "AI": {"tldr": "Overview of the BioASQ challenge at CLEF 2024, highlighting competitions in biomedical indexing and question answering.", "motivation": "To promote advancements in biomedical semantic indexing and question answering through new and established tasks.", "method": "Overview of the challenge structure, tasks, and participation, highlighting both established and new tasks in clinical entity detection and NER.", "result": "37 teams participated with over 700 submissions, showing competitive performance across tasks, indicating advancements in the field.", "conclusion": "The BioASQ challenge continues to evolve, showcasing improvements in biomedical AI through international collaboration.", "key_contributions": ["Introduction of MultiCardioNER for clinical entity detection in cardiology", "Launch of BIONNE for nested NER in Russian and English", "Demonstrated competitive performance across multiple teams and tasks"], "limitations": "", "keywords": ["BioASQ", "biomedical semantic indexing", "question answering", "NER", "clinical entity detection"], "importance_score": 6, "read_time_minutes": 15}}
{"id": "2508.20554", "pdf": "https://arxiv.org/pdf/2508.20554.pdf", "abs": "https://arxiv.org/abs/2508.20554", "title": "Overview of BioASQ 2025: The Thirteenth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering", "authors": ["Anastasios Nentidis", "Georgios Katsimpras", "Anastasia Krithara", "Martin Krallinger", "Miguel Rodrguez-Ortega", "Eduard Rodriguez-Lpez", "Natalia Loukachevitch", "Andrey Sakhovskiy", "Elena Tutubalina", "Dimitris Dimitriadis", "Grigorios Tsoumakas", "George Giannakoulas", "Alexandra Bekiaridou", "Athanasios Samaras", "Giorgio Maria Di Nunzio", "Nicola Ferro", "Stefano Marchesin", "Marco Martinelli", "Gianmaria Silvello", "Georgios Paliouras"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "26 pages, 17 tables, 1 figure", "summary": "This is an overview of the thirteenth edition of the BioASQ challenge in the\ncontext of the Conference and Labs of the Evaluation Forum (CLEF) 2025. BioASQ\nis a series of international challenges promoting advances in large-scale\nbiomedical semantic indexing and question answering. This year, BioASQ\nconsisted of new editions of the two established tasks, b and Synergy, and four\nnew tasks: a) Task MultiClinSum on multilingual clinical summarization. b) Task\nBioNNE-L on nested named entity linking in Russian and English. c) Task\nELCardioCC on clinical coding in cardiology. d) Task GutBrainIE on gut-brain\ninterplay information extraction. In this edition of BioASQ, 83 competing teams\nparticipated with more than 1000 distinct submissions in total for the six\ndifferent shared tasks of the challenge. Similar to previous editions, several\nparticipating systems achieved competitive performance, indicating the\ncontinuous advancement of the state-of-the-art in the field.", "AI": {"tldr": "Overview of the thirteenth BioASQ challenge focusing on biomedical semantic indexing and question answering, highlighting new tasks and participation metrics.", "motivation": "To promote advances in large-scale biomedical semantic indexing and question answering through international challenges.", "method": "The challenge included established tasks and introduced four new tasks focusing on multilingual summarization, nested named entity linking, clinical coding, and information extraction from gut-brain interplay, with 83 teams participating.", "result": "More than 1000 distinct submissions were made across six challenges, with several systems achieving competitive performance.", "conclusion": "The results indicate continuous advancement in the state-of-the-art in biomedical question answering systems.", "key_contributions": ["Introduction of four new tasks related to multilingual clinical summarization and information extraction.", "High participation with 83 teams and over 1000 submissions.", "Demonstration of competitive performances by participating systems."], "limitations": "", "keywords": ["BioASQ", "biomedical semantic indexing", "question answering", "multilingual clinical summarization", "information extraction"], "importance_score": 6, "read_time_minutes": 20}}
{"id": "2508.20557", "pdf": "https://arxiv.org/pdf/2508.20557.pdf", "abs": "https://arxiv.org/abs/2508.20557", "title": "Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data", "authors": ["Jiahao Xiao", "Jiangming Liu"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The widespread success of pre-trained language models has established a new\ntraining paradigm, where a global PLM is fine-tuned using task-specific data\nfrom local clients. The local data are highly different from each other and can\nnot capture the global distribution of the whole data in real world. To address\nthe challenges of non-IID data in real environments, privacy-preserving\nfederated distillation has been proposed and highly investigated. However,\nprevious experimental non-IID scenarios are primarily identified with the label\n(output) diversity, without considering the diversity of language domains\n(input) that is crucial in natural language processing. In this paper, we\nintroduce a comprehensive set of multi-domain non-IID scenarios and propose a\nunified benchmarking framework that includes diverse data. The benchmark can be\nused to evaluate the federated learning framework in a real environment. To\nthis end, we propose an Adaptive Federated Distillation (AdaFD) framework\ndesigned to address multi-domain non-IID challenges in both homogeneous and\nheterogeneous settings. Experimental results demonstrate that our models\ncapture the diversity of local clients and achieve better performance compared\nto the existing works. The code for this paper is available at:\nhttps://github.com/jiahaoxiao1228/AdaFD.", "AI": {"tldr": "This paper introduces a benchmarking framework for multi-domain non-IID scenarios in federated learning and proposes the Adaptive Federated Distillation (AdaFD) method to enhance model performance in diverse data environments.", "motivation": "To tackle the challenges of non-IID data in federated learning, addressing both label diversity and input diversity in natural language processing.", "method": "A unified benchmarking framework is proposed to evaluate federated learning with a focus on multi-domain non-IID scenarios, complemented by the AdaFD framework for improving model performance.", "result": "The AdaFD framework successfully addresses multi-domain non-IID challenges and outperforms existing methods by effectively capturing diversity among local clients.", "conclusion": "Adopting the proposed benchmarking framework and AdaFD method leads to improved performance and better evaluation of federated learning frameworks in real environments.", "key_contributions": ["Introduction of a unified benchmarking framework for multi-domain non-IID scenarios in federated learning.", "Development of Adaptive Federated Distillation (AdaFD) to enhance performance with diverse data.", "Demonstration of improved model effectiveness in both homogeneous and heterogeneous settings."], "limitations": "", "keywords": ["federated learning", "non-IID data", "language models", "benchmarking framework", "privacy-preserving"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2508.20559", "pdf": "https://arxiv.org/pdf/2508.20559.pdf", "abs": "https://arxiv.org/abs/2508.20559", "title": "Leveraging Generative Models for Real-Time Query-Driven Text Summarization in Large-Scale Web Search", "authors": ["Zeyu Xiong", "Yixuan Nan", "Li Gao", "Hengzhu Tang", "Shuaiqiang Wang", "Junfeng Wang", "Dawei Yin"], "categories": ["cs.CL", "cs.IR"], "comment": "CIKM'25", "summary": "In the dynamic landscape of large-scale web search, Query-Driven Text\nSummarization (QDTS) aims to generate concise and informative summaries from\ntextual documents based on a given query, which is essential for improving user\nengagement and facilitating rapid decision-making. Traditional extractive\nsummarization models, based primarily on ranking candidate summary segments,\nhave been the dominant approach in industrial applications. However, these\napproaches suffer from two key limitations: 1) The multi-stage pipeline often\nintroduces cumulative information loss and architectural bottlenecks due to its\nweakest component; 2) Traditional models lack sufficient semantic understanding\nof both user queries and documents, particularly when dealing with complex\nsearch intents. In this study, we propose a novel framework to pioneer the\napplication of generative models to address real-time QDTS in industrial web\nsearch. Our approach integrates large model distillation, supervised\nfine-tuning, direct preference optimization, and lookahead decoding to\ntransform a lightweight model with only 0.1B parameters into a\ndomain-specialized QDTS expert. Evaluated on multiple industry-relevant\nmetrics, our model outperforms the production baseline and achieves a new state\nof the art. Furthermore, it demonstrates excellent deployment efficiency,\nrequiring only 334 NVIDIA L20 GPUs to handle \\textasciitilde50,000 queries per\nsecond under 55~ms average latency per query.", "AI": {"tldr": "This study presents a novel framework for Query-Driven Text Summarization (QDTS) that leverages generative models to enhance user engagement in web search by generating concise summaries based on user queries.", "motivation": "The aim is to improve user engagement and facilitate rapid decision-making by generating informative summaries aligned with user queries, addressing the limitations of traditional extractive models.", "method": "The proposed approach involves a framework that utilizes large model distillation, supervised fine-tuning, direct preference optimization, and lookahead decoding to create an efficient QDTS model with only 0.1B parameters.", "result": "The framework outperforms existing production baselines on multiple industry-relevant metrics, achieving state-of-the-art performance while maintaining high deployment efficiency with low resource requirements.", "conclusion": "The study concludes that the generative model-based approach greatly enhances QDTS capabilities in industrial web search settings, overcoming key limitations of traditional models.", "key_contributions": ["Introduction of a generative model framework for QDTS", "Demonstration of state-of-the-art performance against traditional models", "High deployment efficiency with minimal resource usage"], "limitations": "", "keywords": ["Query-Driven Text Summarization", "Generative Models", "Web Search"], "importance_score": 7, "read_time_minutes": 5}}
{"id": "2508.20567", "pdf": "https://arxiv.org/pdf/2508.20567.pdf", "abs": "https://arxiv.org/abs/2508.20567", "title": "KCS: Diversify Multi-hop Question Generation with Knowledge Composition Sampling", "authors": ["Yangfan Wang", "Jie Liu", "Chen Tang", "Lian Yan", "Jingchi Jiang"], "categories": ["cs.CL"], "comment": null, "summary": "Multi-hop question answering faces substantial challenges due to data\nsparsity, which increases the likelihood of language models learning spurious\npatterns. To address this issue, prior research has focused on diversifying\nquestion generation through content planning and varied expression. However,\nthese approaches often emphasize generating simple questions and neglect the\nintegration of essential knowledge, such as relevant sentences within\ndocuments. This paper introduces the Knowledge Composition Sampling (KCS), an\ninnovative framework designed to expand the diversity of generated multi-hop\nquestions by sampling varied knowledge compositions within a given context. KCS\nmodels the knowledge composition selection as a sentence-level conditional\nprediction task and utilizes a probabilistic contrastive loss to predict the\nnext most relevant piece of knowledge. During inference, we employ a stochastic\ndecoding strategy to effectively balance accuracy and diversity. Compared to\ncompetitive baselines, our KCS improves the overall accuracy of knowledge\ncomposition selection by 3.9%, and its application for data augmentation yields\nimprovements on HotpotQA and 2WikiMultihopQA datasets. Our code is available\nat: https://github.com/yangfanww/kcs.", "AI": {"tldr": "This paper presents Knowledge Composition Sampling (KCS), a framework for enhancing multi-hop question answering by improving the diversity of generated questions through varied knowledge compositions.", "motivation": "The paper addresses challenges in multi-hop question answering caused by data sparsity and the tendency of language models to learn spurious patterns, aiming to improve question generation by integrating essential knowledge.", "method": "KCS treats knowledge composition selection as a sentence-level conditional prediction task and employs a probabilistic contrastive loss function to enhance the relevance of generated knowledge pieces. It uses a stochastic decoding strategy during inference to maintain a balance between accuracy and diversity.", "result": "KCS improves the accuracy of knowledge composition selection by 3.9% compared to competitive baselines and shows effective data augmentation results on HotpotQA and 2WikiMultihopQA datasets.", "conclusion": "The proposed KCS framework successfully enhances the generation of diverse multi-hop questions and demonstrates good performance in data augmentation for multi-hop question answering benchmarks.", "key_contributions": ["Introduction of the Knowledge Composition Sampling framework for multi-hop question answering.", "Use of probabilistic contrastive loss for selecting relevant knowledge compositions.", "Implementation of a stochastic decoding strategy for balancing accuracy and diversity."], "limitations": "", "keywords": ["multi-hop question answering", "knowledge composition", "probabilistic contrastive loss", "data augmentation", "stochastic decoding"], "importance_score": 7, "read_time_minutes": 15}}
{"id": "2508.20583", "pdf": "https://arxiv.org/pdf/2508.20583.pdf", "abs": "https://arxiv.org/abs/2508.20583", "title": "A Graph Talks, But Who's Listening? Rethinking Evaluations for Graph-Language Models", "authors": ["Soham Petkar", "Hari Aakash K", "Anirudh Vempati", "Akshit Sinha", "Ponnurangam Kumarauguru", "Chirag Agarwal"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Developments in Graph-Language Models (GLMs) aim to integrate the structural\nreasoning capabilities of Graph Neural Networks (GNNs) with the semantic\nunderstanding of Large Language Models (LLMs). However, we demonstrate that\ncurrent evaluation benchmarks for GLMs, which are primarily repurposed\nnode-level classification datasets, are insufficient to assess multimodal\nreasoning. Our analysis reveals that strong performance on these benchmarks is\nachievable using unimodal information alone, suggesting that they do not\nnecessitate graph-language integration. To address this evaluation gap, we\nintroduce the CLEGR(Compositional Language-Graph Reasoning) benchmark, designed\nto evaluate multimodal reasoning at various complexity levels. Our benchmark\nemploys a synthetic graph generation pipeline paired with questions that\nrequire joint reasoning over structure and textual semantics. We perform a\nthorough evaluation of representative GLM architectures and find that\nsoft-prompted LLM baselines perform on par with GLMs that incorporate a full\nGNN backbone. This result calls into question the architectural necessity of\nincorporating graph structure into LLMs. We further show that GLMs exhibit\nsignificant performance degradation in tasks that require structural reasoning.\nThese findings highlight limitations in the graph reasoning capabilities of\ncurrent GLMs and provide a foundation for advancing the community toward\nexplicit multimodal reasoning involving graph structure and language.", "AI": {"tldr": "The paper critiques current evaluation benchmarks for Graph-Language Models (GLMs) and introduces the CLEGR benchmark for multimodal reasoning assessment.", "motivation": "To address the inadequacy of existing benchmarks in evaluating GLMs' ability to perform multimodal reasoning that combines graph structure and language semantics.", "method": "Introduction of the CLEGR benchmark with synthetic graph generation and reasoning questions, followed by evaluations of various GLM architectures.", "result": "GLM architectures do not significantly outperform soft-prompted LLMs, indicating that the graph structure may not be necessary for high performance in certain tasks.", "conclusion": "Current GLM models struggle with structural reasoning and may not need integration of graph structures with LLMs, revealing potential limitations in graph-based reasoning capabilities.", "key_contributions": ["Introduction of the CLEGR benchmark for multimodal reasoning", "Analysis of GLM architectures against soft-prompted LLM performance", "Identification of limitations in GLMs' graph reasoning capabilities"], "limitations": "Evaluation primarily focused on specific architectures and may not encompass all types of GLMs.", "keywords": ["Graph-Language Models", "Graph Neural Networks", "Multimodal Reasoning"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2508.20700", "pdf": "https://arxiv.org/pdf/2508.20700.pdf", "abs": "https://arxiv.org/abs/2508.20700", "title": "Generative Annotation for ASR Named Entity Correction", "authors": ["Yuanchang Luo", "Daimeng Wei", "Shaojun Li", "Hengchao Shang", "Jiaxin Guo", "Zongyao Li", "Zhanglin Wu", "Xiaoyu Chen", "Zhiqiang Rao", "Jinlong Yang", "Hao Yang"], "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 7 figures, 7 tables, EMNLP 2025", "summary": "End-to-end automatic speech recognition systems often fail to transcribe\ndomain-specific named entities, causing catastrophic failures in downstream\ntasks. Numerous fast and lightweight named entity correction (NEC) models have\nbeen proposed in recent years. These models, mainly leveraging phonetic-level\nedit distance algorithms, have shown impressive performances. However, when the\nforms of the wrongly-transcribed words(s) and the ground-truth entity are\nsignificantly different, these methods often fail to locate the wrongly\ntranscribed words in hypothesis, thus limiting their usage. We propose a novel\nNEC method that utilizes speech sound features to retrieve candidate entities.\nWith speech sound features and candidate entities, we inovatively design a\ngenerative method to annotate entity errors in ASR transcripts and replace the\ntext with correct entities. This method is effective in scenarios of word form\ndifference. We test our method using open-source and self-constructed test\nsets. The results demonstrate that our NEC method can bring significant\nimprovement to entity accuracy. We will open source our self-constructed test\nset and training data.", "AI": {"tldr": "This paper presents a novel named entity correction (NEC) method leveraging speech sound features to improve transcription accuracy of domain-specific entities in automatic speech recognition systems.", "motivation": "End-to-end automatic speech recognition systems often misinterpret domain-specific named entities, which leads to failures in subsequent tasks.", "method": "The proposed NEC method utilizes speech sound features to identify candidate entities and employs a generative approach to annotate and replace incorrect entities in ASR transcripts.", "result": "The results show that the new NEC method significantly improves entity accuracy compared to traditional models, especially in cases where the wrongly transcribed words differ greatly from the correct entities.", "conclusion": "This method represents a significant advancement in the correction of entity recognition in ASR systems, with open-source datasets to aid further research.", "key_contributions": ["Introduction of a novel NEC method leveraging speech sound features", "Generative approach for annotating and correcting entity errors in ASR transcripts", "Open-sourcing of self-constructed test set and training data"], "limitations": "", "keywords": ["automatic speech recognition", "named entity correction", "speech features", "generative method", "entity accuracy"], "importance_score": 7, "read_time_minutes": 20}}
{"id": "2508.20712", "pdf": "https://arxiv.org/pdf/2508.20712.pdf", "abs": "https://arxiv.org/abs/2508.20712", "title": "Multi-Lingual Implicit Discourse Relation Recognition with Multi-Label Hierarchical Learning", "authors": ["Nelson Filipe Costa", "Leila Kosseim"], "categories": ["cs.CL"], "comment": "Published at SIGDIAL 2025. Best paper award", "summary": "This paper introduces the first multi-lingual and multi-label classification\nmodel for implicit discourse relation recognition (IDRR). Our model, HArch, is\nevaluated on the recently released DiscoGeM 2.0 corpus and leverages\nhierarchical dependencies between discourse senses to predict probability\ndistributions across all three sense levels in the PDTB 3.0 framework. We\ncompare several pre-trained encoder backbones and find that RoBERTa-HArch\nachieves the best performance in English, while XLM-RoBERTa-HArch performs best\nin the multi-lingual setting. In addition, we compare our fine-tuned models\nagainst GPT-4o and Llama-4-Maverick using few-shot prompting across all\nlanguage configurations. Our results show that our fine-tuned models\nconsistently outperform these LLMs, highlighting the advantages of\ntask-specific fine-tuning over prompting in IDRR. Finally, we report SOTA\nresults on the DiscoGeM 1.0 corpus, further validating the effectiveness of our\nhierarchical approach.", "AI": {"tldr": "Introduction of HArch, a multi-lingual and multi-label classification model for implicit discourse relation recognition (IDRR), demonstrating superiority over existing LLMs.", "motivation": "The paper addresses the need for effective implicit discourse relation recognition across multiple languages and aims to improve the performance of discourse relation classification using a hierarchical approach.", "method": "HArch leverages hierarchical dependencies between discourse senses to predict probability distributions in the PDTB 3.0 framework, evaluated on the DiscoGeM 2.0 corpus, compared to various encoder backbones and evaluated against LLMs.", "result": "RoBERTa-HArch performs best in English, while XLM-RoBERTa-HArch excels in the multi-lingual setting; the model consistently outperforms GPT-4o and Llama-4-Maverick in few-shot prompting.", "conclusion": "The hierarchical approach of HArch leads to state-of-the-art results on the DiscoGeM 1.0 corpus, showcasing the advantages of task-specific fine-tuning over general LLM prompting for IDRR.", "key_contributions": ["First multi-lingual and multi-label classification model for IDRR", "Hierarchical approach for improving discourse sense prediction", "Demonstrated superior performance compared to GPT-4o and Llama-4-Maverick"], "limitations": "", "keywords": ["implicit discourse relations", "multi-lingual classification", "hierarchical dependencies", "fine-tuning", "discourse sense prediction"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2508.20718", "pdf": "https://arxiv.org/pdf/2508.20718.pdf", "abs": "https://arxiv.org/abs/2508.20718", "title": "Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models", "authors": ["Ruiyi Yan", "Yugo Murawaki"], "categories": ["cs.CL"], "comment": null, "summary": "Large language models have significantly enhanced the capacities and\nefficiency of text generation. On the one hand, they have improved the quality\nof text-based steganography. On the other hand, they have also underscored the\nimportance of watermarking as a safeguard against malicious misuse. In this\nstudy, we focus on tokenization inconsistency (TI) between Alice and Bob in\nsteganography and watermarking, where TI can undermine robustness. Our\ninvestigation reveals that the problematic tokens responsible for TI exhibit\ntwo key characteristics: infrequency and temporariness. Based on these\nfindings, we propose two tailored solutions for TI elimination: a stepwise\nverification method for steganography and a post-hoc rollback method for\nwatermarking. Experiments show that (1) compared to traditional disambiguation\nmethods in steganography, directly addressing TI leads to improvements in\nfluency, imperceptibility, and anti-steganalysis capacity; (2) for\nwatermarking, addressing TI enhances detectability and robustness against\nattacks.", "AI": {"tldr": "The study addresses tokenization inconsistency in text-based steganography and watermarking, proposing solutions to improve robustness against misuse.", "motivation": "To improve the quality of text-based steganography and watermarking by addressing tokenization inconsistency (TI) which undermines robustness.", "method": "Two tailored methods are proposed: a stepwise verification method for steganography and a post-hoc rollback method for watermarking to eliminate TI.", "result": "Experiments show that directly addressing TI improves fluency, imperceptibility, and anti-steganalysis capacity in steganography, and enhances detectability and robustness in watermarking.", "conclusion": "The findings highlight the critical nature of addressing tokenization inconsistency to strengthen steganography and watermarking techniques.", "key_contributions": ["Proposed solutions for eliminating tokenization inconsistency in steganography and watermarking.", "Demonstrated improvements in various metrics for both steganography and watermarking through experiments.", "Identified key characteristics of problematic tokens that lead to tokenization inconsistency."], "limitations": "", "keywords": ["tokenization inconsistency", "steganography", "watermarking", "text generation", "large language models"], "importance_score": 7, "read_time_minutes": 5}}
{"id": "2508.20722", "pdf": "https://arxiv.org/pdf/2508.20722.pdf", "abs": "https://arxiv.org/abs/2508.20722", "title": "rStar2-Agent: Agentic Reasoning Technical Report", "authors": ["Ning Shang", "Yifei Liu", "Yi Zhu", "Li Lyna Zhang", "Weijiang Xu", "Xinyu Guan", "Buze Zhang", "Bingcheng Dong", "Xudong Zhou", "Bowen Zhang", "Ying Xin", "Ziming Miao", "Scarlett Li", "Fan Yang", "Mao Yang"], "categories": ["cs.CL"], "comment": null, "summary": "We introduce rStar2-Agent, a 14B math reasoning model trained with agentic\nreinforcement learning to achieve frontier-level performance. Beyond current\nlong CoT, the model demonstrates advanced cognitive behaviors, such as thinking\ncarefully before using Python coding tools and reflecting on code execution\nfeedback to autonomously explore, verify, and refine intermediate steps in\ncomplex problem-solving. This capability is enabled through three key\ninnovations that makes agentic RL effective at scale: (i) an efficient RL\ninfrastructure with a reliable Python code environment that supports\nhigh-throughput execution and mitigates the high rollout costs, enabling\ntraining on limited GPU resources (64 MI300X GPUs); (ii) GRPO-RoC, an agentic\nRL algorithm with a Resample-on-Correct rollout strategy that addresses the\ninherent environment noises from coding tools, allowing the model to reason\nmore effectively in a code environment; (iii) An efficient agent training\nrecipe that starts with non-reasoning SFT and progresses through multi-RL\nstages, yielding advanced cognitive abilities with minimal compute cost. To\nthis end, rStar2-Agent boosts a pre-trained 14B model to state of the art in\nonly 510 RL steps within one week, achieving average pass@1 scores of 80.6% on\nAIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B) with significantly\nshorter responses. Beyond mathematics, rStar2-Agent-14B also demonstrates\nstrong generalization to alignment, scientific reasoning, and agentic tool-use\ntasks. Code and training recipes are available at\nhttps://github.com/microsoft/rStar.", "AI": {"tldr": "rStar2-Agent is a 14B math reasoning model that employs agentic reinforcement learning for enhanced cognitive performance in problem-solving and coding tasks.", "motivation": "The paper aims to achieve frontier-level performance in complex problem-solving and coding by leveraging agentic reinforcement learning.", "method": "The model utilizes a new RL infrastructure with a reliable Python environment, the GRPO-RoC algorithm for effective reasoning in noisy coding environments, and a phased agent training approach.", "result": "rStar2-Agent achieved state-of-the-art performance with an average pass@1 score of 80.6% on AIME24 and 69.8% on AIME25 in just 510 RL steps in one week.", "conclusion": "The model demonstrates strong generalization beyond mathematics to alignment and scientific reasoning tasks, with significant improvements over larger models.", "key_contributions": ["Introduced agentic RL infrastructure for coding tasks", "Developed GRPO-RoC for effective reasoning amid noisy environments", "Achieved state-of-the-art performance with efficient training methodology"], "limitations": "", "keywords": ["agentic reinforcement learning", "math reasoning", "Python coding tools", "cognitive abilities", "machine learning"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2508.20736", "pdf": "https://arxiv.org/pdf/2508.20736.pdf", "abs": "https://arxiv.org/abs/2508.20736", "title": "Leveraging Semantic Triples for Private Document Generation with Local Differential Privacy Guarantees", "authors": ["Stephen Meisenbacher", "Maulik Chevli", "Florian Matthes"], "categories": ["cs.CL"], "comment": "17 pages, 2 figures, 11 tables. Accepted to EMNLP 2025 (Main)", "summary": "Many works at the intersection of Differential Privacy (DP) in Natural\nLanguage Processing aim to protect privacy by transforming texts under DP\nguarantees. This can be performed in a variety of ways, from word perturbations\nto full document rewriting, and most often under local DP. Here, an input text\nmust be made indistinguishable from any other potential text, within some bound\ngoverned by the privacy parameter $\\varepsilon$. Such a guarantee is quite\ndemanding, and recent works show that privatizing texts under local DP can only\nbe done reasonably under very high $\\varepsilon$ values. Addressing this\nchallenge, we introduce DP-ST, which leverages semantic triples for\nneighborhood-aware private document generation under local DP guarantees.\nThrough the evaluation of our method, we demonstrate the effectiveness of the\ndivide-and-conquer paradigm, particularly when limiting the DP notion (and\nprivacy guarantees) to that of a privatization neighborhood. When combined with\nLLM post-processing, our method allows for coherent text generation even at\nlower $\\varepsilon$ values, while still balancing privacy and utility. These\nfindings highlight the importance of coherence in achieving balanced\nprivatization outputs at reasonable $\\varepsilon$ levels.", "AI": {"tldr": "This paper introduces DP-ST, a method for generating private documents under local Differential Privacy (DP) guarantees using semantic triples, balancing privacy and utility.", "motivation": "The challenge of transforming text under Differential Privacy while maintaining high coherence and utility, especially at lower  values.", "method": "DP-ST leverages semantic triples for neighborhood-aware private document generation combined with LLM post-processing to ensure coherent text generation.", "result": "DP-ST demonstrates effective text generation that maintains coherence and balances privacy even at lower  values, highlighting the significance of neighborhood-aware strategies.", "conclusion": "The findings suggest that by focusing on privatization neighborhoods, it is possible to achieve reasonable levels of privacy without sacrificing the quality of generated text.", "key_contributions": ["Introduction of a novel method (DP-ST) for document generation under local DP", "Demonstration of coherent text generation at lower  values through semantic triples", "Evaluation of the divide-and-conquer paradigm in the context of privacy and utility."], "limitations": "The performance of DP-ST may still depend on the specific contexts or types of documents being processed.", "keywords": ["Differential Privacy", "Natural Language Processing", "Semantic Triples", "Document Generation", "LLM Post-Processing"], "importance_score": 8, "read_time_minutes": 17}}
{"id": "2508.20750", "pdf": "https://arxiv.org/pdf/2508.20750.pdf", "abs": "https://arxiv.org/abs/2508.20750", "title": "Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets", "authors": ["Vassiliy Cheremetiev", "Quang Long Ho Ngo", "Chau Ying Kot", "Alina Elena Baia", "Andrea Cavallaro"], "categories": ["cs.CL"], "comment": "Paper accepted at the DHOW Workshop at ACM Multimedia 2025. Code\n  available at https://github.com/idiap/implicit-hsd", "summary": "Implicit hate speech (IHS) is indirect language that conveys prejudice or\nhatred through subtle cues, sarcasm or coded terminology. IHS is challenging to\ndetect as it does not include explicit derogatory or inflammatory words. To\naddress this challenge, task-specific pipelines can be complemented with\nexternal knowledge or additional information such as context, emotions and\nsentiment data. In this paper, we show that, by solely fine-tuning recent\ngeneral-purpose embedding models based on large language models (LLMs), such as\nStella, Jasper, NV-Embed and E5, we achieve state-of-the-art performance.\nExperiments on multiple IHS datasets show up to 1.10 percentage points\nimprovements for in-dataset, and up to 20.35 percentage points improvements in\ncross-dataset evaluation, in terms of F1-macro score.", "AI": {"tldr": "This paper presents a method for detecting implicit hate speech by fine-tuning general-purpose embedding models based on large language models, achieving state-of-the-art results across multiple datasets.", "motivation": "The detection of implicit hate speech is crucial due to its subtlety and the challenges posed by the use of indirect language, sarcasm, and coded terminology in conveying prejudice.", "method": "The authors fine-tune recent general-purpose embedding models, namely Stella, Jasper, NV-Embed, and E5, focusing on the incorporation of emotional and contextual information to enhance detection performance.", "result": "The method achieved up to a 1.10 percentage point improvement in F1-macro score on in-dataset evaluations, and up to a 20.35 percentage point improvement in cross-dataset evaluations.", "conclusion": "Fine-tuning LLMs for implicit hate speech detection significantly enhances performance and sets a new standard in this area.", "key_contributions": ["Fine-tuning of LLM-based embedding models for IHS detection", "Demonstrated improvement in detection metrics across multiple datasets", "Integration of contextual and emotional data into detection pipelines"], "limitations": "", "keywords": ["implicit hate speech", "large language models", "embedding models", "fine-tuning", "natural language processing"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2508.20757", "pdf": "https://arxiv.org/pdf/2508.20757.pdf", "abs": "https://arxiv.org/abs/2508.20757", "title": "GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation", "authors": ["Yuanhao Ding", "Esteban Garces Arias", "Meimingwei Li", "Julian Rodemann", "Matthias Aenmacher", "Danlu Chen", "Gaojuan Fan", "Christian Heumann", "Chongsheng Zhang"], "categories": ["cs.CL"], "comment": "Accepted at Findings of the Association for Computational\n  Linguistics: EMNLP (Findings) 2025", "summary": "Open-ended text generation faces a critical challenge: balancing coherence\nwith diversity in LLM outputs. While contrastive search-based decoding\nstrategies have emerged to address this trade-off, their practical utility is\noften limited by hyperparameter dependence and high computational costs. We\nintroduce GUARD, a self-adaptive decoding method that effectively balances\nthese competing objectives through a novel \"Glocal\" uncertainty-driven\nframework. GUARD combines global entropy estimates with local entropy\ndeviations to integrate both long-term and short-term uncertainty signals. We\ndemonstrate that our proposed global entropy formulation effectively mitigates\nabrupt variations in uncertainty, such as sudden overconfidence or high entropy\nspikes, and provides theoretical guarantees of unbiasedness and consistency. To\nreduce computational overhead, we incorporate a simple yet effective\ntoken-count-based penalty into GUARD. Experimental results demonstrate that\nGUARD achieves a good balance between text diversity and coherence, while\nexhibiting substantial improvements in generation speed. In a more nuanced\ncomparison study across different dimensions of text quality, both human and\nLLM evaluators validated its remarkable performance. Our code is available at\nhttps://github.com/YecanLee/GUARD.", "AI": {"tldr": "GUARD is a self-adaptive decoding method that balances coherence and diversity in LLM outputs by using a novel uncertainty-driven framework.", "motivation": "To address the challenge of balancing coherence and diversity in open-ended text generation with LLMs, which is often hindered by hyperparameter dependence and high computational costs.", "method": "GUARD utilizes a 'Glocal' uncertainty-driven approach, combining global entropy estimates with local entropy deviations to manage both long-term and short-term uncertainty signals effectively.", "result": "Experimental results show that GUARD achieves a balance between text diversity and coherence and improves generation speed, with validation from both human and LLM evaluators.", "conclusion": "GUARD provides a robust solution for enhancing LLM output quality by mitigating abrupt variations in uncertainty while maintaining computational efficiency.", "key_contributions": ["Introduced a novel 'Glocal' uncertainty-driven framework for decoding methods in LLMs.", "Achieved improvements in generation speed without sacrificing text quality.", "Provided theoretical guarantees of unbiasedness and consistency for the proposed method."], "limitations": "", "keywords": ["LLM", "text generation", "open-ended generation", "coherence", "diversity"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2508.20764", "pdf": "https://arxiv.org/pdf/2508.20764.pdf", "abs": "https://arxiv.org/abs/2508.20764", "title": "Feel the Difference? A Comparative Analysis of Emotional Arcs in Real and LLM-Generated CBT Sessions", "authors": ["Xiaoyi Wang", "Jiwei Zhang", "Guangtao Zhang", "Honglei Guo"], "categories": ["cs.CL"], "comment": "Accepted at EMNLP 2025,14 page,3 figures", "summary": "Synthetic therapy dialogues generated by large language models (LLMs) are\nincreasingly used in mental health NLP to simulate counseling scenarios, train\nmodels, and supplement limited real-world data. However, it remains unclear\nwhether these synthetic conversations capture the nuanced emotional dynamics of\nreal therapy. In this work, we conduct the first comparative analysis of\nemotional arcs between real and LLM-generated Cognitive Behavioral Therapy\ndialogues. We adapt the Utterance Emotion Dynamics framework to analyze\nfine-grained affective trajectories across valence, arousal, and dominance\ndimensions. Our analysis spans both full dialogues and individual speaker roles\n(counselor and client), using real sessions transcribed from public videos and\nsynthetic dialogues from the CACTUS dataset. We find that while synthetic\ndialogues are fluent and structurally coherent, they diverge from real\nconversations in key emotional properties: real sessions exhibit greater\nemotional variability,more emotion-laden language, and more authentic patterns\nof reactivity and regulation. Moreover, emotional arc similarity between real\nand synthetic speakers is low, especially for clients. These findings\nunderscore the limitations of current LLM-generated therapy data and highlight\nthe importance of emotional fidelity in mental health applications. We\nintroduce RealCBT, a curated dataset of real CBT sessions, to support future\nresearch in this space.", "AI": {"tldr": "This study compares emotional dynamics in real vs. LLM-generated therapy dialogues, finding key differences in emotional properties, leading to concerns about the fidelity of synthetic data.", "motivation": "To investigate the emotional dynamics in therapy dialogues generated by LLMs versus those from real sessions, assessing the implications for mental health applications.", "method": "We adapt the Utterance Emotion Dynamics framework to compare emotional arcs in real CBT dialogues with LLM-generated dialogues from the CACTUS dataset.", "result": "Synthetic dialogues are fluent but lack the emotional variability and authenticity found in real sessions, particularly low emotional arc similarity for clients.", "conclusion": "The findings highlight significant limitations in LLM-generated therapy data and the need for authentic emotional representation in mental health applications.", "key_contributions": ["First comparative analysis of emotional arcs in real vs. synthetic therapy dialogues", "Introduction of RealCBT, a dataset of real CBT sessions for future research", "Insights into the emotional fidelity deficiencies of LLM-generated therapy dialogues"], "limitations": "The analysis is limited to Cognitive Behavioral Therapy dialogues and may not generalize to other therapeutic approaches.", "keywords": ["Cognitive Behavioral Therapy", "Large Language Models", "Emotional Dynamics", "Mental Health", "Synthetic Dialogues"], "importance_score": 9, "read_time_minutes": 14}}
{"id": "2508.20766", "pdf": "https://arxiv.org/pdf/2508.20766.pdf", "abs": "https://arxiv.org/abs/2508.20766", "title": "Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection", "authors": ["Harethah Abu Shairah", "Hasan Abed Al Kader Hammoud", "George Turkiyyah", "Bernard Ghanem"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under Review", "summary": "Safety alignment in Large Language Models (LLMs) often involves mediating\ninternal representations to refuse harmful requests. Recent research has\ndemonstrated that these safety mechanisms can be bypassed by ablating or\nremoving specific representational directions within the model. In this paper,\nwe propose the opposite approach: Rank-One Safety Injection (ROSI), a white-box\nmethod that amplifies a model's safety alignment by permanently steering its\nactivations toward the refusal-mediating subspace. ROSI operates as a simple,\nfine-tuning-free rank-one weight modification applied to all residual stream\nwrite matrices. The required safety direction can be computed from a small set\nof harmful and harmless instruction pairs. We show that ROSI consistently\nincreases safety refusal rates - as evaluated by Llama Guard 3 - while\npreserving the utility of the model on standard benchmarks such as MMLU,\nHellaSwag, and Arc. Furthermore, we show that ROSI can also re-align\n'uncensored' models by amplifying their own latent safety directions,\ndemonstrating its utility as an effective last-mile safety procedure. Our\nresults suggest that targeted, interpretable weight steering is a cheap and\npotent mechanism to improve LLM safety, complementing more resource-intensive\nfine-tuning paradigms.", "AI": {"tldr": "The paper presents Rank-One Safety Injection (ROSI), a method for enhancing safety alignment in Large Language Models by modifying weight matrices to improve refusal rates of harmful requests without extensive fine-tuning.", "motivation": "Existing safety mechanisms in LLMs can be bypassed, necessitating new approaches to enhance safety alignment.", "method": "ROSI involves a simple rank-one modification of write matrices in the model's residual stream, informed by harmful and harmless instruction pairs.", "result": "ROSI significantly increases safety refusal rates, as shown by evaluations with Llama Guard 3, while maintaining performance on standard benchmarks like MMLU and HellaSwag.", "conclusion": "ROSI serves as an efficient last-mile safety procedure that effectively enhances LLM safety using interpretable weight steering without the need for extensive model fine-tuning.", "key_contributions": ["Introduction of Rank-One Safety Injection (ROSI) technique for LLM safety enhancement", "Proven effectiveness of ROSI in increasing safety refusal rates", "Demonstration of ROSI's ability to realign uncensored models with latent safety directions"], "limitations": "", "keywords": ["Large Language Models", "Safety Alignment", "Rank-One Safety Injection", "Harmful Requests", "Machine Learning"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2508.20771", "pdf": "https://arxiv.org/pdf/2508.20771.pdf", "abs": "https://arxiv.org/abs/2508.20771", "title": "Signs of Struggle: Spotting Cognitive Distortions across Language and Register", "authors": ["Abhishek Kuber", "Enrico Liscio", "Ruixuan Zhang", "Caroline Figueroa", "Pradeep K. Murukannaiah"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Rising mental health issues among youth have increased interest in automated\napproaches for detecting early signs of psychological distress in digital text.\nOne key focus is the identification of cognitive distortions, irrational\nthought patterns that have a role in aggravating mental distress. Early\ndetection of these distortions may enable timely, low-cost interventions. While\nprior work has focused on English clinical data, we present the first in-depth\nstudy of cross-lingual and cross-register generalization of cognitive\ndistortion detection, analyzing forum posts written by Dutch adolescents. Our\nfindings show that while changes in language and writing style can\nsignificantly affect model performance, domain adaptation methods show the most\npromise.", "AI": {"tldr": "This paper studies the cross-lingual and cross-register detection of cognitive distortions in Dutch adolescents' forum posts, highlighting domain adaptation methods for improved model performance.", "motivation": "The study addresses rising mental health issues among youth and the need for automated detection of psychological distress through text analysis.", "method": "The research analyzes forum posts written by Dutch adolescents to evaluate the effectiveness of cognitive distortion detection models across different languages and writing styles.", "result": "The study finds that language changes and writing style variations significantly impact model performance, with domain adaptation methods providing promising results.", "conclusion": "Early detection of cognitive distortions can enable timely interventions, but model performance is highly variable based on linguistic factors.", "key_contributions": ["First study on cross-lingual and cross-register cognitive distortion detection in Dutch", "Analysis of the impact of language and style on detection accuracy", "Demonstration of domain adaptation methods' effectiveness"], "limitations": "Focus on a specific language (Dutch) and demographic (adolescents); may not generalize to other languages or age groups.", "keywords": ["mental health", "cognitive distortions", "cross-lingual", "machine learning", "domain adaptation"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2508.20805", "pdf": "https://arxiv.org/pdf/2508.20805.pdf", "abs": "https://arxiv.org/abs/2508.20805", "title": "Exploring Machine Learning and Language Models for Multimodal Depression Detection", "authors": ["Javier Si Zhao Hong", "Timothy Zoe Delaya", "Sherwyn Chan Yin Kit", "Pai Chet Ng", "Xiaoxiao Miao"], "categories": ["cs.CL", "cs.AI", "cs.SD"], "comment": "This paper has been accepted by APCIPA ASC 2025", "summary": "This paper presents our approach to the first Multimodal Personality-Aware\nDepression Detection Challenge, focusing on multimodal depression detection\nusing machine learning and deep learning models. We explore and compare the\nperformance of XGBoost, transformer-based architectures, and large language\nmodels (LLMs) on audio, video, and text features. Our results highlight the\nstrengths and limitations of each type of model in capturing depression-related\nsignals across modalities, offering insights into effective multimodal\nrepresentation strategies for mental health prediction.", "AI": {"tldr": "The paper presents a comparative study on multimodal depression detection using machine learning and deep learning models, focusing on audio, video, and text features.", "motivation": "To advance understanding of how different machine learning and deep learning models perform in the context of detecting depression through various media formats, in a mental health setting.", "method": "The study evaluates the performance of XGBoost, transformer-based architectures, and large language models (LLMs) by analyzing their effectiveness on audio, video, and text data.", "result": "The findings showcase the relative strengths and weaknesses of XGBoost, transformers, and LLMs in capturing depression signals, providing valuable insights for developing effective multimodal prediction strategies.", "conclusion": "The research underscores the importance of exploring multimodal representations in mental health prediction, helping to inform future studies and applications.", "key_contributions": ["Comparative analysis of various model architectures for depression detection across different modalities", "Insights into effective multimodal representation strategies for mental health", "Evaluation of LLMs in the context of mental health applications"], "limitations": "The study may be constrained by the specific datasets used, and results could vary with different data sources or modalities.", "keywords": ["multimodal", "depression detection", "machine learning", "deep learning", "large language models"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2508.20828", "pdf": "https://arxiv.org/pdf/2508.20828.pdf", "abs": "https://arxiv.org/abs/2508.20828", "title": "GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction", "authors": ["Jie Zhao", "Wanting Ning", "Yuxiao Fei", "Yubo Feng", "Lishuang Li"], "categories": ["cs.CL", "cs.IR"], "comment": "Proceedings of the 2025 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP Findings)", "summary": "In Natural Language Processing(NLP), Event Temporal Relation Extraction\n(ETRE) is to recognize the temporal relations of two events. Prior studies have\nnoted the importance of language models for ETRE. However, the restricted\npre-trained knowledge of Small Language Models(SLMs) limits their capability to\nhandle minority class relations in imbalanced classification datasets. For\nLarge Language Models(LLMs), researchers adopt manually designed prompts or\ninstructions, which may introduce extra noise, leading to interference with the\nmodel's judgment of the long-distance dependencies between events. To address\nthese issues, we propose GDLLM, a Global Distance-aware modeling approach based\non LLMs. We first present a distance-aware graph structure utilizing Graph\nAttention Network(GAT) to assist the LLMs in capturing long-distance dependency\nfeatures. Additionally, we design a temporal feature learning paradigm based on\nsoft inference to augment the identification of relations with a short-distance\nproximity band, which supplements the probabilistic information generated by\nLLMs into the multi-head attention mechanism. Since the global feature can be\ncaptured effectively, our framework substantially enhances the performance of\nminority relation classes and improves the overall learning ability.\nExperiments on two publicly available datasets, TB-Dense and MATRES,\ndemonstrate that our approach achieves state-of-the-art (SOTA) performance.", "AI": {"tldr": "GDLLM is a Global Distance-aware approach for Event Temporal Relation Extraction, improving the identification of temporal relations in Natural Language Processing by enhancing the capabilities of Large Language Models, particularly for minority relation classes.", "motivation": "To improve the performance of Event Temporal Relation Extraction (ETRE) using Large Language Models (LLMs) by addressing limitations of minority class relations in imbalanced datasets and noise introduced by manual prompts.", "method": "We propose GDLLM, which integrates a distance-aware graph structure with Graph Attention Network (GAT) and a soft inference-based temporal feature learning paradigm to enhance the learning of long-distance and short-distance dependencies.", "result": "GDLLM achieves state-of-the-art performance on the TB-Dense and MATRES datasets, particularly improving the identification of minority relation classes in ETRE.", "conclusion": "The proposed framework significantly enhances LLM's learning capabilities and overall performance in temporal relation extraction.", "key_contributions": ["Introduction of the GDLLM framework", "Integration of distance-aware graph structure with LLMs", "State-of-the-art performance on temporal relation extraction tasks."], "limitations": "", "keywords": ["Event Temporal Relation Extraction", "Large Language Models", "Graph Attention Network"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2508.20867", "pdf": "https://arxiv.org/pdf/2508.20867.pdf", "abs": "https://arxiv.org/abs/2508.20867", "title": "MSRS: Evaluating Multi-Source Retrieval-Augmented Generation", "authors": ["Rohan Phanse", "Yijie Zhou", "Kejian Shi", "Wencai Zhang", "Yixin Liu", "Yilun Zhao", "Arman Cohan"], "categories": ["cs.CL"], "comment": "COLM 2025; this article supersedes the preprint: arXiv:2309.08960", "summary": "Retrieval-augmented systems are typically evaluated in settings where\ninformation required to answer the query can be found within a single source or\nthe answer is short-form or factoid-based. However, many real-world\napplications demand the ability to integrate and summarize information\nscattered across multiple sources, where no single source is sufficient to\nrespond to the user's question. In such settings, the retrieval component of a\nRAG pipeline must recognize a variety of relevance signals, and the generation\ncomponent must connect and synthesize information across multiple sources. We\npresent a scalable framework for constructing evaluation benchmarks that\nchallenge RAG systems to integrate information across distinct sources and\ngenerate long-form responses. Using our framework, we build two new benchmarks\non Multi-Source Retrieval and Synthesis: MSRS-Story and MSRS-Meet, representing\nnarrative synthesis and summarization tasks, respectively, that require\nretrieval from large collections. Our extensive experiments with various RAG\npipelines -- including sparse and dense retrievers combined with frontier LLMs\n-- reveal that generation quality is highly dependent on retrieval\neffectiveness, which varies greatly by task. While multi-source synthesis\nproves challenging even in an oracle retrieval setting, we find that reasoning\nmodels significantly outperform standard LLMs at this distinct step.", "AI": {"tldr": "The paper presents a framework to evaluate retrieval-augmented generation (RAG) systems on multi-source information integration and long-form response generation.", "motivation": "Existing evaluations of RAG systems are limited to single-source or short-form queries, failing to address real-world scenarios requiring information synthesis across multiple sources.", "method": "A scalable framework for constructing evaluation benchmarks for RAG systems is introduced, along with two new benchmarks: MSRS-Story and MSRS-Meet, focused on narrative synthesis and summarization, respectively.", "result": "Experiments showed that generation quality is highly dependent on retrieval effectiveness, which varies by task, and reasoning models outperformed standard LLMs in multi-source synthesis tasks.", "conclusion": "The study emphasizes that effective retrieval is crucial for long-form response generation from diverse sources, and existing models need advancements to improve synthesis quality.", "key_contributions": ["Introduction of a scalable framework for evaluating RAG systems on multi-source tasks", "Development of two new benchmarks for narrative synthesis and summarization", "Demonstration that reasoning models are more effective than LLMs in multi-source synthesis scenarios."], "limitations": "The benchmarks do not cover all possible real-world complexities of multi-source information retrieval and synthesis.", "keywords": ["retrieval-augmented generation", "multi-source retrieval", "information synthesis"], "importance_score": 8, "read_time_minutes": 15}}
{"id": "2508.20893", "pdf": "https://arxiv.org/pdf/2508.20893.pdf", "abs": "https://arxiv.org/abs/2508.20893", "title": "The Uneven Impact of Post-Training Quantization in Machine Translation", "authors": ["Benjamin Marie", "Atsushi Fujita"], "categories": ["cs.CL"], "comment": null, "summary": "Quantization is essential for deploying large language models (LLMs) on\nresource-constrained hardware, but its implications for multilingual tasks\nremain underexplored. We conduct the first large-scale evaluation of\npost-training quantization (PTQ) on machine translation across 55 languages\nusing five LLMs ranging from 1.7B to 70B parameters. Our analysis reveals that\nwhile 4-bit quantization often preserves translation quality for high-resource\nlanguages and large models, significant degradation occurs for low-resource and\ntypologically diverse languages, particularly in 2-bit settings. We compare\nfour quantization techniques (AWQ, BitsAndBytes, GGUF, and AutoRound), showing\nthat algorithm choice and model size jointly determine robustness. GGUF\nvariants provide the most consistent performance, even at 2-bit precision.\nAdditionally, we quantify the interactions between quantization, decoding\nhyperparameters, and calibration languages, finding that language-matched\ncalibration offers benefits primarily in low-bit scenarios. Our findings offer\nactionable insights for deploying multilingual LLMs for machine translation\nunder quantization constraints, especially in low-resource settings.", "AI": {"tldr": "This paper evaluates post-training quantization for multilingual machine translation across 55 languages, analyzing its effects on translation quality, especially for low-resource languages.", "motivation": "To understand the implications of quantization on deploying large language models (LLMs) for multilingual tasks, particularly in resource-constrained environments.", "method": "Conducted a large-scale evaluation of post-training quantization (PTQ) using five LLMs with varying parameters, examining four quantization techniques across high- and low-resource languages.", "result": "4-bit quantization generally maintains translation quality for high-resource languages, but 2-bit quantization leads to significant quality loss in low-resource and diverse languages. GGUF variants performed consistently well, especially at 2-bit precision.", "conclusion": "The study provides insights into the deployment of multilingual LLMs in translation tasks under quantization constraints, stressing the importance of model size and quantization methods.", "key_contributions": ["First large-scale evaluation of PTQ on machine translation across 55 languages.", "Identification of the impact of quantization techniques on translation quality for different language resources.", "Insights into model calibration and decoding hyperparameters under low-bit conditions."], "limitations": "Limited exploration of other language modeling tasks beyond machine translation; focuses mainly on specific quantization techniques.", "keywords": ["Quantization", "Machine Translation", "Large Language Models", "Low-resource Languages", "Post-training Quantization"], "importance_score": 8, "read_time_minutes": 10}}
{"id": "2508.20916", "pdf": "https://arxiv.org/pdf/2508.20916.pdf", "abs": "https://arxiv.org/abs/2508.20916", "title": "SageLM: A Multi-aspect and Explainable Large Language Model for Speech Judgement", "authors": ["Yuan Ge", "Junxiang Zhang", "Xiaoqian Liu", "Bei Li", "Xiangnan Ma", "Chenglong Wang", "Kaiyang Ye", "Yangfan Du", "Linfeng Zhang", "Yuxin Huang", "Tong Xiao", "Zhengtao Yu", "JingBo Zhu"], "categories": ["cs.CL"], "comment": null, "summary": "Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to\nnatural human-computer interaction, enabling end-to-end spoken dialogue\nsystems. However, evaluating these models remains a fundamental challenge. We\npropose \\texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech\nLLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches\nthat disregard acoustic features, SageLM jointly assesses both semantic and\nacoustic dimensions. Second, it leverages rationale-based supervision to\nenhance explainability and guide model learning, achieving superior alignment\nwith evaluation outcomes compared to rule-based reinforcement learning methods.\nThird, we introduce \\textit{SpeechFeedback}, a synthetic preference dataset,\nand employ a two-stage training paradigm to mitigate the scarcity of speech\npreference data. Trained on both semantic and acoustic dimensions, SageLM\nachieves an 82.79\\% agreement rate with human evaluators, outperforming\ncascaded and SLM-based baselines by at least 7.42\\% and 26.20\\%, respectively.", "AI": {"tldr": "SageLM is a multi-aspect, explainable speech LLM designed for evaluating Speech-to-Speech systems by jointly assessing semantic and acoustic dimensions, achieving a high agreement rate with human evaluators.", "motivation": "To address the fundamental challenge of evaluating Speech-to-Speech Large Language Models by creating a model that incorporates both semantic and acoustic evaluations.", "method": "SageLM jointly assesses semantic and acoustic features, uses rationale-based supervision for explainability, and employs a two-stage training paradigm using a synthetic preference dataset called SpeechFeedback.", "result": "SageLM achieved an 82.79% agreement rate with human evaluators, outperforming existing methods by considerable margins in both semantic and acoustic evaluations.", "conclusion": "SageLM demonstrates a more comprehensive and effective approach to evaluating Speech-to-Speech LLMs by integrating multiple aspects of dialogue quality and providing improved explainability.", "key_contributions": ["Introduction of a multi-aspect evaluation model for S2S LLMs", "Implementing rationale-based supervision for enhanced explainability", "Creation of the SpeechFeedback synthetic preference dataset"], "limitations": "", "keywords": ["speech-to-speech", "large language models", "explainable AI", "evaluation", "human-computer interaction"], "importance_score": 9, "read_time_minutes": 8}}
{"id": "2508.20931", "pdf": "https://arxiv.org/pdf/2508.20931.pdf", "abs": "https://arxiv.org/abs/2508.20931", "title": "How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on $$-bench", "authors": ["Venkatesh Mishra", "Amir Saeidi", "Satyam Raj", "Mutsumi Nakamura", "Jayanth Srinivasa", "Gaowen Liu", "Ali Payani", "Chitta Baral"], "categories": ["cs.CL"], "comment": "Accepted to EMNLP 2025 Findings", "summary": "Recent advances in reasoning and planning capabilities of large language\nmodels (LLMs) have enabled their potential as autonomous agents capable of tool\nuse in dynamic environments. However, in multi-turn conversational environments\nlike $\\tau$-bench, these agents often struggle with consistent reasoning,\nadherence to domain-specific policies, and extracting correct information over\na long horizon of tool-calls and conversation. To capture and mitigate these\nfailures, we conduct a comprehensive manual analysis of the common errors\noccurring in the conversation trajectories. We then experiment with\nreformulations of inputs to the tool-calling agent for improvement in agent\ndecision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)\nframework, which automatically reformulates user queries augmented with\nrelevant domain rules and tool suggestions for the tool-calling agent to focus\non. The results show that IRMA significantly outperforms ReAct, Function\nCalling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in\noverall pass^5 scores. These findings highlight the superior reliability and\nconsistency of IRMA compared to other methods in dynamic environments.", "AI": {"tldr": "This paper introduces the Input-Reformulation Multi-Agent (IRMA) framework to enhance large language models' performance in dynamic, multi-turn conversational environments by automatically reformulating user queries.", "motivation": "To address the failures of large language models as autonomous agents in maintaining consistent reasoning and adhering to domain-specific policies during tool-use in conversations.", "method": "A manual analysis of common errors in conversation trajectories was conducted, followed by experiments on reformulating inputs to improve decision making in agents. The IRMA framework was proposed to automatically reformulate user queries with domain rules and tool suggestions.", "result": "IRMA significantly outperformed other methods (ReAct, Function Calling, and Self-Reflection) by 16.1%, 12.7%, and 19.1%, respectively, in overall pass^5 scores.", "conclusion": "The findings demonstrate IRMA's superior reliability and consistency as a reformulation approach for tool-calling agents in dynamic environments.", "key_contributions": ["Introduction of the IRMA framework for query reformulation in LLMs", "Comprehensive analysis of common conversational errors in agent interactions", "Demonstrated significant performance improvements over existing methodologies"], "limitations": "", "keywords": ["large language models", "tool use", "multi-agent systems", "input reformulation", "conversational agents"], "importance_score": 9, "read_time_minutes": 12}}
{"id": "2508.20944", "pdf": "https://arxiv.org/pdf/2508.20944.pdf", "abs": "https://arxiv.org/abs/2508.20944", "title": "STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment", "authors": ["Jiaqian Li", "Qisheng Hu", "Jing Li", "Wenya Wang"], "categories": ["cs.CL"], "comment": "EMNLP 2025 Main", "summary": "In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to\nperform a wide range of tasks without task-specific fine-tuning. However, the\neffectiveness of ICL heavily depends on the quality of exemplar selection. In\nparticular, for structured prediction tasks such as semantic parsing, existing\nICL selection strategies often overlook structural alignment, leading to\nsuboptimal performance and poor generalization. To address this issue, we\npropose a novel two-stage exemplar selection strategy that achieves a strong\nbalance between efficiency, generalizability, and performance. First, we\nfine-tune a BERT-based retriever using structure-aware supervision, guiding it\nto select exemplars that are both semantically relevant and structurally\naligned. Then, we enhance the retriever with a plug-in module, which amplifies\nsyntactically meaningful information in the hidden representations. This\nplug-in is model-agnostic, requires minimal overhead, and can be seamlessly\nintegrated into existing pipelines. Experiments on four benchmarks spanning\nthree semantic parsing tasks demonstrate that our method consistently\noutperforms existing baselines with multiple recent LLMs as inference-time\nmodels.", "AI": {"tldr": "This paper presents a novel two-stage exemplar selection strategy for improving In-Context Learning (ICL) in structured prediction tasks, focusing on semantic parsing. The proposed method enhances exemplar selection by ensuring structural alignment and semantic relevance, outperforming existing methods on multiple benchmarks.", "motivation": "To improve the effectiveness of In-Context Learning (ICL) for structured prediction tasks by addressing the limitations in existing exemplar selection strategies, particularly the lack of structural alignment.", "method": "A two-stage exemplar selection strategy that first fine-tunes a BERT-based retriever using structure-aware supervision to select exemplars. This is followed by enhancing the retriever with a plug-in module that amplifies syntactically meaningful information in hidden representations.", "result": "The proposed method significantly outperforms existing approaches on four benchmarks across three semantic parsing tasks using various recent LLMs for inference.", "conclusion": "The new two-stage approach provides a strong balance between efficiency, generalizability, and performance, making it effective for semantic parsing tasks in ICL settings.", "key_contributions": ["Introduction of a two-stage exemplar selection strategy for ICL", "Utilization of structure-aware supervision for exemplar selection", "A plug-in module that enhances hidden representations for better semantic alignment"], "limitations": "", "keywords": ["In-Context Learning", "Semantic Parsing", "Exemplar Selection", "BERT", "Machine Learning"], "importance_score": 9, "read_time_minutes": 6}}
{"id": "2508.20973", "pdf": "https://arxiv.org/pdf/2508.20973.pdf", "abs": "https://arxiv.org/abs/2508.20973", "title": "ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents", "authors": ["Tianjian Liu", "Fanqi Wan", "Jiajian Guo", "Xiaojun Quan"], "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "21 pages, 6 Figures", "summary": "Proactive dialogue has emerged as a critical and challenging research problem\nin advancing large language models (LLMs). Existing works predominantly focus\non domain-specific or task-oriented scenarios, which leads to fragmented\nevaluations and limits the comprehensive exploration of models' proactive\nconversation abilities. In this work, we propose ProactiveEval, a unified\nframework designed for evaluating proactive dialogue capabilities of LLMs. This\nframework decomposes proactive dialogue into target planning and dialogue\nguidance, establishing evaluation metrics across various domains. Moreover, it\nalso enables the automatic generation of diverse and challenging evaluation\ndata. Based on the proposed framework, we develop 328 evaluation environments\nspanning 6 distinct domains. Through experiments with 22 different types of\nLLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional\nperformance on target planning and dialogue guidance tasks, respectively.\nFinally, we investigate how reasoning capabilities influence proactive\nbehaviors and discuss their implications for future model development.", "AI": {"tldr": "This paper introduces ProactiveEval, a framework for evaluating proactive dialogue capabilities of large language models (LLMs) across various domains.", "motivation": "The need for a comprehensive evaluation of proactive dialogue abilities in LLMs due to fragmented existing evaluations that focus on domain-specific or task-oriented scenarios.", "method": "The framework decomposes proactive dialogue into target planning and dialogue guidance, establishing evaluation metrics and generating diverse evaluation data across 328 environments in 6 domains.", "result": "Experiments with 22 LLMs revealed that DeepSeek-R1 and Claude-3.7-Sonnet excelled in target planning and dialogue guidance tasks respectively.", "conclusion": "The study highlights the influence of reasoning capabilities on proactive dialogue behaviors and suggests directions for future model development.", "key_contributions": ["Introduction of ProactiveEval for unified evaluation of proactive dialogue in LLMs.", "Creation of 328 evaluation environments across different domains.", "Insights into how reasoning affects proactive dialogue capabilities."], "limitations": "The framework may not cover all aspects of proactive dialogue and may require further domain-specific adaptation.", "keywords": ["Proactive Dialogue", "Large Language Models", "Evaluation Framework", "NLP", "AI"], "importance_score": 8, "read_time_minutes": 21}}
{"id": "2508.21004", "pdf": "https://arxiv.org/pdf/2508.21004.pdf", "abs": "https://arxiv.org/abs/2508.21004", "title": "Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution", "authors": ["Chen Chen", "Yuchen Sun", "Jiaxin Gao", "Xueluan Gong", "Qian Wang", "Ziyao Wang", "Yongsen Zheng", "Kwok-Yan Lam"], "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have seen significant advancements, achieving\nsuperior performance in various Natural Language Processing (NLP) tasks.\nHowever, they remain vulnerable to backdoor attacks, where models behave\nnormally for standard queries but generate harmful responses or unintended\noutput when specific triggers are activated. Existing backdoor defenses either\nlack comprehensiveness, focusing on narrow trigger settings, detection-only\nmechanisms, and limited domains, or fail to withstand advanced scenarios like\nmodel-editing-based, multi-trigger, and triggerless attacks. In this paper, we\npresent LETHE, a novel method to eliminate backdoor behaviors from LLMs through\nknowledge dilution using both internal and external mechanisms. Internally,\nLETHE leverages a lightweight dataset to train a clean model, which is then\nmerged with the backdoored model to neutralize malicious behaviors by diluting\nthe backdoor impact within the model's parametric memory. Externally, LETHE\nincorporates benign and semantically relevant evidence into the prompt to\ndistract LLM's attention from backdoor features. Experimental results on\nclassification and generation domains across 5 widely used LLMs demonstrate\nthat LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor\nattacks. LETHE reduces the attack success rate of advanced backdoor attacks by\nup to 98% while maintaining model utility. Furthermore, LETHE has proven to be\ncost-efficient and robust against adaptive backdoor attacks.", "AI": {"tldr": "LETHE is a novel method designed to eliminate backdoor behaviors in large language models (LLMs) through knowledge dilution, effectively neutralizing malicious triggers while maintaining model performance.", "motivation": "The paper addresses the vulnerability of LLMs to backdoor attacks, highlighting the need for comprehensive defenses against a range of attack types.", "method": "LETHE combines an internal approach using a lightweight dataset to train a clean model, and an external mechanism that adds benign evidence to prompts, distracting the model from backdoor features.", "result": "Experimental results show that LETHE significantly reduces the attack success rate of advanced backdoor attacks by up to 98% across five popular LLMs, while preserving model utility.", "conclusion": "LETHE is a cost-efficient and robust solution to enhance the security of LLMs against a variety of backdoor attacks.", "key_contributions": ["Introduction of LETHE for backdoor defense in LLMs", "Demonstrated superiority of LETHE over eight state-of-the-art defense methods", "Proved effectiveness across multiple widely used language models"], "limitations": "", "keywords": ["large language models", "backdoor attacks", "defense mechanisms", "knowledge dilution", "natural language processing"], "importance_score": 9, "read_time_minutes": 8}}
{"id": "2508.21024", "pdf": "https://arxiv.org/pdf/2508.21024.pdf", "abs": "https://arxiv.org/abs/2508.21024", "title": "An Agile Method for Implementing Retrieval Augmented Generation Tools in Industrial SMEs", "authors": ["Mathieu Bourdin", "Anas Neumann", "Thomas Paviot", "Robert Pellerin", "Samir Lamouri"], "categories": ["cs.CL", "cs.IR"], "comment": "20 pages, 3 figures", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to\nmitigate the limitations of Large Language Models (LLMs), such as\nhallucinations and outdated knowledge. However, deploying RAG-based tools in\nSmall and Medium Enterprises (SMEs) remains a challenge due to their limited\nresources and lack of expertise in natural language processing (NLP). This\npaper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a\nstructured, agile method designed to facilitate the deployment of RAG systems\nin industrial SME contexts. EASI-RAG is based on method engineering principles\nand comprises well-defined roles, activities, and techniques. The method was\nvalidated through a real-world case study in an environmental testing\nlaboratory, where a RAG tool was implemented to answer operators queries using\ndata extracted from operational procedures. The system was deployed in under a\nmonth by a team with no prior RAG experience and was later iteratively improved\nbased on user feedback. Results demonstrate that EASI-RAG supports fast\nimplementation, high user adoption, delivers accurate answers, and enhances the\nreliability of underlying data. This work highlights the potential of RAG\ndeployment in industrial SMEs. Future works include the need for generalization\nacross diverse use cases and further integration with fine-tuned models.", "AI": {"tldr": "The paper introduces EASI-RAG, a method to support the deployment of Retrieval-Augmented Generation (RAG) systems in Small and Medium Enterprises (SMEs), validated through a case study in an environmental testing laboratory.", "motivation": "To address the challenges of deploying RAG systems in SMEs, which often lack resources and NLP expertise.", "method": "EASI-RAG, based on method engineering principles, involves structured roles, activities, and techniques for implementation.", "result": "The deployment of a RAG tool in a real-world case study was completed in under a month, resulting in high user adoption and accurate query responses.", "conclusion": "EASI-RAG demonstrates the feasibility of RAG deployment in industrial contexts, with future work focused on generalizing the method and integrating it with fine-tuned models.", "key_contributions": ["Introduction of EASI-RAG method for RAG deployment in SMEs", "Validation through a case study showing effective implementation", "Demonstrated improvements in user adoption and data reliability"], "limitations": "Further research needed for generalization across diverse use cases and model integration.", "keywords": ["Retrieval-Augmented Generation", "Human-Computer Interaction", "Natural Language Processing", "Small and Medium Enterprises", "Method Engineering"], "importance_score": 9, "read_time_minutes": 20}}
{"id": "2508.21049", "pdf": "https://arxiv.org/pdf/2508.21049.pdf", "abs": "https://arxiv.org/abs/2508.21049", "title": "Re-Representation in Sentential Relation Extraction with Sequence Routing Algorithm", "authors": ["Ramazan Ali Bahrami", "Ramin Yahyapour"], "categories": ["cs.CL"], "comment": "Presented in 8th International Conference on Natural Language and\n  Speech Processing (ICNLSP), 25-27 August 2025, SDU, Odense, Denmark", "summary": "Sentential relation extraction (RE) is an important task in natural language\nprocessing (NLP). In this paper we propose to do sentential RE with dynamic\nrouting in capsules. We first show that the proposed approach outperform state\nof the art on common sentential relation extraction datasets Tacred, Tacredrev,\nRetacred, and Conll04. We then investigate potential reasons for its good\nperformance on the mentioned datasets, and yet low performance on another\nsimilar, yet larger sentential RE dataset, Wikidata. As such, we identify noise\nin Wikidata labels as one of the reasons that can hinder performance.\nAdditionally, we show associativity of better performance with better\nre-representation, a term from neuroscience referred to change of\nrepresentation in human brain to improve the match at comparison time. As\nexample, in the given analogous terms King:Queen::Man:Woman, at comparison\ntime, and as a result of re-representation, the similarity between related head\nterms (King,Man), and tail terms (Queen,Woman) increases. As such, our\nobservation show that our proposed model can do re-representation better than\nthe vanilla model compared with. To that end, beside noise in the labels of the\ndistantly supervised RE datasets, we propose re-representation as a challenge\nin sentential RE.", "AI": {"tldr": "This paper presents an approach for sentential relation extraction using dynamic routing in capsules, achieving superior performance on certain datasets while revealing challenges like noise in larger datasets.", "motivation": "To improve sentential relation extraction in NLP and understand the factors influencing performance on different datasets.", "method": "The approach utilizes dynamic routing in capsules to enhance the extraction of relations between sentences.", "result": "The proposed method outperforms state-of-the-art models on Tacred, Tacredrev, Retacred, and Conll04 datasets, but faces challenges with noise in the labels of the larger Wikidata dataset.", "conclusion": "Re-representation is identified as a significant aspect of improving performance in sentential relation extraction, with implications for understanding the impact of label noise.", "key_contributions": ["Dynamic routing in capsules for sentential relation extraction", "Identification of noise in labels as a performance inhibitor", "Introduction of the concept of re-representation for better matching"], "limitations": "The findings regarding noise in Wikidata labels highlight limitations in generalizability to larger datasets.", "keywords": ["sentential relation extraction", "dynamic routing", "neuroscience", "re-representation", "noise in labels"], "importance_score": 6, "read_time_minutes": 15}}
{"id": "2508.21051", "pdf": "https://arxiv.org/pdf/2508.21051.pdf", "abs": "https://arxiv.org/abs/2508.21051", "title": "Enabling Equitable Access to Trustworthy Financial Reasoning", "authors": ["William Jurayj", "Nils Holzenberger", "Benjamin Van Durme"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "According to the United States Internal Revenue Service, ''the average\nAmerican spends $\\$270$ and 13 hours filing their taxes''. Even beyond the\nU.S., tax filing requires complex reasoning, combining application of\noverlapping rules with numerical calculations. Because errors can incur costly\npenalties, any automated system must deliver high accuracy and auditability,\nmaking modern large language models (LLMs) poorly suited for this task. We\npropose an approach that integrates LLMs with a symbolic solver to calculate\ntax obligations. We evaluate variants of this system on the challenging\nStAtutory Reasoning Assessment (SARA) dataset, and include a novel method for\nestimating the cost of deploying such a system based on real-world penalties\nfor tax errors. We further show how combining up-front translation of\nplain-text rules into formal logic programs, combined with intelligently\nretrieved exemplars for formal case representations, can dramatically improve\nperformance on this task and reduce costs to well below real-world averages.\nOur results demonstrate the promise and economic feasibility of neuro-symbolic\narchitectures for increasing equitable access to reliable tax assistance.", "AI": {"tldr": "The paper proposes a neuro-symbolic approach to automate tax filing by integrating LLMs with symbolic solvers, aiming to enhance accuracy and auditability while reducing costs.", "motivation": "Tax filing involves complex reasoning and high stakes due to potential penalties for errors, necessitating accurate automated systems.", "method": "The proposed system integrates large language models with a symbolic solver, enhancing performance through translation of tax rules into formal logic and using exemplars for case representations.", "result": "Evaluations on the StAtutory Reasoning Assessment (SARA) dataset show improved performance and cost reductions compared to traditional methods.", "conclusion": "Neuro-symbolic architectures can significantly enhance access to reliable tax assistance while maintaining economic feasibility.", "key_contributions": ["Integration of LLMs with symbolic solvers for tax filing automation", "Method for estimating deployment costs based on penalties", "Improvement of performance via translation of text rules into formal logic"], "limitations": "The dependency on the quality of the symbolic reasoning component may limit generalization to all tax scenarios.", "keywords": ["Tax Automation", "Large Language Models", "Symbolic Reasoning", "Neuro-Symbolic Architectures", "Cost Estimation"], "importance_score": 5, "read_time_minutes": 10}}
{"id": "2203.13722", "pdf": "https://arxiv.org/pdf/2203.13722.pdf", "abs": "https://arxiv.org/abs/2203.13722", "title": "Probing Pre-Trained Language Models for Cross-Cultural Differences in Values", "authors": ["Arnav Arora", "Lucie-Aime Kaffee", "Isabelle Augenstein"], "categories": ["cs.CL"], "comment": "Accepted to C3NLP, EACL 2023:\n  https://aclanthology.org/2023.c3nlp-1.12/", "summary": "Language embeds information about social, cultural, and political values\npeople hold. Prior work has explored social and potentially harmful biases\nencoded in Pre-Trained Language models (PTLMs). However, there has been no\nsystematic study investigating how values embedded in these models vary across\ncultures. In this paper, we introduce probes to study which values across\ncultures are embedded in these models, and whether they align with existing\ntheories and cross-cultural value surveys. We find that PTLMs capture\ndifferences in values across cultures, but those only weakly align with\nestablished value surveys. We discuss implications of using mis-aligned models\nin cross-cultural settings, as well as ways of aligning PTLMs with value\nsurveys.", "AI": {"tldr": "The paper studies the cultural values embedded in Pre-Trained Language Models (PTLMs) and their alignment with established value surveys.", "motivation": "To systematically investigate how cultural values are represented in PTLMs and their implications in cross-cultural applications.", "method": "The authors introduce probes to analyze and compare the values embedded in PTLMs against established cross-cultural value surveys.", "result": "The study finds that PTLMs capture cultural value differences, but these do not strongly align with established value surveys.", "conclusion": "Misalignment of values in PTLMs may have implications for their use in diverse cultural contexts, suggesting a need for alignment methods.", "key_contributions": ["Introduced probes for analyzing cultural values in PTLMs", "Found weak alignment of PTLM values with cultural surveys", "Discussed implications and alignment strategies for PTLMs in cross-cultural settings"], "limitations": "The exploration of cultural values is still nascent and the methods may not capture all aspects of cultural nuances.", "keywords": ["Pre-Trained Language Models", "cultural values", "cross-cultural studies", "bias in NLP", "alignment of models"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2312.05821", "pdf": "https://arxiv.org/pdf/2312.05821.pdf", "abs": "https://arxiv.org/abs/2312.05821", "title": "ASVD: Activation-aware Singular Value Decomposition for Compressing Large Language Models", "authors": ["Zhihang Yuan", "Yuzhang Shang", "Yue Song", "Dawei Yang", "Qiang Wu", "Yan Yan", "Guangyu Sun"], "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we introduce a new post-training compression paradigm for\nLarge Language Models (LLMs) to facilitate their wider adoption. We delve into\nLLM weight low-rank decomposition, and find that the challenges of this task\nstem from (1) the distribution variance in the LLM activations and (2) the\nsensitivity difference among various kinds of layers. To address these issues,\nwe propose a training-free approach called Activation-aware Singular Value\nDecomposition (ASVD). Specifically, ASVD manages activation outliers by\ntransforming the weight matrix based on the activation distribution. This\ntransformation allows the outliers in the activation matrix to be absorbed into\nthe transformed weight matrix, thereby enhancing decomposition accuracy.\nAdditionally, we propose an efficient iterative calibration process to optimize\nlayer-specific decomposition by addressing the varying sensitivity of different\nLLM layers. In this way, ASVD can compress a network by 10%-30%. Based on the\nsuccess of the low-rank decomposition of projection matrices in the\nself-attention module, we further introduce ASVD to compress the KV cache. By\nreducing the channel dimension of KV activations, memory requirements for KV\ncache can be largely reduced. ASVD can further achieve 50% KV cache reductions\nwithout performance drop in a training-free manner.", "AI": {"tldr": "This paper presents a new compression method for Large Language Models called Activation-aware Singular Value Decomposition (ASVD), which addresses challenges in weight decomposition and achieves significant reductions in memory usage and model size without compromising performance.", "motivation": "The need for wider adoption of Large Language Models (LLMs) due to their size and resource requirements motivates the exploration of new compression techniques.", "method": "The paper introduces ASVD, a training-free approach that applies low-rank decomposition while managing activation outliers and optimizing layer-specific decomposition through an iterative calibration process.", "result": "ASVD can compress LLM networks by 10%-30% and achieve up to 50% reduction in KV cache memory requirements without any performance drop.", "conclusion": "The proposed ASVD method contributes to more efficient deployment of LLMs by significantly reducing size and resource demands while maintaining performance.", "key_contributions": ["Introduction of Activation-aware Singular Value Decomposition (ASVD) for LLM compression", "Demonstration of layer-specific optimization in weight decomposition", "Significant KV cache memory reductions without performance loss"], "limitations": "", "keywords": ["Large Language Models", "Compression", "Activation-aware Singular Value Decomposition", "Low-rank Decomposition", "KV Cache"], "importance_score": 9, "read_time_minutes": 15}}
{"id": "2405.07764", "pdf": "https://arxiv.org/pdf/2405.07764.pdf", "abs": "https://arxiv.org/abs/2405.07764", "title": "LGDE: Local Graph-based Dictionary Expansion", "authors": ["Juni Schindler", "Sneha Jha", "Xixuan Zhang", "Kilian Buehling", "Annett Heft", "Mauricio Barahona"], "categories": ["cs.CL", "cs.SI", "physics.soc-ph"], "comment": "Python code available at:\n  https://github.com/barahona-research-group/LGDE", "summary": "We present Local Graph-based Dictionary Expansion (LGDE), a method for\ndata-driven discovery of the semantic neighbourhood of words using tools from\nmanifold learning and network science. At the heart of LGDE lies the creation\nof a word similarity graph from the geometry of word embeddings followed by\nlocal community detection based on graph diffusion. The diffusion in the local\ngraph manifold allows the exploration of the complex nonlinear geometry of word\nembeddings to capture word similarities based on paths of semantic association,\nover and above direct pairwise similarities. Exploiting such semantic\nneighbourhoods enables the expansion of dictionaries of pre-selected keywords,\nan important step for tasks in information retrieval, such as database queries\nand online data collection. We validate LGDE on two user-generated\nEnglish-language corpora and show that LGDE enriches the list of keywords with\nimproved performance relative to methods based on direct word similarities or\nco-occurrences. We further demonstrate our method through a real-world use case\nfrom communication science, where LGDE is evaluated quantitatively on the\nexpansion of a conspiracy-related dictionary from online data collected and\nanalysed by domain experts. Our empirical results and expert user assessment\nindicate that LGDE expands the seed dictionary with more useful keywords due to\nthe manifold-learning-based similarity network.", "AI": {"tldr": "The paper introduces Local Graph-based Dictionary Expansion (LGDE), a new method for discovering word similarities using graph diffusion and manifold learning, ultimately enhancing keyword expansion for information retrieval tasks.", "motivation": "To improve keyword expansion in information retrieval by exploring semantic neighbourhoods of words beyond direct similarities.", "method": "The LGDE method creates a word similarity graph using word embeddings and applies local community detection based on graph diffusion to capture complex word similarities.", "result": "Validation on user-generated corpora shows that LGDE enriches keyword lists significantly more than traditional methods based on direct similarities or co-occurrences.", "conclusion": "LGDE effectively expands the seed dictionary with more relevant keywords, as demonstrated in a real-world application in communication science.", "key_contributions": ["Introduction of a novel method for semantic neighbourhood discovery using local graph techniques.", "Validation of LGDE on real-world datasets and domains.", "Demonstration of improved keyword expansion for information retrieval tasks."], "limitations": "", "keywords": ["graph-based methods", "dictionary expansion", "word embeddings", "semantic similarity", "information retrieval"], "importance_score": 7, "read_time_minutes": 10}}
{"id": "2405.14862", "pdf": "https://arxiv.org/pdf/2405.14862.pdf", "abs": "https://arxiv.org/abs/2405.14862", "title": "Bitune: Leveraging Bidirectional Attention to Improve Decoder-Only LLMs", "authors": ["Dawid J. Kopiczko", "Tijmen Blankevoort", "Yuki M. Asano"], "categories": ["cs.CL"], "comment": null, "summary": "Decoder-only large language models typically rely solely on masked causal\nattention, which limits their expressiveness by restricting information flow to\none direction. We propose Bitune, a method that enhances pretrained\ndecoder-only LLMs by incorporating bidirectional attention into prompt\nprocessing. We evaluate Bitune in instruction-tuning and question-answering\nsettings, showing significant improvements in performance on commonsense\nreasoning, arithmetic, and language understanding tasks. Furthermore, extensive\nablation studies validate the role of each component of the method, and\ndemonstrate that Bitune is compatible with various parameter-efficient\nfinetuning techniques and full model finetuning.", "AI": {"tldr": "Bitune enhances decoder-only LLMs with bidirectional attention, improving performance in various tasks.", "motivation": "To address the limitations of masked causal attention in decoder-only large language models, which restricts information flow and expressiveness.", "method": "Introducing Bitune, which incorporates bidirectional attention into the prompt processing of pretrained decoder-only LLMs.", "result": "Significant performance improvements were observed in commonsense reasoning, arithmetic, and language understanding tasks during evaluation in instruction-tuning and question-answering settings.", "conclusion": "Bitune is effective and compatible with parameter-efficient finetuning techniques and full model finetuning, validated through ablation studies.", "key_contributions": ["Proposed a novel method, Bitune, for incorporating bidirectional attention into decoder-only LLMs.", "Demonstrated significant improvements across various performance metrics in NLP tasks.", "Validated compatibility with parameter-efficient finetuning techniques."], "limitations": "", "keywords": ["large language models", "bidirectional attention", "instruction tuning"], "importance_score": 8, "read_time_minutes": 5}}
{"id": "2405.15165", "pdf": "https://arxiv.org/pdf/2405.15165.pdf", "abs": "https://arxiv.org/abs/2405.15165", "title": "SoAy: A Solution-based LLM API-using Methodology for Academic Information Seeking", "authors": ["Yuanchun Wang", "Jifan Yu", "Zijun Yao", "Jing Zhang", "Yuyang Xie", "Shangqing Tu", "Yiyang Fu", "Youhe Feng", "Jinkai Zhang", "Jingyao Zhang", "Bowen Huang", "Yuanyao Li", "Huihui Yuan", "Lei Hou", "Juanzi Li", "Jie Tang"], "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": "KDD 2025; 22 pages, 13 figures", "summary": "Applying large language models (LLMs) for academic API usage shows promise in\nreducing researchers' academic information seeking efforts. However, current\nLLM API-using methods struggle with complex API coupling commonly encountered\nin academic queries. To address this, we introduce SoAy, a solution-based LLM\nAPI-using methodology for academic information seeking. It uses code with a\nsolution as the reasoning method, where a solution is a pre-constructed API\ncalling sequence. The addition of the solution reduces the difficulty for the\nmodel to understand the complex relationships between APIs. Code improves the\nefficiency of reasoning.\n  To evaluate SoAy, we introduce SoAyBench, an evaluation benchmark accompanied\nby SoAyEval, built upon a cloned environment of APIs from AMiner. Experimental\nresults demonstrate a 34.58-75.99\\% performance improvement compared to\nstate-of-the-art LLM API-based baselines. All datasets, codes, tuned models,\nand deployed online services are publicly accessible at\nhttps://github.com/RUCKBReasoning/SoAy.", "AI": {"tldr": "This paper presents SoAy, a methodology leveraging large language models (LLMs) for improved academic API usage in information seeking, addressing complex API interactions through pre-constructed solution sequences.", "motivation": "To simplify the academic information seeking process and enhance the efficiency of using LLMs with complex API couplings.", "method": "SoAy utilizes code with a pre-constructed API calling sequence as a reasoning method to better capture complex relationships between APIs.", "result": "Experimental results indicate a performance improvement of 34.58-75.99% over existing LLM API-based methods.", "conclusion": "SoAy demonstrates significant enhancements in reasoning efficiency for academic queries requiring complex API interactions, supported by an evaluation benchmark and publicly accessible resources.", "key_contributions": ["Development of SoAy methodology for LLM API usage in academic contexts", "Introduction of SoAyBench and SoAyEval for comprehensive evaluation", "Significant performance improvements validated through experiments"], "limitations": "", "keywords": ["large language models", "academic API", "information seeking", "complex API coupling", "SoAy"], "importance_score": 9, "read_time_minutes": 20}}
{"id": "2411.07820", "pdf": "https://arxiv.org/pdf/2411.07820.pdf", "abs": "https://arxiv.org/abs/2411.07820", "title": "Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models", "authors": ["Youan Cong", "Pritom Saha Akash", "Cheng Wang", "Kevin Chen-Chuan Chang"], "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "We introduce the Extract-Refine-Retrieve-Read (ERRR) framework, a novel\napproach designed to bridge the pre-retrieval information gap in\nRetrieval-Augmented Generation (RAG) systems through query optimization\ntailored to meet the specific knowledge requirements of Large Language Models\n(LLMs). Unlike conventional query optimization techniques used in RAG, the ERRR\nframework begins by extracting parametric knowledge from LLMs, followed by\nusing a specialized query optimizer for refining these queries. This process\nensures the retrieval of only the most pertinent information essential for\ngenerating accurate responses. Moreover, to enhance flexibility and reduce\ncomputational costs, we propose a trainable scheme for our pipeline that\nutilizes a smaller, tunable model as the query optimizer, which is refined\nthrough knowledge distillation from a larger teacher model. Our evaluations on\nvarious question-answering (QA) datasets and with different retrieval systems\nshow that ERRR consistently outperforms existing baselines, proving to be a\nversatile and cost-effective module for improving the utility and accuracy of\nRAG systems.", "AI": {"tldr": "The ERRR framework optimizes queries for RAG systems by extracting knowledge from LLMs and refining queries to enhance information retrieval and response accuracy.", "motivation": "To address the pre-retrieval information gap in Retrieval-Augmented Generation systems and optimize query handling for better performance with LLMs.", "method": "The ERRR framework employs a multi-step process starting with extraction of parametric knowledge from LLMs, followed by specialized query optimization and knowledge distillation to refine the queries using a smaller model.", "result": "ERRR outperforms existing query optimization techniques in RAG systems on multiple question-answering datasets, showcasing superior utility and accuracy while being cost-effective.", "conclusion": "The ERRR framework is a versatile and efficient solution for improving retrieval mechanisms in RAG systems, ultimately aiming for enhanced response accuracy in various applications.", "key_contributions": ["Introduction of the ERRR framework for query optimization in RAG systems", "Utilization of parametric knowledge extraction from LLMs", "Implementation of a trainable query optimizer through knowledge distillation"], "limitations": "", "keywords": ["Retrieval-Augmented Generation", "Large Language Models", "query optimization"], "importance_score": 9, "read_time_minutes": 10}}
{"id": "2502.19074", "pdf": "https://arxiv.org/pdf/2502.19074.pdf", "abs": "https://arxiv.org/abs/2502.19074", "title": "Improving the quality of Web-mined Parallel Corpora of Low-Resource Languages using Debiasing Heuristics", "authors": ["Aloka Fernando", "Nisansa de Silva", "Menan Velyuthan", "Charitha Rathnayake", "Surangika Ranathunga"], "categories": ["cs.CL"], "comment": null, "summary": "Parallel Data Curation (PDC) techniques aim to filter out noisy parallel\nsentences from the web-mined corpora. Prior research has demonstrated that\nranking sentence pairs using similarity scores on sentence embeddings derived\nfrom Pre-trained Multilingual Language Models (multiPLMs) and training the NMT\nsystems with the top-ranked samples, produces superior NMT performance than\nwhen trained using the full dataset. However, previous research has shown that\nthe choice of multiPLM significantly impacts the ranking quality. This paper\ninvestigates the reasons behind this disparity across multiPLMs. Using the\nweb-mined corpora CCMatrix and CCAligned for En$\\rightarrow$Si,\nEn$\\rightarrow$Ta and Si$\\rightarrow$Ta, we show that different multiPLMs\n(LASER3, XLM-R, and LaBSE) are biased towards certain types of sentences, which\nallows noisy sentences to creep into the top-ranked samples. We show that by\nemploying a series of heuristics, this noise can be removed to a certain\nextent. This results in improving the results of NMT systems trained with\nweb-mined corpora and reduces the disparity across multiPLMs.", "AI": {"tldr": "This paper examines how different pre-trained multilingual language models (multiPLMs) affect the ranking quality of sentence pairs in parallel data curation, aiming to improve neural machine translation (NMT) performance by filtering out noisy sentences using various heuristics.", "motivation": "The study investigates the impact of multiPLM choice on ranking quality in parallel data curation, which is crucial for enhancing NMT performance.", "method": "The authors analyze multiPLMs (LASER3, XLM-R, LaBSE) using web-mined corpora (CCMatrix and CCAligned) across various language pairs and apply heuristics to reduce noise in top-ranked sentences.", "result": "The research demonstrates that different multiPLMs show biases towards specific sentence types, leading to noise in the top-ranked samples. Heuristics employed significantly reduce this noise.", "conclusion": "By refining the ranking process with heuristics, the quality of data for NMT training can be improved, benefiting performance and consistency across different multiPLMs.", "key_contributions": ["Identifies biases in multiPLMs that affect ranking quality in data curation.", "Proposes heuristics for noise reduction in top-ranked sentence pairs.", "Demonstrates improvements in NMT performance with filtered datasets."], "limitations": "", "keywords": ["multilingual language models", "parallel data curation", "neural machine translation"], "importance_score": 6, "read_time_minutes": 10}}
{"id": "2503.11302", "pdf": "https://arxiv.org/pdf/2503.11302.pdf", "abs": "https://arxiv.org/abs/2503.11302", "title": "Are formal and functional linguistic mechanisms dissociated in language models?", "authors": ["Michael Hanna", "Yonatan Belinkov", "Sandro Pezzelle"], "categories": ["cs.CL", "I.2.7"], "comment": "To appear in Computational Linguistics. Pre-MIT Press publication\n  version. 40 pages, 14 figures, 3 tables. Code available at\n  https://github.com/hannamw/formal-functional-dissociation", "summary": "Although large language models (LLMs) are increasingly capable, these\ncapabilities are unevenly distributed: they excel at formal linguistic tasks,\nsuch as producing fluent, grammatical text, but struggle more with functional\nlinguistic tasks like reasoning and consistent fact retrieval. Inspired by\nneuroscience, recent work suggests that to succeed on both formal and\nfunctional linguistic tasks, LLMs should use different mechanisms for each;\nsuch localization could either be built-in or emerge spontaneously through\ntraining. In this paper, we ask: do current models, with fast-improving\nfunctional linguistic abilities, exhibit distinct localization of formal and\nfunctional linguistic mechanisms? We answer this by finding and comparing the\n\"circuits\", or minimal computational subgraphs, responsible for various formal\nand functional tasks. Comparing 5 LLMs across 10 distinct tasks, we find that\nwhile there is indeed little overlap between circuits for formal and functional\ntasks, there is also little overlap between formal linguistic tasks, as exists\nin the human brain. Thus, a single formal linguistic network, unified and\ndistinct from functional task circuits, remains elusive. However, in terms of\ncross-task faithfulness - the ability of one circuit to solve another's task -\nwe observe a separation between formal and functional mechanisms, suggesting\nthat shared mechanisms between formal tasks may exist.", "AI": {"tldr": "This paper investigates the localization of formal and functional linguistic mechanisms in large language models (LLMs) by analyzing computational circuits across various tasks.", "motivation": "Understanding the computational mechanisms behind LLMs' capabilities in formal and functional linguistic tasks can inform their design and application.", "method": "The study compares 'circuits', or minimal computational subgraphs, responsible for various tasks in 5 LLMs across 10 distinct tasks.", "result": "It was found that circuits for formal and functional tasks exhibit little overlap, as do circuits for different formal tasks, complicating the search for a unified formal linguistic network.", "conclusion": "The separation between formal and functional mechanisms suggests potential shared mechanisms for formal tasks, but a single unified network has not yet been identified.", "key_contributions": ["Identification of distinct circuits for formal and functional tasks in LLMs.", "Comparison of task circuits across multiple LLMs.", "Insights into the functional architecture of LLMs inspired by neuroscience."], "limitations": "The study does not conclusively identify a unified network and focuses on current model limitations.", "keywords": ["large language models", "formal linguistic tasks", "functional linguistic tasks"], "importance_score": 9, "read_time_minutes": 40}}
{"id": "2504.07612", "pdf": "https://arxiv.org/pdf/2504.07612.pdf", "abs": "https://arxiv.org/abs/2504.07612", "title": "SaRoHead: Detecting Satire in a Multi-Domain Romanian News Headline Dataset", "authors": ["Mihnea-Alexandru Vrlan", "Rzvan-Alexandru Smdu", "Dumitru-Clementin Cercel", "Florin Pop", "Mihaela-Claudia Cercel"], "categories": ["cs.CL"], "comment": "13 pages, 2 figures", "summary": "The primary goal of a news headline is to summarize an event in as few words\nas possible. Depending on the media outlet, a headline can serve as a means to\nobjectively deliver a summary or improve its visibility. For the latter,\nspecific publications may employ stylistic approaches that incorporate the use\nof sarcasm, irony, and exaggeration, key elements of a satirical approach. As\nsuch, even the headline must reflect the tone of the satirical main content.\nCurrent approaches for the Romanian language tend to detect the\nnon-conventional tone (i.e., satire and clickbait) of the news content by\ncombining both the main article and the headline. Because we consider a\nheadline to be merely a brief summary of the main article, we investigate in\nthis paper the presence of satirical tone in headlines alone, testing multiple\nbaselines ranging from standard machine learning algorithms to deep learning\nmodels. Our experiments show that Bidirectional Transformer models outperform\nboth standard machine-learning approaches and Large Language Models (LLMs),\nparticularly when the meta-learning Reptile approach is employed.", "AI": {"tldr": "The paper investigates the detection of satirical tone in Romanian news headlines using machine learning and deep learning models, finding that Bidirectional Transformers outperform other approaches.", "motivation": "To explore the effectiveness of detecting satirical tones specifically in news headlines, independent of the main article.", "method": "The study tests various models, including traditional machine learning algorithms and deep learning models, with a focus on Bidirectional Transformer models and the meta-learning Reptile approach.", "result": "The experiments reveal that Bidirectional Transformer models significantly surpass standard machine learning methods and LLMs in detecting satire in headlines.", "conclusion": "The findings suggest that focusing on headlines alone can be a viable method for identifying satirical content, with advanced models providing better accuracy.", "key_contributions": ["Demonstrated the feasibility of detecting satire in headlines without main article context", "Introduced the meta-learning Reptile approach in examining satirical headlines", "Showed superiority of Bidirectional Transformer models over traditional methods for this task"], "limitations": "", "keywords": ["satire detection", "news headlines", "machine learning", "deep learning", "Romanian language"], "importance_score": 4, "read_time_minutes": 15}}
{"id": "2504.12140", "pdf": "https://arxiv.org/pdf/2504.12140.pdf", "abs": "https://arxiv.org/abs/2504.12140", "title": "Multilingual Contextualization of Large Language Models for Document-Level Machine Translation", "authors": ["Miguel Moura Ramos", "Patrick Fernandes", "Sweta Agrawal", "Andr F. T. Martins"], "categories": ["cs.CL"], "comment": "COLM 2025", "summary": "Large language models (LLMs) have demonstrated strong performance in\nsentence-level machine translation, but scaling to document-level translation\nremains challenging, particularly in modeling long-range dependencies and\ndiscourse phenomena across sentences and paragraphs. In this work, we propose a\nmethod to improve LLM-based long-document translation through targeted\nfine-tuning on high-quality document-level data, which we curate and introduce\nas DocBlocks. Our approach supports multiple translation paradigms, including\ndirect document-to-document and chunk-level translation, by integrating\ninstructions both with and without surrounding context. This enables models to\nbetter capture cross-sentence dependencies while maintaining strong\nsentence-level translation performance. Experimental results show that\nincorporating multiple translation paradigms improves document-level\ntranslation quality and inference speed compared to prompting and agent-based\nmethods.", "AI": {"tldr": "This paper presents a method for enhancing document-level translation using large language models (LLMs) by introducing a curated dataset called DocBlocks for targeted fine-tuning.", "motivation": "Improving long-document translation, which remains a challenge due to long-range dependencies and discourse phenomena.", "method": "Targeted fine-tuning on a curated dataset (DocBlocks) that supports multiple translation paradigms, including direct document-to-document and chunk-level translation.", "result": "Incorporating multiple translation paradigms significantly enhances both the quality and speed of document-level translation compared to existing methods.", "conclusion": "The proposed approach effectively addresses the challenges in document-level translation by improving cross-sentence dependency capture while maintaining sentence-level performance.", "key_contributions": ["Introduction of DocBlocks for document-level translation training", "Demonstration of enhanced translation quality using multiple paradigms", "Improvement in inference speed over prompting and agent-based methods."], "limitations": "", "keywords": ["Language Models", "Document Translation", "Natural Language Processing"], "importance_score": 8, "read_time_minutes": 10}}
