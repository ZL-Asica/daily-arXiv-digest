{"id": "2504.16193", "pdf": "https://arxiv.org/pdf/2504.16193", "abs": "https://arxiv.org/abs/2504.16193", "authors": ["Carmine Attanasio", "Alireza Mortezapour"], "title": "Quality of explanation of xAI from the prespective of Italian end-users: Italian version of System Causability Scale (SCS)", "categories": ["cs.HC", "cs.AI"], "comment": "This work will be presented in Coperman 2025 Conference", "summary": "Background and aim: Considering the scope of the application of artificial\nintelligence beyond the field of computer science, one of the concerns of\nresearchers is to provide quality explanations about the functioning of\nalgorithms based on artificial intelligence and the data extracted from it. The\npurpose of the present study is to validate the Italian version of system\ncausability scale (I-SCS) to measure the quality of explanations provided in a\nxAI.\n  Method: For this purpose, the English version, initially provided in 2020 in\ncoordination with the main developer, was utilized. The forward-backward\ntranslation method was applied to ensure accuracy. Finally, these nine steps\nwere completed by calculating the content validity index/ratio and conducting\ncognitive interviews with representative end users.\n  Results: The original version of the questionnaire consisted of 10 questions.\nHowever, based on the obtained indexes (CVR below 0.49), one question (Question\n8) was entirely removed. After completing the aforementioned steps, the Italian\nversion contained 9 questions. The representative sample of Italian end users\nfully comprehended the meaning and content of the questions in the Italian\nversion.\n  Conclusion: The Italian version obtained in this study can be used in future\nresearch studies as well as in the field by xAI developers. This tool can be\nused to measure the quality of explanations provided for an xAI system in\nItalian culture."}
{"id": "2504.16295", "pdf": "https://arxiv.org/pdf/2504.16295", "abs": "https://arxiv.org/abs/2504.16295", "authors": ["Samuel J. Levulis", "Kevin W. Rio", "James Wilmott", "Charlie S. Burlingham", "Phillip Guan"], "title": "Subthreshold Jitter in VR Can Induce Visual Discomfort", "categories": ["cs.HC"], "comment": null, "summary": "Visual-vestibular conflicts (VVCs) are a primary contributor to visually\ninduced motion sickness (VIMS) in head-mounted displays (HMDs). However,\nvirtual reality (VR) comfort studies often rely on exposing seated or standing\nusers to experiences with high intensity visual motion (such as roller\ncoasters). These drastic VVCs tend to induce pronounced VIMS symptoms that can\nbe reliably detected across individuals using common survey measures. The\nconclusions from studies using these extreme motion-based conflicts may not\naccurately generalize to naturalistic use cases in VR where efforts are made to\nminimize, rather than maximize, VIMS symptoms. In this work, we show that a\nsubthreshold visual-vestibular conflict can induce measurable discomfort during\nnaturalistic, long duration use. We first present a psychophysical study,\nconducted outside of an HMD, to rigorously identify the perceptual thresholds\nfor sinusoidal noise in render pose (i.e., jitter) resulting in erroneous 3D\nmotion of rendered content. We next introduce subthreshold levels of jitter to\na Meta Quest 3 VR HMD and demonstrate that this can induce visual discomfort in\nparticipants playing the commercially-available game Cubism across a\nthree-session, repeated-measures study. Importantly, we did not identify\nstatistically significant comfort differences between control and jitter\nconditions with traditional pre- and post-test comparison of Simulator Sickness\nQuestionnaire (SSQ) scores. Significant differences were only identified using\nthe Motion Illness Symptoms Classification (MISC) survey administered every 10\nminutes across each 90 minute session. This highlights the benefits of\nincorporating time-resolved data points and suggests that lightweight, more\nfrequent surveys may be important tools for measuring visual discomfort in more\necologically-valid scenarios."}
{"id": "2504.16323", "pdf": "https://arxiv.org/pdf/2504.16323", "abs": "https://arxiv.org/abs/2504.16323", "authors": ["Merve Cerit", "Eric Zelikman", "Mu-Jung Cho", "Thomas N. Robinson", "Byron Reeves", "Nilam Ram", "Nick Haber"], "title": "Media Content Atlas: A Pipeline to Explore and Investigate Multidimensional Media Space using Multimodal LLMs", "categories": ["cs.HC", "cs.SI", "H.5.0; H.5.1; I.2; J.4"], "comment": "Accepted to CHI 2025, in press. See the project page at\n  mediacontentatlas.github.io", "summary": "As digital media use continues to evolve and influence various aspects of\nlife, developing flexible and scalable tools to study complex media experiences\nis essential. This study introduces the Media Content Atlas (MCA), a novel\npipeline designed to help researchers investigate large-scale screen data\nbeyond traditional screen-use metrics. Leveraging multimodal large language\nmodels (MLLMs), MCA enables moment-by-moment content analysis, content-based\nclustering, topic modeling, image retrieval, and interactive visualizations.\nEvaluated on 1.12 million smartphone screenshots continuously captured during\nscreen use from 112 adults over an entire month, MCA facilitates open-ended\nexploration and hypothesis generation as well as hypothesis-driven\ninvestigations at an unprecedented scale. Expert evaluators underscored its\nusability and potential for research and intervention design, with clustering\nresults rated 96% relevant and descriptions 83% accurate. By bridging\nmethodological possibilities with domain-specific needs, MCA accelerates both\ninductive and deductive inquiry, presenting new opportunities for media and HCI\nresearch."}
{"id": "2504.16373", "pdf": "https://arxiv.org/pdf/2504.16373", "abs": "https://arxiv.org/abs/2504.16373", "authors": ["Yasra Chandio", "Diana Romero", "Salma Elmalaki", "Fatima Anwar"], "title": "What Sensors See, What People Feel: Exploring Subjective Collaboration Perception in Mixed Reality", "categories": ["cs.HC"], "comment": "12 pages, 4 figures, 8 tables", "summary": "Mixed Reality (MR) enables rich, embodied collaboration, yet it's uncertain\nif sensor and system-logged behavioral signals capture how users experience\nthat collaboration. This disconnect stems from a fundamental gap: behavioral\nsignals are observable and continuous, while collaboration is interpreted\nsubjectively, shaped by internal states like presence, cognitive availability,\nand social awareness. Our core insight is that sensor signals serve as\nobservable manifestations of subjective experiences in MR collaboration, and\nthey can be captured through sensor data such as shared gaze, speech, spatial\nmovement, and other system-logged performance metrics. We propose the\nSensor-to-Subjective (S2S) Mapping Framework, a conceptual model that links\nobservable interaction patterns to users' subjective perceptions of\ncollaboration and internal cognitive states through sensor-based indicators and\ntask performance metrics. To validate this model, we conducted a study with 48\nparticipants across 12 MR groups engaged in a collaborative image-sorting task.\nOur findings show a correlation between sensed behavior and perceived\ncollaboration, particularly through shared attention and proximity."}
{"id": "2504.16188", "pdf": "https://arxiv.org/pdf/2504.16188", "abs": "https://arxiv.org/abs/2504.16188", "authors": ["Jabez Magomere", "Elena Kochkina", "Samuel Mensah", "Simerjot Kaur", "Charese H. Smiley"], "title": "FinNLI: Novel Dataset for Multi-Genre Financial Natural Language Inference Benchmarking", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce FinNLI, a benchmark dataset for Financial Natural Language\nInference (FinNLI) across diverse financial texts like SEC Filings, Annual\nReports, and Earnings Call transcripts. Our dataset framework ensures diverse\npremise-hypothesis pairs while minimizing spurious correlations. FinNLI\ncomprises 21,304 pairs, including a high-quality test set of 3,304 instances\nannotated by finance experts. Evaluations show that domain shift significantly\ndegrades general-domain NLI performance. The highest Macro F1 scores for\npre-trained (PLMs) and large language models (LLMs) baselines are 74.57% and\n78.62%, respectively, highlighting the dataset's difficulty. Surprisingly,\ninstruction-tuned financial LLMs perform poorly, suggesting limited\ngeneralizability. FinNLI exposes weaknesses in current LLMs for financial\nreasoning, indicating room for improvement."}
{"id": "2504.16109", "pdf": "https://arxiv.org/pdf/2504.16109", "abs": "https://arxiv.org/abs/2504.16109", "authors": ["Jun-Peng Jiang", "Si-Yang Liu", "Hao-Run Cai", "Qile Zhou", "Han-Jia Ye"], "title": "Representation Learning for Tabular Data: A Comprehensive Survey", "categories": ["cs.LG"], "comment": null, "summary": "Tabular data, structured as rows and columns, is among the most prevalent\ndata types in machine learning classification and regression applications.\nModels for learning from tabular data have continuously evolved, with Deep\nNeural Networks (DNNs) recently demonstrating promising results through their\ncapability of representation learning. In this survey, we systematically\nintroduce the field of tabular representation learning, covering the\nbackground, challenges, and benchmarks, along with the pros and cons of using\nDNNs. We organize existing methods into three main categories according to\ntheir generalization capabilities: specialized, transferable, and general\nmodels. Specialized models focus on tasks where training and evaluation occur\nwithin the same data distribution. We introduce a hierarchical taxonomy for\nspecialized models based on the key aspects of tabular data -- features,\nsamples, and objectives -- and delve into detailed strategies for obtaining\nhigh-quality feature- and sample-level representations. Transferable models are\npre-trained on one or more datasets and subsequently fine-tuned on downstream\ntasks, leveraging knowledge acquired from homogeneous or heterogeneous sources,\nor even cross-modalities such as vision and language. General models, also\nknown as tabular foundation models, extend this concept further, allowing\ndirect application to downstream tasks without fine-tuning. We group these\ngeneral models based on the strategies used to adapt across heterogeneous\ndatasets. Additionally, we explore ensemble methods, which integrate the\nstrengths of multiple tabular models. Finally, we discuss representative\nextensions of tabular learning, including open-environment tabular machine\nlearning, multimodal learning with tabular data, and tabular understanding.\nMore information can be found in the following repository:\nhttps://github.com/LAMDA-Tabular/Tabular-Survey."}
{"id": "2504.16378", "pdf": "https://arxiv.org/pdf/2504.16378", "abs": "https://arxiv.org/abs/2504.16378", "authors": ["Tadashi Okoshi", "Zexiong Gao", "Tan Yi Zhen", "Takumi Karasawa", "Takeshi Miki", "Wataru Sasaki", "Rajesh K. Balan"], "title": "Cyberoception: Finding a Painlessly-Measurable New Sense in the Cyberworld Towards Emotion-Awareness in Computing", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted by ACM CHI2025", "summary": "In Affective computing, recognizing users' emotions accurately is the basis\nof affective human-computer interaction. Understanding users' interoception\ncontributes to a better understanding of individually different emotional\nabilities, which is essential for achieving inter-individually accurate emotion\nestimation. However, existing interoception measurement methods, such as the\nheart rate discrimination task, have several limitations, including their\ndependence on a well-controlled laboratory environment and precision apparatus,\nmaking monitoring users' interoception challenging. This study aims to\ndetermine other forms of data that can explain users' interoceptive or similar\nstates in their real-world lives and propose a novel hypothetical concept\n\"cyberoception,\" a new sense (1) which has properties similar to interoception\nin terms of the correlation with other emotion-related abilities, and (2) which\ncan be measured only by the sensors embedded inside commodity smartphone\ndevices in users' daily lives. Results from a 10-day-long in-lab/in-the-wild\nhybrid experiment reveal a specific cyberoception type \"Turn On\" (users'\nsubjective sensory perception about the frequency of turning-on behavior on\ntheir smartphones), significantly related to participants' emotional valence.\nWe anticipate that cyberoception to serve as a fundamental building block for\ndeveloping more \"emotion-aware\", user-friendly applications and services."}
{"id": "2504.16271", "pdf": "https://arxiv.org/pdf/2504.16271", "abs": "https://arxiv.org/abs/2504.16271", "authors": ["Frederik Bredgaard", "Martin Lund Trinhammer", "Elisa Bassignana"], "title": "The Language of Attachment: Modeling Attachment Dynamics in Psychotherapy", "categories": ["cs.CL"], "comment": null, "summary": "The delivery of mental healthcare through psychotherapy stands to benefit\nimmensely from developments within Natural Language Processing (NLP), in\nparticular through the automatic identification of patient specific qualities,\nsuch as attachment style. Currently, the assessment of attachment style is\nperformed manually using the Patient Attachment Coding System (PACS; Talia et\nal., 2017), which is complex, resource-consuming and requires extensive\ntraining. To enable wide and scalable adoption of attachment informed treatment\nand research, we propose the first exploratory analysis into automatically\nassessing patient attachment style from psychotherapy transcripts using NLP\nclassification models. We further analyze the results and discuss the\nimplications of using automated tools for this purpose -- e.g., confusing\n`preoccupied' patients with `avoidant' likely has a more negative impact on\ntherapy outcomes with respect to other mislabeling. Our work opens an avenue of\nresearch enabling more personalized psychotherapy and more targeted research\ninto the mechanisms of psychotherapy through advancements in NLP."}
{"id": "2504.16136", "pdf": "https://arxiv.org/pdf/2504.16136", "abs": "https://arxiv.org/abs/2504.16136", "authors": ["Chiung-Yi Tseng", "Junhao Song", "Ziqian Bi", "Tianyang Wang", "Chia Xin Liang", "Ming Liu"], "title": "Active Learning Methods for Efficient Data Utilization and Model Performance Enhancement", "categories": ["cs.LG"], "comment": null, "summary": "In the era of data-driven intelligence, the paradox of data abundance and\nannotation scarcity has emerged as a critical bottleneck in the advancement of\nmachine learning. This paper gives a detailed overview of Active Learning (AL),\nwhich is a strategy in machine learning that helps models achieve better\nperformance using fewer labeled examples. It introduces the basic concepts of\nAL and discusses how it is used in various fields such as computer vision,\nnatural language processing, transfer learning, and real-world applications.\nThe paper focuses on important research topics such as uncertainty estimation,\nhandling of class imbalance, domain adaptation, fairness, and the creation of\nstrong evaluation metrics and benchmarks. It also shows that learning methods\ninspired by humans and guided by questions can improve data efficiency and help\nmodels learn more effectively. In addition, this paper talks about current\nchallenges in the field, including the need to rebuild trust, ensure\nreproducibility, and deal with inconsistent methodologies. It points out that\nAL often gives better results than passive learning, especially when good\nevaluation measures are used. This work aims to be useful for both researchers\nand practitioners by providing key insights and proposing directions for future\nprogress in active learning."}
{"id": "2504.16416", "pdf": "https://arxiv.org/pdf/2504.16416", "abs": "https://arxiv.org/abs/2504.16416", "authors": ["Tao Long", "Kendra Wannamaker", "Jo Vermeulen", "George Fitzmaurice", "Justin Matejka"], "title": "FeedQUAC: Quick Unobtrusive AI-Generated Commentary", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.MM"], "comment": "20 pages, 12 figures", "summary": "Design thrives on feedback. However, gathering constant feedback throughout\nthe design process can be labor-intensive and disruptive. We explore how AI can\nbridge this gap by providing effortless, ambient feedback. We introduce\nFeedQUAC, a design companion that delivers real-time AI-generated commentary\nfrom a variety of perspectives through different personas. A design probe study\nwith eight participants highlights how designers can leverage quick yet ambient\nAI feedback to enhance their creative workflows. Participants highlight\nbenefits such as convenience, playfulness, confidence boost, and inspiration\nfrom this lightweight feedback agent, while suggesting additional features,\nlike chat interaction and context curation. We discuss the role of AI feedback,\nits strengths and limitations, and how to integrate it into existing design\nworkflows while balancing user involvement. Our findings also suggest that\nambient interaction is a valuable consideration for both the design and\nevaluation of future creativity support systems."}
{"id": "2504.16286", "pdf": "https://arxiv.org/pdf/2504.16286", "abs": "https://arxiv.org/abs/2504.16286", "authors": ["Li Weigang", "Pedro Carvalho Brom"], "title": "The Paradox of Poetic Intent in Back-Translation: Evaluating the Quality of Large Language Models in Chinese Translation", "categories": ["cs.CL", "68T50", "I.2.7"], "comment": "24 pages, 3 figures", "summary": "The rapid advancement of large language models (LLMs) has reshaped the\nlandscape of machine translation, yet challenges persist in preserving poetic\nintent, cultural heritage, and handling specialized terminology in\nChinese-English translation. This study constructs a diverse corpus\nencompassing Chinese scientific terminology, historical translation paradoxes,\nand literary metaphors. Utilizing a back-translation and Friedman test-based\nevaluation system (BT-Fried), we evaluate BLEU, CHRF, TER, and semantic\nsimilarity metrics across six major LLMs (e.g., GPT-4.5, DeepSeek V3) and three\ntraditional translation tools. Key findings include: (1) Scientific abstracts\noften benefit from back-translation, while traditional tools outperform LLMs in\nlinguistically distinct texts; (2) LLMs struggle with cultural and literary\nretention, exemplifying the \"paradox of poetic intent\"; (3) Some models exhibit\n\"verbatim back-translation\", reflecting emergent memory behavior; (4) A novel\nBLEU variant using Jieba segmentation and n-gram weighting is proposed. The\nstudy contributes to the empirical evaluation of Chinese NLP performance and\nadvances understanding of cultural fidelity in AI-mediated translation."}
{"id": "2504.16140", "pdf": "https://arxiv.org/pdf/2504.16140", "abs": "https://arxiv.org/abs/2504.16140", "authors": ["Max Hartman", "Lav Varshney"], "title": "SparseJEPA: Sparse Representation Learning of Joint Embedding Predictive Architectures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Joint Embedding Predictive Architectures (JEPA) have emerged as a powerful\nframework for learning general-purpose representations. However, these models\noften lack interpretability and suffer from inefficiencies due to dense\nembedding representations. We propose SparseJEPA, an extension that integrates\nsparse representation learning into the JEPA framework to enhance the quality\nof learned representations. SparseJEPA employs a penalty method that encourages\nlatent space variables to be shared among data features with strong semantic\nrelationships, while maintaining predictive performance. We demonstrate the\neffectiveness of SparseJEPA by training on the CIFAR-100 dataset and\npre-training a lightweight Vision Transformer. The improved embeddings are\nutilized in linear-probe transfer learning for both image classification and\nlow-level tasks, showcasing the architecture's versatility across different\ntransfer tasks. Furthermore, we provide a theoretical proof that demonstrates\nthat the grouping mechanism enhances representation quality. This was done by\ndisplaying that grouping reduces Multiinformation among latent-variables,\nincluding proofing the Data Processing Inequality for Multiinformation. Our\nresults indicate that incorporating sparsity not only refines the latent space\nbut also facilitates the learning of more meaningful and interpretable\nrepresentations. In further work, hope to further extend this method by finding\nnew ways to leverage the grouping mechanism through object-centric\nrepresentation learning."}
{"id": "2504.16423", "pdf": "https://arxiv.org/pdf/2504.16423", "abs": "https://arxiv.org/abs/2504.16423", "authors": ["Jiaqi Tang", "Xinbo Xu", "Yinsong Xu", "Qingchao Chen"], "title": "Advancing Radar Hand Gesture Recognition: A Hybrid Spectrum Synthetic Framework Merging Simulation with Neural Networks", "categories": ["cs.HC"], "comment": null, "summary": "Millimeter wave (mmWave) radar sensors play a vital role in hand gesture\nrecognition (HGR) by detecting subtle motions while preserving user privacy.\nHowever, the limited scale of radar datasets hinders the performance. Existing\nsynthetic data generation methods fall short in two key areas. On the one hand,\nmodeling-based approaches fail to accurately simulate the wave propagation and\nreflection at the hand-gesture level, facing unique complexities such as\ndiffraction and occlusion. On the other hand, generative model-based methods\nare hard to converge while radar data is limited, lacking interpretability, and\nsometimes fail to produce kinematically plausible results. To overcome these\nlimitations, we propose a novel hybrid spectrum synthetic framework leveraging\nvisual hand gesture data. It combines a cylinder mesh-based hand reflection\nmodel with a small-scale neural network called RadarWeightNet, which focuses on\nassigning weights to simulated signals. Our framework addresses two key\nchallenges: achieving accurate simulation of complex hand geometry and bridging\nthe simulation-to-real gap in a data-driven manner while preserving\ninterpretability, which balances physical accuracy with machine learning\nadaptability. We tested our framework under extreme scenarios where radar data\nis scarce. The results demonstrate the effectiveness of our hybrid framework,\nachieving up to 63% SSIM in synthetic performance and up to 30% improvement in\nclassification performance in few-shot learning."}
{"id": "2504.16312", "pdf": "https://arxiv.org/pdf/2504.16312", "abs": "https://arxiv.org/abs/2504.16312", "authors": ["Zhangdie Yuan", "Andreas Vlachos"], "title": "Capturing Symmetry and Antisymmetry in Language Models through Symmetry-Aware Training Objectives", "categories": ["cs.CL"], "comment": null, "summary": "Capturing symmetric (e.g., country borders another country) and antisymmetric\n(e.g., parent_of) relations is crucial for a variety of applications. This\npaper tackles this challenge by introducing a novel Wikidata-derived natural\nlanguage inference dataset designed to evaluate large language models (LLMs).\nOur findings reveal that LLMs perform comparably to random chance on this\nbenchmark, highlighting a gap in relational understanding. To address this, we\nexplore encoder retraining via contrastive learning with k-nearest neighbors.\nThe retrained encoder matches the performance of fine-tuned classification\nheads while offering additional benefits, including greater efficiency in\nfew-shot learning and improved mitigation of catastrophic forgetting."}
{"id": "2504.16141", "pdf": "https://arxiv.org/pdf/2504.16141", "abs": "https://arxiv.org/abs/2504.16141", "authors": ["Yue Shi", "Liangxiu Han", "Xin Zhang", "Tam Sobeih", "Thomas Gaiser", "Nguyen Huu Thuy", "Dominik Behrend", "Amit Kumar Srivastava", "Krishnagopal Halder", "Frank Ewert"], "title": "Deep Learning Meets Process-Based Models: A Hybrid Approach to Agricultural Challenges", "categories": ["cs.LG"], "comment": null, "summary": "Process-based models (PBMs) and deep learning (DL) are two key approaches in\nagricultural modelling, each offering distinct advantages and limitations. PBMs\nprovide mechanistic insights based on physical and biological principles,\nensuring interpretability and scientific rigour. However, they often struggle\nwith scalability, parameterisation, and adaptation to heterogeneous\nenvironments. In contrast, DL models excel at capturing complex, nonlinear\npatterns from large datasets but may suffer from limited interpretability, high\ncomputational demands, and overfitting in data-scarce scenarios.\n  This study presents a systematic review of PBMs, DL models, and hybrid PBM-DL\nframeworks, highlighting their applications in agricultural and environmental\nmodelling. We classify hybrid PBM-DL approaches into DL-informed PBMs, where\nneural networks refine process-based models, and PBM-informed DL, where\nphysical constraints guide deep learning predictions. Additionally, we conduct\na case study on crop dry biomass prediction, comparing hybrid models against\nstandalone PBMs and DL models under varying data quality, sample sizes, and\nspatial conditions. The results demonstrate that hybrid models consistently\noutperform traditional PBMs and DL models, offering greater robustness to noisy\ndata and improved generalisation across unseen locations.\n  Finally, we discuss key challenges, including model interpretability,\nscalability, and data requirements, alongside actionable recommendations for\nadvancing hybrid modelling in agriculture. By integrating domain knowledge with\nAI-driven approaches, this study contributes to the development of scalable,\ninterpretable, and reproducible agricultural models that support data-driven\ndecision-making for sustainable agriculture."}
{"id": "2504.16459", "pdf": "https://arxiv.org/pdf/2504.16459", "abs": "https://arxiv.org/abs/2504.16459", "authors": ["Yuga Tsukuda", "Naoto Nishida", "Jun Lu", "Yoichi Ochiai"], "title": "Insect-Computer Hybrid Speaker: Speaker using Chirp of the Cicada Controlled by Electrical Muscle Stimulation", "categories": ["cs.HC", "cs.AR", "cs.ET", "cs.RO", "cs.SD"], "comment": "6 pages, 3 figures", "summary": "We propose \"Insect-Computer Hybrid Speaker\", which enables us to make musics\nmade from combinations of computer and insects. Lots of studies have proposed\nmethods and interfaces for controlling insects and obtaining feedback. However,\nthere have been less research on the use of insects for interaction with third\nparties. In this paper, we propose a method in which cicadas are used as\nspeakers triggered by using Electrical Muscle Stimulation (EMS). We explored\nand investigated the suitable waveform of chirp to be controlled, the\nappropriate voltage range, and the maximum pitch at which cicadas can chirp."}
{"id": "2504.16353", "pdf": "https://arxiv.org/pdf/2504.16353", "abs": "https://arxiv.org/abs/2504.16353", "authors": ["Arpana Hosabettu", "Harsh Shah"], "title": "Transformer-Based Extraction of Statutory Definitions from the U.S. Code", "categories": ["cs.CL", "cs.AI"], "comment": "7 pages, to be published in IEEE AIIoT 2025", "summary": "Automatic extraction of definitions from legal texts is critical for\nenhancing the comprehension and clarity of complex legal corpora such as the\nUnited States Code (U.S.C.). We present an advanced NLP system leveraging\ntransformer-based architectures to automatically extract defined terms, their\ndefinitions, and their scope from the U.S.C. We address the challenges of\nautomatically identifying legal definitions, extracting defined terms, and\ndetermining their scope within this complex corpus of over 200,000 pages of\nfederal statutory law. Building upon previous feature-based machine learning\nmethods, our updated model employs domain-specific transformers (Legal-BERT)\nfine-tuned specifically for statutory texts, significantly improving extraction\naccuracy. Our work implements a multi-stage pipeline that combines document\nstructure analysis with state-of-the-art language models to process legal text\nfrom the XML version of the U.S. Code. Each paragraph is first classified using\na fine-tuned legal domain BERT model to determine if it contains a definition.\nOur system then aggregates related paragraphs into coherent definitional units\nand applies a combination of attention mechanisms and rule-based patterns to\nextract defined terms and their jurisdictional scope. The definition extraction\nsystem is evaluated on multiple titles of the U.S. Code containing thousands of\ndefinitions, demonstrating significant improvements over previous approaches.\nOur best model achieves 96.8% precision and 98.9% recall (98.2% F1-score),\nsubstantially outperforming traditional machine learning classifiers. This work\ncontributes to improving accessibility and understanding of legal information\nwhile establishing a foundation for downstream legal reasoning tasks."}
{"id": "2504.16214", "pdf": "https://arxiv.org/pdf/2504.16214", "abs": "https://arxiv.org/abs/2504.16214", "authors": ["Xiao Zhang", "Yaoyao Ding", "Yang Hu", "Gennady Pekhimenko"], "title": "Hexcute: A Tile-based Programming Language with Automatic Layout and Task-Mapping Synthesis", "categories": ["cs.LG", "cs.AI", "cs.PL"], "comment": "17 pages, 24 figures", "summary": "Deep learning (DL) workloads mainly run on accelerators like GPUs. Recent DL\nquantization techniques demand a new matrix multiplication operator with mixed\ninput data types, further complicating GPU optimization. Prior high-level\ncompilers like Triton lack the expressiveness to implement key optimizations\nlike fine-grained data pipelines and hardware-friendly memory layouts for these\noperators, while low-level programming models, such as Hidet, Graphene, and\nCUTLASS, require significant programming efforts. To balance expressiveness\nwith engineering effort, we propose Hexcute, a tile-based programming language\nthat exposes shared memory and register abstractions to enable fine-grained\noptimization for these operators. Additionally, Hexcute leverages task mapping\nto schedule the GPU program, and to reduce programming efforts, it automates\nlayout and task mapping synthesis with a novel type-inference-based algorithm.\nOur evaluation shows that Hexcute generalizes to a wide range of DL operators,\nachieves 1.7-11.28$\\times$ speedup over existing DL compilers for mixed-type\noperators, and brings up to 2.91$\\times$ speedup in the end-to-end evaluation."}
{"id": "2504.16502", "pdf": "https://arxiv.org/pdf/2504.16502", "abs": "https://arxiv.org/abs/2504.16502", "authors": ["Marcin Furtak", "Florian Pätzold", "Tim Kietzmann", "Silke M. Kärcher", "Peter König"], "title": "Helping Blind People Grasp: Enhancing a Tactile Bracelet with an Automated Hand Navigation System", "categories": ["cs.HC"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Grasping constitutes a critical challenge for visually impaired people. To\naddress this problem, we developed a tactile bracelet that assists in grasping\nby guiding the user's hand to a target object using vibration commands. Here we\ndemonstrate the fully automated system around the bracelet, which can\nconfidently detect and track target and distractor objects and reliably guide\nthe user's hand. We validate our approach in three tasks that resemble complex,\neveryday use cases. In a grasping task, the participants grasp varying target\nobjects on a table, guided via the automated hand navigation system. In the\nmultiple objects task, participants grasp objects from the same class,\ndemonstrating our system's ability to track one specific object without\ntargeting surrounding distractor objects. Finally, the participants grasp one\nspecific target object by avoiding an obstacle along the way in the depth\nnavigation task, showcasing the potential to utilize our system's depth\nestimations to navigate even complex scenarios. Additionally, we demonstrate\nthat the system can aid users in the real world by testing it in a less\nstructured environment with a blind participant. Overall, our results\ndemonstrate that the system, by translating the AI-processed visual inputs into\na reduced data rate of actionable signals, enables autonomous behavior in\neveryday environments, thus potentially increasing the quality of life of\nvisually impaired people."}
{"id": "2504.16358", "pdf": "https://arxiv.org/pdf/2504.16358", "abs": "https://arxiv.org/abs/2504.16358", "authors": ["Tian Bai", "Huiyan Ying", "Kailong Suo", "Junqiu Wei", "Tao Fan", "Yuanfeng Song"], "title": "Text-to-TrajVis: Enabling Trajectory Data Visualizations from Natural Language Questions", "categories": ["cs.CL"], "comment": null, "summary": "This paper introduces the Text-to-TrajVis task, which aims to transform\nnatural language questions into trajectory data visualizations, facilitating\nthe development of natural language interfaces for trajectory visualization\nsystems. As this is a novel task, there is currently no relevant dataset\navailable in the community. To address this gap, we first devised a new\nvisualization language called Trajectory Visualization Language (TVL) to\nfacilitate querying trajectory data and generating visualizations. Building on\nthis foundation, we further proposed a dataset construction method that\nintegrates Large Language Models (LLMs) with human efforts to create\nhigh-quality data. Specifically, we first generate TVLs using a comprehensive\nand systematic process, and then label each TVL with corresponding natural\nlanguage questions using LLMs. This process results in the creation of the\nfirst large-scale Text-to-TrajVis dataset, named TrajVL, which contains 18,140\n(question, TVL) pairs. Based on this dataset, we systematically evaluated the\nperformance of multiple LLMs (GPT, Qwen, Llama, etc.) on this task. The\nexperimental results demonstrate that this task is both feasible and highly\nchallenging and merits further exploration within the research community."}
{"id": "2504.16234", "pdf": "https://arxiv.org/pdf/2504.16234", "abs": "https://arxiv.org/abs/2504.16234", "authors": ["Rene Pilz", "Johannes Schneider"], "title": "Using Phonemes in cascaded S2S translation pipeline", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted at Swiss NLP Conference 2025", "summary": "This paper explores the idea of using phonemes as a textual representation\nwithin a conventional multilingual simultaneous speech-to-speech translation\npipeline, as opposed to the traditional reliance on text-based language\nrepresentations. To investigate this, we trained an open-source\nsequence-to-sequence model on the WMT17 dataset in two formats: one using\nstandard textual representation and the other employing phonemic\nrepresentation. The performance of both approaches was assessed using the BLEU\nmetric. Our findings shows that the phonemic approach provides comparable\nquality but offers several advantages, including lower resource requirements or\nbetter suitability for low-resource languages."}
{"id": "2504.16533", "pdf": "https://arxiv.org/pdf/2504.16533", "abs": "https://arxiv.org/abs/2504.16533", "authors": ["Peisen Xu", "Jérémie Garcia", "Wei Tsang Ooi", "Christophe Jouffrais"], "title": "SafeSpect: Safety-First Augmented Reality Heads-up Display for Drone Inspections", "categories": ["cs.HC"], "comment": null, "summary": "Current tablet-based interfaces for drone operations often impose a heavy\ncognitive load on pilots and reduce situational awareness by dividing attention\nbetween the video feed and the real world. To address these challenges, we\ndesigned a heads-up augmented reality (AR) interface that overlays in-situ\ninformation to support drone pilots in safety-critical tasks. Through\nparticipatory design workshops with professional pilots, we identified key\nfeatures and developed an adaptive AR interface that dynamically switches\nbetween task and safety views to prevent information overload. We evaluated our\nprototype by creating a realistic building inspection task and comparing three\ninterfaces: a 2D tablet, a static AR, and our adaptive AR design. A user study\nwith 15 participants showed that the AR interface improved access to safety\ninformation, while the adaptive AR interface reduced cognitive load and\nenhanced situational awareness without compromising task performance. We offer\ndesign insights for developing safety-first heads-up AR interfaces."}
{"id": "2504.16379", "pdf": "https://arxiv.org/pdf/2504.16379", "abs": "https://arxiv.org/abs/2504.16379", "authors": ["Yash Akhauri", "Anthony Fei", "Chi-Chih Chang", "Ahmed F. AbouElhamayed", "Yueying Li", "Mohamed S. Abdelfattah"], "title": "SplitReason: Learning To Offload Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning in large language models (LLMs) tends to produce substantially\nlonger token generation sequences than simpler language modeling tasks. This\nextended generation length reflects the multi-step, compositional nature of\nreasoning and is often correlated with higher solution accuracy. From an\nefficiency perspective, longer token generation exacerbates the inherently\nsequential and memory-bound decoding phase of LLMs. However, not all parts of\nthis expensive reasoning process are equally difficult to generate. We leverage\nthis observation by offloading only the most challenging parts of the reasoning\nprocess to a larger, more capable model, while performing most of the\ngeneration with a smaller, more efficient model; furthermore, we teach the\nsmaller model to identify these difficult segments and independently trigger\noffloading when needed. To enable this behavior, we annotate difficult segments\nacross 18k reasoning traces from the OpenR1-Math-220k chain-of-thought (CoT)\ndataset. We then apply supervised fine-tuning (SFT) and reinforcement learning\nfine-tuning (RLFT) to a 1.5B-parameter reasoning model, training it to learn to\noffload the most challenging parts of its own reasoning process to a larger\nmodel. This approach improves AIME24 reasoning accuracy by 24% and 28.3% while\noffloading 1.35% and 5% of the generated tokens respectively. We open-source\nour SplitReason model, data, code and logs."}
{"id": "2504.16238", "pdf": "https://arxiv.org/pdf/2504.16238", "abs": "https://arxiv.org/abs/2504.16238", "authors": ["Léandre Eberhard", "Nirek Sharma", "Filipp Shelobolin", "Aalok Ganesh Shanbhag"], "title": "General Post-Processing Framework for Fairness Adjustment of Machine Learning Models", "categories": ["cs.LG"], "comment": "Submitted to FAccT 2025. Does not include reviewer feedback yet", "summary": "As machine learning increasingly influences critical domains such as credit\nunderwriting, public policy, and talent acquisition, ensuring compliance with\nfairness constraints is both a legal and ethical imperative. This paper\nintroduces a novel framework for fairness adjustments that applies to diverse\nmachine learning tasks, including regression and classification, and\naccommodates a wide range of fairness metrics. Unlike traditional approaches\ncategorized as pre-processing, in-processing, or post-processing, our method\nadapts in-processing techniques for use as a post-processing step. By\ndecoupling fairness adjustments from the model training process, our framework\npreserves model performance on average while enabling greater flexibility in\nmodel development. Key advantages include eliminating the need for custom loss\nfunctions, enabling fairness tuning using different datasets, accommodating\nproprietary models as black-box systems, and providing interpretable insights\ninto the fairness adjustments. We demonstrate the effectiveness of this\napproach by comparing it to Adversarial Debiasing, showing that our framework\nachieves a comparable fairness/accuracy tradeoff on real-world datasets."}
{"id": "2504.16548", "pdf": "https://arxiv.org/pdf/2504.16548", "abs": "https://arxiv.org/abs/2504.16548", "authors": ["Lirui Guo", "Michael G. Burke", "Wynita M. Griggs"], "title": "Exploring human-SAV interaction using large language models: The impact of psychological ownership and anthropomorphism on user experience", "categories": ["cs.HC", "cs.AI", "cs.ET"], "comment": null, "summary": "There has been extensive prior work exploring how psychological factors such\nas anthropomorphism affect the adoption of shared autonomous vehicles (SAVs).\nHowever, limited research has been conducted on how prompt strategies in large\nlanguage model (LLM)-powered SAV User Interfaces (UIs) affect users'\nperceptions, experiences, and intentions to adopt such technology. In this\nwork, we investigate how conversational UIs powered by LLMs drive these\npsychological factors and psychological ownership, the sense of possession a\nuser may come to feel towards an entity or object they may not legally own. We\ndesigned four SAV UIs with varying levels of anthropomorphic characteristics\nand psychological ownership triggers. Quantitative measures of psychological\nownership, anthropomorphism, quality of service, disclosure tendency, sentiment\nof SAV responses, and overall acceptance were collected after participants\ninteracted with each SAV. Qualitative feedback was also gathered regarding the\nexperience of psychological ownership during the interactions. The results\nindicate that an SAV conversational UI designed to be more anthropomorphic and\nto induce psychological ownership improved users' perceptions of the SAV's\nhuman-like qualities and improved the sentiment of responses compared to a\ncontrol condition. These findings provide practical guidance for designing\nLLM-based conversational UIs that enhance user experience and adoption of SAVs."}
{"id": "2504.16394", "pdf": "https://arxiv.org/pdf/2504.16394", "abs": "https://arxiv.org/abs/2504.16394", "authors": ["Fahmida Liza Piya", "Rahmatollah Beheshti"], "title": "ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Unstructured clinical data can serve as a unique and rich source of\ninformation that can meaningfully inform clinical practice. Extracting the most\npertinent context from such data is critical for exploiting its true potential\ntoward optimal and timely decision-making in patient care. While prior research\nhas explored various methods for clinical text summarization, most prior\nstudies either process all input tokens uniformly or rely on heuristic-based\nfilters, which can overlook nuanced clinical cues and fail to prioritize\ninformation critical for decision-making. In this study, we propose Contextual,\na novel framework that integrates a Context-Preserving Token Filtering method\nwith a Domain-Specific Knowledge Graph (KG) for contextual augmentation. By\npreserving context-specific important tokens and enriching them with structured\nknowledge, ConTextual improves both linguistic coherence and clinical fidelity.\nOur extensive empirical evaluations on two public benchmark datasets\ndemonstrate that ConTextual consistently outperforms other baselines. Our\nproposed approach highlights the complementary role of token-level filtering\nand structured retrieval in enhancing both linguistic and clinical integrity,\nas well as offering a scalable solution for improving precision in clinical\ntext generation."}
{"id": "2504.16255", "pdf": "https://arxiv.org/pdf/2504.16255", "abs": "https://arxiv.org/abs/2504.16255", "authors": ["Tina Behzad", "Mithilesh Kumar Singh", "Anthony J. Ripa", "Klaus Mueller"], "title": "FairPlay: A Collaborative Approach to Mitigate Bias in Datasets for Improved AI Fairness", "categories": ["cs.LG", "cs.CY", "cs.HC", "H.5.2; H.5.3; I.2.6"], "comment": "Accepted at ACM CSCW 2025. 30 pages total (including references and\n  supplementary material). Contains 10 figures", "summary": "The issue of fairness in decision-making is a critical one, especially given\nthe variety of stakeholder demands for differing and mutually incompatible\nversions of fairness. Adopting a strategic interaction of perspectives provides\nan alternative to enforcing a singular standard of fairness. We present a\nweb-based software application, FairPlay, that enables multiple stakeholders to\ndebias datasets collaboratively. With FairPlay, users can negotiate and arrive\nat a mutually acceptable outcome without a universally agreed-upon theory of\nfairness. In the absence of such a tool, reaching a consensus would be highly\nchallenging due to the lack of a systematic negotiation process and the\ninability to modify and observe changes. We have conducted user studies that\ndemonstrate the success of FairPlay, as users could reach a consensus within\nabout five rounds of gameplay, illustrating the application's potential for\nenhancing fairness in AI systems."}
{"id": "2504.16562", "pdf": "https://arxiv.org/pdf/2504.16562", "abs": "https://arxiv.org/abs/2504.16562", "authors": ["Julian Rasch", "Florian Müller", "Francesco Chiossi"], "title": "A Vision for AI-Driven Adaptation of Dynamic AR Content to Users and Environments", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Augmented Reality (AR) is transforming the way we interact with virtual\ninformation in the physical world. By overlaying digital content in real-world\nenvironments, AR enables new forms of immersive and engaging experiences.\nHowever, existing AR systems often struggle to effectively manage the many\ninteractive possibilities that AR presents. This vision paper speculates on\nAI-driven approaches for adaptive AR content placement, dynamically adjusting\nto user movement and environmental changes. By leveraging machine learning\nmethods, such a system would intelligently manage content distribution between\nAR projections integrated into the external environment and fixed static\ncontent, enabling seamless UI layout and potentially reducing users' cognitive\nload. By exploring the possibilities of AI-driven dynamic AR content placement,\nwe aim to envision new opportunities for innovation and improvement in various\nindustries, from urban navigation and workplace productivity to immersive\nlearning and beyond. This paper outlines a vision for the development of more\nintuitive, engaging, and effective AI-powered AR experiences."}
{"id": "2504.16408", "pdf": "https://arxiv.org/pdf/2504.16408", "abs": "https://arxiv.org/abs/2504.16408", "authors": ["Jiahao Yuan", "Xingzhe Sun", "Xing Yu", "Jingwen Wang", "Dehui Du", "Zhiqing Cui", "Zixiang Di"], "title": "Less is More: Enhancing Structured Multi-Agent Reasoning via Quality-Guided Distillation", "categories": ["cs.CL"], "comment": null, "summary": "The XLLM@ACL2025 Shared Task-III formulates a low-resource structural\nreasoning task that challenges LLMs to generate interpretable, step-by-step\nrationales with minimal labeled data. We present Less is More, the third-place\nwinning approach in the XLLM@ACL2025 Shared Task-III, which focuses on\nstructured reasoning from only 24 labeled examples. Our approach leverages a\nmulti-agent framework with reverse-prompt induction, retrieval-augmented\nreasoning synthesis via GPT-4o, and dual-stage reward-guided filtering to\ndistill high-quality supervision across three subtasks: question parsing, CoT\nparsing, and step-level verification. All modules are fine-tuned from\nMeta-Llama-3-8B-Instruct under a unified LoRA+ setup. By combining structure\nvalidation with reward filtering across few-shot and zero-shot prompts, our\npipeline consistently improves structure reasoning quality. These results\nunderscore the value of controllable data distillation in enhancing structured\ninference under low-resource constraints. Our code is available at\nhttps://github.com/Jiahao-Yuan/Less-is-More."}
{"id": "2504.16262", "pdf": "https://arxiv.org/pdf/2504.16262", "abs": "https://arxiv.org/abs/2504.16262", "authors": ["Junn Yong Loo", "Michelle Adeline", "Julia Kaiwen Lau", "Fang Yu Leong", "Hwa Hui Tew", "Arghya Pal", "Vishnu Monn Baskaran", "Chee-Ming Ting", "Raphaël C. -W. Phan"], "title": "Learning Energy-Based Generative Models via Potential Flow: A Variational Principle Approach to Probability Density Homotopy Matching", "categories": ["cs.LG"], "comment": "Accepted by Transactions on Machine Learning Research (TMLR)", "summary": "Energy-based models (EBMs) are a powerful class of probabilistic generative\nmodels due to their flexibility and interpretability. However, relationships\nbetween potential flows and explicit EBMs remain underexplored, while\ncontrastive divergence training via implicit Markov chain Monte Carlo (MCMC)\nsampling is often unstable and expensive in high-dimensional settings. In this\npaper, we propose Variational Potential Flow Bayes (VPFB), a new energy-based\ngenerative framework that eliminates the need for implicit MCMC sampling and\ndoes not rely on auxiliary networks or cooperative training. VPFB learns an\nenergy-parameterized potential flow by constructing a flow-driven density\nhomotopy that is matched to the data distribution through a variational loss\nminimizing the Kullback-Leibler divergence between the flow-driven and marginal\nhomotopies. This principled formulation enables robust and efficient generative\nmodeling while preserving the interpretability of EBMs. Experimental results on\nimage generation, interpolation, out-of-distribution detection, and\ncompositional generation confirm the effectiveness of VPFB, showing that our\nmethod performs competitively with existing approaches in terms of sample\nquality and versatility across diverse generative modeling tasks."}
{"id": "2504.16572", "pdf": "https://arxiv.org/pdf/2504.16572", "abs": "https://arxiv.org/abs/2504.16572", "authors": ["Sneha Nanavati", "Nimmi Rangaswamy"], "title": "Bridging Data Gaps and Building Knowledge Networks in Indian Football Analytics", "categories": ["cs.HC"], "comment": "6 pages", "summary": "The global rise of football analytics has rapidly transformed how clubs make\nstrategic decisions. However, in India, the adoption of analytics remains\nconstrained by institutional resistance, infrastructural limitations, and\ncultural barriers -- challenges that grassroots innovation and low-cost data\nsolutions have the potential to overcome. Despite the growing popularity of the\nIndian Super League, resource scarcity and fragmented governance continue to\nhinder the widespread adoption and impact of analytics. This mixed-methods\nstudy explores how informal, decentralised analytics communities -- comprising\namateur analysts and Twitter-based \"data sleuths\" -- navigate these constraints\nthrough peer mentorship and grassroots innovation. Drawing on extensive digital\nethnography, participant observation, and interviews, the study illustrates how\nthese informal networks mitigate data scarcity, limited digital infrastructure,\nand institutional indifference while fostering skill development and\nprofessional growth. Building on these insights, the paper proposes HCI\ninterventions such as decentralised knowledge platforms to facilitate\nstructured, cross-border peer mentorship and low-cost data solutions --\nincluding AI-assisted player tracking and mobile analytics dashboards -- rooted\nin principles of frugal innovation. These interventions aim to bridge the data\ndivide, support inclusive technical engagement in sport, and enhance\nanalytics-driven decision-making in resource-constrained environments. This\npaper contributes to HCIxB's focus on cross-border collaboration by\nhighlighting how community-driven technological adaptation in the Global South\ncan foster meaningful participation, skill-building, and long-term\nsustainability through informal learning networks and scalable,\ncontext-sensitive tools."}
{"id": "2504.16411", "pdf": "https://arxiv.org/pdf/2504.16411", "abs": "https://arxiv.org/abs/2504.16411", "authors": ["Kosuke Yamada", "Peinan Zhang"], "title": "Out-of-the-Box Conditional Text Embeddings from Large Language Models", "categories": ["cs.CL"], "comment": "work in progress", "summary": "Conditional text embedding is a proposed representation that captures the\nshift in perspective on texts when conditioned on a specific aspect. Previous\nmethods have relied on extensive training data for fine-tuning models, leading\nto challenges in terms of labor and resource costs. We propose PonTE, a novel\nunsupervised conditional text embedding method that leverages a causal large\nlanguage model and a conditional prompt. Through experiments on conditional\nsemantic text similarity and text clustering, we demonstrate that PonTE can\ngenerate useful conditional text embeddings and achieve performance comparable\nto supervised methods without fine-tuning. We also show the interpretability of\ntext embeddings with PonTE by analyzing word generation following prompts and\nembedding visualization."}
{"id": "2504.16263", "pdf": "https://arxiv.org/pdf/2504.16263", "abs": "https://arxiv.org/abs/2504.16263", "authors": ["Magnus Sieverding", "Nathan Steffen", "Kelly Cohen"], "title": "Gradient-Optimized Fuzzy Classifier: A Benchmark Study Against State-of-the-Art Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper presents a performance benchmarking study of a Gradient-Optimized\nFuzzy Inference System (GF) classifier against several state-of-the-art machine\nlearning models, including Random Forest, XGBoost, Logistic Regression, Support\nVector Machines, and Neural Networks. The evaluation was conducted across five\ndatasets from the UCI Machine Learning Repository, each chosen for their\ndiversity in input types, class distributions, and classification complexity.\nUnlike traditional Fuzzy Inference Systems that rely on derivative-free\noptimization methods, the GF leverages gradient descent to significantly\nimproving training efficiency and predictive performance. Results demonstrate\nthat the GF model achieved competitive, and in several cases superior,\nclassification accuracy while maintaining high precision and exceptionally low\ntraining times. In particular, the GF exhibited strong consistency across folds\nand datasets, underscoring its robustness in handling noisy data and variable\nfeature sets. These findings support the potential of gradient optimized fuzzy\nsystems as interpretable, efficient, and adaptable alternatives to more complex\ndeep learning models in supervised learning tasks."}
{"id": "2504.16573", "pdf": "https://arxiv.org/pdf/2504.16573", "abs": "https://arxiv.org/abs/2504.16573", "authors": ["Xianghe Liu", "Jiaqi Xu", "Tao Sun"], "title": "PsyCounAssist: A Full-Cycle AI-Powered Psychological Counseling Assistant System", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Psychological counseling is a highly personalized and dynamic process that\nrequires therapists to continuously monitor emotional changes, document session\ninsights, and maintain therapeutic continuity. In this paper, we introduce\nPsyCounAssist, a comprehensive AI-powered counseling assistant system\nspecifically designed to augment psychological counseling practices.\nPsyCounAssist integrates multimodal emotion recognition combining speech and\nphotoplethysmography (PPG) signals for accurate real-time affective analysis,\nautomated structured session reporting using large language models (LLMs), and\npersonalized AI-generated follow-up support. Deployed on Android-based tablet\ndevices, the system demonstrates practical applicability and flexibility in\nreal-world counseling scenarios. Experimental evaluation confirms the\nreliability of PPG-based emotional classification and highlights the system's\npotential for non-intrusive, privacy-aware emotional support. PsyCounAssist\nrepresents a novel approach to ethically and effectively integrating AI into\npsychological counseling workflows."}
{"id": "2504.16414", "pdf": "https://arxiv.org/pdf/2504.16414", "abs": "https://arxiv.org/abs/2504.16414", "authors": ["Mohammad Khodadad", "Ali Shiraee Kasmaee", "Mahdi Astaraki", "Nicholas Sherck", "Hamidreza Mahyar", "Soheila Samiee"], "title": "Evaluating Multi-Hop Reasoning in Large Language Models: A Chemistry-Centric Case Study", "categories": ["cs.CL"], "comment": null, "summary": "In this study, we introduced a new benchmark consisting of a curated dataset\nand a defined evaluation process to assess the compositional reasoning\ncapabilities of large language models within the chemistry domain. We designed\nand validated a fully automated pipeline, verified by subject matter experts,\nto facilitate this task. Our approach integrates OpenAI reasoning models with\nnamed entity recognition (NER) systems to extract chemical entities from recent\nliterature, which are then augmented with external knowledge bases to form a\ncomprehensive knowledge graph. By generating multi-hop questions across these\ngraphs, we assess LLM performance in both context-augmented and non-context\naugmented settings. Our experiments reveal that even state-of-the-art models\nface significant challenges in multi-hop compositional reasoning. The results\nreflect the importance of augmenting LLMs with document retrieval, which can\nhave a substantial impact on improving their performance. However, even perfect\nretrieval accuracy with full context does not eliminate reasoning errors,\nunderscoring the complexity of compositional reasoning. This work not only\nbenchmarks and highlights the limitations of current LLMs but also presents a\nnovel data generation pipeline capable of producing challenging reasoning\ndatasets across various domains. Overall, this research advances our\nunderstanding of reasoning in computational linguistics."}
{"id": "2504.16268", "pdf": "https://arxiv.org/pdf/2504.16268", "abs": "https://arxiv.org/abs/2504.16268", "authors": ["Abdesslem Layeb"], "title": "Boosting Classifier Performance with Opposition-Based Data Transformation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we introduce a novel data transformation framework based on\nOpposition-Based Learning (OBL) to boost the performance of traditional\nclassification algorithms. Originally developed to accelerate convergence in\noptimization tasks, OBL is leveraged here to generate synthetic opposite\nsamples that replace the acutely training data and improve decision boundary\nformation. We explore three OBL variants; Global OBL, Class-Wise OBL, and\nLocalized Class-Wise OBL; and integrate them with several widely used\nclassifiers, including K-Nearest Neighbors (KNN), Support Vector Machines\n(SVM), Logistic Regression (LR), and Decision Tree (DT). Extensive experiments\nconducted on 26 heterogeneous and high-dimensional datasets demonstrate that\nOBL-enhanced classifiers consistently outperform their standard counterparts in\nterms of accuracy and F1-score, frequently achieving near-perfect or perfect\nclassification. Furthermore, OBL contributes to improved computational\nefficiency, particularly in SVM and LR. These findings underscore the potential\nof OBL as a lightweight yet powerful data transformation strategy for enhancing\nclassification performance, especially in complex or sparse learning\nenvironments."}
{"id": "2504.16615", "pdf": "https://arxiv.org/pdf/2504.16615", "abs": "https://arxiv.org/abs/2504.16615", "authors": ["Yui Kondo", "Kevin Dunnell", "Qing Xiao", "Jun Zhao", "Luc Rocher"], "title": "Algorithmic Mirror: Designing an Interactive Tool to Promote Self-Reflection for YouTube Recommendations", "categories": ["cs.HC"], "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING", "summary": "Big Data analytics and Artificial Intelligence systems derive non-intuitive\nand often unverifiable inferences about individuals' behaviors, preferences,\nand private lives. Drawing on diverse, feature-rich datasets of unpredictable\nvalue, these systems erode the intuitive connection between our actions and how\nwe are perceived, diminishing control over our digital identities. While\nExplainable Artificial Intelligence scholars have attempted to explain the\ninner workings of algorithms, their visualizations frequently overwhelm\nend-users with complexity. This research introduces 'hypothetical inference', a\nnovel approach that uses language models to simulate how algorithms might\ninterpret users' digital footprints and infer personal characteristics without\nrequiring access to proprietary platform algorithms. Through empirical studies\nwith fourteen adult participants, we identified three key design opportunities\nto foster critical algorithmic literacy: (1) reassembling scattered digital\nfootprints into a unified map, (2) simulating algorithmic inference through\nLLM-generated interpretations, and (3) incorporating temporal dimensions to\nvisualize evolving patterns. This research lays the groundwork for tools that\ncan help users recognize the influence of data on platforms and develop greater\nautonomy in increasingly algorithm-mediated digital environments."}
{"id": "2504.16427", "pdf": "https://arxiv.org/pdf/2504.16427", "abs": "https://arxiv.org/abs/2504.16427", "authors": ["Hanlei Zhang", "Zhuohang Li", "Yeshuang Zhu", "Hua Xu", "Peiwu Wang", "Jinchao Zhang", "Jie Zhou", "Haige Zhu"], "title": "Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark", "categories": ["cs.CL", "cs.AI", "cs.MM"], "comment": "23 pages, 5 figures", "summary": "Multimodal language analysis is a rapidly evolving field that leverages\nmultiple modalities to enhance the understanding of high-level semantics\nunderlying human conversational utterances. Despite its significance, little\nresearch has investigated the capability of multimodal large language models\n(MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce\nMMLA, a comprehensive benchmark specifically designed to address this gap. MMLA\ncomprises over 61K multimodal utterances drawn from both staged and real-world\nscenarios, covering six core dimensions of multimodal semantics: intent,\nemotion, dialogue act, sentiment, speaking style, and communication behavior.\nWe evaluate eight mainstream branches of LLMs and MLLMs using three methods:\nzero-shot inference, supervised fine-tuning, and instruction tuning. Extensive\nexperiments reveal that even fine-tuned models achieve only about 60%~70%\naccuracy, underscoring the limitations of current MLLMs in understanding\ncomplex human language. We believe that MMLA will serve as a solid foundation\nfor exploring the potential of large language models in multimodal language\nanalysis and provide valuable resources to advance this field. The datasets and\ncode are open-sourced at https://github.com/thuiar/MMLA."}
{"id": "2504.16272", "pdf": "https://arxiv.org/pdf/2504.16272", "abs": "https://arxiv.org/abs/2504.16272", "authors": ["Ryan Koo", "Ian Yang", "Vipul Raheja", "Mingyi Hong", "Kwang-Sung Jun", "Dongyeop Kang"], "title": "Learning Explainable Dense Reward Shapes via Bayesian Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Current reinforcement learning from human feedback (RLHF) pipelines for large\nlanguage model (LLM) alignment typically assign scalar rewards to sequences,\nusing the final token as a surrogate indicator for the quality of the entire\nsequence. However, this leads to sparse feedback and suboptimal token-level\ncredit assignment. In this work, we frame reward shaping as an optimization\nproblem focused on token-level credit assignment. We propose a reward-shaping\nfunction leveraging explainability methods such as SHAP and LIME to estimate\nper-token rewards from the reward model. To learn parameters of this shaping\nfunction, we employ a bilevel optimization framework that integrates Bayesian\nOptimization and policy training to handle noise from the token reward\nestimates. Our experiments show that achieving a better balance of token-level\nreward attribution leads to performance improvements over baselines on\ndownstream tasks and finds an optimal policy faster during training.\nFurthermore, we show theoretically that explainability methods that are feature\nadditive attribution functions maintain the optimal policy as the original\nreward."}
{"id": "2504.16671", "pdf": "https://arxiv.org/pdf/2504.16671", "abs": "https://arxiv.org/abs/2504.16671", "authors": ["Joel Oksanen", "Andrés Lucero", "Perttu Hämäläinen"], "title": "LLMCode: Evaluating and Enhancing Researcher-AI Alignment in Qualitative Analysis", "categories": ["cs.HC"], "comment": null, "summary": "The use of large language models (LLMs) in qualitative analysis offers\nenhanced efficiency but raises questions about their alignment with the\ncontextual nature of research for design (RfD). This research examines the\ntrustworthiness of LLM-driven design insights, using qualitative coding as a\ncase study to explore the interpretive processes central to RfD. We introduce\nLLMCode, an open-source tool integrating two metrics, namely Intersection over\nUnion (IoU) and Modified Hausdorff Distance, to assess the alignment between\nhuman and LLM-generated insights. Across two studies involving 26 designers, we\nfind that while the model performs well with deductive coding, its ability to\nemulate a designer's deeper interpretive lens over the data is limited,\nemphasising the importance of human-AI collaboration. Our results highlight a\nreciprocal dynamic where users refine LLM outputs and adapt their own\nperspectives based on the model's suggestions. These findings underscore the\nimportance of fostering appropriate reliance on LLMs by designing tools that\npreserve interpretive depth while facilitating intuitive collaboration between\ndesigners and AI."}
{"id": "2504.16448", "pdf": "https://arxiv.org/pdf/2504.16448", "abs": "https://arxiv.org/abs/2504.16448", "authors": ["Shuguang Zhao", "Qiangzhong Feng", "Zhiyang He", "Peipei Sun", "Yingying Wang", "Xiaodong Tao", "Xiaoliang Lu", "Mei Cheng", "Xinyue Wu", "Yanyan Wang", "Wei Liang"], "title": "EMRModel: A Large Language Model for Extracting Medical Consultation Dialogues into Structured Medical Records", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Medical consultation dialogues contain critical clinical information, yet\ntheir unstructured nature hinders effective utilization in diagnosis and\ntreatment. Traditional methods, relying on rule-based or shallow machine\nlearning techniques, struggle to capture deep and implicit semantics. Recently,\nlarge pre-trained language models and Low-Rank Adaptation (LoRA), a lightweight\nfine-tuning method, have shown promise for structured information extraction.\nWe propose EMRModel, a novel approach that integrates LoRA-based fine-tuning\nwith code-style prompt design, aiming to efficiently convert medical\nconsultation dialogues into structured electronic medical records (EMRs).\nAdditionally, we construct a high-quality, realistically grounded dataset of\nmedical consultation dialogues with detailed annotations. Furthermore, we\nintroduce a fine-grained evaluation benchmark for medical consultation\ninformation extraction and provide a systematic evaluation methodology,\nadvancing the optimization of medical natural language processing (NLP) models.\nExperimental results show EMRModel achieves an F1 score of 88.1%, improving\nby49.5% over standard pre-trained models. Compared to traditional LoRA\nfine-tuning methods, our model shows superior performance, highlighting its\neffectiveness in structured medical record extraction tasks."}
{"id": "2504.16275", "pdf": "https://arxiv.org/pdf/2504.16275", "abs": "https://arxiv.org/abs/2504.16275", "authors": ["Jannis Born", "Filip Skogh", "Kahn Rhrissorrakrai", "Filippo Utro", "Nico Wagner", "Aleksandros Sobczyk"], "title": "Quantum Doubly Stochastic Transformers", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.CV"], "comment": "Under Review", "summary": "At the core of the Transformer, the Softmax normalizes the attention matrix\nto be right stochastic. Previous research has shown that this often\ndestabilizes training and that enforcing the attention matrix to be doubly\nstochastic (through Sinkhorn's algorithm) consistently improves performance\nacross different tasks, domains and Transformer flavors. However, Sinkhorn's\nalgorithm is iterative, approximative, non-parametric and thus inflexible\nw.r.t. the obtained doubly stochastic matrix (DSM). Recently, it has been\nproven that DSMs can be obtained with a parametric quantum circuit, yielding a\nnovel quantum inductive bias for DSMs with no known classical analogue.\nMotivated by this, we demonstrate the feasibility of a hybrid classical-quantum\ndoubly stochastic Transformer (QDSFormer) that replaces the Softmax in the\nself-attention layer with a variational quantum circuit. We study the\nexpressive power of the circuit and find that it yields more diverse DSMs that\nbetter preserve information than classical operators. Across multiple\nsmall-scale object recognition tasks, we find that our QDSFormer consistently\nsurpasses both a standard Vision Transformer and other doubly stochastic\nTransformers. Beyond the established Sinkformer, this comparison includes a\nnovel quantum-inspired doubly stochastic Transformer (based on QR\ndecomposition) that can be of independent interest. The QDSFormer also shows\nimproved training stability and lower performance variation suggesting that it\nmay mitigate the notoriously unstable training of ViTs on small-scale data."}
{"id": "2504.16741", "pdf": "https://arxiv.org/pdf/2504.16741", "abs": "https://arxiv.org/abs/2504.16741", "authors": ["Orland Hoeber", "Md Nazmul Islam", "Miriam Boon", "Dale Storie", "Veronica Ramshaw"], "title": "Search Timelines: Visualizing Search History to Enable Cross-Session Exploratory Search", "categories": ["cs.HC", "cs.IR"], "comment": null, "summary": "Purpose: The timespan over which exploratory searching can occur, as well as\nthe scope and volume of the search activities undertaken, can make it difficult\nfor searchers to remember key details about their search activities. These\ndifficulties are present both in the midst of searching as well as when\nresuming a search that spans multiple sessions. In this paper, we present a\nsearch interface designed to support cross-session exploratory search in a\npublic digital library context. Methods: Search Timelines provides a\nvisualization of current and past search activities via a dynamic timeline of\nthe search activity (queries and saved resources). This timeline is presented\nat two levels of detail. An overview timeline is provided alongside the search\nresults in a typical search engine results page design. A detailed timeline is\nprovided in the workspace, where searchers can review the history of their\nsearch activities and their saved resources. A controlled laboratory study was\nconducted to compare this approach to a baseline interface modelled after a\ntypical public digital library search/workspace interface. Results:\nParticipants who used Search Timelines reported higher levels of user\nengagement, usability, and perceived knowledge gain, during an initial search\nsession and when resuming the search after a 7-8 day interval. This came at the\nexpense of the searchers taking more time to complete the search task, which we\nview as positive evidence of engagement in cross-session exploratory search\nprocesses. Conclusion: Search Timelines serves as an example of how lightweight\nvisualization approaches can be used to enhance typical search interface\ndesigns to support exploratory search. The results highlight the value of\nproviding persistent representations of past search activities within the\nsearch interface."}
{"id": "2504.16460", "pdf": "https://arxiv.org/pdf/2504.16460", "abs": "https://arxiv.org/abs/2504.16460", "authors": ["Vignesh Ethiraj", "Sidhanth Menon", "Divya Vijay"], "title": "T-VEC: A Telecom-Specific Vectorization Model with Enhanced Semantic Understanding via Deep Triplet Loss Fine-Tuning", "categories": ["cs.CL", "cs.AI", "68T50"], "comment": "Introduces T-VEC, a telecom-specific text embedding model. Fine-tuned\n  gte-Qwen2-1.5B-instruct on curated telecom data points. Includes the first\n  open-source telecom tokenizer. Model available at\n  https://huggingface.co/NetoAISolutions/T-VEC", "summary": "The specialized vocabulary and complex concepts of the telecommunications\nindustry present significant challenges for standard Natural Language\nProcessing models. Generic text embeddings often fail to capture\ntelecom-specific semantics, hindering downstream task performance. We introduce\nT-VEC (Telecom Vectorization Model), a novel embedding model tailored for the\ntelecom domain through deep fine-tuning. Developed by NetoAI, T-VEC is created\nby adapting the state-of-the-art gte-Qwen2-1.5B-instruct model using a triplet\nloss objective on a meticulously curated, large-scale dataset of\ntelecom-specific data. Crucially, this process involved substantial\nmodification of weights across 338 layers of the base model, ensuring deep\nintegration of domain knowledge, far exceeding superficial adaptation\ntechniques. We quantify this deep change via weight difference analysis. A key\ncontribution is the development and open-sourcing (MIT License) of the first\ndedicated telecom-specific tokenizer, enhancing the handling of industry\njargon. T-VEC achieves a leading average MTEB score (0.825) compared to\nestablished models and demonstrates vastly superior performance (0.9380 vs.\nless than 0.07) on our internal telecom-specific triplet evaluation benchmark,\nindicating an exceptional grasp of domain-specific nuances, visually confirmed\nby improved embedding separation. This work positions NetoAI at the forefront\nof telecom AI innovation, providing the community with a powerful, deeply\nadapted, open-source tool."}
{"id": "2504.16276", "pdf": "https://arxiv.org/pdf/2504.16276", "abs": "https://arxiv.org/abs/2504.16276", "authors": ["Abhishek Jana", "Moeumu Uili", "James Atherton", "Mark O'Brien", "Joe Wood", "Leandra Brickson"], "title": "An Automated Pipeline for Few-Shot Bird Call Classification: A Case Study with the Tooth-Billed Pigeon", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.SD"], "comment": "16 pages, 5 figures, 4 tables", "summary": "This paper presents an automated one-shot bird call classification pipeline\ndesigned for rare species absent from large publicly available classifiers like\nBirdNET and Perch. While these models excel at detecting common birds with\nabundant training data, they lack options for species with only 1-3 known\nrecordings-a critical limitation for conservationists monitoring the last\nremaining individuals of endangered birds. To address this, we leverage the\nembedding space of large bird classification networks and develop a classifier\nusing cosine similarity, combined with filtering and denoising preprocessing\ntechniques, to optimize detection with minimal training data. We evaluate\nvarious embedding spaces using clustering metrics and validate our approach in\nboth a simulated scenario with Xeno-Canto recordings and a real-world test on\nthe critically endangered tooth-billed pigeon (Didunculus strigirostris), which\nhas no existing classifiers and only three confirmed recordings. The final\nmodel achieved 1.0 recall and 0.95 accuracy in detecting tooth-billed pigeon\ncalls, making it practical for use in the field. This open-source system\nprovides a practical tool for conservationists seeking to detect and monitor\nrare species on the brink of extinction."}
{"id": "2504.16770", "pdf": "https://arxiv.org/pdf/2504.16770", "abs": "https://arxiv.org/abs/2504.16770", "authors": ["Chaeyeon Lim"], "title": "DeBiasMe: De-biasing Human-AI Interactions with Metacognitive AIED (AI in Education) Interventions", "categories": ["cs.HC"], "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING", "summary": "While generative artificial intelligence (Gen AI) increasingly transforms\nacademic environments, a critical gap exists in understanding and mitigating\nhuman biases in AI interactions, such as anchoring and confirmation bias. This\nposition paper advocates for metacognitive AI literacy interventions to help\nuniversity students critically engage with AI and address biases across the\nHuman-AI interaction workflows. The paper presents the importance of\nconsidering (1) metacognitive support with deliberate friction focusing on\nhuman bias; (2) bi-directional Human-AI interaction intervention addressing\nboth input formulation and output interpretation; and (3) adaptive scaffolding\nthat responds to diverse user engagement patterns. These frameworks are\nillustrated through ongoing work on \"DeBiasMe,\" AIED (AI in Education)\ninterventions designed to enhance awareness of cognitive biases while\nempowering user agency in AI interactions. The paper invites multiple\nstakeholders to engage in discussions on design and evaluation methods for\nscaffolding mechanisms, bias visualization, and analysis frameworks. This\nposition contributes to the emerging field of AI-augmented learning by\nemphasizing the critical role of metacognition in helping students navigate the\ncomplex interaction between human, statistical, and systemic biases in AI use\nwhile highlighting how cognitive adaptation to AI systems must be explicitly\nintegrated into comprehensive AI literacy frameworks."}
{"id": "2504.16511", "pdf": "https://arxiv.org/pdf/2504.16511", "abs": "https://arxiv.org/abs/2504.16511", "authors": ["Fengze Liu", "Weidong Zhou", "Binbin Liu", "Zhimiao Yu", "Yifan Zhang", "Haobin Lin", "Yifeng Yu", "Xiaohuan Zhou", "Taifeng Wang", "Yong Cao"], "title": "QuaDMix: Quality-Diversity Balanced Data Selection for Efficient LLM Pretraining", "categories": ["cs.CL"], "comment": null, "summary": "Quality and diversity are two critical metrics for the training data of large\nlanguage models (LLMs), positively impacting performance. Existing studies\noften optimize these metrics separately, typically by first applying quality\nfiltering and then adjusting data proportions. However, these approaches\noverlook the inherent trade-off between quality and diversity, necessitating\ntheir joint consideration. Given a fixed training quota, it is essential to\nevaluate both the quality of each data point and its complementary effect on\nthe overall dataset. In this paper, we introduce a unified data selection\nframework called QuaDMix, which automatically optimizes the data distribution\nfor LLM pretraining while balancing both quality and diversity. Specifically,\nwe first propose multiple criteria to measure data quality and employ domain\nclassification to distinguish data points, thereby measuring overall diversity.\nQuaDMix then employs a unified parameterized data sampling function that\ndetermines the sampling probability of each data point based on these quality\nand diversity related labels. To accelerate the search for the optimal\nparameters involved in the QuaDMix framework, we conduct simulated experiments\non smaller models and use LightGBM for parameters searching, inspired by the\nRegMix method. Our experiments across diverse models and datasets demonstrate\nthat QuaDMix achieves an average performance improvement of 7.2% across\nmultiple benchmarks. These results outperform the independent strategies for\nquality and diversity, highlighting the necessity and ability to balance data\nquality and diversity."}
{"id": "2504.16277", "pdf": "https://arxiv.org/pdf/2504.16277", "abs": "https://arxiv.org/abs/2504.16277", "authors": ["Neha Hulkund", "Alaa Maalouf", "Levi Cai", "Daniel Yang", "Tsun-Hsuan Wang", "Abigail O'Neil", "Timm Haucke", "Sandeep Mukherjee", "Vikram Ramaswamy", "Judy Hansen Shen", "Gabriel Tseng", "Mike Walmsley", "Daniela Rus", "Ken Goldberg", "Hannah Kerner", "Irene Chen", "Yogesh Girdhar", "Sara Beery"], "title": "DataS^3: Dataset Subset Selection for Specialization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In many real-world machine learning (ML) applications (e.g. detecting broken\nbones in x-ray images, detecting species in camera traps), in practice models\nneed to perform well on specific deployments (e.g. a specific hospital, a\nspecific national park) rather than the domain broadly. However, deployments\noften have imbalanced, unique data distributions. Discrepancy between the\ntraining distribution and the deployment distribution can lead to suboptimal\nperformance, highlighting the need to select deployment-specialized subsets\nfrom the available training data. We formalize dataset subset selection for\nspecialization (DS3): given a training set drawn from a general distribution\nand a (potentially unlabeled) query set drawn from the desired\ndeployment-specific distribution, the goal is to select a subset of the\ntraining data that optimizes deployment performance.\n  We introduce DataS^3; the first dataset and benchmark designed specifically\nfor the DS3 problem. DataS^3 encompasses diverse real-world application\ndomains, each with a set of distinct deployments to specialize in. We conduct a\ncomprehensive study evaluating algorithms from various families--including\ncoresets, data filtering, and data curation--on DataS^3, and find that\ngeneral-distribution methods consistently fail on deployment-specific tasks.\nAdditionally, we demonstrate the existence of manually curated\n(deployment-specific) expert subsets that outperform training on all available\ndata with accuracy gains up to 51.3 percent. Our benchmark highlights the\ncritical role of tailored dataset curation in enhancing performance and\ntraining efficiency on deployment-specific distributions, which we posit will\nonly become more important as global, public datasets become available across\ndomains and ML models are deployed in the real world."}
{"id": "2504.16824", "pdf": "https://arxiv.org/pdf/2504.16824", "abs": "https://arxiv.org/abs/2504.16824", "authors": ["Rhayza Jolley Rangel"], "title": "Nurturing Language Proficiency in Spanish.speaking children Through digital competence", "categories": ["cs.HC"], "comment": null, "summary": "This article explores into the intricate design and meticulous construction\nof a digital platform aimed at revolutionizing early-age English education,\nparticularly for Spanish-speaking children. The focus of this work used an\ninnovative methodologies, vibrant and engaging visuals, and a comprehensive\napproach to phonics. The principles of usability, accessibility, and\nuser-centered design are intricately woven into every facet of the platform's\narchitecture."}
{"id": "2504.16537", "pdf": "https://arxiv.org/pdf/2504.16537", "abs": "https://arxiv.org/abs/2504.16537", "authors": ["Hong Ting Tsang", "Zihao Wang", "Yangqiu Song"], "title": "Transformers for Complex Query Answering over Knowledge Hypergraphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Complex Query Answering (CQA) has been extensively studied in recent years.\nIn order to model data that is closer to real-world distribution, knowledge\ngraphs with different modalities have been introduced. Triple KGs, as the\nclassic KGs composed of entities and relations of arity 2, have limited\nrepresentation of real-world facts. Real-world data is more sophisticated.\nWhile hyper-relational graphs have been introduced, there are limitations in\nrepresenting relationships of varying arity that contain entities with equal\ncontributions. To address this gap, we sampled new CQA datasets: JF17k-HCQA and\nM-FB15k-HCQA. Each dataset contains various query types that include logical\noperations such as projection, negation, conjunction, and disjunction. In order\nto answer knowledge hypergraph (KHG) existential first-order queries, we\npropose a two-stage transformer model, the Logical Knowledge Hypergraph\nTransformer (LKHGT), which consists of a Projection Encoder for atomic\nprojection and a Logical Encoder for complex logical operations. Both encoders\nare equipped with Type Aware Bias (TAB) for capturing token interactions.\nExperimental results on CQA datasets show that LKHGT is a state-of-the-art CQA\nmethod over KHG and is able to generalize to out-of-distribution query types."}
{"id": "2504.16283", "pdf": "https://arxiv.org/pdf/2504.16283", "abs": "https://arxiv.org/abs/2504.16283", "authors": ["Jaya Narain", "Amrit Romana", "Vikramjit Mitra", "Colin Lea", "Shirley Ren"], "title": "Affect Models Have Weak Generalizability to Atypical Speech", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Speech and voice conditions can alter the acoustic properties of speech,\nwhich could impact the performance of paralinguistic models for affect for\npeople with atypical speech. We evaluate publicly available models for\nrecognizing categorical and dimensional affect from speech on a dataset of\natypical speech, comparing results to datasets of typical speech. We\ninvestigate three dimensions of speech atypicality: intelligibility, which is\nrelated to pronounciation; monopitch, which is related to prosody, and\nharshness, which is related to voice quality. We look at (1) distributional\ntrends of categorical affect predictions within the dataset, (2) distributional\ncomparisons of categorical affect predictions to similar datasets of typical\nspeech, and (3) correlation strengths between text and speech predictions for\nspontaneous speech for valence and arousal. We find that the output of affect\nmodels is significantly impacted by the presence and degree of speech\natypicalities. For instance, the percentage of speech predicted as sad is\nsignificantly higher for all types and grades of atypical speech when compared\nto similar typical speech datasets. In a preliminary investigation on improving\nrobustness for atypical speech, we find that fine-tuning models on\npseudo-labeled atypical speech data improves performance on atypical speech\nwithout impacting performance on typical speech. Our results emphasize the need\nfor broader training and evaluation datasets for speech emotion models, and for\nmodeling approaches that are robust to voice and speech differences."}
{"id": "2504.16883", "pdf": "https://arxiv.org/pdf/2504.16883", "abs": "https://arxiv.org/abs/2504.16883", "authors": ["Xuyang Zhu", "Sejoon Chang", "Andrew Kuik"], "title": "Enhancing Critical Thinking with AI: A Tailored Warning System for RAG Models", "categories": ["cs.HC"], "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning", "summary": "Retrieval-Augmented Generation (RAG) systems offer a powerful approach to\nenhancing large language model (LLM) outputs by incorporating fact-checked,\ncontextually relevant information. However, fairness and reliability concerns\npersist, as hallucinations can emerge at both the retrieval and generation\nstages, affecting users' reasoning and decision-making. Our research explores\nhow tailored warning messages -- whose content depends on the specific context\nof hallucination -- shape user reasoning and actions in an educational quiz\nsetting. Preliminary findings suggest that while warnings improve accuracy and\nawareness of high-level hallucinations, they may also introduce cognitive\nfriction, leading to confusion and diminished trust in the system. By examining\nthese interactions, this work contributes to the broader goal of AI-augmented\nreasoning: developing systems that actively support human reflection, critical\nthinking, and informed decision-making rather than passive information\nconsumption."}
{"id": "2504.16574", "pdf": "https://arxiv.org/pdf/2504.16574", "abs": "https://arxiv.org/abs/2504.16574", "authors": ["Lizhe Chen", "Binjia Zhou", "Yuyao Ge", "Jiayi Chen", "Shiguang NI"], "title": "PIS: Linking Importance Sampling and Attention Mechanisms for Efficient Prompt Compression", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress, demonstrating\nunprecedented capabilities across various natural language processing tasks.\nHowever, the high costs associated with such exceptional performance limit the\nwidespread adoption of LLMs, highlighting the need for prompt compression.\nExisting prompt compression methods primarily rely on heuristic truncation or\nabstractive summarization techniques, which fundamentally overlook the\nintrinsic mechanisms of LLMs and lack a systematic evaluation of token\nimportance for generation. In this work, we introduce Prompt Importance\nSampling (PIS), a novel compression framework that dynamically compresses\nprompts by sampling important tokens based on the analysis of attention scores\nof hidden states. PIS employs a dual-level compression mechanism: 1) at the\ntoken level, we quantify saliency using LLM-native attention scores and\nimplement adaptive compression through a lightweight 9-layer reinforcement\nlearning (RL) network; 2) at the semantic level, we propose a Russian roulette\nsampling strategy for sentence-level importance sampling. Comprehensive\nevaluations across multiple domain benchmarks demonstrate that our method\nachieves state-of-the-art compression performance. Notably, our framework\nserendipitously enhances reasoning efficiency through optimized context\nstructuring. This work advances prompt engineering by offering both theoretical\ngrounding and practical efficiency in context management for LLMs."}
{"id": "2504.16318", "pdf": "https://arxiv.org/pdf/2504.16318", "abs": "https://arxiv.org/abs/2504.16318", "authors": ["Kisung You"], "title": "Semantics at an Angle: When Cosine Similarity Works Until It Doesn't", "categories": ["cs.LG"], "comment": null, "summary": "Cosine similarity has become a standard metric for comparing embeddings in\nmodern machine learning. Its scale-invariance and alignment with model training\nobjectives have contributed to its widespread adoption. However, recent studies\nhave revealed important limitations, particularly when embedding norms carry\nmeaningful semantic information. This informal article offers a reflective and\nselective examination of the evolution, strengths, and limitations of cosine\nsimilarity. We highlight why it performs well in many settings, where it tends\nto break down, and how emerging alternatives are beginning to address its blind\nspots. We hope to offer a mix of conceptual clarity and practical perspective,\nespecially for quantitative scientists who think about embeddings not just as\nvectors, but as geometric and philosophical objects."}
{"id": "2504.16898", "pdf": "https://arxiv.org/pdf/2504.16898", "abs": "https://arxiv.org/abs/2504.16898", "authors": ["Will Epperson", "Arpit Mathur", "Adam Perer", "Dominik Moritz"], "title": "Texture: Structured Exploration of Text Datasets", "categories": ["cs.HC"], "comment": null, "summary": "Exploratory analysis of a text corpus is essential for assessing data quality\nand developing meaningful hypotheses. Text analysis relies on understanding\ndocuments through structured attributes spanning various granularities of the\ndocuments such as words, phrases, sentences, topics, or clusters. However,\ncurrent text visualization tools typically adopt a fixed representation\ntailored to specific tasks or domains, requiring users to switch tools as their\nanalytical goals change. To address this limitation, we present Texture, a\ngeneral-purpose interactive text exploration tool. Texture introduces a\nconfigurable data schema for representing text documents enriched with\ndescriptive attributes. These attributes can appear at arbitrary levels of\ngranularity in the text and possibly have multiple values, including\ndocument-level attributes, multi-valued attributes (e.g., topics), fine-grained\nspan-level attributes (e.g., words), and vector embeddings. The system then\ncombines existing interactive methods for text exploration into a single\ninterface that provides attribute overview visualizations, supports\ncross-filtering attribute charts to explore subsets, uses embeddings for a\ndataset overview and similar instance search, and contextualizes filters in the\nactual documents. We evaluated Texture through a two-part user study with 10\nparticipants from varied domains who each analyzed their own dataset in a\nbaseline session and then with Texture. Texture was able to represent all of\nthe previously derived dataset attributes, enabled participants to more quickly\niterate during their exploratory analysis, and discover new insights about\ntheir data. Our findings contribute to the design of scalable, interactive, and\nflexible exploration systems that improve users' ability to make sense of text\ndata."}
{"id": "2504.16601", "pdf": "https://arxiv.org/pdf/2504.16601", "abs": "https://arxiv.org/abs/2504.16601", "authors": ["Andy Li", "Wei Zhou", "Rashina Hoda", "Chris Bain", "Peter Poon"], "title": "Comparing Large Language Models and Traditional Machine Translation Tools for Translating Medical Consultation Summaries: A Pilot Study", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 2 tables and 1 Figure", "summary": "This study evaluates how well large language models (LLMs) and traditional\nmachine translation (MT) tools translate medical consultation summaries from\nEnglish into Arabic, Chinese, and Vietnamese. It assesses both patient,\nfriendly and clinician, focused texts using standard automated metrics. Results\nshowed that traditional MT tools generally performed better, especially for\ncomplex texts, while LLMs showed promise, particularly in Vietnamese and\nChinese, when translating simpler summaries. Arabic translations improved with\ncomplexity due to the language's morphology. Overall, while LLMs offer\ncontextual flexibility, they remain inconsistent, and current evaluation\nmetrics fail to capture clinical relevance. The study highlights the need for\ndomain-specific training, improved evaluation methods, and human oversight in\nmedical translation."}
{"id": "2504.16360", "pdf": "https://arxiv.org/pdf/2504.16360", "abs": "https://arxiv.org/abs/2504.16360", "authors": ["Mao Wang", "Tao Wu", "Xingping Xian", "Shaojie Qiao", "Weina Niu", "Canyixing Cui"], "title": "Disentangled Graph Representation Based on Substructure-Aware Graph Optimal Matching Kernel Convolutional Networks", "categories": ["cs.LG"], "comment": null, "summary": "Graphs effectively characterize relational data, driving graph representation\nlearning methods that uncover underlying predictive information. As\nstate-of-the-art approaches, Graph Neural Networks (GNNs) enable end-to-end\nlearning for diverse tasks. Recent disentangled graph representation learning\nenhances interpretability by decoupling independent factors in graph data.\nHowever, existing methods often implicitly and coarsely characterize graph\nstructures, limiting structural pattern analysis within the graph. This paper\nproposes the Graph Optimal Matching Kernel Convolutional Network (GOMKCN) to\naddress this limitation. We view graphs as node-centric subgraphs, where each\nsubgraph acts as a structural factor encoding position-specific information.\nThis transforms graph prediction into structural pattern recognition. Inspired\nby CNNs, GOMKCN introduces the Graph Optimal Matching Kernel (GOMK) as a\nconvolutional operator, computing similarities between subgraphs and learnable\ngraph filters. Mathematically, GOMK maps subgraphs and filters into a Hilbert\nspace, representing graphs as point sets. Disentangled representations emerge\nfrom projecting subgraphs onto task-optimized filters, which adaptively capture\nrelevant structural patterns via gradient descent. Crucially, GOMK incorporates\nlocal correspondences in similarity measurement, resolving the trade-off\nbetween differentiability and accuracy in graph kernels. Experiments validate\nthat GOMKCN achieves superior accuracy and interpretability in graph pattern\nmining and prediction. The framework advances the theoretical foundation for\ndisentangled graph representation learning."}
{"id": "2504.16086", "pdf": "https://arxiv.org/pdf/2504.16086", "abs": "https://arxiv.org/abs/2504.16086", "authors": ["Guanzhou Ji", "Azadeh O. Sawyer", "Srinivasa G. Narasimhan"], "title": "Digital Kitchen Remodeling: Editing and Relighting Intricate Indoor Scenes from a Single Panorama", "categories": ["cs.GR", "cs.HC"], "comment": "Submitted to IES25 - The Lighting Conference, Anaheim, California,\n  August 21 - 23, 2025", "summary": "We present a novel virtual staging application for kitchen remodeling from a\nsingle panorama. To ensure the realism of the virtual rendered scene, we\ncapture real-world High Dynamic Range (HDR) panoramas and recover the absolute\nscene radiance for high-quality scene relighting. Our application pipeline\nconsists of three key components: (1) HDR photography for capturing paired\nindoor and outdoor panoramas, (2) automatic kitchen layout generation with new\nkitchen components, and (3) an editable rendering pipeline that flexibly edits\nscene materials and relights the new virtual scene with global illumination.\nAdditionally, we contribute a novel Pano-Pano HDR dataset with 141 paired\nindoor and outdoor panoramas and present a low-cost photometric calibration\nmethod for panoramic HDR photography."}
{"id": "2504.16604", "pdf": "https://arxiv.org/pdf/2504.16604", "abs": "https://arxiv.org/abs/2504.16604", "authors": ["Mareike Lisker", "Christina Gottschalk", "Helena Mihaljević"], "title": "Debunking with Dialogue? Exploring AI-Generated Counterspeech to Challenge Conspiracy Theories", "categories": ["cs.CL", "cs.AI", "cs.SI", "I.2.7"], "comment": "15 pages", "summary": "Counterspeech is a key strategy against harmful online content, but scaling\nexpert-driven efforts is challenging. Large Language Models (LLMs) present a\npotential solution, though their use in countering conspiracy theories is\nunder-researched. Unlike for hate speech, no datasets exist that pair\nconspiracy theory comments with expert-crafted counterspeech. We address this\ngap by evaluating the ability of GPT-4o, Llama 3, and Mistral to effectively\napply counterspeech strategies derived from psychological research provided\nthrough structured prompts. Our results show that the models often generate\ngeneric, repetitive, or superficial results. Additionally, they\nover-acknowledge fear and frequently hallucinate facts, sources, or figures,\nmaking their prompt-based use in practical applications problematic."}
{"id": "2504.16415", "pdf": "https://arxiv.org/pdf/2504.16415", "abs": "https://arxiv.org/abs/2504.16415", "authors": ["Neharika Jali", "Eshika Pathak", "Pranay Sharma", "Guannan Qu", "Gauri Joshi"], "title": "Natural Policy Gradient for Average Reward Non-Stationary RL", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We consider the problem of non-stationary reinforcement learning (RL) in the\ninfinite-horizon average-reward setting. We model it by a Markov Decision\nProcess with time-varying rewards and transition probabilities, with a\nvariation budget of $\\Delta_T$. Existing non-stationary RL algorithms focus on\nmodel-based and model-free value-based methods. Policy-based methods despite\ntheir flexibility in practice are not theoretically well understood in\nnon-stationary RL. We propose and analyze the first model-free policy-based\nalgorithm, Non-Stationary Natural Actor-Critic (NS-NAC), a policy gradient\nmethod with a restart based exploration for change and a novel interpretation\nof learning rates as adapting factors. Further, we present a bandit-over-RL\nbased parameter-free algorithm BORL-NS-NAC that does not require prior\nknowledge of the variation budget $\\Delta_T$. We present a dynamic regret of\n$\\tilde{\\mathscr O}(|S|^{1/2}|A|^{1/2}\\Delta_T^{1/6}T^{5/6})$ for both\nalgorithms, where $T$ is the time horizon, and $|S|$, $|A|$ are the sizes of\nthe state and action spaces. The regret analysis leverages a novel adaptation\nof the Lyapunov function analysis of NAC to dynamic environments and\ncharacterizes the effects of simultaneous updates in policy, value function\nestimate and changes in the environment."}
{"id": "2504.16092", "pdf": "https://arxiv.org/pdf/2504.16092", "abs": "https://arxiv.org/abs/2504.16092", "authors": ["Mahrad Almotahari"], "title": "Cooperative Speech, Semantic Competence, and AI", "categories": ["cs.CY", "cs.CL", "cs.HC"], "comment": "25 pages", "summary": "Cooperative speech is purposive. From the speaker's perspective, one crucial\npurpose is the transmission of knowledge. Cooperative speakers care about\ngetting things right for their conversational partners. This attitude is a kind\nof respect. Cooperative speech is an ideal form of communication because\nparticipants have respect for each other. And having respect within a\ncooperative enterprise is sufficient for a particular kind of moral standing:\nwe ought to respect those who have respect for us. Respect demands reciprocity.\nI maintain that large language models aren't owed the kind of respect that\npartly constitutes a cooperative conversation. This implies that they aren't\ncooperative interlocutors, otherwise we would be obliged to reciprocate the\nattitude. Leveraging this conclusion, I argue that present-day LLMs are\nincapable of assertion and that this raises an overlooked doubt about their\nsemantic competence. One upshot of this argument is that knowledge of meaning\nisn't just a subject for the cognitive psychologist. It's also a subject for\nthe moral psychologist."}
{"id": "2504.16627", "pdf": "https://arxiv.org/pdf/2504.16627", "abs": "https://arxiv.org/abs/2504.16627", "authors": ["Prasanna Devadiga", "Arya Suneesh", "Pawan Kumar Rajpoot", "Bharatdeep Hazarika", "Aditya U Baliga"], "title": "TIFIN India at SemEval-2025: Harnessing Translation to Overcome Multilingual IR Challenges in Fact-Checked Claim Retrieval", "categories": ["cs.CL"], "comment": null, "summary": "We address the challenge of retrieving previously fact-checked claims in\nmonolingual and crosslingual settings - a critical task given the global\nprevalence of disinformation. Our approach follows a two-stage strategy: a\nreliable baseline retrieval system using a fine-tuned embedding model and an\nLLM-based reranker. Our key contribution is demonstrating how LLM-based\ntranslation can overcome the hurdles of multilingual information retrieval.\nAdditionally, we focus on ensuring that the bulk of the pipeline can be\nreplicated on a consumer GPU. Our final integrated system achieved a success@10\nscore of 0.938 and 0.81025 on the monolingual and crosslingual test sets,\nrespectively."}
{"id": "2504.16430", "pdf": "https://arxiv.org/pdf/2504.16430", "abs": "https://arxiv.org/abs/2504.16430", "authors": ["Andrew Ilyas", "Logan Engstrom"], "title": "MAGIC: Near-Optimal Data Attribution for Deep Learning", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "comment": null, "summary": "The goal of predictive data attribution is to estimate how adding or removing\na given set of training datapoints will affect model predictions. In convex\nsettings, this goal is straightforward (i.e., via the infinitesimal jackknife).\nIn large-scale (non-convex) settings, however, existing methods are far less\nsuccessful -- current methods' estimates often only weakly correlate with\nground truth. In this work, we present a new data attribution method (MAGIC)\nthat combines classical methods and recent advances in metadifferentiation to\n(nearly) optimally estimate the effect of adding or removing training data on\nmodel predictions."}
{"id": "2504.16117", "pdf": "https://arxiv.org/pdf/2504.16117", "abs": "https://arxiv.org/abs/2504.16117", "authors": ["Sridevi Polavaram", "Xin Zhou", "Meenu Ravi", "Mohammad Zarei", "Anmol Srivastava"], "title": "Context-Awareness and Interpretability of Rare Occurrences for Discovery and Formalization of Critical Failure Modes", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": "Accepted to IEEE Conference for Artificial Intelligence, 2025", "summary": "Vision systems are increasingly deployed in critical domains such as\nsurveillance, law enforcement, and transportation. However, their\nvulnerabilities to rare or unforeseen scenarios pose significant safety risks.\nTo address these challenges, we introduce Context-Awareness and\nInterpretability of Rare Occurrences (CAIRO), an ontology-based human-assistive\ndiscovery framework for failure cases (or CP - Critical Phenomena) detection\nand formalization. CAIRO by design incentivizes human-in-the-loop for testing\nand evaluation of criticality that arises from misdetections, adversarial\nattacks, and hallucinations in AI black-box models. Our robust analysis of\nobject detection model(s) failures in automated driving systems (ADS) showcases\nscalable and interpretable ways of formalizing the observed gaps between camera\nperception and real-world contexts, resulting in test cases stored as explicit\nknowledge graphs (in OWL/XML format) amenable for sharing, downstream analysis,\nlogical reasoning, and accountability."}
{"id": "2504.16677", "pdf": "https://arxiv.org/pdf/2504.16677", "abs": "https://arxiv.org/abs/2504.16677", "authors": ["Luisa Shimabucoro", "Ahmet Ustun", "Marzieh Fadaee", "Sebastian Ruder"], "title": "A Post-trainer's Guide to Multilingual Training Data: Uncovering Cross-lingual Transfer Dynamics", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In order for large language models to be useful across the globe, they are\nfine-tuned to follow instructions on multilingual data. Despite the ubiquity of\nsuch post-training, a clear understanding of the dynamics that enable\ncross-lingual transfer remains elusive. This study examines cross-lingual\ntransfer (CLT) dynamics in realistic post-training settings. We study two model\nfamilies of up to 35B parameters in size trained on carefully controlled\nmixtures of multilingual data on three generative tasks with varying levels of\ncomplexity (summarization, instruction following, and mathematical reasoning)\nin both single-task and multi-task instruction tuning settings. Overall, we\nfind that the dynamics of cross-lingual transfer and multilingual performance\ncannot be explained by isolated variables, varying depending on the combination\nof post-training settings. Finally, we identify the conditions that lead to\neffective cross-lingual transfer in practice."}
{"id": "2504.16431", "pdf": "https://arxiv.org/pdf/2504.16431", "abs": "https://arxiv.org/abs/2504.16431", "authors": ["Ruixiang Zhang", "Shuangfei Zhai", "Yizhe Zhang", "James Thornton", "Zijing Ou", "Joshua Susskind", "Navdeep Jaitly"], "title": "Target Concrete Score Matching: A Holistic Framework for Discrete Diffusion", "categories": ["cs.LG"], "comment": null, "summary": "Discrete diffusion is a promising framework for modeling and generating\ndiscrete data. In this work, we present Target Concrete Score Matching (TCSM),\na novel and versatile objective for training and fine-tuning discrete diffusion\nmodels. TCSM provides a general framework with broad applicability. It supports\npre-training discrete diffusion models directly from data samples, and many\nexisting discrete diffusion approaches naturally emerge as special cases of our\nmore general TCSM framework. Furthermore, the same TCSM objective extends to\npost-training of discrete diffusion models, including fine-tuning using reward\nfunctions or preference data, and distillation of knowledge from pre-trained\nautoregressive models. These new capabilities stem from the core idea of TCSM,\nestimating the concrete score of the target distribution, which resides in the\noriginal (clean) data space. This allows seamless integration with reward\nfunctions and pre-trained models, which inherently only operate in the clean\ndata space rather than the noisy intermediate spaces of diffusion processes.\nOur experiments on language modeling tasks demonstrate that TCSM matches or\nsurpasses current methods. Additionally, TCSM is versatile, applicable to both\npre-training and post-training scenarios, offering greater flexibility and\nsample efficiency."}
{"id": "2504.16180", "pdf": "https://arxiv.org/pdf/2504.16180", "abs": "https://arxiv.org/abs/2504.16180", "authors": ["Md Saeed Siddik", "Hao Li", "Cor-Paul Bezemer"], "title": "A Systematic Literature Review of Software Engineering Research on Jupyter Notebook", "categories": ["cs.SE", "cs.CE", "cs.HC"], "comment": null, "summary": "Context: Jupyter Notebook has emerged as a versatile tool that transforms how\nresearchers, developers, and data scientists conduct and communicate their\nwork. As the adoption of Jupyter notebooks continues to rise, so does the\ninterest from the software engineering research community in improving the\nsoftware engineering practices for Jupyter notebooks.\n  Objective: The purpose of this study is to analyze trends, gaps, and\nmethodologies used in software engineering research on Jupyter notebooks.\n  Method: We selected 146 relevant publications from the DBLP Computer Science\nBibliography up to the end of 2024, following established systematic literature\nreview guidelines. We explored publication trends, categorized them based on\nsoftware engineering topics, and reported findings based on those topics.\n  Results: The most popular venues for publishing software engineering research\non Jupyter notebooks are related to human-computer interaction instead of\ntraditional software engineering venues. Researchers have addressed a wide\nrange of software engineering topics on notebooks, such as code reuse,\nreadability, and execution environment. Although reusability is one of the\nresearch topics for Jupyter notebooks, only 64 of the 146 studies can be reused\nbased on their provided URLs. Additionally, most replication packages are not\nhosted on permanent repositories for long-term availability and adherence to\nopen science principles.\n  Conclusion: Solutions specific to notebooks for software engineering issues,\nincluding testing, refactoring, and documentation, are underexplored. Future\nresearch opportunities exist in automatic testing frameworks, refactoring\nclones between notebooks, and generating group documentation for coherent code\ncells."}
{"id": "2504.16754", "pdf": "https://arxiv.org/pdf/2504.16754", "abs": "https://arxiv.org/abs/2504.16754", "authors": ["Kwangseob Ahn"], "title": "HEMA : A Hippocampus-Inspired Extended Memory Architecture for Long-Context AI Conversations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) struggle with maintaining coherence in extended\nconversations spanning hundreds of turns, despite performing well within their\ncontext windows. This paper introduces HEMA (Hippocampus-Inspired Extended\nMemory Architecture), a dual-memory system inspired by human cognitive\nprocesses. HEMA combines Compact Memory - a continuously updated one-sentence\nsummary preserving global narrative coherence, and Vector Memory - an episodic\nstore of chunk embeddings queried via cosine similarity. When integrated with a\n6B-parameter transformer, HEMA maintains coherent dialogues beyond 300 turns\nwhile keeping prompt length under 3,500 tokens. Experimental results show\nsubstantial improvements: factual recall accuracy increases from 41% to 87%,\nand human-rated coherence improves from 2.7 to 4.3 on a 5-point scale. With 10K\nindexed chunks, Vector Memory achieves P@5 >= 0.80 and R@50 >= 0.74, doubling\nthe area under the precision-recall curve compared to summarization-only\napproaches. Ablation studies reveal two key insights: semantic forgetting\nthrough age-weighted pruning reduces retrieval latency by 34% with minimal\nrecall loss, and a two-level summary hierarchy prevents cascade errors in\nultra-long conversations exceeding 1,000 turns. HEMA demonstrates that\ncombining verbatim recall with semantic continuity provides a practical\nsolution for privacy-aware conversational AI capable of month-long dialogues\nwithout model retraining."}
{"id": "2504.16432", "pdf": "https://arxiv.org/pdf/2504.16432", "abs": "https://arxiv.org/abs/2504.16432", "authors": ["Ziran Liang", "Rui An", "Wenqi Fan", "Yanghui Rao", "Yuxuan Liang"], "title": "iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As time evolves, data within specific domains exhibit predictability that\nmotivates time series forecasting to predict future trends from historical\ndata. However, current deep forecasting methods can achieve promising\nperformance but generally lack interpretability, hindering trustworthiness and\npractical deployment in safety-critical applications such as auto-driving and\nhealthcare. In this paper, we propose a novel interpretable model, iTFKAN, for\ncredible time series forecasting. iTFKAN enables further exploration of model\ndecision rationales and underlying data patterns due to its interpretability\nachieved through model symbolization. Besides, iTFKAN develops two strategies,\nprior knowledge injection, and time-frequency synergy learning, to effectively\nguide model learning under complex intertwined time series data. Extensive\nexperimental results demonstrated that iTFKAN can achieve promising forecasting\nperformance while simultaneously possessing high interpretive capabilities."}
{"id": "2504.16255", "pdf": "https://arxiv.org/pdf/2504.16255", "abs": "https://arxiv.org/abs/2504.16255", "authors": ["Tina Behzad", "Mithilesh Kumar Singh", "Anthony J. Ripa", "Klaus Mueller"], "title": "FairPlay: A Collaborative Approach to Mitigate Bias in Datasets for Improved AI Fairness", "categories": ["cs.LG", "cs.CY", "cs.HC", "H.5.2; H.5.3; I.2.6"], "comment": "Accepted at ACM CSCW 2025. 30 pages total (including references and\n  supplementary material). Contains 10 figures", "summary": "The issue of fairness in decision-making is a critical one, especially given\nthe variety of stakeholder demands for differing and mutually incompatible\nversions of fairness. Adopting a strategic interaction of perspectives provides\nan alternative to enforcing a singular standard of fairness. We present a\nweb-based software application, FairPlay, that enables multiple stakeholders to\ndebias datasets collaboratively. With FairPlay, users can negotiate and arrive\nat a mutually acceptable outcome without a universally agreed-upon theory of\nfairness. In the absence of such a tool, reaching a consensus would be highly\nchallenging due to the lack of a systematic negotiation process and the\ninability to modify and observe changes. We have conducted user studies that\ndemonstrate the success of FairPlay, as users could reach a consensus within\nabout five rounds of gameplay, illustrating the application's potential for\nenhancing fairness in AI systems."}
{"id": "2504.16768", "pdf": "https://arxiv.org/pdf/2504.16768", "abs": "https://arxiv.org/abs/2504.16768", "authors": ["Waad Alhoshan", "Alessio Ferrari", "Liping Zhao"], "title": "How Effective are Generative Large Language Models in Performing Requirements Classification?", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": null, "summary": "In recent years, transformer-based large language models (LLMs) have\nrevolutionised natural language processing (NLP), with generative models\nopening new possibilities for tasks that require context-aware text generation.\nRequirements engineering (RE) has also seen a surge in the experimentation of\nLLMs for different tasks, including trace-link detection, regulatory\ncompliance, and others. Requirements classification is a common task in RE.\nWhile non-generative LLMs like BERT have been successfully applied to this\ntask, there has been limited exploration of generative LLMs. This gap raises an\nimportant question: how well can generative LLMs, which produce context-aware\noutputs, perform in requirements classification? In this study, we explore the\neffectiveness of three generative LLMs-Bloom, Gemma, and Llama-in performing\nboth binary and multi-class requirements classification. We design an extensive\nexperimental study involving over 400 experiments across three widely used\ndatasets (PROMISE NFR, Functional-Quality, and SecReq). Our study concludes\nthat while factors like prompt design and LLM architecture are universally\nimportant, others-such as dataset variations-have a more situational impact,\ndepending on the complexity of the classification task. This insight can guide\nfuture model development and deployment strategies, focusing on optimising\nprompt structures and aligning model architectures with task-specific needs for\nimproved performance."}
{"id": "2504.16438", "pdf": "https://arxiv.org/pdf/2504.16438", "abs": "https://arxiv.org/abs/2504.16438", "authors": ["Charlie Hou", "Mei-Yu Wang", "Yige Zhu", "Daniel Lazar", "Giulia Fanti"], "title": "Private Federated Learning using Preference-Optimized Synthetic Data", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC"], "comment": "Spotlight presentation at SynthData Workshop ICLR25", "summary": "In practical settings, differentially private Federated learning (DP-FL) is\nthe dominant method for training models from private, on-device client data.\nRecent work has suggested that DP-FL may be enhanced or outperformed by methods\nthat use DP synthetic data (Wu et al., 2024; Hou et al., 2024). The primary\nalgorithms for generating DP synthetic data for FL applications require careful\nprompt engineering based on public information and/or iterative private client\nfeedback. Our key insight is that the private client feedback collected by\nprior DP synthetic data methods (Hou et al., 2024; Xie et al., 2024) can be\nviewed as a preference ranking. Our algorithm, Preference Optimization for\nPrivate Client Data (POPri) harnesses client feedback using preference\noptimization algorithms such as Direct Preference Optimization (DPO) to\nfine-tune LLMs to generate high-quality DP synthetic data. To evaluate POPri,\nwe release LargeFedBench, a new federated text benchmark for uncontaminated LLM\nevaluations on federated client data. POPri substantially improves the utility\nof DP synthetic data relative to prior work on LargeFedBench datasets and an\nexisting benchmark from Xie et al. (2024). POPri closes the gap between\nnext-token prediction accuracy in the fully-private and non-private settings by\nup to 68%, compared to 52% for prior synthetic data methods, and 10% for\nstate-of-the-art DP federated learning methods. The code and data are available\nat https://github.com/meiyuw/POPri."}
{"id": "2504.16273", "pdf": "https://arxiv.org/pdf/2504.16273", "abs": "https://arxiv.org/abs/2504.16273", "authors": ["Joseph Lee", "Tianqi Shang", "Jae Young Baik", "Duy Duong-Tran", "Shu Yang", "Lingyao Li", "Li Shen"], "title": "Investigating LLMs in Clinical Triage: Promising Capabilities, Persistent Intersectional Biases", "categories": ["cs.AI", "cs.HC"], "comment": "Accepted to GenAI4Health Workshop @ AAAI 2025", "summary": "Large Language Models (LLMs) have shown promise in clinical decision support,\nyet their application to triage remains underexplored. We systematically\ninvestigate the capabilities of LLMs in emergency department triage through two\nkey dimensions: (1) robustness to distribution shifts and missing data, and (2)\ncounterfactual analysis of intersectional biases across sex and race. We assess\nmultiple LLM-based approaches, ranging from continued pre-training to\nin-context learning, as well as machine learning approaches. Our results\nindicate that LLMs exhibit superior robustness, and we investigate the key\nfactors contributing to the promising LLM-based approaches. Furthermore, in\nthis setting, we identify gaps in LLM preferences that emerge in particular\nintersections of sex and race. LLMs generally exhibit sex-based differences,\nbut they are most pronounced in certain racial groups. These findings suggest\nthat LLMs encode demographic preferences that may emerge in specific clinical\ncontexts or particular combinations of characteristics."}
{"id": "2504.16778", "pdf": "https://arxiv.org/pdf/2504.16778", "abs": "https://arxiv.org/abs/2504.16778", "authors": ["Sarah Jabbour", "Trenton Chang", "Anindya Das Antar", "Joseph Peper", "Insu Jang", "Jiachen Liu", "Jae-Won Chung", "Shiqi He", "Michael Wellman", "Bryan Goodman", "Elizabeth Bondi-Kelly", "Kevin Samy", "Rada Mihalcea", "Mosharaf Chowhury", "David Jurgens", "Lu Wang"], "title": "Evaluation Framework for AI Systems in \"the Wild\"", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "35 pages", "summary": "Generative AI (GenAI) models have become vital across industries, yet current\nevaluation methods have not adapted to their widespread use. Traditional\nevaluations often rely on benchmarks and fixed datasets, frequently failing to\nreflect real-world performance, which creates a gap between lab-tested outcomes\nand practical applications. This white paper proposes a comprehensive framework\nfor how we should evaluate real-world GenAI systems, emphasizing diverse,\nevolving inputs and holistic, dynamic, and ongoing assessment approaches. The\npaper offers guidance for practitioners on how to design evaluation methods\nthat accurately reflect real-time capabilities, and provides policymakers with\nrecommendations for crafting GenAI policies focused on societal impacts, rather\nthan fixed performance numbers or parameter sizes. We advocate for holistic\nframeworks that integrate performance, fairness, and ethics and the use of\ncontinuous, outcome-oriented methods that combine human and automated\nassessments while also being transparent to foster trust among stakeholders.\nImplementing these strategies ensures GenAI models are not only technically\nproficient but also ethically responsible and impactful."}
{"id": "2504.16447", "pdf": "https://arxiv.org/pdf/2504.16447", "abs": "https://arxiv.org/abs/2504.16447", "authors": ["Jeesuk Shin", "Cheolwoong Kim", "Sunwoong Yang", "Minseo Lee", "Sung Joong Kim", "Joongoo Jeon"], "title": "Node Assigned physics-informed neural networks for thermal-hydraulic system simulation: CVH/FL module", "categories": ["cs.LG"], "comment": "40 pages, 12 figures. Jeesuk Shin and Cheolwoong Kim contributed\n  equally to this work. Sung Joong Kim and Joongoo Jeon are co-corresponding\n  authors", "summary": "Severe accidents (SAs) in nuclear power plants have been analyzed using\nthermal-hydraulic (TH) system codes such as MELCOR and MAAP. These codes\nefficiently simulate the progression of SAs, while they still have inherent\nlimitations due to their inconsistent finite difference schemes. The use of\nempirical schemes incorporating both implicit and explicit formulations\ninherently induces unidirectional coupling in multi-physics analyses. The\nobjective of this study is to develop a novel numerical method for TH system\ncodes using physics-informed neural network (PINN). They have shown strength in\nsolving multi-physics due to the innate feature of neural networks-automatic\ndifferentiation. We propose a node-assigned PINN (NA-PINN) that is suitable for\nthe control volume approach-based system codes. NA-PINN addresses the issue of\nspatial governing equation variation by assigning an individual network to each\nnodalization of the system code, such that spatial information is excluded from\nboth the input and output domains, and each subnetwork learns to approximate a\npurely temporal solution. In this phase, we evaluated the accuracy of the PINN\nmethods for the hydrodynamic module. In the 6 water tank simulation, PINN and\nNA-PINN showed maximum absolute errors of 1.678 and 0.007, respectively. It\nshould be noted that only NA-PINN demonstrated acceptable accuracy. To the best\nof the authors' knowledge, this is the first study to successfully implement a\nsystem code using PINN. Our future work involves extending NA-PINN to a\nmulti-physics solver and developing it in a surrogate manner."}
{"id": "2504.16419", "pdf": "https://arxiv.org/pdf/2504.16419", "abs": "https://arxiv.org/abs/2504.16419", "authors": ["Qi Yang", "Weichen Bi", "Haiyang Shen", "Yaoqi Guo", "Yun Ma"], "title": "PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": null, "summary": "Graphical User Interface (GUI) datasets are crucial for various downstream\ntasks. However, GUI datasets often generate annotation information through\nautomatic labeling, which commonly results in inaccurate GUI element BBox\nannotations, including missing, duplicate, or meaningless BBoxes. These issues\ncan degrade the performance of models trained on these datasets, limiting their\neffectiveness in real-world applications. Additionally, existing GUI datasets\nonly provide BBox annotations visually, which restricts the development of\nvisually related GUI downstream tasks. To address these issues, we introduce\nPixelWeb, a large-scale GUI dataset containing over 100,000 annotated web\npages. PixelWeb is constructed using a novel automatic annotation approach that\nintegrates visual feature extraction and Document Object Model (DOM) structure\nanalysis through two core modules: channel derivation and layer analysis.\nChannel derivation ensures accurate localization of GUI elements in cases of\nocclusion and overlapping elements by extracting BGRA four-channel bitmap\nannotations. Layer analysis uses the DOM to determine the visibility and\nstacking order of elements, providing precise BBox annotations. Additionally,\nPixelWeb includes comprehensive metadata such as element images, contours, and\nmask annotations. Manual verification by three independent annotators confirms\nthe high quality and accuracy of PixelWeb annotations. Experimental results on\nGUI element detection tasks show that PixelWeb achieves performance on the\nmAP95 metric that is 3-7 times better than existing datasets. We believe that\nPixelWeb has great potential for performance improvement in downstream tasks\nsuch as GUI generation and automated user interaction."}
{"id": "2504.16786", "pdf": "https://arxiv.org/pdf/2504.16786", "abs": "https://arxiv.org/abs/2504.16786", "authors": ["Fengwei Zhou", "Jiafei Song", "Wenjin Jason Li", "Gengjian Xue", "Zhikang Zhao", "Yichao Lu", "Bailin Na"], "title": "MOOSComp: Improving Lightweight Long-Context Compressor via Mitigating Over-Smoothing and Incorporating Outlier Scores", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in large language models have significantly improved their\nability to process long-context input, but practical applications are\nchallenged by increased inference time and resource consumption, particularly\nin resource-constrained environments. To address these challenges, we propose\nMOOSComp, a token-classification-based long-context compression method that\nenhances the performance of a BERT-based compressor by mitigating the\nover-smoothing problem and incorporating outlier scores. In the training phase,\nwe add an inter-class cosine similarity loss term to penalize excessively\nsimilar token representations, thereby improving the token classification\naccuracy. During the compression phase, we introduce outlier scores to preserve\nrare but critical tokens that are prone to be discarded in task-agnostic\ncompression. These scores are integrated with the classifier's output, making\nthe compressor more generalizable to various tasks. Superior performance is\nachieved at various compression ratios on long-context understanding and\nreasoning benchmarks. Moreover, our method obtains a speedup of 3.3x at a 4x\ncompression ratio on a resource-constrained mobile device."}
{"id": "2504.16450", "pdf": "https://arxiv.org/pdf/2504.16450", "abs": "https://arxiv.org/abs/2504.16450", "authors": ["Rubing Yang", "Pratik Chaudhari"], "title": "An Effective Gram Matrix Characterizes Generalization in Deep Networks", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We derive a differential equation that governs the evolution of the\ngeneralization gap when a deep network is trained by gradient descent. This\ndifferential equation is controlled by two quantities, a contraction factor\nthat brings together trajectories corresponding to slightly different datasets,\nand a perturbation factor that accounts for them training on different\ndatasets. We analyze this differential equation to compute an ``effective Gram\nmatrix'' that characterizes the generalization gap after training in terms of\nthe alignment between this Gram matrix and a certain initial ``residual''.\nEmpirical evaluations on image classification datasets indicate that this\nanalysis can predict the test loss accurately. Further, at any point during\ntraining, the residual predominantly lies in the subspace of the effective Gram\nmatrix with the smallest eigenvalues. This indicates that the training process\nis benign, i.e., it does not lead to significant deterioration of the\ngeneralization gap (which is zero at initialization). The alignment between the\neffective Gram matrix and the residual is different for different datasets and\narchitectures. The match/mismatch of the data and the architecture is primarily\nresponsible for good/bad generalization."}
{"id": "2504.16504", "pdf": "https://arxiv.org/pdf/2504.16504", "abs": "https://arxiv.org/abs/2504.16504", "authors": ["Zhenguang Zhong", "Zhixuan Wang"], "title": "Intelligent Depression Prevention via LLM-Based Dialogue Analysis: Overcoming the Limitations of Scale-Dependent Diagnosis through Precise Emotional Pattern Recognition", "categories": ["q-bio.NC", "cs.HC"], "comment": null, "summary": "Existing depression screening predominantly relies on standardized\nquestionnaires (e.g., PHQ-9, BDI), which suffer from high misdiagnosis rates\n(18-34% in clinical studies) due to their static, symptom-counting nature and\nsusceptibility to patient recall bias. This paper presents an AI-powered\ndepression prevention system that leverages large language models (LLMs) to\nanalyze real-time conversational cues--including subtle emotional expressions\n(e.g., micro-sentiment shifts, self-referential language patterns)--for more\naccurate and dynamic mental state assessment. Our system achieves three key\ninnovations: (1) Continuous monitoring through natural dialogue, detecting\ndepression-indicative linguistic features (anhedonia markers, hopelessness\nsemantics) with 89% precision (vs. 72% for PHQ-9); (2) Adaptive risk\nstratification that updates severity levels based on conversational context,\nreducing false positives by 41% compared to scale-based thresholds; and (3)\nPersonalized intervention strategies tailored to users' emotional granularity,\ndemonstrating 2.3x higher adherence rates than generic advice. Clinical\nvalidation with 450 participants shows the system identifies 92% of at-risk\ncases missed by traditional scales, while its explainable AI interface bridges\nthe gap between automated analysis and clinician judgment. This work\nestablishes conversational AI as a paradigm shift from episodic scale-dependent\ndiagnosis to continuous, emotionally intelligent mental health monitoring."}
{"id": "2504.16787", "pdf": "https://arxiv.org/pdf/2504.16787", "abs": "https://arxiv.org/abs/2504.16787", "authors": ["Ningning Zhang", "Chi Zhang", "Zhizhong Tan", "Xingxing Yang", "Weiping Deng", "Wenyong Wang"], "title": "Credible plan-driven RAG method for Multi-hop Question Answering", "categories": ["cs.CL", "cs.AI", "I.2.0"], "comment": "18 pages, 3 figures", "summary": "Multi-hop question answering (QA) presents a considerable challenge for\nRetrieval-Augmented Generation (RAG), requiring the structured decomposition of\ncomplex queries into logical reasoning paths and the generation of dependable\nintermediate results. However, deviations in reasoning paths or errors in\nintermediate results, which are common in current RAG methods, may propagate\nand accumulate throughout the reasoning process, diminishing the accuracy of\nthe answer to complex queries. To address this challenge, we propose the\nPlan-then-Act-and-Review (PAR RAG) framework, which is organized into three key\nstages: planning, act, and review, and aims to offer an interpretable and\nincremental reasoning paradigm for accurate and reliable multi-hop question\nanswering by mitigating error propagation.PAR RAG initially applies a top-down\nproblem decomposition strategy, formulating a comprehensive plan that\nintegrates multiple executable steps from a holistic viewpoint. This approach\navoids the pitfalls of local optima common in traditional RAG methods, ensuring\nthe accuracy of the entire reasoning path. Subsequently, PAR RAG incorporates a\nplan execution mechanism based on multi-granularity verification. By utilizing\nboth coarse-grained similarity information and fine-grained relevant data, the\nframework thoroughly checks and adjusts intermediate results, ensuring process\naccuracy while effectively managing error propagation and amplification.\nExperimental results on multi-hop QA datasets demonstrate that the PAR RAG\nframework substantially outperforms existing state-of-the-art methods in key\nmetrics, including EM and F1 scores."}
{"id": "2504.16501", "pdf": "https://arxiv.org/pdf/2504.16501", "abs": "https://arxiv.org/abs/2504.16501", "authors": ["Seungyoon Choi", "Sein Kim", "Hongseok Kang", "Wonjoong Kim", "Chanyoung Park"], "title": "Dynamic Time-aware Continual User Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "Traditional user modeling (UM) approaches have primarily focused on designing\nmodels for a single specific task, but they face limitations in generalization\nand adaptability across various tasks. Recognizing these challenges, recent\nstudies have shifted towards continual learning (CL)-based universal user\nrepresentation learning aiming to develop a single model capable of handling\nmultiple tasks. Despite advancements, existing methods are in fact evaluated\nunder an unrealistic scenario that does not consider the passage of time as\ntasks progress, which overlooks newly emerged items that may change the item\ndistribution of previous tasks. In this paper, we introduce a practical\nevaluation scenario on which CL-based universal user representation learning\napproaches should be evaluated, which takes into account the passage of time as\ntasks progress. Then, we propose a novel framework Dynamic Time-aware continual\nuser representation learner, named DITTO, designed to alleviate catastrophic\nforgetting despite continuous shifts in item distribution, while also allowing\nthe knowledge acquired from previous tasks to adapt to the current shifted item\ndistribution. Through our extensive experiments, we demonstrate the superiority\nof DITTO over state-of-the-art methods under a practical evaluation scenario.\nOur source code is available at\nhttps://github.com/seungyoon-Choi/DITTO_official."}
{"id": "2504.16546", "pdf": "https://arxiv.org/pdf/2504.16546", "abs": "https://arxiv.org/abs/2504.16546", "authors": ["Bolun Zhang", "Yang Shen", "Linzhuo Li", "Yu Ji", "Di Wu", "Tongyu Wu", "Lianghao Dai"], "title": "Tinkering Against Scaling", "categories": ["cs.CY", "cs.HC"], "comment": "43 pages, 4 figures", "summary": "The ascent of scaling in artificial intelligence research has revolutionized\nthe field over the past decade, yet it presents significant challenges for\nacademic researchers, particularly in computational social science and critical\nalgorithm studies. The dominance of large language models, characterized by\ntheir extensive parameters and costly training processes, creates a disparity\nwhere only industry-affiliated researchers can access these resources. This\nimbalance restricts academic researchers from fully understanding their tools,\nleading to issues like reproducibility in computational social science and a\nreliance on black-box metaphors in critical studies.\n  To address these challenges, we propose a \"tinkering\" approach that is\ninspired by existing works. This method involves engaging with smaller models\nor components that are manageable for ordinary researchers, fostering hands-on\ninteraction with algorithms. We argue that tinkering is both a way of making\nand knowing for computational social science and a way of knowing for critical\nstudies, and fundamentally, it is a way of caring that has broader implications\nfor both fields."}
{"id": "2504.16795", "pdf": "https://arxiv.org/pdf/2504.16795", "abs": "https://arxiv.org/abs/2504.16795", "authors": ["Xiang Hu", "Jiaqi Leng", "Jun Zhao", "Kewei Tu", "Wei Wu"], "title": "Random Long-Context Access for Mamba via Hardware-aligned Hierarchical Sparse Attention", "categories": ["cs.CL", "cs.AI"], "comment": "preprint", "summary": "A key advantage of Recurrent Neural Networks (RNNs) over Transformers is\ntheir linear computational and space complexity enables faster training and\ninference for long sequences. However, RNNs are fundamentally unable to\nrandomly access historical context, and simply integrating attention mechanisms\nmay undermine their efficiency advantages. To overcome this limitation, we\npropose \\textbf{H}ierarchical \\textbf{S}parse \\textbf{A}ttention (HSA), a novel\nattention mechanism that enhances RNNs with long-range random access\nflexibility while preserving their merits in efficiency and length\ngeneralization. HSA divides inputs into chunks, selecting the top-$k$ chunks\nand hierarchically aggregates information. The core innovation lies in learning\ntoken-to-chunk relevance based on fine-grained token-level information inside\neach chunk. This approach enhances the precision of chunk selection across both\nin-domain and out-of-domain context lengths. To make HSA efficient, we further\nintroduce a hardware-aligned kernel design. By combining HSA with Mamba, we\nintroduce RAMba, which achieves perfect accuracy in passkey retrieval across 64\nmillion contexts despite pre-training on only 4K-length contexts, and\nsignificant improvements on various downstream tasks, with nearly constant\nmemory footprint. These results show RAMba's huge potential in long-context\nmodeling."}
{"id": "2504.16506", "pdf": "https://arxiv.org/pdf/2504.16506", "abs": "https://arxiv.org/abs/2504.16506", "authors": ["Ruxue Shi", "Yili Wang", "Mengnan Du", "Xu Shen", "Xin Wang"], "title": "A Comprehensive Survey of Synthetic Tabular Data Generation", "categories": ["cs.LG"], "comment": null, "summary": "Tabular data remains one of the most prevalent and critical data formats\nacross diverse real-world applications. However, its effective use in machine\nlearning (ML) is often constrained by challenges such as data scarcity, privacy\nconcerns, and class imbalance. Synthetic data generation has emerged as a\npromising solution, leveraging generative models to learn the distribution of\nreal datasets and produce high-fidelity, privacy-preserving samples. Various\ngenerative paradigms have been explored, including energy-based models (EBMs),\nvariational autoencoders (VAEs), generative adversarial networks (GANs), large\nlanguage models (LLMs), and diffusion models. While several surveys have\ninvestigated synthetic tabular data generation, most focus on narrow subdomains\nor specific generative methods, such as GANs, diffusion models, or\nprivacy-preserving techniques. This limited scope often results in fragmented\ninsights, lacking a comprehensive synthesis that bridges diverse approaches. In\nparticular, recent advances driven by LLMs and diffusion-based models remain\nunderexplored. This gap hinders a holistic understanding of the field`s\nevolution, methodological interplay, and open challenges. To address this, our\nsurvey provides a unified and systematic review of synthetic tabular data\ngeneration. Our contributions are threefold: (1) we propose a comprehensive\ntaxonomy that organizes existing methods into traditional approaches,\ndiffusion-based methods, and LLM-based models, and provide an in-depth\ncomparative analysis; (2) we detail the complete pipeline for synthetic tabular\ndata generation, including data synthesis, post-processing, and evaluation; (3)\nwe identify major challenges, explore real-world applications, and outline open\nresearch questions and future directions to guide future work in this rapidly\nevolving area."}
{"id": "2504.16670", "pdf": "https://arxiv.org/pdf/2504.16670", "abs": "https://arxiv.org/abs/2504.16670", "authors": ["Wenyi Lu", "Enock Kasaadah", "S M Rakib Ul Karim", "Matt Germonprez", "Sean Goggins"], "title": "Open Source Software Lifecycle Classification: Developing Wrangling Techniques for Complex Sociotechnical Systems", "categories": ["cs.SE", "cs.HC", "H.4"], "comment": null, "summary": "Open source software is a rapidly evolving center for distributed work, and\nunderstanding the characteristics of this work across its different contexts is\nvital for informing policy, economics, and the design of enabling software. The\nsteep increase in open source projects and corporate participation have\ntransformed a peripheral, cottage industry component of the global technology\necosystem into a large, infinitely complex \"technology parts supplier\" wired\ninto every corner of contemporary life. The lack of theory and tools for\nbreaking this complexity down into identifiable project types or strategies for\nunderstanding them more systematically is incommensurate with current industry,\nsociety, and developer needs. This paper reviews previous attempts to classify\nopen source software and other organizational ecosystems, using open source\nscientific software ecosystems in contrast with those found in corporatized\nopen source software. It then examines the divergent and sometimes conflicting\npurposes that may exist for classifying open source projects and how these\ncompeting interests impede our progress in developing a comprehensive\nunderstanding of how open source software projects and companies operate.\nFinally, we will present an empirical, mixed-methods study demonstrating how to\nclassify open-source projects by their lifecycle position. This is the first\nstep forward, advancing our scientific and practical knowledge of open source\nsoftware through the lens of dynamic and evolving open source genres. It\nconcludes with examples and a proposed path forward."}
{"id": "2504.16813", "pdf": "https://arxiv.org/pdf/2504.16813", "abs": "https://arxiv.org/abs/2504.16813", "authors": ["Sima Iranmanesh", "Hadeel Saadany", "Edlira Vakaj"], "title": "LLM-assisted Graph-RAG Information Extraction from IFC Data", "categories": ["cs.CL"], "comment": "2025 European Conference on Computing in Construction", "summary": "IFC data has become the general building information standard for\ncollaborative work in the construction industry. However, IFC data can be very\ncomplicated because it allows for multiple ways to represent the same product\ninformation. In this research, we utilise the capabilities of LLMs to parse the\nIFC data with Graph Retrieval-Augmented Generation (Graph-RAG) technique to\nretrieve building object properties and their relations. We will show that,\ndespite limitations due to the complex hierarchy of the IFC data, the Graph-RAG\nparsing enhances generative LLMs like GPT-4o with graph-based knowledge,\nenabling natural language query-response retrieval without the need for a\ncomplex pipeline."}
{"id": "2504.16553", "pdf": "https://arxiv.org/pdf/2504.16553", "abs": "https://arxiv.org/abs/2504.16553", "authors": ["Mohammad Mahdi Abedi", "David Pardo", "Tariq Alkhalifah"], "title": "Least-Squares-Embedded Optimization for Accelerated Convergence of PINNs in Acoustic Wavefield Simulations", "categories": ["cs.LG", "physics.comp-ph", "physics.geo-ph"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have shown promise in solving\npartial differential equations (PDEs), including the frequency-domain Helmholtz\nequation. However, standard training of PINNs using gradient descent (GD)\nsuffers from slow convergence and instability, particularly for high-frequency\nwavefields. For scattered acoustic wavefield simulation based on Helmholtz\nequation, we derive a hybrid optimization framework that accelerates training\nconvergence by embedding a least-squares (LS) solver directly into the GD loss\nfunction. This formulation enables optimal updates for the linear output layer.\nOur method is applicable with or without perfectly matched layers (PML), and we\nprovide practical tensor-based implementations for both scenarios. Numerical\nexperiments on benchmark velocity models demonstrate that our approach achieves\nfaster convergence, higher accuracy, and improved stability compared to\nconventional PINN training. In particular, our results show that the\nLS-enhanced method converges rapidly even in cases where standard GD-based\ntraining fails. The LS solver operates on a small normal matrix, ensuring\nminimal computational overhead and making the method scalable for large-scale\nwavefield simulations."}
{"id": "2504.16832", "pdf": "https://arxiv.org/pdf/2504.16832", "abs": "https://arxiv.org/abs/2504.16832", "authors": ["Luu Quy Tung", "Hoang Quoc Viet", "Vo Trong Thu"], "title": "GreenMind: A Next-Generation Vietnamese Large Language Model for Structured and Logical Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Chain-of-Thought (CoT) is a robust approach for tackling LLM tasks that\nrequire intermediate reasoning steps prior to generating a final answer. In\nthis paper, we present GreenMind-Medium-14B-R1, the Vietnamese reasoning model\ninspired by the finetuning strategy based on Group Relative Policy\nOptimization. We also leverage a high-quality Vietnamese synthesized reasoning\ndataset and design two reward functions to tackle the main limitations of this\ntechnique: (i) language mixing, where we explicitly detect the presence of\nbiased language characters during the process of sampling tokens, and (ii) we\nleverage Sentence Transformer-based models to ensure that the generated\nreasoning content maintains factual correctness and does not distort the final\noutput. Experimental results on the Vietnamese dataset from the VLSP 2023\nChallenge demonstrate that our model outperforms prior works and enhances\nlinguistic consistency in its responses. Furthermore, we extend our evaluation\nto SeaExam-a multilingual multiple-choice dataset, showing the effectiveness of\nour reasoning method compared to few-shot prompting techniques."}
{"id": "2504.16559", "pdf": "https://arxiv.org/pdf/2504.16559", "abs": "https://arxiv.org/abs/2504.16559", "authors": ["Adam Izdebski", "Jan Olszewski", "Pankhil Gawade", "Krzysztof Koras", "Serra Korkmaz", "Valentin Rauscher", "Jakub M. Tomczak", "Ewa Szczurek"], "title": "Unified Molecule Generation and Property Prediction", "categories": ["cs.LG", "q-bio.QM", "68T01", "I.2.1"], "comment": "17 pages, 4 figures", "summary": "Modeling the joint distribution of the data samples and their properties\nallows to construct a single model for both data generation and property\nprediction, with synergistic capabilities reaching beyond purely generative or\npredictive models. However, training joint models presents daunting\narchitectural and optimization challenges. Here, we propose Hyformer, a\ntransformer-based joint model that successfully blends the generative and\npredictive functionalities, using an alternating attention mask together with a\nunified pre-training scheme. We show that Hyformer rivals other joint models,\nas well as state-of-the-art molecule generation and property prediction models.\nAdditionally, we show the benefits of joint modeling in downstream tasks of\nmolecular representation learning, hit identification and antimicrobial peptide\ndesign."}
{"id": "2504.16855", "pdf": "https://arxiv.org/pdf/2504.16855", "abs": "https://arxiv.org/abs/2504.16855", "authors": ["Zijing Shi", "Meng Fang", "Ling Chen"], "title": "Monte Carlo Planning with Large Language Model for Text-Based Game Agents", "categories": ["cs.CL"], "comment": null, "summary": "Text-based games provide valuable environments for language-based autonomous\nagents. However, planning-then-learning paradigms, such as those combining\nMonte Carlo Tree Search (MCTS) and reinforcement learning (RL), are notably\ntime-consuming due to extensive iterations. Additionally, these algorithms\nperform uncertainty-driven exploration but lack language understanding and\nreasoning abilities. In this paper, we introduce the Monte Carlo planning with\nDynamic Memory-guided Large language model (MC-DML) algorithm. MC-DML leverages\nthe language understanding and reasoning capabilities of Large Language Models\n(LLMs) alongside the exploratory advantages of tree search algorithms.\nSpecifically, we enhance LLMs with in-trial and cross-trial memory mechanisms,\nenabling them to learn from past experiences and dynamically adjust action\nevaluations during planning. We conduct experiments on a series of text-based\ngames from the Jericho benchmark. Our results demonstrate that the MC-DML\nalgorithm significantly enhances performance across various games at the\ninitial planning phase, outperforming strong contemporary methods that require\nmultiple iterations. This demonstrates the effectiveness of our algorithm,\npaving the way for more efficient language-grounded planning in complex\nenvironments."}
{"id": "2504.16580", "pdf": "https://arxiv.org/pdf/2504.16580", "abs": "https://arxiv.org/abs/2504.16580", "authors": ["Ignacio Peis", "Batuhan Koyuncu", "Isabel Valera", "Jes Frellsen"], "title": "Hyper-Transforming Latent Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We introduce a novel generative framework for functions by integrating\nImplicit Neural Representations (INRs) and Transformer-based hypernetworks into\nlatent variable models. Unlike prior approaches that rely on MLP-based\nhypernetworks with scalability limitations, our method employs a\nTransformer-based decoder to generate INR parameters from latent variables,\naddressing both representation capacity and computational efficiency. Our\nframework extends latent diffusion models (LDMs) to INR generation by replacing\nstandard decoders with a Transformer-based hypernetwork, which can be trained\neither from scratch or via hyper-transforming-a strategy that fine-tunes only\nthe decoder while freezing the pre-trained latent space. This enables efficient\nadaptation of existing generative models to INR-based representations without\nrequiring full retraining."}
{"id": "2504.16856", "pdf": "https://arxiv.org/pdf/2504.16856", "abs": "https://arxiv.org/abs/2504.16856", "authors": ["Alexander Shvets"], "title": "Emo Pillars: Knowledge Distillation to Support Fine-Grained Context-Aware and Context-Less Emotion Classification", "categories": ["cs.CL"], "comment": null, "summary": "Most datasets for sentiment analysis lack context in which an opinion was\nexpressed, often crucial for emotion understanding, and are mainly limited by a\nfew emotion categories. Foundation large language models (LLMs) like GPT-4\nsuffer from over-predicting emotions and are too resource-intensive. We design\nan LLM-based data synthesis pipeline and leverage a large model, Mistral-7b,\nfor the generation of training examples for more accessible, lightweight\nBERT-type encoder models. We focus on enlarging the semantic diversity of\nexamples and propose grounding the generation into a corpus of narratives to\nproduce non-repetitive story-character-centered utterances with unique contexts\nover 28 emotion classes. By running 700K inferences in 450 GPU hours, we\ncontribute with the dataset of 100K contextual and also 300K context-less\nexamples to cover both scenarios. We use it for fine-tuning pre-trained\nencoders, which results in several Emo Pillars models. We show that Emo Pillars\nmodels are highly adaptive to new domains when tuned to specific tasks such as\nGoEmotions, ISEAR, IEMOCAP, and EmoContext, reaching the SOTA performance on\nthe first three. We also validate our dataset, conducting statistical analysis\nand human evaluation, and confirm the success of our measures in utterance\ndiversification (although less for the neutral class) and context\npersonalization, while pointing out the need for improved handling of\nout-of-taxonomy labels within the pipeline."}
{"id": "2504.16585", "pdf": "https://arxiv.org/pdf/2504.16585", "abs": "https://arxiv.org/abs/2504.16585", "authors": ["Xiaofei Wu", "Rongmei Liang"], "title": "Enhancing Variable Selection in Large-scale Logistic Regression: Leveraging Manual Labeling with Beneficial Noise", "categories": ["cs.LG", "stat.CO", "stat.ML"], "comment": null, "summary": "In large-scale supervised learning, penalized logistic regression (PLR)\neffectively addresses the overfitting problem by introducing regularization\nterms yet its performance still depends on efficient variable selection\nstrategies. This paper theoretically demonstrates that label noise stemming\nfrom manual labeling, which is solely related to classification difficulty,\nrepresents a type of beneficial noise for variable selection in PLR. This\nbenefit is reflected in a more accurate estimation of the selected non-zero\ncoefficients when compared with the case where only truth labels are used.\nUnder large-scale settings, the sample size for PLR can become very large,\nmaking it infeasible to store on a single machine. In such cases, distributed\ncomputing methods are required to handle PLR model with manual labeling. This\npaper presents a partition-insensitive parallel algorithm founded on the ADMM\n(alternating direction method of multipliers) algorithm to address PLR by\nincorporating manual labeling. The partition insensitivity of the proposed\nalgorithm refers to the fact that the solutions obtained by the algorithm will\nnot change with the distributed storage of data. In addition, the algorithm has\nglobal convergence and a sublinear convergence rate. Experimental results\nindicate that, as compared with traditional variable selection classification\ntechniques, the PLR with manually-labeled noisy data achieves higher estimation\nand classification accuracy across multiple large-scale datasets."}
{"id": "2504.16858", "pdf": "https://arxiv.org/pdf/2504.16858", "abs": "https://arxiv.org/abs/2504.16858", "authors": ["Hanwen Du", "Bo Peng", "Xia Ning"], "title": "Planning with Diffusion Models for Target-Oriented Dialogue Systems", "categories": ["cs.CL"], "comment": null, "summary": "Target-Oriented Dialogue (TOD) remains a significant challenge in the LLM\nera, where strategic dialogue planning is crucial for directing conversations\ntoward specific targets. However, existing dialogue planning methods generate\ndialogue plans in a step-by-step sequential manner, and may suffer from\ncompounding errors and myopic actions. To address these limitations, we\nintroduce a novel dialogue planning framework, DiffTOD, which leverages\ndiffusion models to enable non-sequential dialogue planning. DiffTOD formulates\ndialogue planning as a trajectory generation problem with conditional guidance,\nand leverages a diffusion language model to estimate the likelihood of the\ndialogue trajectory. To optimize the dialogue action strategies, DiffTOD\nintroduces three tailored guidance mechanisms for different target types,\noffering flexible guidance towards diverse TOD targets at test time. Extensive\nexperiments across three diverse TOD settings show that DiffTOD can effectively\nperform non-myopic lookahead exploration and optimize action strategies over a\nlong horizon through non-sequential dialogue planning, and demonstrates strong\nflexibility across complex and diverse dialogue scenarios. Our code and data\nare accessible through https://anonymous.4open.science/r/DiffTOD."}
{"id": "2504.16624", "pdf": "https://arxiv.org/pdf/2504.16624", "abs": "https://arxiv.org/abs/2504.16624", "authors": ["Leo Henry", "Thomas Neele", "Mohammad Mousavi", "Matteo Sammartino"], "title": "Compositional Active Learning of Synchronous Systems through Automated Alphabet Refinement", "categories": ["cs.LG", "cs.FL"], "comment": null, "summary": "Active automata learning infers automaton models of systems from behavioral\nobservations, a technique successfully applied to a wide range of domains.\nCompositional approaches for concurrent systems have recently emerged. We take\na significant step beyond available results, including those by the authors,\nand develop a general technique for compositional learning of a synchronizing\nparallel system with an unknown decomposition. Our approach automatically\nrefines the global alphabet into component alphabets while learning the\ncomponent models. We develop a theoretical treatment of distributions of\nalphabets, i.e., sets of possibly overlapping component alphabets. We\ncharacterize counter-examples that reveal inconsistencies with global\nobservations, and show how to systematically update the distribution to restore\nconsistency. We present a compositional learning algorithm implementing these\nideas, where learning counterexamples precisely correspond to distribution\ncounterexamples under well-defined conditions. We provide an implementation,\ncalled CoalA, using the state-of-the-art active learning library LearnLib. Our\nexperiments show that in more than 630 subject systems, CoalA delivers orders\nof magnitude improvements (up to five orders) in membership queries and in\nsystems with significant concurrency, it also achieves better scalability in\nthe number of equivalence queries."}
{"id": "2504.16884", "pdf": "https://arxiv.org/pdf/2504.16884", "abs": "https://arxiv.org/abs/2504.16884", "authors": ["Joseph M. Denning", "Xiaohan", "Guo", "Bryor Snefjella", "Idan A. Blank"], "title": "Do Large Language Models know who did what to whom?", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are commonly criticized for not understanding\nlanguage. However, many critiques focus on cognitive abilities that, in humans,\nare distinct from language processing. Here, we instead study a kind of\nunderstanding tightly linked to language: inferring who did what to whom\n(thematic roles) in a sentence. Does the central training objective of\nLLMs-word prediction-result in sentence representations that capture thematic\nroles? In two experiments, we characterized sentence representations in four\nLLMs. In contrast to human similarity judgments, in LLMs the overall\nrepresentational similarity of sentence pairs reflected syntactic similarity\nbut not whether their agent and patient assignments were identical vs.\nreversed. Furthermore, we found little evidence that thematic role information\nwas available in any subset of hidden units. However, some attention heads\nrobustly captured thematic roles, independently of syntax. Therefore, LLMs can\nextract thematic roles but, relative to humans, this information influences\ntheir representations more weakly."}
{"id": "2504.16628", "pdf": "https://arxiv.org/pdf/2504.16628", "abs": "https://arxiv.org/abs/2504.16628", "authors": ["Haoran Gu", "Handing Wang", "Yi Mei", "Mengjie Zhang", "Yaochu Jin"], "title": "ParetoHqD: Fast Offline Multiobjective Alignment of Large Language Models using Pareto High-quality Data", "categories": ["cs.LG", "cs.CL"], "comment": "19 pages, 6 figure, Multiobjective Alignment of LLMs", "summary": "Aligning large language models with multiple human expectations and values is\ncrucial for ensuring that they adequately serve a variety of user needs. To\nthis end, offline multiobjective alignment algorithms such as the\nRewards-in-Context algorithm have shown strong performance and efficiency.\nHowever, inappropriate preference representations and training with imbalanced\nreward scores limit the performance of such algorithms. In this work, we\nintroduce ParetoHqD that addresses the above issues by representing human\npreferences as preference directions in the objective space and regarding data\nnear the Pareto front as ''high-quality'' data. For each preference, ParetoHqD\nfollows a two-stage supervised fine-tuning process, where each stage uses an\nindividual Pareto high-quality training set that best matches its preference\ndirection. The experimental results have demonstrated the superiority of\nParetoHqD over five baselines on two multiobjective alignment tasks."}
{"id": "2504.16913", "pdf": "https://arxiv.org/pdf/2504.16913", "abs": "https://arxiv.org/abs/2504.16913", "authors": ["Shifali Agrahari", "Sanasam Ranbir Singh"], "title": "Tracing Thought: Using Chain-of-Thought Reasoning to Identify the LLM Behind AI-Generated Text", "categories": ["cs.CL", "cs.AI"], "comment": "De-Factify 4: 4th Workshop on Multimodal Fact Checking and Hate\n  Speech Detection, co-located with AAAI 2025. Pennsylvania", "summary": "In recent years, the detection of AI-generated text has become a critical\narea of research due to concerns about academic integrity, misinformation, and\nethical AI deployment. This paper presents COT Fine-tuned, a novel framework\nfor detecting AI-generated text and identifying the specific language model.\nresponsible for generating the text. We propose a dual-task approach, where\nTask A involves classifying text as AI-generated or human-written, and Task B\nidentifies the specific LLM behind the text. The key innovation of our method\nlies in the use of Chain-of-Thought reasoning, which enables the model to\ngenerate explanations for its predictions, enhancing transparency and\ninterpretability. Our experiments demonstrate that COT Fine-tuned achieves high\naccuracy in both tasks, with strong performance in LLM identification and\nhuman-AI classification. We also show that the CoT reasoning process\ncontributes significantly to the models effectiveness and interpretability."}
{"id": "2504.16639", "pdf": "https://arxiv.org/pdf/2504.16639", "abs": "https://arxiv.org/abs/2504.16639", "authors": ["Haoran Chen", "Jiapeng Liu", "Jiafan Wang", "Wenjun Shi"], "title": "DAPLSR: Data Augmentation Partial Least Squares Regression Model via Manifold Optimization", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Traditional Partial Least Squares Regression (PLSR) models frequently\nunderperform when handling data characterized by uneven categories. To address\nthe issue, this paper proposes a Data Augmentation Partial Least Squares\nRegression (DAPLSR) model via manifold optimization. The DAPLSR model\nintroduces the Synthetic Minority Over-sampling Technique (SMOTE) to increase\nthe number of samples and utilizes the Value Difference Metric (VDM) to select\nthe nearest neighbor samples that closely resemble the original samples for\ngenerating synthetic samples. In solving the model, in order to obtain a more\naccurate numerical solution for PLSR, this paper proposes a manifold\noptimization method that uses the geometric properties of the constraint space\nto improve model degradation and optimization. Comprehensive experiments show\nthat the proposed DAPLSR model achieves superior classification performance and\noutstanding evaluation metrics on various datasets, significantly outperforming\nexisting methods."}
{"id": "2504.16918", "pdf": "https://arxiv.org/pdf/2504.16918", "abs": "https://arxiv.org/abs/2504.16918", "authors": ["Raghav Thind", "Youran Sun", "Ling Liang", "Haizhao Yang"], "title": "OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Optimization plays a vital role in scientific research and practical\napplications, but formulating a concrete optimization problem described in\nnatural language into a mathematical form and selecting a suitable solver to\nsolve the problem requires substantial domain expertise. We introduce\n\\textbf{OptimAI}, a framework for solving \\underline{Optim}ization problems\ndescribed in natural language by leveraging LLM-powered \\underline{AI} agents,\nachieving superior performance over current state-of-the-art methods. Our\nframework is built upon four key roles: (1) a \\emph{formulator} that translates\nnatural language problem descriptions into precise mathematical formulations;\n(2) a \\emph{planner} that constructs a high-level solution strategy prior to\nexecution; and (3) a \\emph{coder} and a \\emph{code critic} capable of\ninteracting with the environment and reflecting on outcomes to refine future\nactions. Ablation studies confirm that all roles are essential; removing the\nplanner or code critic results in $5.8\\times$ and $3.1\\times$ drops in\nproductivity, respectively. Furthermore, we introduce UCB-based debug\nscheduling to dynamically switch between alternative plans, yielding an\nadditional $3.3\\times$ productivity gain. Our design emphasizes multi-agent\ncollaboration, allowing us to conveniently explore the synergistic effect of\ncombining diverse models within a unified system. Our approach attains 88.1\\%\naccuracy on the NLP4LP dataset and 71.2\\% on the Optibench (non-linear w/o\ntable) subset, reducing error rates by 58\\% and 50\\% respectively over prior\nbest results."}
{"id": "2504.16667", "pdf": "https://arxiv.org/pdf/2504.16667", "abs": "https://arxiv.org/abs/2504.16667", "authors": ["Zhaohan Daniel Guo", "Bernardo Avila Pires", "Khimya Khetarpal", "Dale Schuurmans", "Bo Dai"], "title": "Representation Learning via Non-Contrastive Mutual Information", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML", "I.2.6; I.2.10"], "comment": null, "summary": "Labeling data is often very time consuming and expensive, leaving us with a\nmajority of unlabeled data. Self-supervised representation learning methods\nsuch as SimCLR (Chen et al., 2020) or BYOL (Grill et al., 2020) have been very\nsuccessful at learning meaningful latent representations from unlabeled image\ndata, resulting in much more general and transferable representations for\ndownstream tasks. Broadly, self-supervised methods fall into two types: 1)\nContrastive methods, such as SimCLR; and 2) Non-Contrastive methods, such as\nBYOL. Contrastive methods are generally trying to maximize mutual information\nbetween related data points, so they need to compare every data point to every\nother data point, resulting in high variance, and thus requiring large batch\nsizes to work well. Non-contrastive methods like BYOL have much lower variance\nas they do not need to make pairwise comparisons, but are much trickier to\nimplement as they have the possibility of collapsing to a constant vector. In\nthis paper, we aim to develop a self-supervised objective that combines the\nstrength of both types. We start with a particular contrastive method called\nthe Spectral Contrastive Loss (HaoChen et al., 2021; Lu et al., 2024), and we\nconvert it into a more general non-contrastive form; this removes the pairwise\ncomparisons resulting in lower variance, but keeps the mutual information\nformulation of the contrastive method preventing collapse. We call our new\nobjective the Mutual Information Non-Contrastive (MINC) loss. We test MINC by\nlearning image representations on ImageNet (similar to SimCLR and BYOL) and\nshow that it consistently improves upon the Spectral Contrastive loss baseline."}
{"id": "2504.16921", "pdf": "https://arxiv.org/pdf/2504.16921", "abs": "https://arxiv.org/abs/2504.16921", "authors": ["José Ángel González", "Ian Borrego Obrador", "Álvaro Romo Herrero", "Areg Mikael Sarvazyan", "Mara Chinea-Ríos", "Angelo Basile", "Marc Franco-Salvador"], "title": "IberBench: LLM Evaluation on Iberian Languages", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) remain difficult to evaluate comprehensively,\nparticularly for languages other than English, where high-quality data is often\nlimited. Existing benchmarks and leaderboards are predominantly\nEnglish-centric, with only a few addressing other languages. These benchmarks\nfall short in several key areas: they overlook the diversity of language\nvarieties, prioritize fundamental Natural Language Processing (NLP)\ncapabilities over tasks of industrial relevance, and are static. With these\naspects in mind, we present IberBench, a comprehensive and extensible benchmark\ndesigned to assess LLM performance on both fundamental and industry-relevant\nNLP tasks, in languages spoken across the Iberian Peninsula and Ibero-America.\nIberBench integrates 101 datasets from evaluation campaigns and recent\nbenchmarks, covering 22 task categories such as sentiment and emotion analysis,\ntoxicity detection, and summarization. The benchmark addresses key limitations\nin current evaluation practices, such as the lack of linguistic diversity and\nstatic evaluation setups by enabling continual updates and community-driven\nmodel and dataset submissions moderated by a committee of experts. We evaluate\n23 LLMs ranging from 100 million to 14 billion parameters and provide empirical\ninsights into their strengths and limitations. Our findings indicate that (i)\nLLMs perform worse on industry-relevant tasks than in fundamental ones, (ii)\nperformance is on average lower for Galician and Basque, (iii) some tasks show\nresults close to random, and (iv) in other tasks LLMs perform above random but\nbelow shared task systems. IberBench offers open-source implementations for the\nentire evaluation pipeline, including dataset normalization and hosting,\nincremental evaluation of LLMs, and a publicly accessible leaderboard."}
{"id": "2504.16668", "pdf": "https://arxiv.org/pdf/2504.16668", "abs": "https://arxiv.org/abs/2504.16668", "authors": ["Shuyue Wei", "Yongxin Tong", "Zimu Zhou", "Tianran He", "Yi Xu"], "title": "Efficient Data Valuation Approximation in Federated Learning: A Sampling-based Approach", "categories": ["cs.LG", "cs.DB"], "comment": null, "summary": "Federated learning paradigm to utilize datasets across multiple data\nproviders. In FL, cross-silo data providers often hesitate to share their\nhigh-quality dataset unless their data value can be fairly assessed. Shapley\nvalue (SV) has been advocated as the standard metric for data valuation in FL\ndue to its desirable properties. However, the computational overhead of SV is\nprohibitive in practice, as it inherently requires training and evaluating an\nFL model across an exponential number of dataset combinations. Furthermore,\nexisting solutions fail to achieve high accuracy and efficiency, making\npractical use of SV still out of reach, because they ignore choosing suitable\ncomputation scheme for approximation framework and overlook the property of\nutility function in FL. We first propose a unified stratified-sampling\nframework for two widely-used schemes. Then, we analyze and choose the more\npromising scheme under the FL linear regression assumption. After that, we\nidentify a phenomenon termed key combinations, where only limited dataset\ncombinations have a high-impact on final data value. Building on these\ninsights, we propose a practical approximation algorithm, IPSS, which\nstrategically selects high-impact dataset combinations rather than evaluating\nall possible combinations, thus substantially reducing time cost with minor\napproximation error. Furthermore, we conduct extensive evaluations on the FL\nbenchmark datasets to demonstrate that our proposed algorithm outperforms a\nseries of representative baselines in terms of efficiency and effectiveness."}
{"id": "2504.16092", "pdf": "https://arxiv.org/pdf/2504.16092", "abs": "https://arxiv.org/abs/2504.16092", "authors": ["Mahrad Almotahari"], "title": "Cooperative Speech, Semantic Competence, and AI", "categories": ["cs.CY", "cs.CL", "cs.HC"], "comment": "25 pages", "summary": "Cooperative speech is purposive. From the speaker's perspective, one crucial\npurpose is the transmission of knowledge. Cooperative speakers care about\ngetting things right for their conversational partners. This attitude is a kind\nof respect. Cooperative speech is an ideal form of communication because\nparticipants have respect for each other. And having respect within a\ncooperative enterprise is sufficient for a particular kind of moral standing:\nwe ought to respect those who have respect for us. Respect demands reciprocity.\nI maintain that large language models aren't owed the kind of respect that\npartly constitutes a cooperative conversation. This implies that they aren't\ncooperative interlocutors, otherwise we would be obliged to reciprocate the\nattitude. Leveraging this conclusion, I argue that present-day LLMs are\nincapable of assertion and that this raises an overlooked doubt about their\nsemantic competence. One upshot of this argument is that knowledge of meaning\nisn't just a subject for the cognitive psychologist. It's also a subject for\nthe moral psychologist."}
{"id": "2504.16682", "pdf": "https://arxiv.org/pdf/2504.16682", "abs": "https://arxiv.org/abs/2504.16682", "authors": ["Youngmi Hur", "Hyojae Lim", "Mikyoung Lim"], "title": "Provable wavelet-based neural approximation", "categories": ["cs.LG", "math.CA", "stat.ML"], "comment": null, "summary": "In this paper, we develop a wavelet-based theoretical framework for analyzing\nthe universal approximation capabilities of neural networks over a wide range\nof activation functions. Leveraging wavelet frame theory on the spaces of\nhomogeneous type, we derive sufficient conditions on activation functions to\nensure that the associated neural network approximates any functions in the\ngiven space, along with an error estimate. These sufficient conditions\naccommodate a variety of smooth activation functions, including those that\nexhibit oscillatory behavior. Furthermore, by considering the $L^2$-distance\nbetween smooth and non-smooth activation functions, we establish a generalized\napproximation result that is applicable to non-smooth activations, with the\nerror explicitly controlled by this distance. This provides increased\nflexibility in the design of network architectures."}
{"id": "2504.16112", "pdf": "https://arxiv.org/pdf/2504.16112", "abs": "https://arxiv.org/abs/2504.16112", "authors": ["Myunghyun Rhee", "Joonseop Sim", "Taeyoung Ahn", "Seungyong Lee", "Daegun Yoon", "Euiseok Kim", "Kyoung Park", "Youngpyo Joo", "Hosik Kim"], "title": "HPU: High-Bandwidth Processing Unit for Scalable, Cost-effective LLM Inference via GPU Co-processing", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.DC"], "comment": "6 pages", "summary": "The attention layer, a core component of Transformer-based LLMs, brings out\ninefficiencies in current GPU systems due to its low operational intensity and\nthe substantial memory requirements of KV caches. We propose a High-bandwidth\nProcessing Unit (HPU), a memoryintensive co-processor that enhances GPU\nresource utilization during large-batched LLM inference. By offloading\nmemory-bound operations, the HPU allows the GPU to focus on compute-intensive\ntasks, increasing overall efficiency. Also, the HPU, as an add-on card, scales\nout to accommodate surging memory demands driven by large batch sizes and\nextended sequence lengths. In this paper, we show the HPU prototype implemented\nwith PCIe-based FPGA cards mounted on a GPU system. Our novel GPU-HPU\nheterogeneous system demonstrates up to 4.1x performance gains and 4.6x energy\nefficiency improvements over a GPUonly system, providing scalability without\nincreasing the number of GPUs."}
{"id": "2504.16683", "pdf": "https://arxiv.org/pdf/2504.16683", "abs": "https://arxiv.org/abs/2504.16683", "authors": ["Ceren Yildirim", "Kamer Kaya", "Sinan Yildirim", "Erkay Savas"], "title": "MCMC for Bayesian estimation of Differential Privacy from Membership Inference Attacks", "categories": ["cs.LG", "stat.ML"], "comment": "Code available:\n  https://github.com/cerenyildirim/MCMC_for_Bayesian_estimation", "summary": "We propose a new framework for Bayesian estimation of differential privacy,\nincorporating evidence from multiple membership inference attacks (MIA).\nBayesian estimation is carried out via a Markov chain Monte Carlo (MCMC)\nalgorithm, named MCMC-DP-Est, which provides an estimate of the full posterior\ndistribution of the privacy parameter (e.g., instead of just credible\nintervals). Critically, the proposed method does not assume that privacy\nauditing is performed with the most powerful attack on the worst-case (dataset,\nchallenge point) pair, which is typically unrealistic. Instead, MCMC-DP-Est\njointly estimates the strengths of MIAs used and the privacy of the training\nalgorithm, yielding a more cautious privacy analysis. We also present an\neconomical way to generate measurements for the performance of an MIA that is\nto be used by the MCMC method to estimate privacy. We present the use of the\nmethods with numerical examples with both artificial and real data."}
{"id": "2504.16121", "pdf": "https://arxiv.org/pdf/2504.16121", "abs": "https://arxiv.org/abs/2504.16121", "authors": ["Muhammad Rafsan Kabir", "Rafeed Mohammad Sultan", "Fuad Rahman", "Mohammad Ruhul Amin", "Sifat Momen", "Nabeel Mohammed", "Shafin Rahman"], "title": "LegalRAG: A Hybrid RAG System for Multilingual Legal Information Retrieval", "categories": ["cs.IR", "cs.CL", "cs.LG"], "comment": "Accepted at IJCNN 2025", "summary": "Natural Language Processing (NLP) and computational linguistic techniques are\nincreasingly being applied across various domains, yet their use in legal and\nregulatory tasks remains limited. To address this gap, we develop an efficient\nbilingual question-answering framework for regulatory documents, specifically\nthe Bangladesh Police Gazettes, which contain both English and Bangla text. Our\napproach employs modern Retrieval Augmented Generation (RAG) pipelines to\nenhance information retrieval and response generation. In addition to\nconventional RAG pipelines, we propose an advanced RAG-based approach that\nimproves retrieval performance, leading to more precise answers. This system\nenables efficient searching for specific government legal notices, making legal\ninformation more accessible. We evaluate both our proposed and conventional RAG\nsystems on a diverse test set on Bangladesh Police Gazettes, demonstrating that\nour approach consistently outperforms existing methods across all evaluation\nmetrics."}
{"id": "2504.16693", "pdf": "https://arxiv.org/pdf/2504.16693", "abs": "https://arxiv.org/abs/2504.16693", "authors": ["Wenxuan Li", "Hang Zhao", "Zhiyuan Yu", "Yu Du", "Qin Zou", "Ruizhen Hu", "Kai Xu"], "title": "PIN-WM: Learning Physics-INformed World Models for Non-Prehensile Manipulation", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "While non-prehensile manipulation (e.g., controlled pushing/poking)\nconstitutes a foundational robotic skill, its learning remains challenging due\nto the high sensitivity to complex physical interactions involving friction and\nrestitution. To achieve robust policy learning and generalization, we opt to\nlearn a world model of the 3D rigid body dynamics involved in non-prehensile\nmanipulations and use it for model-based reinforcement learning. We propose\nPIN-WM, a Physics-INformed World Model that enables efficient end-to-end\nidentification of a 3D rigid body dynamical system from visual observations.\nAdopting differentiable physics simulation, PIN-WM can be learned with only\nfew-shot and task-agnostic physical interaction trajectories. Further, PIN-WM\nis learned with observational loss induced by Gaussian Splatting without\nneeding state estimation. To bridge Sim2Real gaps, we turn the learned PIN-WM\ninto a group of Digital Cousins via physics-aware randomizations which perturb\nphysics and rendering parameters to generate diverse and meaningful variations\nof the PIN-WM. Extensive evaluations on both simulation and real-world tests\ndemonstrate that PIN-WM, enhanced with physics-aware digital cousins,\nfacilitates learning robust non-prehensile manipulation skills with Sim2Real\ntransfer, surpassing the Real2Sim2Real state-of-the-arts."}
{"id": "2504.16134", "pdf": "https://arxiv.org/pdf/2504.16134", "abs": "https://arxiv.org/abs/2504.16134", "authors": ["Mohammad Abu Tami", "Mohammed Elhenawy", "Huthaifa I. Ashqar"], "title": "Multimodal Large Language Models for Enhanced Traffic Safety: A Comprehensive Review and Future Trends", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Traffic safety remains a critical global challenge, with traditional Advanced\nDriver-Assistance Systems (ADAS) often struggling in dynamic real-world\nscenarios due to fragmented sensor processing and susceptibility to adversarial\nconditions. This paper reviews the transformative potential of Multimodal Large\nLanguage Models (MLLMs) in addressing these limitations by integrating\ncross-modal data such as visual, spatial, and environmental inputs to enable\nholistic scene understanding. Through a comprehensive analysis of MLLM-based\napproaches, we highlight their capabilities in enhancing perception,\ndecision-making, and adversarial robustness, while also examining the role of\nkey datasets (e.g., KITTI, DRAMA, ML4RoadSafety) in advancing research.\nFurthermore, we outline future directions, including real-time edge deployment,\ncausality-driven reasoning, and human-AI collaboration. By positioning MLLMs as\na cornerstone for next-generation traffic safety systems, this review\nunderscores their potential to revolutionize the field, offering scalable,\ncontext-aware solutions that proactively mitigate risks and improve overall\nroad safety."}
{"id": "2504.16711", "pdf": "https://arxiv.org/pdf/2504.16711", "abs": "https://arxiv.org/abs/2504.16711", "authors": ["Shiyin Tan", "Jaeeon Park", "Dongyuan Li", "Renhe Jiang", "Manabu Okumura"], "title": "A Unified Retrieval Framework with Document Ranking and EDU Filtering for Multi-document Summarization", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "In the field of multi-document summarization (MDS), transformer-based models\nhave demonstrated remarkable success, yet they suffer an input length\nlimitation. Current methods apply truncation after the retrieval process to fit\nthe context length; however, they heavily depend on manually well-crafted\nqueries, which are impractical to create for each document set for MDS.\nAdditionally, these methods retrieve information at a coarse granularity,\nleading to the inclusion of irrelevant content. To address these issues, we\npropose a novel retrieval-based framework that integrates query selection and\ndocument ranking and shortening into a unified process. Our approach identifies\nthe most salient elementary discourse units (EDUs) from input documents and\nutilizes them as latent queries. These queries guide the document ranking by\ncalculating relevance scores. Instead of traditional truncation, our approach\nfilters out irrelevant EDUs to fit the context length, ensuring that only\ncritical information is preserved for summarization. We evaluate our framework\non multiple MDS datasets, demonstrating consistent improvements in ROUGE\nmetrics while confirming its scalability and flexibility across diverse model\narchitectures. Additionally, we validate its effectiveness through an in-depth\nanalysis, emphasizing its ability to dynamically select appropriate queries and\naccurately rank documents based on their relevance scores. These results\ndemonstrate that our framework effectively addresses context-length\nconstraints, establishing it as a robust and reliable solution for MDS."}
{"id": "2504.16204", "pdf": "https://arxiv.org/pdf/2504.16204", "abs": "https://arxiv.org/abs/2504.16204", "authors": ["Christian Djeffal"], "title": "Reflexive Prompt Engineering: A Framework for Responsible Prompt Engineering and Interaction Design", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.ET"], "comment": "20 pages one figure", "summary": "Responsible prompt engineering has emerged as a critical framework for\nensuring that generative artificial intelligence (AI) systems serve society's\nneeds while minimizing potential harms. As generative AI applications become\nincreasingly powerful and ubiquitous, the way we instruct and interact with\nthem through prompts has profound implications for fairness, accountability,\nand transparency. This article examines how strategic prompt engineering can\nembed ethical and legal considerations and societal values directly into AI\ninteractions, moving beyond mere technical optimization for functionality. This\narticle proposes a comprehensive framework for responsible prompt engineering\nthat encompasses five interconnected components: prompt design, system\nselection, system configuration, performance evaluation, and prompt management.\nDrawing from empirical evidence, the paper demonstrates how each component can\nbe leveraged to promote improved societal outcomes while mitigating potential\nrisks. The analysis reveals that effective prompt engineering requires a\ndelicate balance between technical precision and ethical consciousness,\ncombining the systematic rigor and focus on functionality with the nuanced\nunderstanding of social impact. Through examination of real-world and emerging\npractices, the article illustrates how responsible prompt engineering serves as\na crucial bridge between AI development and deployment, enabling organizations\nto fine-tune AI outputs without modifying underlying model architectures. This\napproach aligns with broader \"Responsibility by Design\" principles, embedding\nethical considerations directly into the implementation process rather than\ntreating them as post-hoc additions. The article concludes by identifying key\nresearch directions and practical guidelines for advancing the field of\nresponsible prompt engineering."}
{"id": "2504.16748", "pdf": "https://arxiv.org/pdf/2504.16748", "abs": "https://arxiv.org/abs/2504.16748", "authors": ["Yanan Zhao", "Feng Ji", "Kai Zhao", "Xuhao Li", "Qiyu Kang", "Wenfei Liang", "Yahya Alkhatib", "Xingchao Jian", "Wee Peng Tay"], "title": "Simple Graph Contrastive Learning via Fractional-order Neural Diffusion Networks", "categories": ["cs.LG"], "comment": "Submitted to ICML", "summary": "Graph Contrastive Learning (GCL) has recently made progress as an\nunsupervised graph representation learning paradigm. GCL approaches can be\ncategorized into augmentation-based and augmentation-free methods. The former\nrelies on complex data augmentations, while the latter depends on encoders that\ncan generate distinct views of the same input. Both approaches may require\nnegative samples for training. In this paper, we introduce a novel\naugmentation-free GCL framework based on graph neural diffusion models.\nSpecifically, we utilize learnable encoders governed by Fractional Differential\nEquations (FDE). Each FDE is characterized by an order parameter of the\ndifferential operator. We demonstrate that varying these parameters allows us\nto produce learnable encoders that generate diverse views, capturing either\nlocal or global information, for contrastive learning. Our model does not\nrequire negative samples for training and is applicable to both homophilic and\nheterophilic datasets. We demonstrate its effectiveness across various\ndatasets, achieving state-of-the-art performance."}
{"id": "2504.16234", "pdf": "https://arxiv.org/pdf/2504.16234", "abs": "https://arxiv.org/abs/2504.16234", "authors": ["Rene Pilz", "Johannes Schneider"], "title": "Using Phonemes in cascaded S2S translation pipeline", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted at Swiss NLP Conference 2025", "summary": "This paper explores the idea of using phonemes as a textual representation\nwithin a conventional multilingual simultaneous speech-to-speech translation\npipeline, as opposed to the traditional reliance on text-based language\nrepresentations. To investigate this, we trained an open-source\nsequence-to-sequence model on the WMT17 dataset in two formats: one using\nstandard textual representation and the other employing phonemic\nrepresentation. The performance of both approaches was assessed using the BLEU\nmetric. Our findings shows that the phonemic approach provides comparable\nquality but offers several advantages, including lower resource requirements or\nbetter suitability for low-resource languages."}
{"id": "2504.16755", "pdf": "https://arxiv.org/pdf/2504.16755", "abs": "https://arxiv.org/abs/2504.16755", "authors": ["Owain Parry", "Phil McMinn"], "title": "QAOA-PCA: Enhancing Efficiency in the Quantum Approximate Optimization Algorithm via Principal Component Analysis", "categories": ["cs.LG", "cs.ET"], "comment": null, "summary": "The Quantum Approximate Optimization Algorithm (QAOA) is a promising\nvariational algorithm for solving combinatorial optimization problems on\nnear-term devices. However, as the number of layers in a QAOA circuit\nincreases, which is correlated with the quality of the solution, the number of\nparameters to optimize grows linearly. This results in more iterations required\nby the classical optimizer, which results in an increasing computational burden\nas more circuit executions are needed. To mitigate this issue, we introduce\nQAOA-PCA, a novel reparameterization technique that employs Principal Component\nAnalysis (PCA) to reduce the dimensionality of the QAOA parameter space. By\nextracting principal components from optimized parameters of smaller problem\ninstances, QAOA-PCA facilitates efficient optimization with fewer parameters on\nlarger instances. Our empirical evaluation on the prominent MaxCut problem\ndemonstrates that QAOA-PCA consistently requires fewer iterations than standard\nQAOA, achieving substantial efficiency gains. While this comes at the cost of a\nslight reduction in approximation ratio compared to QAOA with the same number\nof layers, QAOA-PCA almost always outperforms standard QAOA when matched by\nparameter count. QAOA-PCA strikes a favorable balance between efficiency and\nperformance, reducing optimization overhead without significantly compromising\nsolution quality."}
{"id": "2504.16264", "pdf": "https://arxiv.org/pdf/2504.16264", "abs": "https://arxiv.org/abs/2504.16264", "authors": ["Francisco Valentini", "Diego Kozlowski", "Vincent Larivière"], "title": "CLIRudit: Cross-Lingual Information Retrieval of Scientific Documents", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Cross-lingual information retrieval (CLIR) consists in finding relevant\ndocuments in a language that differs from the language of the queries. This\npaper presents CLIRudit, a new dataset created to evaluate cross-lingual\nacademic search, focusing on English queries and French documents. The dataset\nis built using bilingual article metadata from \\'Erudit, a Canadian publishing\nplatform, and is designed to represent scenarios in which researchers search\nfor scholarly content in languages other than English. We perform a\ncomprehensive benchmarking of different zero-shot first-stage retrieval methods\non the dataset, including dense and sparse retrievers, query and document\nmachine translation, and state-of-the-art multilingual retrievers. Our results\nshow that large dense retrievers, not necessarily trained for the cross-lingual\nretrieval task, can achieve zero-shot performance comparable to using ground\ntruth human translations, without the need for machine translation. Sparse\nretrievers, such as BM25 or SPLADE, combined with document translation, show\ncompetitive results, providing an efficient alternative to large dense models.\nThis research advances the understanding of cross-lingual academic information\nretrieval and provides a framework that others can use to build comparable\ndatasets across different languages and disciplines. By making the dataset and\ncode publicly available, we aim to facilitate further research that will help\nmake scientific knowledge more accessible across language barriers."}
{"id": "2504.16763", "pdf": "https://arxiv.org/pdf/2504.16763", "abs": "https://arxiv.org/abs/2504.16763", "authors": ["Edison Mucllari", "Aswin Raghavan", "Zachary Alan Daniels"], "title": "Noise-Tolerant Coreset-Based Class Incremental Continual Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE"], "comment": "Work-in-Progress", "summary": "Many applications of computer vision require the ability to adapt to novel\ndata distributions after deployment. Adaptation requires algorithms capable of\ncontinual learning (CL). Continual learners must be plastic to adapt to novel\ntasks while minimizing forgetting of previous tasks.However, CL opens up\navenues for noise to enter the training pipeline and disrupt the CL. This work\nfocuses on label noise and instance noise in the context of class-incremental\nlearning (CIL), where new classes are added to a classifier over time, and\nthere is no access to external data from past classes. We aim to understand the\nsensitivity of CL methods that work by replaying items from a memory\nconstructed using the idea of Coresets. We derive a new bound for the\nrobustness of such a method to uncorrelated instance noise under a general\nadditive noise threat model, revealing several insights. Putting the theory\ninto practice, we create two continual learning algorithms to construct\nnoise-tolerant replay buffers. We empirically compare the effectiveness of\nprior memory-based continual learners and the proposed algorithms under label\nand uncorrelated instance noise on five diverse datasets. We show that existing\nmemory-based CL are not robust whereas the proposed methods exhibit significant\nimprovements in maximizing classification accuracy and minimizing forgetting in\nthe noisy CIL setting."}
{"id": "2504.16315", "pdf": "https://arxiv.org/pdf/2504.16315", "abs": "https://arxiv.org/abs/2504.16315", "authors": ["Sen Fang", "Chunyu Sui", "Hongwei Yi", "Carol Neidle", "Dimitris N. Metaxas"], "title": "SignX: The Foundation Model for Sign Recognition", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "The complexity of sign language data processing brings many challenges. The\ncurrent approach to recognition of ASL signs aims to translate RGB sign\nlanguage videos through pose information into English-based ID glosses, which\nserve to uniquely identify ASL signs. Note that there is no shared convention\nfor assigning such glosses to ASL signs, so it is essential that the same\nglossing conventions are used for all of the data in the datasets that are\nemployed. This paper proposes SignX, a foundation model framework for sign\nrecognition. It is a concise yet powerful framework applicable to multiple\nhuman activity recognition scenarios. First, we developed a Pose2Gloss\ncomponent based on an inverse diffusion model, which contains a multi-track\npose fusion layer that unifies five of the most powerful pose information\nsources--SMPLer-X, DWPose, Mediapipe, PrimeDepth, and Sapiens\nSegmentation--into a single latent pose representation. Second, we trained a\nVideo2Pose module based on ViT that can directly convert raw video into signer\npose representation. Through this 2-stage training framework, we enable sign\nlanguage recognition models to be compatible with existing pose formats, laying\nthe foundation for the common pose estimation necessary for sign recognition.\nExperimental results show that SignX can recognize signs from sign language\nvideo, producing predicted gloss representations with greater accuracy than has\nbeen reported in prior work."}
{"id": "2504.16767", "pdf": "https://arxiv.org/pdf/2504.16767", "abs": "https://arxiv.org/abs/2504.16767", "authors": ["Andrea Nóvoa", "Luca Magri"], "title": "Online model learning with data-assimilated reservoir computers", "categories": ["cs.LG", "physics.flu-dyn", "stat.AP"], "comment": "8 pages, 5 figures", "summary": "We propose an online learning framework for forecasting nonlinear\nspatio-temporal signals (fields). The method integrates (i) dimensionality\nreduction, here, a simple proper orthogonal decomposition (POD) projection;\n(ii) a generalized autoregressive model to forecast reduced dynamics, here, a\nreservoir computer; (iii) online adaptation to update the reservoir computer\n(the model), here, ensemble sequential data assimilation.We demonstrate the\nframework on a wake past a cylinder governed by the Navier-Stokes equations,\nexploring the assimilation of full flow fields (projected onto POD modes) and\nsparse sensors. Three scenarios are examined: a na\\\"ive physical state\nestimation; a two-fold estimation of physical and reservoir states; and a\nthree-fold estimation that also adjusts the model parameters. The two-fold\nstrategy significantly improves ensemble convergence and reduces reconstruction\nerror compared to the na\\\"ive approach. The three-fold approach enables robust\nonline training of partially-trained reservoir computers, overcoming\nlimitations of a priori training. By unifying data-driven reduced order\nmodelling with Bayesian data assimilation, this work opens new opportunities\nfor scalable online model learning for nonlinear time series forecasting."}
{"id": "2504.16430", "pdf": "https://arxiv.org/pdf/2504.16430", "abs": "https://arxiv.org/abs/2504.16430", "authors": ["Andrew Ilyas", "Logan Engstrom"], "title": "MAGIC: Near-Optimal Data Attribution for Deep Learning", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "comment": null, "summary": "The goal of predictive data attribution is to estimate how adding or removing\na given set of training datapoints will affect model predictions. In convex\nsettings, this goal is straightforward (i.e., via the infinitesimal jackknife).\nIn large-scale (non-convex) settings, however, existing methods are far less\nsuccessful -- current methods' estimates often only weakly correlate with\nground truth. In this work, we present a new data attribution method (MAGIC)\nthat combines classical methods and recent advances in metadifferentiation to\n(nearly) optimally estimate the effect of adding or removing training data on\nmodel predictions."}
{"id": "2504.16828", "pdf": "https://arxiv.org/pdf/2504.16828", "abs": "https://arxiv.org/abs/2504.16828", "authors": ["Muhammad Khalifa", "Rishabh Agarwal", "Lajanugen Logeswaran", "Jaekyeom Kim", "Hao Peng", "Moontae Lee", "Honglak Lee", "Lu Wang"], "title": "Process Reward Models That Think", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Step-by-step verifiers -- also known as process reward models (PRMs) -- are a\nkey ingredient for test-time scaling. PRMs require step-level supervision,\nmaking them expensive to train. This work aims to build data-efficient PRMs as\nverbalized step-wise reward models that verify every step in the solution by\ngenerating a verification chain-of-thought (CoT). We propose ThinkPRM, a long\nCoT verifier fine-tuned on orders of magnitude fewer process labels than those\nrequired by discriminative PRMs. Our approach capitalizes on the inherent\nreasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and\ndiscriminative verifiers -- using only 1% of the process labels in PRM800K --\nacross several challenging benchmarks. Specifically, ThinkPRM beats the\nbaselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and\nreward-guided search. In an out-of-domain evaluation on a subset of\nGPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers\ntrained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the\nsame token budget, ThinkPRM scales up verification compute more effectively\ncompared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of\nProcessBench. Our work highlights the value of generative, long CoT PRMs that\ncan scale test-time compute for verification while requiring minimal\nsupervision for training. Our code, data, and models will be released at\nhttps://github.com/mukhal/thinkprm."}
{"id": "2504.16628", "pdf": "https://arxiv.org/pdf/2504.16628", "abs": "https://arxiv.org/abs/2504.16628", "authors": ["Haoran Gu", "Handing Wang", "Yi Mei", "Mengjie Zhang", "Yaochu Jin"], "title": "ParetoHqD: Fast Offline Multiobjective Alignment of Large Language Models using Pareto High-quality Data", "categories": ["cs.LG", "cs.CL"], "comment": "19 pages, 6 figure, Multiobjective Alignment of LLMs", "summary": "Aligning large language models with multiple human expectations and values is\ncrucial for ensuring that they adequately serve a variety of user needs. To\nthis end, offline multiobjective alignment algorithms such as the\nRewards-in-Context algorithm have shown strong performance and efficiency.\nHowever, inappropriate preference representations and training with imbalanced\nreward scores limit the performance of such algorithms. In this work, we\nintroduce ParetoHqD that addresses the above issues by representing human\npreferences as preference directions in the objective space and regarding data\nnear the Pareto front as ''high-quality'' data. For each preference, ParetoHqD\nfollows a two-stage supervised fine-tuning process, where each stage uses an\nindividual Pareto high-quality training set that best matches its preference\ndirection. The experimental results have demonstrated the superiority of\nParetoHqD over five baselines on two multiobjective alignment tasks."}
{"id": "2504.16831", "pdf": "https://arxiv.org/pdf/2504.16831", "abs": "https://arxiv.org/abs/2504.16831", "authors": ["Frederik L. Dennig", "Nina Geyer", "Daniela Blumberg", "Yannick Metz", "Daniel A. Keim"], "title": "Evaluating Autoencoders for Parametric and Invertible Multidimensional Projections", "categories": ["cs.LG"], "comment": "12 pages, 7 figures, 2 tables, LaTeX; to appear at the 16th\n  International EuroVis Workshop on Visual Analytics (EuroVA'25)", "summary": "Recently, neural networks have gained attention for creating parametric and\ninvertible multidimensional data projections. Parametric projections allow for\nembedding previously unseen data without recomputing the projection as a whole,\nwhile invertible projections enable the generation of new data points. However,\nthese properties have never been explored simultaneously for arbitrary\nprojection methods. We evaluate three autoencoder (AE) architectures for\ncreating parametric and invertible projections. Based on a given projection, we\ntrain AEs to learn a mapping into 2D space and an inverse mapping into the\noriginal space. We perform a quantitative and qualitative comparison on four\ndatasets of varying dimensionality and pattern complexity using t-SNE. Our\nresults indicate that AEs with a customized loss function can create smoother\nparametric and inverse projections than feed-forward neural networks while\ngiving users control over the strength of the smoothing effect."}
{"id": "2504.16728", "pdf": "https://arxiv.org/pdf/2504.16728", "abs": "https://arxiv.org/abs/2504.16728", "authors": ["Aniketh Garikaparthi", "Manasi Patwardhan", "Lovekesh Vig", "Arman Cohan"], "title": "IRIS: Interactive Research Ideation System for Accelerating Scientific Discovery", "categories": ["cs.AI", "cs.CL"], "comment": "6 pages main-text, 2 pages appendix", "summary": "The rapid advancement in capabilities of large language models (LLMs) raises\na pivotal question: How can LLMs accelerate scientific discovery? This work\ntackles the crucial first stage of research, generating novel hypotheses. While\nrecent work on automated hypothesis generation focuses on multi-agent\nframeworks and extending test-time compute, none of the approaches effectively\nincorporate transparency and steerability through a synergistic\nHuman-in-the-loop (HITL) approach. To address this gap, we introduce IRIS:\nInteractive Research Ideation System, an open-source platform designed for\nresearchers to leverage LLM-assisted scientific ideation. IRIS incorporates\ninnovative features to enhance ideation, including adaptive test-time compute\nexpansion via Monte Carlo Tree Search (MCTS), fine-grained feedback mechanism,\nand query-based literature synthesis. Designed to empower researchers with\ngreater control and insight throughout the ideation process. We additionally\nconduct a user study with researchers across diverse disciplines, validating\nthe effectiveness of our system in enhancing ideation. We open-source our code\nat https://github.com/Anikethh/IRIS-Interactive-Research-Ideation-System"}
{"id": "2504.16834", "pdf": "https://arxiv.org/pdf/2504.16834", "abs": "https://arxiv.org/abs/2504.16834", "authors": ["Yilin Zhai", "Hongyuan Shi", "Chao Zhan", "Qing Wang", "Zaijin You", "Nan Wang"], "title": "Improving Significant Wave Height Prediction Using Chronos Models", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "Accurate wave height prediction is critical for maritime safety and coastal\nresilience, yet conventional physics-based models and traditional machine\nlearning methods face challenges in computational efficiency and nonlinear\ndynamics modeling. This study introduces Chronos, the first implementation of a\nlarge language model (LLM)-powered temporal architecture (Chronos) optimized\nfor wave forecasting. Through advanced temporal pattern recognition applied to\nhistorical wave data from three strategically chosen marine zones in the\nNorthwest Pacific basin, our framework achieves multimodal improvements: (1)\n14.3% reduction in training time with 2.5x faster inference speed compared to\nPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;\n(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)\nsustained predictive leadership in extended-range forecasts (1-120h); and (4)\ndemonstrated zero-shot capability maintaining median performance (rank 4/12)\nagainst specialized operational models. This LLM-enhanced temporal modeling\nparadigm establishes a new standard in wave prediction, offering both\ncomputationally efficient solutions and a transferable framework for complex\ngeophysical systems modeling."}
{"id": "2504.16828", "pdf": "https://arxiv.org/pdf/2504.16828", "abs": "https://arxiv.org/abs/2504.16828", "authors": ["Muhammad Khalifa", "Rishabh Agarwal", "Lajanugen Logeswaran", "Jaekyeom Kim", "Hao Peng", "Moontae Lee", "Honglak Lee", "Lu Wang"], "title": "Process Reward Models That Think", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Step-by-step verifiers -- also known as process reward models (PRMs) -- are a\nkey ingredient for test-time scaling. PRMs require step-level supervision,\nmaking them expensive to train. This work aims to build data-efficient PRMs as\nverbalized step-wise reward models that verify every step in the solution by\ngenerating a verification chain-of-thought (CoT). We propose ThinkPRM, a long\nCoT verifier fine-tuned on orders of magnitude fewer process labels than those\nrequired by discriminative PRMs. Our approach capitalizes on the inherent\nreasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and\ndiscriminative verifiers -- using only 1% of the process labels in PRM800K --\nacross several challenging benchmarks. Specifically, ThinkPRM beats the\nbaselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and\nreward-guided search. In an out-of-domain evaluation on a subset of\nGPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers\ntrained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the\nsame token budget, ThinkPRM scales up verification compute more effectively\ncompared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of\nProcessBench. Our work highlights the value of generative, long CoT PRMs that\ncan scale test-time compute for verification while requiring minimal\nsupervision for training. Our code, data, and models will be released at\nhttps://github.com/mukhal/thinkprm."}
{"id": "2504.16866", "pdf": "https://arxiv.org/pdf/2504.16866", "abs": "https://arxiv.org/abs/2504.16866", "authors": ["Panagiotis Kakosimos", "Alireza Nemat Saberi", "Luca Peretti"], "title": "An Adaptive ML Framework for Power Converter Monitoring via Federated Transfer Learning", "categories": ["cs.LG"], "comment": "2025 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "This study explores alternative framework configurations for adapting thermal\nmachine learning (ML) models for power converters by combining transfer\nlearning (TL) and federated learning (FL) in a piecewise manner. This approach\ninherently addresses challenges such as varying operating conditions, data\nsharing limitations, and security implications. The framework starts with a\nbase model that is incrementally adapted by multiple clients via adapting three\nstate-of-the-art domain adaptation techniques: Fine-tuning, Transfer Component\nAnalysis (TCA), and Deep Domain Adaptation (DDA). The Flower framework is\nemployed for FL, using Federated Averaging for aggregation. Validation with\nfield data demonstrates that fine-tuning offers a straightforward TL approach\nwith high accuracy, making it suitable for practical applications. Benchmarking\nresults reveal a comprehensive comparison of these methods, showcasing their\nrespective strengths and weaknesses when applied in different scenarios.\nLocally hosted FL enhances performance when data aggregation is not feasible,\nwhile cloud-based FL becomes more practical with a significant increase in the\nnumber of clients, addressing scalability and connectivity challenges."}
{"id": "2504.16891", "pdf": "https://arxiv.org/pdf/2504.16891", "abs": "https://arxiv.org/abs/2504.16891", "authors": ["Ivan Moshkov", "Darragh Hanley", "Ivan Sorokin", "Shubham Toshniwal", "Christof Henkel", "Benedikt Schifferer", "Wei Du", "Igor Gitman"], "title": "AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Report of AIMO-2 winning submission", "summary": "This paper presents our winning submission to the AI Mathematical Olympiad -\nProgress Prize 2 (AIMO-2) competition. Our recipe for building state-of-the-art\nmathematical reasoning models relies on three key pillars. First, we create a\nlarge-scale dataset comprising 540K unique high-quality math problems,\nincluding olympiad-level problems, and their 3.2M long-reasoning solutions.\nSecond, we develop a novel method to integrate code execution with long\nreasoning models through iterative training, generation, and quality filtering,\nresulting in 1.7M high-quality Tool-Integrated Reasoning solutions. Third, we\ncreate a pipeline to train models to select the most promising solution from\nmany candidates. We show that such generative solution selection (GenSelect)\ncan significantly improve upon majority voting baseline. Combining these ideas,\nwe train a series of models that achieve state-of-the-art results on\nmathematical reasoning benchmarks. To facilitate further research, we release\nour code, models, and the complete OpenMathReasoning dataset under a\ncommercially permissive license."}
{"id": "2504.16871", "pdf": "https://arxiv.org/pdf/2504.16871", "abs": "https://arxiv.org/abs/2504.16871", "authors": ["Mirian Hipolito Garcia", "Camille Couturier", "Daniel Madrigal Diaz", "Ankur Mallick", "Anastasios Kyrillidis", "Robert Sim", "Victor Ruhle", "Saravan Rajmohan"], "title": "Exploring How LLMs Capture and Represent Domain-Specific Knowledge", "categories": ["cs.LG"], "comment": null, "summary": "We study whether Large Language Models (LLMs) inherently capture\ndomain-specific nuances in natural language. Our experiments probe the domain\nsensitivity of LLMs by examining their ability to distinguish queries from\ndifferent domains using hidden states generated during the prefill phase. We\nreveal latent domain-related trajectories that indicate the model's internal\nrecognition of query domains. We also study the robustness of these domain\nrepresentations to variations in prompt styles and sources. Our approach\nleverages these representations for model selection, mapping the LLM that best\nmatches the domain trace of the input query (i.e., the model with the highest\nperformance on similar traces). Our findings show that LLMs can differentiate\nqueries for related domains, and that the fine-tuned model is not always the\nmost accurate. Unlike previous work, our interpretations apply to both closed\nand open-ended generative tasks"}
{"id": "2504.16875", "pdf": "https://arxiv.org/pdf/2504.16875", "abs": "https://arxiv.org/abs/2504.16875", "authors": ["Julian Bedei", "Murray McBain", "Charles Robert Koch", "Jakob Andert", "David Gordon"], "title": "Hybrid Reinforcement Learning and Model Predictive Control for Adaptive Control of Hydrogen-Diesel Dual-Fuel Combustion", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement Learning (RL) and Machine Learning Integrated Model Predictive\nControl (ML-MPC) are promising approaches for optimizing hydrogen-diesel\ndual-fuel engine control, as they can effectively control multiple-input\nmultiple-output systems and nonlinear processes. ML-MPC is advantageous for\nproviding safe and optimal controls, ensuring the engine operates within\npredefined safety limits. In contrast, RL is distinguished by its adaptability\nto changing conditions through its learning-based approach. However, the\npractical implementation of either method alone poses challenges. RL requires\nhigh variance in control inputs during early learning phases, which can pose\nrisks to the system by potentially executing unsafe actions, leading to\nmechanical damage. Conversely, ML-MPC relies on an accurate system model to\ngenerate optimal control inputs and has limited adaptability to system drifts,\nsuch as injector aging, which naturally occur in engine applications. To\naddress these limitations, this study proposes a hybrid RL and ML-MPC approach\nthat uses an ML-MPC framework while incorporating an RL agent to dynamically\nadjust the ML-MPC load tracking reference in response to changes in the\nenvironment. At the same time, the ML-MPC ensures that actions stay safe\nthroughout the RL agent's exploration. To evaluate the effectiveness of this\napproach, fuel pressure is deliberately varied to introduce a model-plant\nmismatch between the ML-MPC and the engine test bench. The result of this\nmismatch is a root mean square error (RMSE) in indicated mean effective\npressure of 0.57 bar when running the ML-MPC. The experimental results\ndemonstrate that RL successfully adapts to changing boundary conditions by\naltering the tracking reference while ML-MPC ensures safe control inputs. The\nquantitative improvement in load tracking by implementing RL is an RSME of 0.44\nbar."}
{"id": "2504.16929", "pdf": "https://arxiv.org/pdf/2504.16929", "abs": "https://arxiv.org/abs/2504.16929", "authors": ["Shaden Alshammari", "John Hershey", "Axel Feldmann", "William T. Freeman", "Mark Hamilton"], "title": "I-Con: A Unifying Framework for Representation Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT", "math.IT"], "comment": "ICLR 2025; website: https://aka.ms/i-con . Proceedings of the\n  Thirteenth International Conference on Learning Representations (ICLR 2025)", "summary": "As the field of representation learning grows, there has been a proliferation\nof different loss functions to solve different classes of problems. We\nintroduce a single information-theoretic equation that generalizes a large\ncollection of modern loss functions in machine learning. In particular, we\nintroduce a framework that shows that several broad classes of machine learning\nmethods are precisely minimizing an integrated KL divergence between two\nconditional distributions: the supervisory and learned representations. This\nviewpoint exposes a hidden information geometry underlying clustering, spectral\nmethods, dimensionality reduction, contrastive learning, and supervised\nlearning. This framework enables the development of new loss functions by\ncombining successful techniques from across the literature. We not only present\na wide array of proofs, connecting over 23 different approaches, but we also\nleverage these theoretical results to create state-of-the-art unsupervised\nimage classifiers that achieve a +8% improvement over the prior\nstate-of-the-art on unsupervised classification on ImageNet-1K. We also\ndemonstrate that I-Con can be used to derive principled debiasing methods which\nimprove contrastive representation learners."}
{"id": "2504.16097", "pdf": "https://arxiv.org/pdf/2504.16097", "abs": "https://arxiv.org/abs/2504.16097", "authors": ["Arthur Buzelin", "Pedro Robles Dutenhefner", "Turi Rezende", "Luisa G. Porfirio", "Pedro Bento", "Yan Aquino", "Jose Fernandes", "Caio Santana", "Gabriela Miana", "Gisele L. Pappa", "Antonio Ribeiro", "Wagner Meira Jr"], "title": "A CNN-based Local-Global Self-Attention via Averaged Window Embeddings for Hierarchical ECG Analysis", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Cardiovascular diseases remain the leading cause of global mortality,\nemphasizing the critical need for efficient diagnostic tools such as\nelectrocardiograms (ECGs). Recent advancements in deep learning, particularly\ntransformers, have revolutionized ECG analysis by capturing detailed waveform\nfeatures as well as global rhythm patterns. However, traditional transformers\nstruggle to effectively capture local morphological features that are critical\nfor accurate ECG interpretation. We propose a novel Local-Global Attention ECG\nmodel (LGA-ECG) to address this limitation, integrating convolutional inductive\nbiases with global self-attention mechanisms. Our approach extracts queries by\naveraging embeddings obtained from overlapping convolutional windows, enabling\nfine-grained morphological analysis, while simultaneously modeling global\ncontext through attention to keys and values derived from the entire sequence.\nExperiments conducted on the CODE-15 dataset demonstrate that LGA-ECG\noutperforms state-of-the-art models and ablation studies validate the\neffectiveness of the local-global attention strategy. By capturing the\nhierarchical temporal dependencies and morphological patterns in ECG signals,\nthis new design showcases its potential for clinical deployment with robust\nautomated ECG classification."}
{"id": "2504.16098", "pdf": "https://arxiv.org/pdf/2504.16098", "abs": "https://arxiv.org/abs/2504.16098", "authors": ["Tianning Feng", "Junting Ni", "Ezequiel Gleichgerrcht", "Wei Jin"], "title": "SeizureFormer: A Transformer Model for IEA-Based Seizure Risk Forecasting", "categories": ["eess.SP", "cs.LG", "I.5.1; I.2.6"], "comment": "9 pages, 2 figures. Submitted to AMIA 2025. Also submitted as an\n  undergraduate honors thesis at Emory University", "summary": "We present SeizureFormer, a Transformer-based model for long-term seizure\nrisk forecasting using interictal epileptiform activity (IEA) surrogate\nbiomarkers and long episode (LE) biomarkers from responsive neurostimulation\n(RNS) systems. Unlike raw scalp EEG-based models, SeizureFormer leverages\nstructured, clinically relevant features and integrates CNN-based patch\nembedding, multi-head self-attention, and squeeze-and-excitation blocks to\nmodel both short-term dynamics and long-term seizure cycles. Tested across five\npatients and multiple prediction windows (1 to 14 days), SeizureFormer achieved\nstate-of-the-art performance with mean ROC AUC of 79.44 percent and mean PR AUC\nof 76.29 percent. Compared to statistical, machine learning, and deep learning\nbaselines, it demonstrates enhanced generalizability and seizure risk\nforecasting performance under class imbalance. This work supports future\nclinical integration of interpretable and robust seizure forecasting tools for\npersonalized epilepsy management."}
{"id": "2504.16100", "pdf": "https://arxiv.org/pdf/2504.16100", "abs": "https://arxiv.org/abs/2504.16100", "authors": ["Eloi Lindas", "Yannig Goude", "Philippe Ciais"], "title": "Towards Accurate Forecasting of Renewable Energy : Building Datasets and Benchmarking Machine Learning Models for Solar and Wind Power in France", "categories": ["eess.SP", "cs.AI", "cs.LG", "stat.ML"], "comment": "24 pages, 4 tables, 18 figures", "summary": "Accurate prediction of non-dispatchable renewable energy sources is essential\nfor grid stability and price prediction. Regional power supply forecasts are\nusually indirect through a bottom-up approach of plant-level forecasts,\nincorporate lagged power values, and do not use the potential of spatially\nresolved data. This study presents a comprehensive methodology for predicting\nsolar and wind power production at country scale in France using machine\nlearning models trained with spatially explicit weather data combined with\nspatial information about production sites capacity. A dataset is built\nspanning from 2012 to 2023, using daily power production data from RTE (the\nnational grid operator) as the target variable, with daily weather data from\nERA5, production sites capacity and location, and electricity prices as input\nfeatures. Three modeling approaches are explored to handle spatially resolved\nweather data: spatial averaging over the country, dimension reduction through\nprincipal component analysis, and a computer vision architecture to exploit\ncomplex spatial relationships. The study benchmarks state-of-the-art machine\nlearning models as well as hyperparameter tuning approaches based on\ncross-validation methods on daily power production data. Results indicate that\ncross-validation tailored to time series is best suited to reach low error. We\nfound that neural networks tend to outperform traditional tree-based models,\nwhich face challenges in extrapolation due to the increasing renewable capacity\nover time. Model performance ranges from 4% to 10% in nRMSE for midterm\nhorizon, achieving similar error metrics to local models established at a\nsingle-plant level, highlighting the potential of these methods for regional\npower supply forecasting."}
{"id": "2504.16101", "pdf": "https://arxiv.org/pdf/2504.16101", "abs": "https://arxiv.org/abs/2504.16101", "authors": ["Lei Kang", "Xuanshuo Fu", "Javier Vazquez-Corral", "Ernest Valveny", "Dimosthenis Karatzas"], "title": "xLSTM-ECG: Multi-label ECG Classification via Feature Fusion with xLSTM", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Cardiovascular diseases (CVDs) remain the leading cause of mortality\nworldwide, highlighting the critical need for efficient and accurate diagnostic\ntools. Electrocardiograms (ECGs) are indispensable in diagnosing various heart\nconditions; however, their manual interpretation is time-consuming and\nerror-prone. In this paper, we propose xLSTM-ECG, a novel approach that\nleverages an extended Long Short-Term Memory (xLSTM) network for multi-label\nclassification of ECG signals, using the PTB-XL dataset. To the best of our\nknowledge, this work represents the first design and application of xLSTM\nmodules specifically adapted for multi-label ECG classification. Our method\nemploys a Short-Time Fourier Transform (STFT) to convert time-series ECG\nwaveforms into the frequency domain, thereby enhancing feature extraction. The\nxLSTM architecture is specifically tailored to address the complexities of\n12-lead ECG recordings by capturing both local and global signal features.\nComprehensive experiments on the PTB-XL dataset reveal that our model achieves\nstrong multi-label classification performance, while additional tests on the\nGeorgia 12-Lead dataset underscore its robustness and efficiency. This approach\nsignificantly improves ECG classification accuracy, thereby advancing clinical\ndiagnostics and patient care. The code will be publicly available upon\nacceptance."}
{"id": "2504.16115", "pdf": "https://arxiv.org/pdf/2504.16115", "abs": "https://arxiv.org/abs/2504.16115", "authors": ["Yibo Jacky Zhang", "Sanmi Koyejo"], "title": "A Framework for Objective-Driven Dynamical Stochastic Fields", "categories": ["cs.AI", "cs.LG", "cs.MA", "nlin.AO"], "comment": null, "summary": "Fields offer a versatile approach for describing complex systems composed of\ninteracting and dynamic components. In particular, some of these dynamical and\nstochastic systems may exhibit goal-directed behaviors aimed at achieving\nspecific objectives, which we refer to as $\\textit{intelligent fields}$.\nHowever, due to their inherent complexity, it remains challenging to develop a\nformal theoretical description of such systems and to effectively translate\nthese descriptions into practical applications. In this paper, we propose three\nfundamental principles -- complete configuration, locality, and purposefulness\n-- to establish a theoretical framework for understanding intelligent fields.\nMoreover, we explore methodologies for designing such fields from the\nperspective of artificial intelligence applications. This initial investigation\naims to lay the groundwork for future theoretical developments and practical\nadvances in understanding and harnessing the potential of such objective-driven\ndynamical stochastic fields."}
{"id": "2504.16121", "pdf": "https://arxiv.org/pdf/2504.16121", "abs": "https://arxiv.org/abs/2504.16121", "authors": ["Muhammad Rafsan Kabir", "Rafeed Mohammad Sultan", "Fuad Rahman", "Mohammad Ruhul Amin", "Sifat Momen", "Nabeel Mohammed", "Shafin Rahman"], "title": "LegalRAG: A Hybrid RAG System for Multilingual Legal Information Retrieval", "categories": ["cs.IR", "cs.CL", "cs.LG"], "comment": "Accepted at IJCNN 2025", "summary": "Natural Language Processing (NLP) and computational linguistic techniques are\nincreasingly being applied across various domains, yet their use in legal and\nregulatory tasks remains limited. To address this gap, we develop an efficient\nbilingual question-answering framework for regulatory documents, specifically\nthe Bangladesh Police Gazettes, which contain both English and Bangla text. Our\napproach employs modern Retrieval Augmented Generation (RAG) pipelines to\nenhance information retrieval and response generation. In addition to\nconventional RAG pipelines, we propose an advanced RAG-based approach that\nimproves retrieval performance, leading to more precise answers. This system\nenables efficient searching for specific government legal notices, making legal\ninformation more accessible. We evaluate both our proposed and conventional RAG\nsystems on a diverse test set on Bangladesh Police Gazettes, demonstrating that\nour approach consistently outperforms existing methods across all evaluation\nmetrics."}
{"id": "2504.16128", "pdf": "https://arxiv.org/pdf/2504.16128", "abs": "https://arxiv.org/abs/2504.16128", "authors": ["Stanley Mugisha", "Rashid Kisitu", "Florence Tushabe"], "title": "Hybrid Knowledge Transfer through Attention and Logit Distillation for On-Device Vision Systems in Agricultural IoT", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2.10; I.4.9"], "comment": "12 pages and 4 figures", "summary": "Integrating deep learning applications into agricultural IoT systems faces a\nserious challenge of balancing the high accuracy of Vision Transformers (ViTs)\nwith the efficiency demands of resource-constrained edge devices. Large\ntransformer models like the Swin Transformers excel in plant disease\nclassification by capturing global-local dependencies. However, their\ncomputational complexity (34.1 GFLOPs) limits applications and renders them\nimpractical for real-time on-device inference. Lightweight models such as\nMobileNetV3 and TinyML would be suitable for on-device inference but lack the\nrequired spatial reasoning for fine-grained disease detection. To bridge this\ngap, we propose a hybrid knowledge distillation framework that synergistically\ntransfers logit and attention knowledge from a Swin Transformer teacher to a\nMobileNetV3 student model. Our method includes the introduction of adaptive\nattention alignment to resolve cross-architecture mismatch (resolution,\nchannels) and a dual-loss function optimizing both class probabilities and\nspatial focus. On the lantVillage-Tomato dataset (18,160 images), the distilled\nMobileNetV3 attains 92.4% accuracy relative to 95.9% for Swin-L but at an 95%\nreduction on PC and < 82% in inference latency on IoT devices. (23ms on PC CPU\nand 86ms/image on smartphone CPUs). Key innovations include IoT-centric\nvalidation metrics (13 MB memory, 0.22 GFLOPs) and dynamic resolution-matching\nattention maps. Comparative experiments show significant improvements over\nstandalone CNNs and prior distillation methods, with a 3.5% accuracy gain over\nMobileNetV3 baselines. Significantly, this work advances real-time,\nenergy-efficient crop monitoring in precision agriculture and demonstrates how\nwe can attain ViT-level diagnostic precision on edge devices. Code and models\nwill be made available for replication after acceptance."}
{"id": "2504.16129", "pdf": "https://arxiv.org/pdf/2504.16129", "abs": "https://arxiv.org/abs/2504.16129", "authors": ["Junwei Liao", "Muning Wen", "Jun Wang", "Weinan Zhang"], "title": "MARFT: Multi-Agent Reinforcement Fine-Tuning", "categories": ["cs.MA", "cs.AI", "cs.LG", "cs.RO"], "comment": "36 pages", "summary": "LLM-based Multi-Agent Systems have demonstrated remarkable capabilities in\naddressing complex, agentic tasks requiring multifaceted reasoning and\ncollaboration, from generating high-quality presentation slides to conducting\nsophisticated scientific research. Meanwhile, RL has been widely recognized for\nits effectiveness in enhancing agent intelligence, but limited research has\ninvestigated the fine-tuning of LaMAS using foundational RL techniques.\nMoreover, the direct application of MARL methodologies to LaMAS introduces\nsignificant challenges, stemming from the unique characteristics and mechanisms\ninherent to LaMAS. To address these challenges, this article presents a\ncomprehensive study of LLM-based MARL and proposes a novel paradigm termed\nMulti-Agent Reinforcement Fine-Tuning (MARFT). We introduce a universal\nalgorithmic framework tailored for LaMAS, outlining the conceptual foundations,\nkey distinctions, and practical implementation strategies. We begin by\nreviewing the evolution from RL to Reinforcement Fine-Tuning, setting the stage\nfor a parallel analysis in the multi-agent domain. In the context of LaMAS, we\nelucidate critical differences between MARL and MARFT. These differences\nmotivate a transition toward a novel, LaMAS-oriented formulation of RFT.\nCentral to this work is the presentation of a robust and scalable MARFT\nframework. We detail the core algorithm and provide a complete, open-source\nimplementation to facilitate adoption and further research. The latter sections\nof the paper explore real-world application perspectives and opening challenges\nin MARFT. By bridging theoretical underpinnings with practical methodologies,\nthis work aims to serve as a roadmap for researchers seeking to advance MARFT\ntoward resilient and adaptive solutions in agentic systems. Our implementation\nof the proposed framework is publicly available at:\nhttps://github.com/jwliao-ai/MARFT."}
{"id": "2504.16130", "pdf": "https://arxiv.org/pdf/2504.16130", "abs": "https://arxiv.org/abs/2504.16130", "authors": ["Pengju Ren", "Ri-gui Zhou", "Yaochong Li"], "title": "A Self-supervised Learning Method for Raman Spectroscopy based on Masked Autoencoders", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "15 pages, 10 figures", "summary": "Raman spectroscopy serves as a powerful and reliable tool for analyzing the\nchemical information of substances. The integration of Raman spectroscopy with\ndeep learning methods enables rapid qualitative and quantitative analysis of\nmaterials. Most existing approaches adopt supervised learning methods. Although\nsupervised learning has achieved satisfactory accuracy in spectral analysis, it\nis still constrained by costly and limited well-annotated spectral datasets for\ntraining. When spectral annotation is challenging or the amount of annotated\ndata is insufficient, the performance of supervised learning in spectral\nmaterial identification declines. In order to address the challenge of feature\nextraction from unannotated spectra, we propose a self-supervised learning\nparadigm for Raman Spectroscopy based on a Masked AutoEncoder, termed SMAE.\nSMAE does not require any spectral annotations during pre-training. By randomly\nmasking and then reconstructing the spectral information, the model learns\nessential spectral features. The reconstructed spectra exhibit certain\ndenoising properties, improving the signal-to-noise ratio (SNR) by more than\ntwofold. Utilizing the network weights obtained from masked pre-training, SMAE\nachieves clustering accuracy of over 80% for 30 classes of isolated bacteria in\na pathogenic bacterial dataset, demonstrating significant improvements compared\nto classical unsupervised methods and other state-of-the-art deep clustering\nmethods. After fine-tuning the network with a limited amount of annotated data,\nSMAE achieves an identification accuracy of 83.90% on the test set, presenting\ncompetitive performance against the supervised ResNet (83.40%)."}
{"id": "2504.16131", "pdf": "https://arxiv.org/pdf/2504.16131", "abs": "https://arxiv.org/abs/2504.16131", "authors": ["Samuel Yen-Chi Chen", "Zhiding Liang"], "title": "Introduction to Quantum Machine Learning and Quantum Architecture Search", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG", "cs.NE"], "comment": "ISCAS 2025 Tutorial", "summary": "Recent advancements in quantum computing (QC) and machine learning (ML) have\nfueled significant research efforts aimed at integrating these two\ntransformative technologies. Quantum machine learning (QML), an emerging\ninterdisciplinary field, leverages quantum principles to enhance the\nperformance of ML algorithms. Concurrently, the exploration of systematic and\nautomated approaches for designing high-performance quantum circuit\narchitectures for QML tasks has gained prominence, as these methods empower\nresearchers outside the quantum computing domain to effectively utilize\nquantum-enhanced tools. This tutorial will provide an in-depth overview of\nrecent breakthroughs in both areas, highlighting their potential to expand the\napplication landscape of QML across diverse fields."}
{"id": "2504.16137", "pdf": "https://arxiv.org/pdf/2504.16137", "abs": "https://arxiv.org/abs/2504.16137", "authors": ["Jasper Götting", "Pedro Medeiros", "Jon G Sanders", "Nathaniel Li", "Long Phan", "Karam Elabd", "Lennart Justen", "Dan Hendrycks", "Seth Donoughe"], "title": "Virology Capabilities Test (VCT): A Multimodal Virology Q&A Benchmark", "categories": ["cs.CY", "cs.LG"], "comment": "31 pages", "summary": "We present the Virology Capabilities Test (VCT), a large language model (LLM)\nbenchmark that measures the capability to troubleshoot complex virology\nlaboratory protocols. Constructed from the inputs of dozens of PhD-level expert\nvirologists, VCT consists of $322$ multimodal questions covering fundamental,\ntacit, and visual knowledge that is essential for practical work in virology\nlaboratories. VCT is difficult: expert virologists with access to the internet\nscore an average of $22.1\\%$ on questions specifically in their sub-areas of\nexpertise. However, the most performant LLM, OpenAI's o3, reaches $43.8\\%$\naccuracy, outperforming $94\\%$ of expert virologists even within their\nsub-areas of specialization. The ability to provide expert-level virology\ntroubleshooting is inherently dual-use: it is useful for beneficial research,\nbut it can also be misused. Therefore, the fact that publicly available models\noutperform virologists on VCT raises pressing governance considerations. We\npropose that the capability of LLMs to provide expert-level troubleshooting of\ndual-use virology work should be integrated into existing frameworks for\nhandling dual-use technologies in the life sciences."}
{"id": "2504.16142", "pdf": "https://arxiv.org/pdf/2504.16142", "abs": "https://arxiv.org/abs/2504.16142", "authors": ["Hangxu Liu", "Yaojie Sun", "Yu Wang"], "title": "A Non-Invasive Load Monitoring Method for Edge Computing Based on MobileNetV3 and Dynamic Time Regulation", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "In recent years, non-intrusive load monitoring (NILM) technology has\nattracted much attention in the related research field by virtue of its unique\nadvantage of utilizing single meter data to achieve accurate decomposition of\ndevice-level energy consumption. Cutting-edge methods based on machine learning\nand deep learning have achieved remarkable results in load decomposition\naccuracy by fusing time-frequency domain features. However, these methods\ngenerally suffer from high computational costs and huge memory requirements,\nwhich become the main obstacles for their deployment on resource-constrained\nmicrocontroller units (MCUs). To address these challenges, this study proposes\nan innovative Dynamic Time Warping (DTW) algorithm in the time-frequency domain\nand systematically compares and analyzes the performance of six machine\nlearning techniques in home electricity scenarios. Through complete\nexperimental validation on edge MCUs, this scheme successfully achieves a\nrecognition accuracy of 95%. Meanwhile, this study deeply optimizes the\nfrequency domain feature extraction process, which effectively reduces the\nrunning time by 55.55% and the storage overhead by about 34.6%. The algorithm\nperformance will be further optimized in future research work. Considering that\nthe elimination of voltage transformer design can significantly reduce the\ncost, the subsequent research will focus on this direction, and is committed to\nproviding more cost-effective solutions for the practical application of NILM,\nand providing a solid theoretical foundation and feasible technical paths for\nthe design of efficient NILM systems in edge computing environments."}
{"id": "2504.16143", "pdf": "https://arxiv.org/pdf/2504.16143", "abs": "https://arxiv.org/abs/2504.16143", "authors": ["Gideon Vos", "Maryam Ebrahimpour", "Liza van Eijk", "Zoltan Sarnyai", "Mostafa Rahimi Azghadi"], "title": "A Statistical Approach for Synthetic EEG Data Generation", "categories": ["eess.SP", "cs.LG", "68T01, 92-08"], "comment": "24 pages, 10 figures", "summary": "Electroencephalogram (EEG) data is crucial for diagnosing mental health\nconditions but is costly and time-consuming to collect at scale. Synthetic data\ngeneration offers a promising solution to augment datasets for machine learning\napplications. However, generating high-quality synthetic EEG that preserves\nemotional and mental health signals remains challenging. This study proposes a\nmethod combining correlation analysis and random sampling to generate realistic\nsynthetic EEG data.\n  We first analyze interdependencies between EEG frequency bands using\ncorrelation analysis. Guided by this structure, we generate synthetic samples\nvia random sampling. Samples with high correlation to real data are retained\nand evaluated through distribution analysis and classification tasks. A Random\nForest model trained to distinguish synthetic from real EEG performs at chance\nlevel, indicating high fidelity.\n  The generated synthetic data closely match the statistical and structural\nproperties of the original EEG, with similar correlation coefficients and no\nsignificant differences in PERMANOVA tests. This method provides a scalable,\nprivacy-preserving approach for augmenting EEG datasets, enabling more\nefficient model training in mental health research."}
{"id": "2504.16152", "pdf": "https://arxiv.org/pdf/2504.16152", "abs": "https://arxiv.org/abs/2504.16152", "authors": ["Mohammad Molaee", "Nasrollah Moghadam Charkari"], "title": "Heterogeneous networks in drug-target interaction prediction", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": "18 pages, 5 figures, 10 tables", "summary": "Drug discovery requires a tremendous amount of time and cost. Computational\ndrug-target interaction prediction, a significant part of this process, can\nreduce these requirements by narrowing the search space for wet lab\nexperiments. In this survey, we provide comprehensive details of graph machine\nlearning-based methods in predicting drug-target interaction, as they have\nshown promising results in this field. These details include the overall\nframework, main contribution, datasets, and their source codes. The selected\npapers were mainly published from 2020 to 2024. Prior to discussing papers, we\nbriefly introduce the datasets commonly used with these methods and\nmeasurements to assess their performance. Finally, future challenges and some\ncrucial areas that need to be explored are discussed."}
{"id": "2504.16172", "pdf": "https://arxiv.org/pdf/2504.16172", "abs": "https://arxiv.org/abs/2504.16172", "authors": ["Zexi Fan", "Yan Sun", "Shihao Yang", "Yiping Lu"], "title": "Physics-Informed Inference Time Scaling via Simulation-Calibrated Scientific Machine Learning", "categories": ["math.NA", "cs.AI", "cs.LG", "cs.NA", "math.PR", "stat.ML"], "comment": null, "summary": "High-dimensional partial differential equations (PDEs) pose significant\ncomputational challenges across fields ranging from quantum chemistry to\neconomics and finance. Although scientific machine learning (SciML) techniques\noffer approximate solutions, they often suffer from bias and neglect crucial\nphysical insights. Inspired by inference-time scaling strategies in language\nmodels, we propose Simulation-Calibrated Scientific Machine Learning (SCaSML),\na physics-informed framework that dynamically refines and debiases the SCiML\npredictions during inference by enforcing the physical laws. SCaSML leverages\nderived new physical laws that quantifies systematic errors and employs Monte\nCarlo solvers based on the Feynman-Kac and Elworthy-Bismut-Li formulas to\ndynamically correct the prediction. Both numerical and theoretical analysis\nconfirms enhanced convergence rates via compute-optimal inference methods. Our\nnumerical experiments demonstrate that SCaSML reduces errors by 20-50% compared\nto the base surrogate model, establishing it as the first algorithm to refine\napproximated solutions to high-dimensional PDE during inference. Code of SCaSML\nis available at https://github.com/Francis-Fan-create/SCaSML."}
{"id": "2504.16185", "pdf": "https://arxiv.org/pdf/2504.16185", "abs": "https://arxiv.org/abs/2504.16185", "authors": ["Emily Minus", "R. Yates Coley", "Susan M. Shortreed", "Brian D. Williamson"], "title": "Behavior of prediction performance metrics with rare events", "categories": ["stat.ML", "cs.LG"], "comment": "55 pages (21 main, 34 supplementary), 26 tables (3 main, 23\n  supplementary), 5 figures (3 main, 2 supplementary)", "summary": "Area under the receiving operator characteristic curve (AUC) is commonly\nreported alongside binary prediction models. However, there are concerns that\nAUC might be a misleading measure of prediction performance in the rare event\nsetting. This setting is common since many events of clinical importance are\nrare events. We conducted a simulation study to determine when or whether AUC\nis unstable in the rare event setting. Specifically, we aimed to determine\nwhether the bias and variance of AUC are driven by the number of events or the\nevent rate. We also investigated the behavior of other commonly used measures\nof prediction performance, including positive predictive value, accuracy,\nsensitivity, and specificity. Our results indicate that poor AUC behavior -- as\nmeasured by empirical bias, variability of cross-validated AUC estimates, and\nempirical coverage of confidence intervals -- is driven by the minimum class\nsize, not event rate. Performance of sensitivity is driven by the number of\nevents, while that of specificity is driven by the number of non-events. Other\nmeasures, including positive predictive value and accuracy, depend on the event\nrate even in large samples. AUC is reliable in the rare event setting provided\nthat the total number of events is moderately large."}
{"id": "2504.16188", "pdf": "https://arxiv.org/pdf/2504.16188", "abs": "https://arxiv.org/abs/2504.16188", "authors": ["Jabez Magomere", "Elena Kochkina", "Samuel Mensah", "Simerjot Kaur", "Charese H. Smiley"], "title": "FinNLI: Novel Dataset for Multi-Genre Financial Natural Language Inference Benchmarking", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce FinNLI, a benchmark dataset for Financial Natural Language\nInference (FinNLI) across diverse financial texts like SEC Filings, Annual\nReports, and Earnings Call transcripts. Our dataset framework ensures diverse\npremise-hypothesis pairs while minimizing spurious correlations. FinNLI\ncomprises 21,304 pairs, including a high-quality test set of 3,304 instances\nannotated by finance experts. Evaluations show that domain shift significantly\ndegrades general-domain NLI performance. The highest Macro F1 scores for\npre-trained (PLMs) and large language models (LLMs) baselines are 74.57% and\n78.62%, respectively, highlighting the dataset's difficulty. Surprisingly,\ninstruction-tuned financial LLMs perform poorly, suggesting limited\ngeneralizability. FinNLI exposes weaknesses in current LLMs for financial\nreasoning, indicating room for improvement."}
{"id": "2504.16192", "pdf": "https://arxiv.org/pdf/2504.16192", "abs": "https://arxiv.org/abs/2504.16192", "authors": ["Lucas Howard", "Aneesh C. Subramanian", "Gregory Thompson", "Benjamin Johnson", "Thomas Auligne"], "title": "Probabilistic Emulation of the Community Radiative Transfer Model Using Machine Learning", "categories": ["physics.ao-ph", "cs.LG", "stat.ML"], "comment": "26 pages, 9 figures, 1 table", "summary": "The continuous improvement in weather forecast skill over the past several\ndecades is largely due to the increasing quantity of available satellite\nobservations and their assimilation into operational forecast systems.\nAssimilating these observations requires observation operators in the form of\nradiative transfer models. Significant efforts have been dedicated to enhancing\nthe computational efficiency of these models. Computational cost remains a\nbottleneck, and a large fraction of available data goes unused for\nassimilation. To address this, we used machine learning to build an efficient\nneural network based probabilistic emulator of the Community Radiative Transfer\nModel (CRTM), applied to the GOES Advanced Baseline Imager. The trained NN\nemulator predicts brightness temperatures output by CRTM and the corresponding\nerror with respect to CRTM. RMSE of the predicted brightness temperature is 0.3\nK averaged across all channels. For clear sky conditions, the RMSE is less than\n0.1 K for 9 out of 10 infrared channels. The error predictions are generally\nreliable across a wide range of conditions. Explainable AI methods demonstrate\nthat the trained emulator reproduces the relevant physics, increasing\nconfidence that the model will perform well when presented with new data."}
{"id": "2504.16226", "pdf": "https://arxiv.org/pdf/2504.16226", "abs": "https://arxiv.org/abs/2504.16226", "authors": ["Yazan Otoum", "Arghavan Asad", "Amiya Nayak"], "title": "Blockchain Meets Adaptive Honeypots: A Trust-Aware Approach to Next-Gen IoT Security", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.LG"], "comment": "This paper has been submitted to the IEEE Transactions on Network\n  Science and Engineering (TNSE) for possible publication", "summary": "Edge computing-based Next-Generation Wireless Networks (NGWN)-IoT offer\nenhanced bandwidth capacity for large-scale service provisioning but remain\nvulnerable to evolving cyber threats. Existing intrusion detection and\nprevention methods provide limited security as adversaries continually adapt\ntheir attack strategies. We propose a dynamic attack detection and prevention\napproach to address this challenge. First, blockchain-based authentication uses\nthe Deoxys Authentication Algorithm (DAA) to verify IoT device legitimacy\nbefore data transmission. Next, a bi-stage intrusion detection system is\nintroduced: the first stage uses signature-based detection via an Improved\nRandom Forest (IRF) algorithm. In contrast, the second stage applies\nfeature-based anomaly detection using a Diffusion Convolution Recurrent Neural\nNetwork (DCRNN). To ensure Quality of Service (QoS) and maintain Service Level\nAgreements (SLA), trust-aware service migration is performed using Heap-Based\nOptimization (HBO). Additionally, on-demand virtual High-Interaction honeypots\ndeceive attackers and extract attack patterns, which are securely stored using\nthe Bimodal Lattice Signature Scheme (BLISS) to enhance signature-based\nIntrusion Detection Systems (IDS). The proposed framework is implemented in the\nNS3 simulation environment and evaluated against existing methods across\nmultiple performance metrics, including accuracy, attack detection rate, false\nnegative rate, precision, recall, ROC curve, memory usage, CPU usage, and\nexecution time. Experimental results demonstrate that the framework\nsignificantly outperforms existing approaches, reinforcing the security of\nNGWN-enabled IoT ecosystems"}
{"id": "2504.16227", "pdf": "https://arxiv.org/pdf/2504.16227", "abs": "https://arxiv.org/abs/2504.16227", "authors": ["Amir Ali-Pour", "Sadra Bekrani", "Laya Samizadeh", "Julien Gascon-Samson"], "title": "Towards a Distributed Federated Learning Aggregation Placement using Particle Swarm Intelligence", "categories": ["cs.DC", "cs.LG", "cs.NE", "cs.NI"], "comment": null, "summary": "Federated learning has become a promising distributed learning concept with\nextra insurance on data privacy. Extensive studies on various models of\nFederated learning have been done since the coinage of its term. One of the\nimportant derivatives of federated learning is hierarchical semi-decentralized\nfederated learning, which distributes the load of the aggregation task over\nmultiple nodes and parallelizes the aggregation workload at the breadth of each\nlevel of the hierarchy. Various methods have also been proposed to perform\ninter-cluster and intra-cluster aggregation optimally. Most of the solutions,\nnonetheless, require monitoring the nodes' performance and resource consumption\nat each round, which necessitates frequently exchanging systematic data. To\noptimally perform distributed aggregation in SDFL with minimal reliance on\nsystematic data, we propose Flag-Swap, a Particle Swarm Optimization (PSO)\nmethod that optimizes the aggregation placement according only to the\nprocessing delay. Our simulation results show that PSO-based placement can find\nthe optimal placement relatively fast, even in scenarios with many clients as\ncandidates for aggregation. Our real-world docker-based implementation of\nFlag-Swap over the recently emerged FL framework shows superior performance\ncompared to black-box-based deterministic placement strategies, with about 43%\nminutes faster than random placement, and 32% minutes faster than uniform\nplacement, in terms of total processing time."}
{"id": "2504.16237", "pdf": "https://arxiv.org/pdf/2504.16237", "abs": "https://arxiv.org/abs/2504.16237", "authors": ["Obed Korshie Dzikunu", "Amirhossein Toosi", "Shadab Ahamed", "Sara Harsini", "Francois Benard", "Xiaoxiao Li", "Arman Rahmim"], "title": "Comprehensive Evaluation of Quantitative Measurements from Automated Deep Segmentations of PSMA PET/CT Images", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "12 pages, 8 figures", "summary": "This study performs a comprehensive evaluation of quantitative measurements\nas extracted from automated deep-learning-based segmentation methods, beyond\ntraditional Dice Similarity Coefficient assessments, focusing on six\nquantitative metrics, namely SUVmax, SUVmean, total lesion activity (TLA),\ntumor volume (TMTV), lesion count, and lesion spread. We analyzed 380\nprostate-specific membrane antigen (PSMA) targeted [18F]DCFPyL PET/CT scans of\npatients with biochemical recurrence of prostate cancer, training deep neural\nnetworks, U-Net, Attention U-Net and SegResNet with four loss functions: Dice\nLoss, Dice Cross Entropy, Dice Focal Loss, and our proposed L1 weighted Dice\nFocal Loss (L1DFL). Evaluations indicated that Attention U-Net paired with\nL1DFL achieved the strongest correlation with the ground truth (concordance\ncorrelation = 0.90-0.99 for SUVmax and TLA), whereas models employing the Dice\nLoss and the other two compound losses, particularly with SegResNet,\nunderperformed. Equivalence testing (TOST, alpha = 0.05, Delta = 20%) confirmed\nhigh performance for SUV metrics, lesion count and TLA, with L1DFL yielding the\nbest performance. By contrast, tumor volume and lesion spread exhibited greater\nvariability. Bland-Altman, Coverage Probability, and Total Deviation Index\nanalyses further highlighted that our proposed L1DFL minimizes variability in\nquantification of the ground truth clinical measures. The code is publicly\navailable at: https://github.com/ObedDzik/pca\\_segment.git."}
{"id": "2504.16266", "pdf": "https://arxiv.org/pdf/2504.16266", "abs": "https://arxiv.org/abs/2504.16266", "authors": ["Ye Qiao", "Zhiheng Cheng", "Yifan Zhang", "Yian Wang", "Sitao Huang"], "title": "TeLLMe: An Energy-Efficient Ternary LLM Accelerator for Prefilling and Decoding on Edge FPGAs", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Deploying large language models (LLMs) on edge platforms is challenged by\ntheir high computational and memory demands. Although recent low-bit\nquantization methods (e.g., BitNet, DeepSeek) compress weights to as little as\n1.58 bits with minimal accuracy loss, edge deployment is still constrained by\nlimited on-chip resources, power budgets, and the often-neglected latency of\nthe prefill phase. We present TeLLMe, the first ternary LLM accelerator for\nlow-power FPGAs (e.g., AMD KV260) that fully supports both prefill and\nautoregressive decoding using 1.58-bit weights and 8-bit activations. Our\ncontributions include: (1) a table-lookup matrix engine for ternary matmul that\nmerges grouped activations with online precomputation to minimize resource use;\n(2) a fused, bandwidth-efficient attention module featuring a reversed\nreordering scheme to accelerate prefill; and (3) a tightly integrated\nnormalization and quantization--dequantization unit optimized for ultra-low-bit\ninference. Under a 7W power budget, TeLLMe delivers up to 9 tokens/s throughput\nover 1,024-token contexts and prefill latencies of 0.55--1.15 s for 64--128\ntoken prompts, marking a significant energy-efficiency advance and establishing\na new edge FPGA benchmark for generative AI."}
{"id": "2504.16269", "pdf": "https://arxiv.org/pdf/2504.16269", "abs": "https://arxiv.org/abs/2504.16269", "authors": ["Ye Qiao", "Zhiheng Cheng", "Yian Wang", "Yifan Zhang", "Yunzhe Deng", "Sitao Huang"], "title": "COBRA: Algorithm-Architecture Co-optimized Binary Transformer Accelerator for Edge Inference", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Transformer-based models have demonstrated superior performance in various\nfields, including natural language processing and computer vision. However,\ntheir enormous model size and high demands in computation, memory, and\ncommunication limit their deployment to edge platforms for local, secure\ninference. Binary transformers offer a compact, low-complexity solution for\nedge deployment with reduced bandwidth needs and acceptable accuracy. However,\nexisting binary transformers perform inefficiently on current hardware due to\nthe lack of binary specific optimizations. To address this, we introduce COBRA,\nan algorithm-architecture co-optimized binary Transformer accelerator for edge\ncomputing. COBRA features a real 1-bit binary multiplication unit, enabling\nmatrix operations with -1, 0, and +1 values, surpassing ternary methods. With\nfurther hardware-friendly optimizations in the attention block, COBRA achieves\nup to 3,894.7 GOPS throughput and 448.7 GOPS/Watt energy efficiency on edge\nFPGAs, delivering a 311x energy efficiency improvement over GPUs and a 3.5x\nthroughput improvement over the state-of-the-art binary accelerator, with only\nnegligible inference accuracy degradation."}
{"id": "2504.16270", "pdf": "https://arxiv.org/pdf/2504.16270", "abs": "https://arxiv.org/abs/2504.16270", "authors": ["Naren Sarayu Manoj"], "title": "A Geometric Approach to Problems in Optimization and Data Science", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": "PhD dissertation", "summary": "We give new results for problems in computational and statistical machine\nlearning using tools from high-dimensional geometry and probability.\n  We break up our treatment into two parts. In Part I, we focus on\ncomputational considerations in optimization. Specifically, we give new\nalgorithms for approximating convex polytopes in a stream, sparsification and\nrobust least squares regression, and dueling optimization.\n  In Part II, we give new statistical guarantees for data science problems. In\nparticular, we formulate a new model in which we analyze statistical properties\nof backdoor data poisoning attacks, and we study the robustness of graph\nclustering algorithms to ``helpful'' misspecification."}
{"id": "2504.16290", "pdf": "https://arxiv.org/pdf/2504.16290", "abs": "https://arxiv.org/abs/2504.16290", "authors": ["André Longon"], "title": "Naturally Computed Scale Invariance in the Residual Stream of ResNet18", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "An important capacity in visual object recognition is invariance to\nimage-altering variables which leave the identity of objects unchanged, such as\nlighting, rotation, and scale. How do neural networks achieve this? Prior\nmechanistic interpretability research has illuminated some invariance-building\ncircuitry in InceptionV1, but the results are limited and networks with\ndifferent architectures have remained largely unexplored. This work\ninvestigates ResNet18 with a particular focus on its residual stream, an\narchitectural component which InceptionV1 lacks. We observe that many\nconvolutional channels in intermediate blocks exhibit scale invariant\nproperties, computed by the element-wise residual summation of scale\nequivariant representations: the block input's smaller-scale copy with the\nblock pre-sum output's larger-scale copy. Through subsequent ablation\nexperiments, we attempt to causally link these neural properties with\nscale-robust object recognition behavior. Our tentative findings suggest how\nthe residual stream computes scale invariance and its possible role in\nbehavior. Code is available at:\nhttps://github.com/cest-andre/residual-stream-interp"}
{"id": "2504.16316", "pdf": "https://arxiv.org/pdf/2504.16316", "abs": "https://arxiv.org/abs/2504.16316", "authors": ["Hossein Shokouhinejad", "Griffin Higgins", "Roozbeh Razavi-Far", "Hesamodin Mohammadian", "Ali A. Ghorbani"], "title": "On the Consistency of GNN Explanations for Malware Detection", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Control Flow Graphs (CFGs) are critical for analyzing program execution and\ncharacterizing malware behavior. With the growing adoption of Graph Neural\nNetworks (GNNs), CFG-based representations have proven highly effective for\nmalware detection. This study proposes a novel framework that dynamically\nconstructs CFGs and embeds node features using a hybrid approach combining\nrule-based encoding and autoencoder-based embedding. A GNN-based classifier is\nthen constructed to detect malicious behavior from the resulting graph\nrepresentations. To improve model interpretability, we apply state-of-the-art\nexplainability techniques, including GNNExplainer, PGExplainer, and\nCaptumExplainer, the latter is utilized three attribution methods: Integrated\nGradients, Guided Backpropagation, and Saliency. In addition, we introduce a\nnovel aggregation method, called RankFusion, that integrates the outputs of the\ntop-performing explainers to enhance the explanation quality. We also evaluate\nexplanations using two subgraph extraction strategies, including the proposed\nGreedy Edge-wise Composition (GEC) method for improved structural coherence. A\ncomprehensive evaluation using accuracy, fidelity, and consistency metrics\ndemonstrates the effectiveness of the proposed framework in terms of accurate\nidentification of malware samples and generating reliable and interpretable\nexplanations."}
{"id": "2504.16320", "pdf": "https://arxiv.org/pdf/2504.16320", "abs": "https://arxiv.org/abs/2504.16320", "authors": ["Yaofeng Cheng", "Fusheng Zha", "Wei Guo", "Pengfei Wang", "Chao Zeng", "Lining Sun", "Chenguang Yang"], "title": "PCF-Grasp: Converting Point Completion to Geometry Feature to Enhance 6-DoF Grasp", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "The 6-Degree of Freedom (DoF) grasp method based on point clouds has shown\nsignificant potential in enabling robots to grasp target objects. However, most\nexisting methods are based on the point clouds (2.5D points) generated from\nsingle-view depth images. These point clouds only have one surface side of the\nobject providing incomplete geometry information, which mislead the grasping\nalgorithm to judge the shape of the target object, resulting in low grasping\naccuracy. Humans can accurately grasp objects from a single view by leveraging\ntheir geometry experience to estimate object shapes. Inspired by humans, we\npropose a novel 6-DoF grasping framework that converts the point completion\nresults as object shape features to train the 6-DoF grasp network. Here, point\ncompletion can generate approximate complete points from the 2.5D points\nsimilar to the human geometry experience, and converting it as shape features\nis the way to utilize it to improve grasp efficiency. Furthermore, due to the\ngap between the network generation and actual execution, we integrate a score\nfilter into our framework to select more executable grasp proposals for the\nreal robot. This enables our method to maintain a high grasp quality in any\ncamera viewpoint. Extensive experiments demonstrate that utilizing complete\npoint features enables the generation of significantly more accurate grasp\nproposals and the inclusion of a score filter greatly enhances the credibility\nof real-world robot grasping. Our method achieves a 17.8\\% success rate higher\nthan the state-of-the-art method in real-world experiments."}
{"id": "2504.16331", "pdf": "https://arxiv.org/pdf/2504.16331", "abs": "https://arxiv.org/abs/2504.16331", "authors": ["Jie JW Wu", "Manav Chaudhary", "Davit Abrahamyan", "Arhaan Khaku", "Anjiang Wei", "Fatemeh H. Fard"], "title": "ClarifyCoder: Clarification-Aware Fine-Tuning for Programmatic Problem Solving", "categories": ["cs.SE", "cs.LG"], "comment": "12 pages, 5 figures, 6 tables", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode generation tasks. However, a significant gap remains between their current\nperformance and that of expert software engineers. A key differentiator is that\nhuman engineers actively seek clarification when faced with ambiguous\nrequirements, while LLMs typically generate code regardless of uncertainties in\nthe problem description. We present ClarifyCoder, a novel framework with\nsynthetic data generation and instruction-tuning that enables LLMs to identify\nambiguities and request clarification before proceeding with code generation.\nWhile recent work has focused on LLM-based agents for iterative code\ngeneration, we argue that the fundamental ability to recognize and query\nambiguous requirements should be intrinsic to the models themselves. Our\napproach consists of two main components: (1) a data synthesis technique that\naugments existing programming datasets with scenarios requiring clarification\nto generate clarification-aware training data, and (2) a fine-tuning strategy\nthat teaches models to prioritize seeking clarification over immediate code\ngeneration when faced with incomplete or ambiguous requirements. We further\nprovide an empirical analysis of integrating ClarifyCoder with standard\nfine-tuning for a joint optimization of both clarify-awareness and coding\nability. Experimental results demonstrate that ClarifyCoder significantly\nimproves the communication capabilities of Code LLMs through meaningful\nclarification dialogues while maintaining code generation capabilities."}
{"id": "2504.16334", "pdf": "https://arxiv.org/pdf/2504.16334", "abs": "https://arxiv.org/abs/2504.16334", "authors": ["Kamran Majid"], "title": "Deep Neural Network Emulation of the Quantum-Classical Transition via Learned Wigner Function Dynamics", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "The emergence of classical behavior from quantum mechanics as Planck's\nconstant $\\hbar$ approaches zero remains a fundamental challenge in physics\n[1-3]. This paper introduces a novel approach employing deep neural networks to\ndirectly learn the dynamical mapping from initial quantum state parameters (for\nGaussian wave packets of the one-dimensional harmonic oscillator) and $\\hbar$\nto the parameters of the time-evolved Wigner function in phase space [4-6]. A\ncomprehensive dataset of analytically derived time-evolved Wigner functions was\ngenerated, and a deep feedforward neural network with an enhanced architecture\nwas successfully trained for this prediction task, achieving a final training\nloss of ~ 0.0390. The network demonstrates a significant and previously\nunrealized ability to accurately capture the underlying mapping of the Wigner\nfunction dynamics. This allows for a direct emulation of the quantum-classical\ntransition by predicting the evolution of phase-space distributions as $\\hbar$\nis systematically varied. The implications of these findings for providing a\nnew computational lens on the emergence of classicality are discussed,\nhighlighting the potential of this direct phase-space learning approach for\nstudying fundamental aspects of quantum mechanics. This work presents a\nsignificant advancement beyond previous efforts that focused on learning\nobservable mappings [7], offering a direct route via the phase-space\nrepresentation."}
{"id": "2504.16355", "pdf": "https://arxiv.org/pdf/2504.16355", "abs": "https://arxiv.org/abs/2504.16355", "authors": ["Hassan Asghar", "Chenhan Zhang", "Dali Kaafar"], "title": "Property-Preserving Hashing for $\\ell_1$-Distance Predicates: Applications to Countering Adversarial Input Attacks", "categories": ["cs.CR", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Perceptual hashing is used to detect whether an input image is similar to a\nreference image with a variety of security applications. Recently, they have\nbeen shown to succumb to adversarial input attacks which make small\nimperceptible changes to the input image yet the hashing algorithm does not\ndetect its similarity to the original image. Property-preserving hashing (PPH)\nis a recent construct in cryptography, which preserves some property\n(predicate) of its inputs in the hash domain. Researchers have so far shown\nconstructions of PPH for Hamming distance predicates, which, for instance,\noutputs 1 if two inputs are within Hamming distance $t$. A key feature of PPH\nis its strong correctness guarantee, i.e., the probability that the predicate\nwill not be correctly evaluated in the hash domain is negligible. Motivated by\nthe use case of detecting similar images under adversarial setting, we propose\nthe first PPH construction for an $\\ell_1$-distance predicate. Roughly, this\npredicate checks if the two one-sided $\\ell_1$-distances between two images are\nwithin a threshold $t$. Since many adversarial attacks use $\\ell_2$-distance\n(related to $\\ell_1$-distance) as the objective function to perturb the input\nimage, by appropriately choosing the threshold $t$, we can force the attacker\nto add considerable noise to evade detection, and hence significantly\ndeteriorate the image quality. Our proposed scheme is highly efficient, and\nruns in time $O(t^2)$. For grayscale images of size $28 \\times 28$, we can\nevaluate the predicate in $0.0784$ seconds when pixel values are perturbed by\nup to $1 \\%$. For larger RGB images of size $224 \\times 224$, by dividing the\nimage into 1,000 blocks, we achieve times of $0.0128$ seconds per block for $1\n\\%$ change, and up to $0.2641$ seconds per block for $14\\%$ change."}
{"id": "2504.16356", "pdf": "https://arxiv.org/pdf/2504.16356", "abs": "https://arxiv.org/abs/2504.16356", "authors": ["Jiahe Lin", "Yikai Zhang", "George Michailidis"], "title": "Covariate-dependent Graphical Model Estimation via Neural Networks with Statistical Guarantees", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "Accepted by Transactions on Machine Learning Research (TMLR)", "summary": "Graphical models are widely used in diverse application domains to model the\nconditional dependencies amongst a collection of random variables. In this\npaper, we consider settings where the graph structure is covariate-dependent,\nand investigate a deep neural network-based approach to estimate it. The method\nallows for flexible functional dependency on the covariate, and fits the data\nreasonably well in the absence of a Gaussianity assumption. Theoretical results\nwith PAC guarantees are established for the method, under assumptions commonly\nused in an Empirical Risk Minimization framework. The performance of the\nproposed method is evaluated on several synthetic data settings and benchmarked\nagainst existing approaches. The method is further illustrated on real datasets\ninvolving data from neuroscience and finance, respectively, and produces\ninterpretable results."}
{"id": "2504.16357", "pdf": "https://arxiv.org/pdf/2504.16357", "abs": "https://arxiv.org/abs/2504.16357", "authors": ["Ying Chang", "Xiaohu Shi", "Xiaohui Zhao", "Zhaohuang Chen", "Deyin Ma"], "title": "DP2FL: Dual Prompt Personalized Federated Learning in Foundation Models", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Personalized federated learning (PFL) has garnered significant attention for\nits ability to address heterogeneous client data distributions while preserving\ndata privacy. However, when local client data is limited, deep learning models\noften suffer from insufficient training, leading to suboptimal performance.\nFoundation models, such as CLIP (Contrastive Language-Image Pretraining),\nexhibit strong feature extraction capabilities and can alleviate this issue by\nfine-tuning on limited local data. Despite their potential, foundation models\nare rarely utilized in federated learning scenarios, and challenges related to\nintegrating new clients remain largely unresolved. To address these challenges,\nwe propose the Dual Prompt Personalized Federated Learning (DP2FL) framework,\nwhich introduces dual prompts and an adaptive aggregation strategy. DP2FL\ncombines global task awareness with local data-driven insights, enabling local\nmodels to achieve effective generalization while remaining adaptable to\nspecific data distributions. Moreover, DP2FL introduces a global model that\nenables prediction on new data sources and seamlessly integrates newly added\nclients without requiring retraining. Experimental results in highly\nheterogeneous environments validate the effectiveness of DP2FL's prompt design\nand aggregation strategy, underscoring the advantages of prediction on novel\ndata sources and demonstrating the seamless integration of new clients into the\nfederated learning framework."}
{"id": "2504.16371", "pdf": "https://arxiv.org/pdf/2504.16371", "abs": "https://arxiv.org/abs/2504.16371", "authors": ["Arghavan Zibaie", "Spencer Hutchinson", "Ramtin Pedarsani", "Mahnoosh Alizadeh"], "title": "The Safety-Privacy Tradeoff in Linear Bandits", "categories": ["math.OC", "cs.LG"], "comment": "16 pages, 3 figures, accepted to 2025 IEEE International Symposium on\n  Information Theory (ISIT)", "summary": "We consider a collection of linear stochastic bandit problems, each modeling\nthe random response of different agents to proposed interventions, coupled\ntogether by a global safety constraint. We assume a central coordinator must\nchoose actions to play on each bandit with the objective of regret\nminimization, while also ensuring that the expected response of all agents\nsatisfies the global safety constraints at each round, in spite of uncertainty\nabout the bandits' parameters. The agents consider their observed responses to\nbe private and in order to protect their sensitive information, the data\nsharing with the central coordinator is performed under local differential\nprivacy (LDP). However, providing higher level of privacy to different agents\nwould have consequences in terms of safety and regret. We formalize these\ntradeoffs by building on the notion of the sharpness of the safety set - a\nmeasure of how the geometric properties of the safe set affects the growth of\nregret - and propose a unilaterally unimprovable vector of privacy levels for\ndifferent agents given a maximum regret budget."}
{"id": "2504.16397", "pdf": "https://arxiv.org/pdf/2504.16397", "abs": "https://arxiv.org/abs/2504.16397", "authors": ["Banruo Liu", "Wei-Yu Lin", "Minghao Fang", "Yihan Jiang", "Fan Lai"], "title": "Circinus: Efficient Query Planner for Compound ML Serving", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "The rise of compound AI serving -- integrating multiple operators in a\npipeline that may span edge and cloud tiers -- enables end-user applications\nsuch as autonomous driving, generative AI-powered meeting companions, and\nimmersive gaming. Achieving high service goodput -- i.e., meeting service level\nobjectives (SLOs) for pipeline latency, accuracy, and costs -- requires\neffective planning of operator placement, configuration, and resource\nallocation across infrastructure tiers. However, the diverse SLO requirements,\nvarying edge capabilities, and high query volumes create an enormous planning\nsearch space, rendering current solutions fundamentally limited for real-time\nserving and cost-efficient deployments.\n  This paper presents Circinus, an SLO-aware query planner for large-scale\ncompound AI workloads. Circinus novelly decomposes multi-query planning and\nmulti-dimensional SLO objectives while preserving global decision quality. By\nexploiting plan similarities within and across queries, it significantly\nreduces search steps. It further improves per-step efficiency with a\nprecision-aware plan profiler that incrementally profiles and strategically\napplies early stopping based on imprecise estimates of plan performance. At\nscale, Circinus selects query-plan combinations to maximize global SLO goodput.\nEvaluations in real-world settings show that Circinus improves service goodput\nby 3.2-5.0$\\times$, accelerates query planning by 4.2-5.8$\\times$, achieving\nquery response in seconds, while reducing deployment costs by 3.2-4.0$\\times$\nover state of the arts even in their intended single-tier deployments."}
{"id": "2504.16404", "pdf": "https://arxiv.org/pdf/2504.16404", "abs": "https://arxiv.org/abs/2504.16404", "authors": ["Md Fahimuzzman Sohan"], "title": "Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle Lameness Detection", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": null, "summary": "Cattle lameness is often caused by hoof injuries or interdigital dermatitis,\nleads to pain and significantly impacts essential physiological activities such\nas walking, feeding, and drinking. This study presents a deep learning-based\nmodel for detecting cattle lameness, sickness, or gait abnormalities using\npublicly available video data. The dataset consists of 50 unique videos from 40\nindividual cattle, recorded from various angles in both indoor and outdoor\nenvironments. Half of the dataset represents naturally walking\n(normal/non-lame) cattle, while the other half consists of cattle exhibiting\ngait abnormalities (lame). To enhance model robustness and generalizability,\ndata augmentation was applied to the training data. The pre-processed videos\nwere then classified using two deep learning models: ConvLSTM2D and 3D CNN. A\ncomparative analysis of the results demonstrates strong classification\nperformance. Specifically, the 3D CNN model achieved a video-level\nclassification accuracy of 90%, with precision, recall, and f1-score of 90.9%,\n90.9%, and 90.91% respectively. The ConvLSTM2D model exhibited a slightly lower\naccuracy of 85%. This study highlights the effectiveness of directly applying\nclassification models to learn spatiotemporal features from video data,\noffering an alternative to traditional multi-stage approaches that typically\ninvolve object detection, pose estimation, and feature extraction. Besides, the\nfindings demonstrate that the proposed deep learning models, particularly the\n3D CNN, effectively classify and detect lameness in cattle while simplifying\nthe processing pipeline."}
{"id": "2504.16449", "pdf": "https://arxiv.org/pdf/2504.16449", "abs": "https://arxiv.org/abs/2504.16449", "authors": ["Ye Tian", "Yanqiu Yu", "Jianguo Sun", "Yanbin Wang"], "title": "From Past to Present: A Survey of Malicious URL Detection Techniques, Datasets and Code Repositories", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Malicious URLs persistently threaten the cybersecurity ecosystem, by either\ndeceiving users into divulging private data or distributing harmful payloads to\ninfiltrate host systems. Gaining timely insights into the current state of this\nongoing battle holds significant importance. However, existing reviews exhibit\n4 critical gaps: 1) Their reliance on algorithm-centric taxonomies obscures\nunderstanding of how detection approaches exploit specific modal information\nchannels; 2) They fail to incorporate pivotal LLM/Transformer-based defenses;\n3) No open-source implementations are collected to facilitate benchmarking; 4)\nInsufficient dataset coverage.This paper presents a comprehensive review of\nmalicious URL detection technologies, systematically analyzing methods from\ntraditional blacklisting to advanced deep learning approaches (e.g.\nTransformer, GNNs, and LLMs). Unlike prior surveys, we propose a novel\nmodality-based taxonomy that categorizes existing works according to their\nprimary data modalities (URL, HTML, Visual, etc.). This hierarchical\nclassification enables both rigorous technical analysis and clear understanding\nof multimodal information utilization. Furthermore, to establish a profile of\naccessible datasets and address the lack of standardized benchmarking (where\ncurrent studies often lack proper baseline comparisons), we curate and analyze:\n1) publicly available datasets (2016-2024), and 2) open-source implementations\nfrom published works(2013-2025). Then, we outline essential design principles\nand architectural frameworks for product-level implementations. The review\nconcludes by examining emerging challenges and proposing actionable directions\nfor future research. We maintain a GitHub repository for ongoing curating\ndatasets and open-source implementations:\nhttps://github.com/sevenolu7/Malicious-URL-Detection-Open-Source/tree/master."}
{"id": "2504.16474", "pdf": "https://arxiv.org/pdf/2504.16474", "abs": "https://arxiv.org/abs/2504.16474", "authors": ["Meixi Zheng", "Kehan Wu", "Yanbo Fan", "Rui Huang", "Baoyuan Wu"], "title": "Seeking Flat Minima over Diverse Surrogates for Improved Adversarial Transferability: A Theoretical Framework and Algorithmic Instantiation", "categories": ["cs.CR", "cs.LG"], "comment": "26 pages, 6 figures", "summary": "The transfer-based black-box adversarial attack setting poses the challenge\nof crafting an adversarial example (AE) on known surrogate models that remain\neffective against unseen target models. Due to the practical importance of this\ntask, numerous methods have been proposed to address this challenge. However,\nmost previous methods are heuristically designed and intuitively justified,\nlacking a theoretical foundation. To bridge this gap, we derive a novel\ntransferability bound that offers provable guarantees for adversarial\ntransferability. Our theoretical analysis has the advantages of \\textit{(i)}\ndeepening our understanding of previous methods by building a general attack\nframework and \\textit{(ii)} providing guidance for designing an effective\nattack algorithm. Our theoretical results demonstrate that optimizing AEs\ntoward flat minima over the surrogate model set, while controlling the\nsurrogate-target model shift measured by the adversarial model discrepancy,\nyields a comprehensive guarantee for AE transferability. The results further\nlead to a general transfer-based attack framework, within which we observe that\nprevious methods consider only partial factors contributing to the\ntransferability. Algorithmically, inspired by our theoretical results, we first\nelaborately construct the surrogate model set in which models exhibit diverse\nadversarial vulnerabilities with respect to AEs to narrow an instantiated\nadversarial model discrepancy. Then, a \\textit{model-Diversity-compatible\nReverse Adversarial Perturbation} (DRAP) is generated to effectively promote\nthe flatness of AEs over diverse surrogate models to improve transferability.\nExtensive experiments on NIPS2017 and CIFAR-10 datasets against various target\nmodels demonstrate the effectiveness of our proposed attack."}
{"id": "2504.16493", "pdf": "https://arxiv.org/pdf/2504.16493", "abs": "https://arxiv.org/abs/2504.16493", "authors": ["Luuk H. E. Kempen", "Marius Juul Nielsen", "Mie Andersen"], "title": "Breaking scaling relations with inverse catalysts: a machine learning exploration of trends in $\\mathrm{CO_2}$ hydrogenation energy barriers", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph"], "comment": "10 pages, 6 figures + supporting information (5 pages, 7 figures, 2\n  tables)", "summary": "The conversion of $\\mathrm{CO_2}$ into useful products such as methanol is a\nkey strategy for abating climate change and our dependence on fossil fuels.\nDeveloping new catalysts for this process is costly and time-consuming and can\nthus benefit from computational exploration of possible active sites. However,\nthis is complicated by the complexity of the materials and reaction networks.\nHere, we present a workflow for exploring transition states of elementary\nreaction steps at inverse catalysts, which is based on the training of a neural\nnetwork-based machine learning interatomic potential. We focus on the crucial\nformate intermediate and its formation over nanoclusters of indium oxide\nsupported on Cu(111). The speedup compared to an approach purely based on\ndensity functional theory allows us to probe a wide variety of active sites\nfound at nanoclusters of different sizes and stoichiometries. Analysis of the\nobtained set of transition state geometries reveals different\nstructure--activity trends at the edge or interior of the nanoclusters.\nFurthermore, the identified geometries allow for the breaking of linear scaling\nrelations, which could be a key underlying reason for the excellent catalytic\nperformance of inverse catalysts observed in experiments."}
{"id": "2504.16503", "pdf": "https://arxiv.org/pdf/2504.16503", "abs": "https://arxiv.org/abs/2504.16503", "authors": ["Jiří Kubalík", "Robert Babuška"], "title": "Neuro-Evolutionary Approach to Physics-Aware Symbolic Regression", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Symbolic regression is a technique that can automatically derive analytic\nmodels from data. Traditionally, symbolic regression has been implemented\nprimarily through genetic programming that evolves populations of candidate\nsolutions sampled by genetic operators, crossover and mutation. More recently,\nneural networks have been employed to learn the entire analytical model, i.e.,\nits structure and coefficients, using regularized gradient-based optimization.\nAlthough this approach tunes the model's coefficients better, it is prone to\npremature convergence to suboptimal model structures. Here, we propose a\nneuro-evolutionary symbolic regression method that combines the strengths of\nevolutionary-based search for optimal neural network (NN) topologies with\ngradient-based tuning of the network's parameters. Due to the inherent high\ncomputational demand of evolutionary algorithms, it is not feasible to learn\nthe parameters of every candidate NN topology to full convergence. Thus, our\nmethod employs a memory-based strategy and population perturbations to enhance\nexploitation and reduce the risk of being trapped in suboptimal NNs. In this\nway, each NN topology can be trained using only a short sequence of\nbackpropagation iterations. The proposed method was experimentally evaluated on\nthree real-world test problems and has been shown to outperform other NN-based\napproaches regarding the quality of the models obtained."}
{"id": "2504.16538", "pdf": "https://arxiv.org/pdf/2504.16538", "abs": "https://arxiv.org/abs/2504.16538", "authors": ["Joan Perez", "Giovanni Fusco"], "title": "Streetscape Analysis with Generative AI (SAGAI): Vision-Language Assessment and Mapping of Urban Scenes", "categories": ["cs.CV", "cs.LG", "I.2; I.4; J.4"], "comment": "25 pages, 6 figures in main paper, 6 figures in appendices", "summary": "Streetscapes are an essential component of urban space. Their assessment is\npresently either limited to morphometric properties of their mass skeleton or\nrequires labor-intensive qualitative evaluations of visually perceived\nqualities. This paper introduces SAGAI: Streetscape Analysis with Generative\nArtificial Intelligence, a modular workflow for scoring street-level urban\nscenes using open-access data and vision-language models. SAGAI integrates\nOpenStreetMap geometries, Google Street View imagery, and a lightweight version\nof the LLaVA model to generate structured spatial indicators from images via\ncustomizable natural language prompts. The pipeline includes an automated\nmapping module that aggregates visual scores at both the point and street\nlevels, enabling direct cartographic interpretation. It operates without\ntask-specific training or proprietary software dependencies, supporting\nscalable and interpretable analysis of urban environments. Two exploratory case\nstudies in Nice and Vienna illustrate SAGAI's capacity to produce geospatial\noutputs from vision-language inference. The initial results show strong\nperformance for binary urban-rural scene classification, moderate precision in\ncommercial feature detection, and lower estimates, but still informative, of\nsidewalk width. Fully deployable by any user, SAGAI can be easily adapted to a\nwide range of urban research themes, such as walkability, safety, or urban\ndesign, through prompt modification alone."}
{"id": "2504.16555", "pdf": "https://arxiv.org/pdf/2504.16555", "abs": "https://arxiv.org/abs/2504.16555", "authors": ["Eugenio Clerico", "Hamish Flynn", "Wojciech Kotłowski", "Gergely Neu"], "title": "Confidence Sequences for Generalized Linear Models via Regret Analysis", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "We develop a methodology for constructing confidence sets for parameters of\nstatistical models via a reduction to sequential prediction. Our key\nobservation is that for any generalized linear model (GLM), one can construct\nan associated game of sequential probability assignment such that achieving low\nregret in the game implies a high-probability upper bound on the excess\nlikelihood of the true parameter of the GLM. This allows us to develop a scheme\nthat we call online-to-confidence-set conversions, which effectively reduces\nthe problem of proving the desired statistical claim to an algorithmic\nquestion. We study two varieties of this conversion scheme: 1) analytical\nconversions that only require proving the existence of algorithms with low\nregret and provide confidence sets centered at the maximum-likelihood estimator\n2) algorithmic conversions that actively leverage the output of the online\nalgorithm to construct confidence sets (and may be centered at other,\nadaptively constructed point estimators). The resulting methodology recovers\nall state-of-the-art confidence set constructions within a single framework,\nand also provides several new types of confidence sets that were previously\nunknown in the literature."}
{"id": "2504.16588", "pdf": "https://arxiv.org/pdf/2504.16588", "abs": "https://arxiv.org/abs/2504.16588", "authors": ["Defne E. Ozan", "Andrea Nóvoa", "Luca Magri"], "title": "Data-Assimilated Model-Based Reinforcement Learning for Partially Observed Chaotic Flows", "categories": ["eess.SY", "cs.LG", "cs.SY", "physics.flu-dyn"], "comment": null, "summary": "The goal of many applications in energy and transport sectors is to control\nturbulent flows. However, because of chaotic dynamics and high dimensionality,\nthe control of turbulent flows is exceedingly difficult. Model-free\nreinforcement learning (RL) methods can discover optimal control policies by\ninteracting with the environment, but they require full state information,\nwhich is often unavailable in experimental settings. We propose a\ndata-assimilated model-based RL (DA-MBRL) framework for systems with partial\nobservability and noisy measurements. Our framework employs a control-aware\nEcho State Network for data-driven prediction of the dynamics, and integrates\ndata assimilation with an Ensemble Kalman Filter for real-time state\nestimation. An off-policy actor-critic algorithm is employed to learn optimal\ncontrol strategies from state estimates. The framework is tested on the\nKuramoto-Sivashinsky equation, demonstrating its effectiveness in stabilizing a\nspatiotemporally chaotic flow from noisy and partial measurements."}
{"id": "2504.16595", "pdf": "https://arxiv.org/pdf/2504.16595", "abs": "https://arxiv.org/abs/2504.16595", "authors": ["Gojko Perovic", "Nuno Ferreira Duarte", "Atabak Dehban", "Gonçalo Teixeira", "Egidio Falotico", "José Santos-Victor"], "title": "HERB: Human-augmented Efficient Reinforcement learning for Bin-packing", "categories": ["cs.RO", "cs.LG"], "comment": "7 pages, 5 Figures", "summary": "Packing objects efficiently is a fundamental problem in logistics, warehouse\nautomation, and robotics. While traditional packing solutions focus on\ngeometric optimization, packing irregular, 3D objects presents significant\nchallenges due to variations in shape and stability. Reinforcement\nLearning~(RL) has gained popularity in robotic packing tasks, but training\npurely from simulation can be inefficient and computationally expensive. In\nthis work, we propose HERB, a human-augmented RL framework for packing\nirregular objects. We first leverage human demonstrations to learn the best\nsequence of objects to pack, incorporating latent factors such as space\noptimization, stability, and object relationships that are difficult to model\nexplicitly. Next, we train a placement algorithm that uses visual information\nto determine the optimal object positioning inside a packing container. Our\napproach is validated through extensive performance evaluations, analyzing both\npacking efficiency and latency. Finally, we demonstrate the real-world\nfeasibility of our method on a robotic system. Experimental results show that\nour method outperforms geometric and purely RL-based approaches by leveraging\nhuman intuition, improving both packing robustness and adaptability. This work\nhighlights the potential of combining human expertise-driven RL to tackle\ncomplex real-world packing challenges in robotic systems."}
{"id": "2504.16612", "pdf": "https://arxiv.org/pdf/2504.16612", "abs": "https://arxiv.org/abs/2504.16612", "authors": ["Max Kirchner", "Alexander C. Jenke", "Sebastian Bodenstedt", "Fiona R. Kolbinger", "Oliver Saldanha", "Jakob N. Kather", "Martin Wagner", "Stefanie Speidel"], "title": "Federated EndoViT: Pretraining Vision Transformers via Federated Learning on Endoscopic Image Collections", "categories": ["cs.CV", "cs.LG"], "comment": "Preprint submitted to MEDIA", "summary": "Purpose: In this study, we investigate the training of foundation models\nusing federated learning to address data-sharing limitations and enable\ncollaborative model training without data transfer for minimally invasive\nsurgery. Methods: Inspired by the EndoViT study, we adapt the Masked\nAutoencoder for federated learning, enhancing it with adaptive Sharpness-Aware\nMinimization (FedSAM) and Stochastic Weight Averaging (SWA). Our model is\npretrained on the Endo700k dataset collection and later fine-tuned and\nevaluated for tasks such as Semantic Segmentation, Action Triplet Recognition,\nand Surgical Phase Recognition. Results: Our findings demonstrate that\nintegrating adaptive FedSAM into the federated MAE approach improves\npretraining, leading to a reduction in reconstruction loss per patch. The\napplication of FL-EndoViT in surgical downstream tasks results in performance\ncomparable to CEN-EndoViT. Furthermore, FL-EndoViT exhibits advantages over\nCEN-EndoViT in surgical scene segmentation when data is limited and in action\ntriplet recognition when large datasets are used. Conclusion: These findings\nhighlight the potential of federated learning for privacy-preserving training\nof surgical foundation models, offering a robust and generalizable solution for\nsurgical data science. Effective collaboration requires adapting federated\nlearning methods, such as the integration of FedSAM, which can accommodate the\ninherent data heterogeneity across institutions. In future, exploring FL in\nvideo-based models may enhance these capabilities by incorporating\nspatiotemporal dynamics crucial for real-world surgical environments."}
{"id": "2504.16651", "pdf": "https://arxiv.org/pdf/2504.16651", "abs": "https://arxiv.org/abs/2504.16651", "authors": ["William Corrias", "Fabio De Gaspari", "Dorjan Hitaj", "Luigi V. Mancini"], "title": "MAYA: Addressing Inconsistencies in Generative Password Guessing through a Unified Benchmark", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid evolution of generative models has led to their integration across\nvarious fields, including password guessing, aiming to generate passwords that\nresemble human-created ones in complexity, structure, and patterns. Despite\ngenerative model's promise, inconsistencies in prior research and a lack of\nrigorous evaluation have hindered a comprehensive understanding of their true\npotential. In this paper, we introduce MAYA, a unified, customizable,\nplug-and-play password benchmarking framework. MAYA provides a standardized\napproach for evaluating generative password-guessing models through a rigorous\nset of advanced testing scenarios and a collection of eight real-life password\ndatasets. Using MAYA, we comprehensively evaluate six state-of-the-art\napproaches, which have been re-implemented and adapted to ensure\nstandardization, for a total of over 15,000 hours of computation. Our findings\nindicate that these models effectively capture different aspects of human\npassword distribution and exhibit strong generalization capabilities. However,\ntheir effectiveness varies significantly with long and complex passwords.\nThrough our evaluation, sequential models consistently outperform other\ngenerative architectures and traditional password-guessing tools, demonstrating\nunique capabilities in generating accurate and complex guesses. Moreover,\nmodels learn and generate different password distributions, enabling a\nmulti-model attack that outperforms the best individual model. By releasing\nMAYA, we aim to foster further research, providing the community with a new\ntool to consistently and reliably benchmark password-generation techniques. Our\nframework is publicly available at\nhttps://github.com/williamcorrias/MAYA-Password-Benchmarking"}
{"id": "2504.16680", "pdf": "https://arxiv.org/pdf/2504.16680", "abs": "https://arxiv.org/abs/2504.16680", "authors": ["Chenhao Li", "Andreas Krause", "Marco Hutter"], "title": "Offline Robotic World Model: Learning Robotic Policies without a Physics Simulator", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement Learning (RL) has demonstrated impressive capabilities in\nrobotic control but remains challenging due to high sample complexity, safety\nconcerns, and the sim-to-real gap. While offline RL eliminates the need for\nrisky real-world exploration by learning from pre-collected data, it suffers\nfrom distributional shift, limiting policy generalization. Model-Based RL\n(MBRL) addresses this by leveraging predictive models for synthetic rollouts,\nyet existing approaches often lack robust uncertainty estimation, leading to\ncompounding errors in offline settings. We introduce Offline Robotic World\nModel (RWM-O), a model-based approach that explicitly estimates epistemic\nuncertainty to improve policy learning without reliance on a physics simulator.\nBy integrating these uncertainty estimates into policy optimization, our\napproach penalizes unreliable transitions, reducing overfitting to model errors\nand enhancing stability. Experimental results show that RWM-O improves\ngeneralization and safety, enabling policy learning purely from real-world data\nand advancing scalable, data-efficient RL for robotics."}
{"id": "2504.16684", "pdf": "https://arxiv.org/pdf/2504.16684", "abs": "https://arxiv.org/abs/2504.16684", "authors": ["Gerardus Croonen", "Andreas Trondl", "Julia Simon", "Daniel Steininger"], "title": "SemanticSugarBeets: A Multi-Task Framework and Dataset for Inspecting Harvest and Storage Characteristics of Sugar Beets", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at Conference on Computer Vision and Pattern Recognition\n  Workshops (CVPRW). Code and dataset available at\n  https://github.com/semanticsugarbeets/semanticsugarbeets", "summary": "While sugar beets are stored prior to processing, they lose sugar due to\nfactors such as microorganisms present in adherent soil and excess vegetation.\nTheir automated visual inspection promises to aide in quality assurance and\nthereby increase efficiency throughout the processing chain of sugar\nproduction. In this work, we present a novel high-quality annotated dataset and\ntwo-stage method for the detection, semantic segmentation and mass estimation\nof post-harvest and post-storage sugar beets in monocular RGB images. We\nconduct extensive ablation experiments for the detection of sugar beets and\ntheir fine-grained semantic segmentation regarding damages, rot, soil adhesion\nand excess vegetation. For these tasks, we evaluate multiple image sizes, model\narchitectures and encoders, as well as the influence of environmental\nconditions. Our experiments show an mAP50-95 of 98.8 for sugar-beet detection\nand an mIoU of 64.0 for the best-performing segmentation model."}
{"id": "2504.16688", "pdf": "https://arxiv.org/pdf/2504.16688", "abs": "https://arxiv.org/abs/2504.16688", "authors": ["Nahshon Mokua", "Obiri", "Kristof", "Van Laerhoven"], "title": "A Statistical Evaluation of Indoor LoRaWAN Environment-Aware Propagation for 6G: MLR, ANOVA, and Residual Distribution Analysis", "categories": ["cs.NI", "cs.LG", "eess.SP"], "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  This is the accepted version of the article: To appear in the 2025 Joint\n  European Conference on Networks and Communications & 6G Summit (EuCNC/6G\n  Summit)", "summary": "Modeling path loss in indoor LoRaWAN technology deployments is inherently\nchallenging due to structural obstructions, occupant density and activities,\nand fluctuating environmental conditions. This study proposes a two-stage\napproach to capture and analyze these complexities using an extensive dataset\nof 1,328,334 field measurements collected over six months in a single-floor\noffice at the University of Siegen's Hoelderlinstrasse Campus, Germany. First,\nwe implement a multiple linear regression model that includes traditional\npropagation metrics (distance, structural walls) and an extension with proposed\nenvironmental variables (relative humidity, temperature, carbon dioxide,\nparticulate matter, and barometric pressure). Using analysis of variance, we\ndemonstrate that adding these environmental factors can reduce unexplained\nvariance by 42.32 percent. Secondly, we examine residual distributions by\nfitting five candidate probability distributions: Normal, Skew-Normal, Cauchy,\nStudent's t, and Gaussian Mixture Models with one to five components. Our\nresults show that a four-component Gaussian Mixture Model captures the residual\nheterogeneity of indoor signal propagation most accurately, significantly\noutperforming single-distribution approaches. Given the push toward\nultra-reliable, context-aware communications in 6G networks, our analysis shows\nthat environment-aware modeling can substantially improve LoRaWAN network\ndesign in dynamic indoor IoT deployments."}
{"id": "2504.16732", "pdf": "https://arxiv.org/pdf/2504.16732", "abs": "https://arxiv.org/abs/2504.16732", "authors": ["Yanjie Wu", "Yuhao Ji", "Saiho Lee", "Juniad Akram", "Ali Braytee", "Ali Anaissi"], "title": "Simplified Swarm Learning Framework for Robust and Scalable Diagnostic Services in Cancer Histopathology", "categories": ["cs.DC", "cs.LG"], "comment": "8 pages, 4 figures, 2025 International Conference on Computational\n  Science", "summary": "The complexities of healthcare data, including privacy concerns, imbalanced\ndatasets, and interoperability issues, necessitate innovative machine learning\nsolutions. Swarm Learning (SL), a decentralized alternative to Federated\nLearning, offers privacy-preserving distributed training, but its reliance on\nblockchain technology hinders accessibility and scalability. This paper\nintroduces a \\textit{Simplified Peer-to-Peer Swarm Learning (P2P-SL) Framework}\ntailored for resource-constrained environments. By eliminating blockchain\ndependencies and adopting lightweight peer-to-peer communication, the proposed\nframework ensures robust model synchronization while maintaining data privacy.\nApplied to cancer histopathology, the framework integrates optimized\npre-trained models, such as TorchXRayVision, enhanced with DenseNet decoders,\nto improve diagnostic accuracy. Extensive experiments demonstrate the\nframework's efficacy in handling imbalanced and biased datasets, achieving\ncomparable performance to centralized models while preserving privacy. This\nstudy paves the way for democratizing advanced machine learning in healthcare,\noffering a scalable, accessible, and efficient solution for privacy-sensitive\ndiagnostic applications."}
{"id": "2504.16786", "pdf": "https://arxiv.org/pdf/2504.16786", "abs": "https://arxiv.org/abs/2504.16786", "authors": ["Fengwei Zhou", "Jiafei Song", "Wenjin Jason Li", "Gengjian Xue", "Zhikang Zhao", "Yichao Lu", "Bailin Na"], "title": "MOOSComp: Improving Lightweight Long-Context Compressor via Mitigating Over-Smoothing and Incorporating Outlier Scores", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in large language models have significantly improved their\nability to process long-context input, but practical applications are\nchallenged by increased inference time and resource consumption, particularly\nin resource-constrained environments. To address these challenges, we propose\nMOOSComp, a token-classification-based long-context compression method that\nenhances the performance of a BERT-based compressor by mitigating the\nover-smoothing problem and incorporating outlier scores. In the training phase,\nwe add an inter-class cosine similarity loss term to penalize excessively\nsimilar token representations, thereby improving the token classification\naccuracy. During the compression phase, we introduce outlier scores to preserve\nrare but critical tokens that are prone to be discarded in task-agnostic\ncompression. These scores are integrated with the classifier's output, making\nthe compressor more generalizable to various tasks. Superior performance is\nachieved at various compression ratios on long-context understanding and\nreasoning benchmarks. Moreover, our method obtains a speedup of 3.3x at a 4x\ncompression ratio on a resource-constrained mobile device."}
{"id": "2504.16798", "pdf": "https://arxiv.org/pdf/2504.16798", "abs": "https://arxiv.org/abs/2504.16798", "authors": ["Yuxiang Wei", "Yanteng Zhang", "Xi Xiao", "Tianyang Wang", "Xiao Wang", "Vince D. Calhoun"], "title": "4D Multimodal Co-attention Fusion Network with Latent Contrastive Alignment for Alzheimer's Diagnosis", "categories": ["cs.MM", "cs.CV", "cs.LG"], "comment": null, "summary": "Multimodal neuroimaging provides complementary structural and functional\ninsights into both human brain organization and disease-related dynamics.\nRecent studies demonstrate enhanced diagnostic sensitivity for Alzheimer's\ndisease (AD) through synergistic integration of neuroimaging data (e.g., sMRI,\nfMRI) with behavioral cognitive scores tabular data biomarkers. However, the\nintrinsic heterogeneity across modalities (e.g., 4D spatiotemporal fMRI\ndynamics vs. 3D anatomical sMRI structure) presents critical challenges for\ndiscriminative feature fusion. To bridge this gap, we propose M2M-AlignNet: a\ngeometry-aware multimodal co-attention network with latent alignment for early\nAD diagnosis using sMRI and fMRI. At the core of our approach is a\nmulti-patch-to-multi-patch (M2M) contrastive loss function that quantifies and\nreduces representational discrepancies via geometry-weighted patch\ncorrespondence, explicitly aligning fMRI components across brain regions with\ntheir sMRI structural substrates without one-to-one constraints. Additionally,\nwe propose a latent-as-query co-attention module to autonomously discover\nfusion patterns, circumventing modality prioritization biases while minimizing\nfeature redundancy. We conduct extensive experiments to confirm the\neffectiveness of our method and highlight the correspondance between fMRI and\nsMRI as AD biomarkers."}
{"id": "2504.16864", "pdf": "https://arxiv.org/pdf/2504.16864", "abs": "https://arxiv.org/abs/2504.16864", "authors": ["Manuel Quintero", "William T. Stephenson", "Advik Shreekumar", "Tamara Broderick"], "title": "Common Functional Decompositions Can Mis-attribute Differences in Outcomes Between Populations", "categories": ["stat.ME", "cs.LG", "econ.EM", "stat.ML"], "comment": "30 pages, appearing in 2nd Workshop on Navigating and Addressing Data\n  Problems for Foundation Models (DATA-FM @ ICLR 2025)", "summary": "In science and social science, we often wish to explain why an outcome is\ndifferent in two populations. For instance, if a jobs program benefits members\nof one city more than another, is that due to differences in program\nparticipants (particular covariates) or the local labor markets (outcomes given\ncovariates)? The Kitagawa-Oaxaca-Blinder (KOB) decomposition is a standard tool\nin econometrics that explains the difference in the mean outcome across two\npopulations. However, the KOB decomposition assumes a linear relationship\nbetween covariates and outcomes, while the true relationship may be\nmeaningfully nonlinear. Modern machine learning boasts a variety of nonlinear\nfunctional decompositions for the relationship between outcomes and covariates\nin one population. It seems natural to extend the KOB decomposition using these\nfunctional decompositions. We observe that a successful extension should not\nattribute the differences to covariates -- or, respectively, to outcomes given\ncovariates -- if those are the same in the two populations. Unfortunately, we\ndemonstrate that, even in simple examples, two common decompositions --\nfunctional ANOVA and Accumulated Local Effects -- can attribute differences to\noutcomes given covariates, even when they are identical in two populations. We\nprovide a characterization of when functional ANOVA misattributes, as well as a\ngeneral property that any discrete decomposition must satisfy to avoid\nmisattribution. We show that if the decomposition is independent of its input\ndistribution, it does not misattribute. We further conjecture that\nmisattribution arises in any reasonable additive decomposition that depends on\nthe distribution of the covariates."}
{"id": "2504.16879", "pdf": "https://arxiv.org/pdf/2504.16879", "abs": "https://arxiv.org/abs/2504.16879", "authors": ["Puja Chaudhury", "Alexander Estornell", "Michael Everett"], "title": "Learning Verifiable Control Policies Using Relaxed Verification", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "To provide safety guarantees for learning-based control systems, recent work\nhas developed formal verification methods to apply after training ends.\nHowever, if the trained policy does not meet the specifications, or there is\nconservatism in the verification algorithm, establishing these guarantees may\nnot be possible. Instead, this work proposes to perform verification throughout\ntraining to ultimately aim for policies whose properties can be evaluated\nthroughout runtime with lightweight, relaxed verification algorithms. The\napproach is to use differentiable reachability analysis and incorporate new\ncomponents into the loss function. Numerical experiments on a quadrotor model\nand unicycle model highlight the ability of this approach to lead to learned\ncontrol policies that satisfy desired reach-avoid and invariance\nspecifications."}
{"id": "2504.16886", "pdf": "https://arxiv.org/pdf/2504.16886", "abs": "https://arxiv.org/abs/2504.16886", "authors": ["Arnav Sharma", "Anthony Gitter"], "title": "Exploring zero-shot structure-based protein fitness prediction", "categories": ["q-bio.QM", "cs.LG", "q-bio.BM"], "comment": "26 pages, 7 figures", "summary": "The ability to make zero-shot predictions about the fitness consequences of\nprotein sequence changes with pre-trained machine learning models enables many\npractical applications. Such models can be applied for downstream tasks like\ngenetic variant interpretation and protein engineering without additional\nlabeled data. The advent of capable protein structure prediction tools has led\nto the availability of orders of magnitude more precomputed predicted\nstructures, giving rise to powerful structure-based fitness prediction models.\nThrough our experiments, we assess several modeling choices for structure-based\nmodels and their effects on downstream fitness prediction. Zero-shot fitness\nprediction models can struggle to assess the fitness landscape within\ndisordered regions of proteins, those that lack a fixed 3D structure. We\nconfirm the importance of matching protein structures to fitness assays and\nfind that predicted structures for disordered regions can be misleading and\naffect predictive performance. Lastly, we evaluate an additional\nstructure-based model on the ProteinGym substitution benchmark and show that\nsimple multi-modal ensembles are strong baselines."}
{"id": "2504.16891", "pdf": "https://arxiv.org/pdf/2504.16891", "abs": "https://arxiv.org/abs/2504.16891", "authors": ["Ivan Moshkov", "Darragh Hanley", "Ivan Sorokin", "Shubham Toshniwal", "Christof Henkel", "Benedikt Schifferer", "Wei Du", "Igor Gitman"], "title": "AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Report of AIMO-2 winning submission", "summary": "This paper presents our winning submission to the AI Mathematical Olympiad -\nProgress Prize 2 (AIMO-2) competition. Our recipe for building state-of-the-art\nmathematical reasoning models relies on three key pillars. First, we create a\nlarge-scale dataset comprising 540K unique high-quality math problems,\nincluding olympiad-level problems, and their 3.2M long-reasoning solutions.\nSecond, we develop a novel method to integrate code execution with long\nreasoning models through iterative training, generation, and quality filtering,\nresulting in 1.7M high-quality Tool-Integrated Reasoning solutions. Third, we\ncreate a pipeline to train models to select the most promising solution from\nmany candidates. We show that such generative solution selection (GenSelect)\ncan significantly improve upon majority voting baseline. Combining these ideas,\nwe train a series of models that achieve state-of-the-art results on\nmathematical reasoning benchmarks. To facilitate further research, we release\nour code, models, and the complete OpenMathReasoning dataset under a\ncommercially permissive license."}
{"id": "2504.16917", "pdf": "https://arxiv.org/pdf/2504.16917", "abs": "https://arxiv.org/abs/2504.16917", "authors": ["Ghazal Mirzaee", "Jonathan Chang", "Shahrzad Latifi"], "title": "Application of an attention-based CNN-BiLSTM framework for in vivo two-photon calcium imaging of neuronal ensembles: decoding complex bilateral forelimb movements from unilateral M1", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Decoding behavior, such as movement, from multiscale brain networks remains a\ncentral objective in neuroscience. Over the past decades, artificial\nintelligence and machine learning have played an increasingly significant role\nin elucidating the neural mechanisms underlying motor function. The advancement\nof brain-monitoring technologies, capable of capturing complex neuronal signals\nwith high spatial and temporal resolution, necessitates the development and\napplication of more sophisticated machine learning models for behavioral\ndecoding. In this study, we employ a hybrid deep learning framework, an\nattention-based CNN-BiLSTM model, to decode skilled and complex forelimb\nmovements using signals obtained from in vivo two-photon calcium imaging. Our\nfindings demonstrate that the intricate movements of both ipsilateral and\ncontralateral forelimbs can be accurately decoded from unilateral M1 neuronal\nensembles. These results highlight the efficacy of advanced hybrid deep\nlearning models in capturing the spatiotemporal dependencies of neuronal\nnetworks activity linked to complex movement execution."}
{"id": "2504.16922", "pdf": "https://arxiv.org/pdf/2504.16922", "abs": "https://arxiv.org/abs/2504.16922", "authors": ["Ali Hassani", "Fengzhe Zhou", "Aditya Kane", "Jiannan Huang", "Chieh-Yun Chen", "Min Shi", "Steven Walton", "Markus Hoehnerbach", "Vijay Thakkar", "Michael Isaev", "Qinsheng Zhang", "Bing Xu", "Haicheng Wu", "Wen-mei Hwu", "Ming-Yu Liu", "Humphrey Shi"], "title": "Generalized Neighborhood Attention: Multi-dimensional Sparse Attention at the Speed of Light", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "https://github.com/SHI-Labs/NATTEN/", "summary": "Many sparse attention mechanisms such as Neighborhood Attention have\ntypically failed to consistently deliver speedup over the self attention\nbaseline. This is largely due to the level of complexity in attention\ninfrastructure, and the rapid evolution of AI hardware architecture. At the\nsame time, many state-of-the-art foundational models, particularly in computer\nvision, are heavily bound by attention, and need reliable sparsity to escape\nthe O(n^2) complexity. In this paper, we study a class of promising sparse\nattention mechanisms that focus on locality, and aim to develop a better\nanalytical model of their performance improvements. We first introduce\nGeneralized Neighborhood Attention (GNA), which can describe sliding window,\nstrided sliding window, and blocked attention. We then consider possible design\nchoices in implementing these approaches, and create a simulator that can\nprovide much more realistic speedup upper bounds for any given setting.\nFinally, we implement GNA on top of a state-of-the-art fused multi-headed\nattention (FMHA) kernel designed for the NVIDIA Blackwell architecture in\nCUTLASS. Our implementation can fully realize the maximum speedup theoretically\npossible in many perfectly block-sparse cases, and achieves an effective\nutilization of 1.3 petaFLOPs/second in FP16. In addition, we plug various GNA\nconfigurations into off-the-shelf generative models, such as Cosmos-7B,\nHunyuanVideo, and FLUX, and show that it can deliver 28% to 46% end-to-end\nspeedup on B200 without any fine-tuning. We will open source our simulator and\nBlackwell kernels directly through the NATTEN project."}
{"id": "2504.16923", "pdf": "https://arxiv.org/pdf/2504.16923", "abs": "https://arxiv.org/abs/2504.16923", "authors": ["Jacob Levy", "Jason Gibson", "Bogdan Vlahov", "Erica Tevere", "Evangelos Theodorou", "David Fridovich-Keil", "Patrick Spieler"], "title": "Meta-Learning Online Dynamics Model Adaptation in Off-Road Autonomous Driving", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "High-speed off-road autonomous driving presents unique challenges due to\ncomplex, evolving terrain characteristics and the difficulty of accurately\nmodeling terrain-vehicle interactions. While dynamics models used in\nmodel-based control can be learned from real-world data, they often struggle to\ngeneralize to unseen terrain, making real-time adaptation essential. We propose\na novel framework that combines a Kalman filter-based online adaptation scheme\nwith meta-learned parameters to address these challenges. Offline meta-learning\noptimizes the basis functions along which adaptation occurs, as well as the\nadaptation parameters, while online adaptation dynamically adjusts the onboard\ndynamics model in real time for model-based control. We validate our approach\nthrough extensive experiments, including real-world testing on a full-scale\nautonomous off-road vehicle, demonstrating that our method outperforms baseline\napproaches in prediction accuracy, performance, and safety metrics,\nparticularly in safety-critical scenarios. Our results underscore the\neffectiveness of meta-learned dynamics model adaptation, advancing the\ndevelopment of reliable autonomous systems capable of navigating diverse and\nunseen environments. Video is available at: https://youtu.be/cCKHHrDRQEA"}
